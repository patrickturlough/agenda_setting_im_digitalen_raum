{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorgehen gem√§√ü Paper\n",
    "Poljak, ≈Ωeljko. 2024. ‚ÄûFrom Speech to Feed: How Parliamentary Debates Shape Party Agendas on Social Media‚Äå‚Äú. Swiss Political Science Review: spsr.12634. doi:10.1111/spsr.12634.\n",
    "\n",
    "Ziel ist es eine logistische Regression mit den vorhandenen Daten unter Ber√ºcksichtigung der relativen Aufmerksamkeit eines Themas durchzuf√ºhren. Vllt nochmal mit mehr Lags untersuchen, als nur einem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Daten Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "subset_reden = pd.read_csv(\"subset_reden.csv\")\n",
    "subset_posts = pd.read_csv(\"subset_posts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fehlerhafte Topics\n",
    "Ermitteln der fehlerhaft deklarierten Themen und Umbennenung dieser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zielvariable\n",
    "In der bisherigen Analyse hatte ich einen zentralen Denkfehler: Da die Werte in der Zeitreihe nicht konstant sind, muss ich als Zielvariable die Facebookposts am Tag *nach* einer Bundestagswahl analysieren. Bisher hatte ich posts_common, also die Facebookposts an Tag y als Zielvariable und √ºber shift(-1) die Redebeitr√§ge -1 gelaggt. Dieses Vorgehen geht, wie bei der Zeitreihenanalyse, *nicht*, da die Abst√§nde zwischen den einzelnen Punkten in den Daten nicht gleich verteilt sind, da nicht an jedem Tag Sitzungen sind. Stattdessen w√§hle ich jetzt einen Tag in die Zukunft gelaggte Facebookposts als Zielvariable. Somit kann ich die Sitzungsdaten so belassen wie sie sind und einfach t+1 gelaggte Werte der Facebookdaten als Zielvariable nutzen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_reden[\"date\"] = pd.to_datetime(subset_reden[\"date\"])\n",
    "subset_posts[\"date\"] = pd.to_datetime(subset_posts[\"date\"])\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich = subset_reden.groupby(['date','Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich = subset_posts.groupby(['date', 'Topic' ]).size().unstack(fill_value=0)\n",
    "# Berechnung der t√§glichen Summen der Wortanzahlen\n",
    "reden_komplexit√§t_t√§glich = subset_reden.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich = subset_posts.groupby('date')['komplexit√§t'].sum()\n",
    "\n",
    "\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates = redethemen_t√§glich.index.intersection(postthemen_t√§glich.index)\n",
    "redethemen_t√§glich_aligned = redethemen_t√§glich.loc[common_dates]\n",
    "postthemen_t√§glich_aligned = postthemen_t√§glich.loc[common_dates]\n",
    "rede_komplex = reden_komplexit√§t_t√§glich.loc[common_dates]\n",
    "posts_komplex = posts_komplexit√§t_t√§glich.loc[common_dates]\n",
    "# Zielvariable: Facebookposts um einen Tag in die Zukunft gelaggt\n",
    "# posts_shifted enth√§lt die Facebookposts mit lag t+1, Die Daten hier sind zwar die gleichen wie in den anderen Dataframes,\n",
    "# # die Werte jedoch die vom Vortag, weshalb die Analyse zul√§ssig ist\n",
    "# posts_shifted=postthemen_t√§glich_aligned.shift().dropna()\n",
    "# # # Erneute Anpassung des Datums\n",
    "# common_dates2 = redethemen_t√§glich.index.intersection(posts_shifted.index)\n",
    "# redethemen_t√§glich_aligned = redethemen_t√§glich.loc[common_dates2]\n",
    "# postthemen_t√§glich_aligned = postthemen_t√§glich.loc[common_dates2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2022-05-31    2712\n",
       "2022-06-01    4939\n",
       "2022-06-02    2277\n",
       "2022-06-03    4780\n",
       "2022-06-22    3475\n",
       "              ... \n",
       "2023-04-27    2553\n",
       "2023-04-28    2364\n",
       "2023-05-10    2350\n",
       "2023-05-11    3783\n",
       "2023-05-12    4190\n",
       "Name: komplexit√§t, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_komplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nur Topics ber√ºcksichtigen, die in beiden Datens√§tzen vorkommen\n",
    "# Filterfunktion\n",
    "def filter_common_topics(df1, df2):\n",
    "    \"\"\"\n",
    "    Filtert gemeinsame Topics aus zwei DataFrames und gibt neue DataFrames zur√ºck,\n",
    "    die nur die gemeinsamen Topics enthalten.\n",
    "    \n",
    "    Args:\n",
    "    - df1: Erster DataFrame\n",
    "    - df2: Zweiter DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_df1: DataFrame mit den gemeinsamen Topics aus df1\n",
    "    - filtered_df2: DataFrame mit den gemeinsamen Topics aus df2\n",
    "    \"\"\"\n",
    "    # Extrahiere die Spaltennamen, die Topics darstellen\n",
    "    topics_df1 = set(df1.columns)\n",
    "    topics_df2 = set(df2.columns)\n",
    "    \n",
    "    # Finde gemeinsame Topics\n",
    "    common_topics = topics_df1.intersection(topics_df2)\n",
    "    \n",
    "    print(f\"Gemeinsame Topics: {common_topics}\")\n",
    "    \n",
    "    # Filtere DataFrames auf die gemeinsamen Topics\n",
    "    filtered_df1 = df1[list(common_topics)]\n",
    "    filtered_df2 = df2[list(common_topics)]\n",
    "    \n",
    "    return filtered_df1, filtered_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 88, 90, 91, 92, 93}\n"
     ]
    }
   ],
   "source": [
    "rede_common, post_common = filter_common_topics(redethemen_t√§glich_aligned, postthemen_t√§glich_aligned)\n",
    "#posts_shifted_common, post_common = filter_common_topics(post_common, posts_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Topic</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>88</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-03</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-22</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-10</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows √ó 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Topic       0   1   2   3   4   5   6   7   8   9   ...  80  81  83  84  85  \\\n",
       "date                                                ...                       \n",
       "2022-05-31   0   3   3   3   4   0   3   2   0   2  ...   0   0   0   0   0   \n",
       "2022-06-01   1  10   6   0   7   0  18   0   5   0  ...   0   0   0   0   0   \n",
       "2022-06-02   3   6   4   3   1   0   0   0   3   2  ...   0   1   0   0   0   \n",
       "2022-06-03   7   4   8   2   4   0   2   0   1   1  ...   0   0   0   0   0   \n",
       "2022-06-22   7   2   5   2   1   0   2   3   0   3  ...   0   0   1   0   0   \n",
       "...         ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..   \n",
       "2023-04-27   6   2   1   3   4   0   1   0   0   7  ...   0   1   0   0   0   \n",
       "2023-04-28   1   8   1   8   2   0   0   0   1   3  ...   0   0   0   0   0   \n",
       "2023-05-10   2   5   2   8   1   0   2   0   1   1  ...   0   0   0   0   0   \n",
       "2023-05-11   2   7   1  16   5   0   0   0   1   0  ...   0   1   0   0   0   \n",
       "2023-05-12  21   6   2   8   5   0   0   0   2   2  ...   0   0   0   0   0   \n",
       "\n",
       "Topic       88  90  91  92  93  \n",
       "date                            \n",
       "2022-05-31   0   0   0   0   0  \n",
       "2022-06-01   0   0   0   0   0  \n",
       "2022-06-02   0   0   0   0   0  \n",
       "2022-06-03   0   0   0   0   0  \n",
       "2022-06-22   1   0   0   0   0  \n",
       "...         ..  ..  ..  ..  ..  \n",
       "2023-04-27   0   0   0   0   0  \n",
       "2023-04-28   0   0   0   0   0  \n",
       "2023-05-10   0   0   0   0   0  \n",
       "2023-05-11   0   1   0   0   0  \n",
       "2023-05-12   0   0   0   0   0  \n",
       "\n",
       "[66 rows x 80 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ =  rede_common.div(rede_common.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ = post_common.div(post_common.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalten mit 100% Nullwerten: [5, 31, 44, 52, 55, 59, 60, 61, 63, 64, 69, 72, 74, 77, 78, 80, 83, 85, 90, 91, 92, 93]\n"
     ]
    }
   ],
   "source": [
    "# √úberpr√ºfen, ob es gemeinsame Spalten mit nur 0-Werten gibt.\n",
    "# Prozentsatz der Nullwerte je Spalte berechnen\n",
    "percent_zeros_reden = (post_relativ == 0).mean() * 100\n",
    "\n",
    "\n",
    "# Spalten ausgeben, die 100 % Nullwerte haben\n",
    "print(\"Spalten mit 100% Nullwerten:\", percent_zeros_reden[percent_zeros_reden > 90].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Themen mit mehr als 90% Nullwerten; Reden: [9, 26, 27, 28, 32, 33, 35, 38, 39, 44, 45, 46, 47, 51, 53, 55, 56, 58, 59, 60, 63, 65, 67, 70, 79, 81, 83, 84, 88, 91, 93]\n",
      "Themen mit mehr als 90% Nullwerten; Posts: [5, 31, 44, 52, 55, 59, 60, 61, 63, 64, 69, 72, 74, 77, 78, 80, 83, 85, 90, 91, 92, 93]\n",
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 30, 34, 36, 37, 40, 41, 43, 54, 68, 75}\n"
     ]
    }
   ],
   "source": [
    "# √úberpr√ºfen, wie viele Themen es gibt, die zu mehr als 90% aus 0-Werten bestehen\n",
    "# √úberpr√ºfen, ob es gemeinsame Spalten mit nur 0-Werten gibt.\n",
    "# Prozentsatz der Nullwerte je Spalte berechnen\n",
    "percent_zeros_reden = (reden_relativ == 0).mean() * 100\n",
    "percent_zeros_posts = (post_relativ == 0).mean() * 100\n",
    "\n",
    "# Spalten ausgeben, die 100 % Nullwerte haben\n",
    "print(\"Themen mit mehr als 90% Nullwerten; Reden:\", percent_zeros_reden[percent_zeros_reden > 90].index.tolist())\n",
    "print(\"Themen mit mehr als 90% Nullwerten; Posts:\", percent_zeros_posts[percent_zeros_posts > 90].index.tolist())\n",
    "def remove_near_constant(df):\n",
    "    \"\"\"\n",
    "    Entfernt Topics, wo mehr als 90% der Werte 0 sind, da diese als Konstant interpretiert werden\n",
    "    \"\"\"\n",
    "    percent_zeros_reden = (df == 0).mean() * 100\n",
    "    df = df.loc[:, percent_zeros_reden <= 90]\n",
    "    return df\n",
    "reden_relativ = remove_near_constant(reden_relativ)\n",
    "post_relativ = remove_near_constant(post_relativ)\n",
    "rede_relativ_reduced, post_relativ_reduced = filter_common_topics(reden_relativ, post_relativ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logisitsche Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_with_lags_SM(relativ_rede, relativ_posts, post_to_shift):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit zeitversetzten unabh√§ngigen Variablen durch.\n",
    "    \n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit Erw√§hnungen im Parlament; relative Anteile.\n",
    "    - relativ_posts: DataFrame mit Erw√§hnungen auf Social Media; relative Anteile.\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    # # Erneute Anpassung des Datums\n",
    "    # common_dates2 = redethemen_t√§glich.index.intersection(posts_shifted.index)\n",
    "    # redethemen_t√§glich_aligned = redethemen_t√§glich.loc[common_dates2]\n",
    "    # postthemen_t√§glich_aligned = postthemen_t√§glich.loc[common_dates2]\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    posts_shifted_common = post_to_shift.shift().dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(posts_shifted_common.index)\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts=relativ_posts.loc[common_dates2]\n",
    "    y = (posts_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen (t-1): Erw√§hnungen im Parlament mit Zeitversatz\n",
    "    #absolute = rede_common.shift(lag_days).stack()\n",
    "    \n",
    "    relative_reden = relativ_rede.stack()\n",
    "\n",
    "    relative_posts = relativ_posts.stack()\n",
    "\n",
    "    # DataFrame f√ºr die logistische Regression\n",
    "    X = pd.DataFrame({ 'posts_relative': relative_posts, 'reden_relativ': relative_reden}).dropna()\n",
    "\n",
    "    # Zielvariable und unabh√§ngige Variablen ausrichten\n",
    "    y = y[X.index]\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y, X).fit()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.598824\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2272\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1356\n",
      "Time:                        11:03:14   Log-Likelihood:                -1362.3\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.452e-93\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -0.7187      0.057    -12.669      0.000      -0.830      -0.608\n",
      "posts_relative    35.6840      2.398     14.882      0.000      30.984      40.384\n",
      "reden_relativ      2.2260      1.029      2.164      0.030       0.210       4.242\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Zielvariable: Thema auf Social Media erw√§hnt (t+1) in Abh√§ngigkeit von relativem Anteil an Erw√§hnungen am Vortag im Bundestag und auf Social Media\n",
    "logistic_regression_with_lags_SM(reden_relativ, post_relativ, post_common)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistische Regression mit Fixed Effects\n",
    "Folgendes Vorgehen scheint nun zu funktionieren! Topic 0 bei den Fixed Effects zur Referenzkategorie zu machen, war hier der Knackpunkt, was wahrscheinlich daran liegt, dass dieses Topic am meisten erw√§hnt wird. Auch das rausl√∂schen der quasi \"leeren\" Topic mit mehr als 90% 0-Werten scheint dem Modell sehr gut getan zu haben. In dem vorhandenen Code wird Thema 0 gel√∂scht, um perfekte Multikolinearit√§t zu vermeiden. Die Konstante entspricht dann in diesem Modell Topic 0 und alle anderen Topics sind im Verh√§ltnis zu Topic 0 zu interpretieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit fixed_effects\n",
    "def logistic_regression_with_lags_SM_fixed_effects(relativ_rede, relativ_posts, post_to_shift):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit Fixed Effects f√ºr Themen durch.\n",
    "    \n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit Erw√§hnungen im Parlament; relative Anteile.\n",
    "    - relativ_posts: DataFrame mit Erw√§hnungen auf Social Media; relative Anteile.\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    posts_shifted_common = post_to_shift.shift().dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(posts_shifted_common.index)\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts=relativ_posts.loc[common_dates2]\n",
    "    y = (posts_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen: relative Anteile im Parlament und auf Social Media\n",
    "    relative_reden = relativ_rede.stack()\n",
    "    relative_posts = relativ_posts.stack()\n",
    "\n",
    "    # Zielvariable und unabh√§ngige Variablen als DataFrame zusammenf√ºhren\n",
    "    X = pd.DataFrame({'posts_relative': relative_posts, 'reden_relativ': relative_reden}).dropna()\n",
    "    y = y.reindex(X.index).dropna()\n",
    "\n",
    "    # Konvertiere MultiIndex zu flachem Index, um die Kompatibilit√§t sicherzustellen\n",
    "    X.index = X.index.to_flat_index()\n",
    "    y.index = y.index.to_flat_index()\n",
    "\n",
    "    # Dummy-Variablen f√ºr Themen (Fixed Effects)\n",
    "    topics = [idx[1] for idx in X.index]  # Der zweite Wert im Tupel repr√§sentiert das Topic\n",
    "    topic_dummies = pd.get_dummies(topics, prefix='topic',drop_first=True).astype(int) # ohne.astype(int) kommen hier Fehlermeldungen\n",
    "    # Versuch aus den Topics Topic 0 zu l√∂schen und somit bessere Daten zu erlangen\n",
    "\n",
    "    # F√ºge Dummy-Variablen hinzu\n",
    "    X = pd.concat([X.reset_index(drop=True), topic_dummies.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y.values, X).fit(maxiter=100)\n",
    "    print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistische Regression mit Social Media Nutzung als Kontrollvariable\n",
    "Zus√§tzlich noch die Aufnahme der Landtagswahlen in Schleswig-Holstein (08-05-2022), Nordrhein-Westfalen (15-05-2022) und Niedersachsen (09-10-2022). Angenommen wird, dass diese die Aktivit√§t auf Facebook bis zu 30 Tage nach der Wahl besch√§ftigen k√∂nnen *(--> pr√ºfen, ob es hier Quellen f√ºr gibt!)*. Die Dummy-Variablen sind dementsprechend 0/1 codiert; 1 f√ºr den Zeitraum Wahl+30 Tage und 0 f√ºr die restliche Zeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-05-01    2\n",
       "2022-05-02    2\n",
       "2022-05-03    2\n",
       "2022-05-04    2\n",
       "2022-05-05    2\n",
       "             ..\n",
       "2023-05-27    0\n",
       "2023-05-28    0\n",
       "2023-05-29    0\n",
       "2023-05-30    0\n",
       "2023-05-31    0\n",
       "Freq: D, Length: 396, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Liste der Landtagswahltermine\n",
    "landtagswahltermine = [\n",
    "    \"2022-05-08\",  # Schleswig-Holstein\n",
    "    \"2022-05-15\",  # Nordrhein-Westfalen\n",
    "    \"2022-10-09\"   # Niedersachsen\n",
    "]\n",
    "\n",
    "# Konvertiere die Termine zu Datetime\n",
    "landtagswahltermine = pd.to_datetime(landtagswahltermine)\n",
    "\n",
    "# Zeitfenster: 30 Tage vor und nach der Wahl\n",
    "zeitfenster = 30\n",
    "\n",
    "# Erstelle eine vollst√§ndige Datumsreihe im Beobachtungszeitraum\n",
    "beobachtungszeitraum = pd.date_range(start=\"2022-05-01\", end=\"2023-05-31\", freq=\"D\")\n",
    "\n",
    "# Initialisiere die Series mit Nullen\n",
    "landtagswahlen_series = pd.Series(0, index=beobachtungszeitraum)\n",
    "\n",
    "# Inkrementiere die Werte f√ºr sich √ºberlappende Zeitfenster\n",
    "for wahltermin in landtagswahltermine:\n",
    "    startdatum = wahltermin - pd.Timedelta(days=zeitfenster)\n",
    "    enddatum = wahltermin + pd.Timedelta(days=zeitfenster)\n",
    "    landtagswahlen_series.loc[startdatum:enddatum] += 1\n",
    "\n",
    "# Kontrolliere die Series\n",
    "landtagswahlen_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2022-05-24     8\n",
       "2022-05-25    37\n",
       "2022-05-26    15\n",
       "2022-05-27    29\n",
       "2022-05-28    25\n",
       "              ..\n",
       "2023-05-17    68\n",
       "2023-05-18     7\n",
       "2023-05-19    22\n",
       "2023-05-20    17\n",
       "2023-05-21    10\n",
       "Length: 363, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annahme: subset_posts enth√§lt eine 'date'-Spalte und repr√§sentiert alle Social Media Posts\n",
    "# Gruppieren der Anzahl der Posts nach Datum\n",
    "social_media_usage = subset_posts.groupby('date').size()\n",
    "social_media_usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistische Regression mit der Kontrollvariable 'social_media_usage'\n",
    "def logistic_regression_with_control(relativ_rede, relativ_posts, post_to_shift, social_media_usage):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit der Kontrollvariable 'social_media_usage' durch.\n",
    "    \n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit relativen Anteilen der Themen im Bundestag.\n",
    "    - relativ_posts: DataFrame mit relativen Anteilen der Themen auf Social Media.\n",
    "    - post_to_shift: DataFrame mit Themen auf Social Media (Zielvariable, t+1).\n",
    "    - social_media_usage: Series mit t√§glicher Social-Media-Aktivit√§t.\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    posts_shifted_common = post_to_shift.shift().dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(posts_shifted_common.index)\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts = relativ_posts.loc[common_dates2]\n",
    "    social_media_usage = social_media_usage.loc[common_dates2]\n",
    "    landtagswahlen = landtagswahlen_series.loc[common_dates2]\n",
    "\n",
    "    y = (posts_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen\n",
    "    relative_reden = relativ_rede.stack()\n",
    "    relative_posts = relativ_posts.stack()\n",
    "\n",
    "    # Kontrollvariablen hinzuf√ºgen\n",
    "    social_media_usage_stacked = social_media_usage.reindex(relativ_rede.index)\n",
    "    social_media_usage_stacked = social_media_usage_stacked.repeat(relativ_rede.shape[1])\n",
    "    social_media_usage_stacked.index = relative_reden.index\n",
    "\n",
    "   # Dummy-Variable f√ºr Landtagswahlen\n",
    "    landtagswahlen_stacked = landtagswahlen.reindex(relativ_rede.index)\n",
    "    landtagswahlen_stacked = landtagswahlen_stacked.repeat(relativ_rede.shape[1])\n",
    "    landtagswahlen_stacked.index = relative_reden.index\n",
    "\n",
    "   \n",
    "    \n",
    "    # DataFrame f√ºr die logistische Regression\n",
    "    X = pd.DataFrame({\n",
    "        'posts_relative': relative_posts, \n",
    "        'reden_relativ': relative_reden,\n",
    "        'social_media_usage': social_media_usage_stacked,\n",
    "        'Landtagswahlen': landtagswahlen_stacked\n",
    "    }).dropna()\n",
    "\n",
    "    # Zielvariable und X ausrichten\n",
    "    y = y.reindex(X.index).dropna()\n",
    "    X = X.loc[y.index]\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y, X).fit()\n",
    "    print(model.summary())\n",
    "\n",
    "# Beispielaufruf\n",
    "#logistic_regression_with_control(reden_relativ, post_relativ, post_common, social_media_usage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit fixed_effects\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, brier_score_loss, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "def log_reg_FE_control(relativ_rede, relativ_posts, post_to_shift,shifts, social_media_usage):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit Fixed Effects f√ºr Themen durch.\n",
    "    \n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit Erw√§hnungen im Parlament; relative Anteile.\n",
    "    - relativ_posts: DataFrame mit Erw√§hnungen auf Social Media; relative Anteile.\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    posts_shifted_common = post_to_shift.shift(shifts).dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(posts_shifted_common.index)\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts=relativ_posts.loc[common_dates2]\n",
    "    social_media_usage = social_media_usage.loc[common_dates2]\n",
    "    landtagswahlen = landtagswahlen_series.loc[common_dates2]\n",
    "    y = (posts_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen: relative Anteile im Parlament und auf Social Media\n",
    "    relative_reden = relativ_rede.stack()\n",
    "    relative_posts = relativ_posts.stack()\n",
    "    # Kontrollvariable Social Media hinzuf√ºgen\n",
    "    social_media_usage_stacked = social_media_usage.reindex(relativ_rede.index)\n",
    "    social_media_usage_stacked = social_media_usage_stacked.repeat(relativ_rede.shape[1])\n",
    "    social_media_usage_stacked.index = relative_reden.index\n",
    "\n",
    "    # Kontrollvariable Landtagswahlen hinzuf√ºgen\n",
    "    # Dummy-Variable f√ºr Landtagswahlen\n",
    "    landtagswahlen_stacked = landtagswahlen.reindex(relativ_rede.index)\n",
    "    landtagswahlen_stacked = landtagswahlen_stacked.repeat(relativ_rede.shape[1])\n",
    "    landtagswahlen_stacked.index = relative_reden.index\n",
    "    # Zielvariable und unabh√§ngige Variablen als DataFrame zusammenf√ºhren\n",
    "    X = pd.DataFrame({'issue attention Facebook': relative_posts, \n",
    "                      'issue attention Bundestag': relative_reden,\n",
    "                      'Social Media Nutzung': social_media_usage_stacked,\n",
    "                       'Landtagswahlen': landtagswahlen_stacked }).dropna()\n",
    "    y = y.reindex(X.index).dropna()\n",
    "\n",
    "    # Konvertiere MultiIndex zu flachem Index, um die Kompatibilit√§t sicherzustellen\n",
    "    X.index = X.index.to_flat_index()\n",
    "    y.index = y.index.to_flat_index()\n",
    "\n",
    "    # Dummy-Variablen f√ºr Themen (Fixed Effects)\n",
    "    topics = [idx[1] for idx in X.index]  # Der zweite Wert im Tupel repr√§sentiert das Topic\n",
    "    topic_dummies = pd.get_dummies(topics, prefix='topic',drop_first=True).astype(int) # ohne.astype(int) kommen hier Fehlermeldungen\n",
    "    # Versuch aus den Topics Topic 0 zu l√∂schen und somit bessere Daten zu erlangen\n",
    "\n",
    "    # F√ºge Dummy-Variablen hinzu\n",
    "    X = pd.concat([X.reset_index(drop=True), topic_dummies.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y.values, X).fit(maxiter=100)\n",
    "    print(model.summary())\n",
    "    # Modellg√ºte-Kennzahlen berechnen\n",
    "    y_pred_prob = model.predict(X)  # Vorhergesagte Wahrscheinlichkeiten\n",
    "    y_pred = (y_pred_prob >= 0.5).astype(int)  # Bin√§re Vorhersagen\n",
    "\n",
    "    # AUC-ROC\n",
    "    auc_roc = roc_auc_score(y, y_pred_prob)\n",
    "    print(f\"AUC-ROC: {auc_roc}\")\n",
    "\n",
    "    # Pr√§zision, Recall und F1-Score\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(f\"Pr√§zision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "\n",
    "    # Brier-Score\n",
    "    brier_score = brier_score_loss(y, y_pred_prob)\n",
    "    print(f\"Brier-Score: {brier_score}\")\n",
    "\n",
    "    # Confusion-Matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    print(\"Confusion-Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    return model, auc_roc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, brier_score_loss, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "def log_reg_FE_control_test(relativ_rede, relativ_posts, post_to_shift, shifts, social_media_usage, complexity_rede, complexity_post):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit Fixed Effects f√ºr Themen durch, inklusive Kontrolle f√ºr Komplexit√§t.\n",
    "\n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit Erw√§hnungen im Parlament; relative Anteile.\n",
    "    - relativ_posts: DataFrame mit Erw√§hnungen auf Social Media; relative Anteile.\n",
    "    - post_to_shift: DataFrame der Social-Media-Posts zur Erstellung der Zielvariablen (verschoben um t+1).\n",
    "    - shifts: Anzahl der Tage, um die Zielvariable zu verschieben.\n",
    "    - social_media_usage: DataFrame mit der Anzahl der t√§glichen Social-Media-Beitr√§ge.\n",
    "    - landtagswahlen_series: Series mit Dummy-Variablen f√ºr Landtagswahlen.\n",
    "    - complexity_rede: DataFrame mit der Komplexit√§t (z. B. Wortanzahl) pro Tag f√ºr Reden.\n",
    "    - complexity_post: DataFrame mit der Komplexit√§t (z. B. Wortanzahl) pro Tag f√ºr Social-Media-Posts.\n",
    "\n",
    "    Returns:\n",
    "    - model: Das trainierte logistische Regressionsmodell.\n",
    "    - auc_roc: Der AUC-ROC-Wert des Modells.\n",
    "    - f1: Der F1-Score des Modells.\n",
    "    \"\"\"\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    posts_shifted_common = post_to_shift.shift(shifts).dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(posts_shifted_common.index)\n",
    "\n",
    "    # Synchronisiere alle relevanten Daten mit den gemeinsamen Datenpunkten\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts = relativ_posts.loc[common_dates2]\n",
    "    social_media_usage = social_media_usage.loc[common_dates2]\n",
    "    landtagswahlen = landtagswahlen_series.loc[common_dates2]\n",
    "    complexity_rede = complexity_rede.loc[common_dates2]\n",
    "    complexity_post = complexity_post.loc[common_dates2]\n",
    "    landtagswahlen = landtagswahlen_series.loc[common_dates2]\n",
    "\n",
    "    # Zielvariable erstellen\n",
    "    y = (posts_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen erstellen\n",
    "    relative_reden = relativ_rede.stack()\n",
    "    relative_posts = relativ_posts.stack()\n",
    "\n",
    "    # Kontrollvariable: Social Media Nutzung\n",
    "    social_media_usage_stacked = social_media_usage.reindex(relativ_rede.index)\n",
    "    social_media_usage_stacked = social_media_usage_stacked.repeat(relativ_rede.shape[1])\n",
    "    social_media_usage_stacked.index = relative_reden.index\n",
    "\n",
    "    # Kontrollvariable: Landtagswahlen\n",
    "    landtagswahlen_stacked = landtagswahlen.reindex(relativ_rede.index)\n",
    "    landtagswahlen_stacked = landtagswahlen_stacked.repeat(relativ_rede.shape[1])\n",
    "    landtagswahlen_stacked.index = relative_reden.index\n",
    "\n",
    "    # Kontrollvariable: Komplexit√§t der Reden (Z-Scores)\n",
    "    complexity_rede_z = (complexity_rede - complexity_rede.mean()) / complexity_rede.std()\n",
    "    complexity_rede_stacked = complexity_rede_z.reindex(relativ_rede.index)\n",
    "    complexity_rede_stacked = complexity_rede_stacked.repeat(relativ_rede.shape[1])\n",
    "    complexity_rede_stacked.index = relative_reden.index\n",
    "\n",
    "    # Kontrollvariable: Komplexit√§t der Posts (Z-Scores)\n",
    "    complexity_post_z = (complexity_post - complexity_post.mean()) / complexity_post.std()\n",
    "    complexity_post_stacked = complexity_post_z.reindex(relativ_posts.index)\n",
    "    complexity_post_stacked = complexity_post_stacked.repeat(relativ_posts.shape[1])\n",
    "    complexity_post_stacked.index = relative_posts.index\n",
    "\n",
    "    # Zielvariable und unabh√§ngige Variablen zusammenf√ºhren\n",
    "    X = pd.DataFrame({\n",
    "        'issue attention Facebook': relative_posts,\n",
    "        'issue attention Bundestag': relative_reden,\n",
    "        'Social Media Nutzung': social_media_usage_stacked,\n",
    "        'Landtagswahlen': landtagswahlen_stacked,\n",
    "        'Komplexit√§t Reden': complexity_rede_stacked,\n",
    "        'Komplexit√§t Posts': complexity_post_stacked\n",
    "    }).dropna()\n",
    "\n",
    "    y = y.reindex(X.index).dropna()\n",
    "\n",
    "    # Konvertiere MultiIndex zu flachem Index, um die Kompatibilit√§t sicherzustellen\n",
    "    X.index = X.index.to_flat_index()\n",
    "    y.index = y.index.to_flat_index()\n",
    "\n",
    "    # Dummy-Variablen f√ºr Themen (Fixed Effects)\n",
    "    topics = [idx[1] for idx in X.index]  # Der zweite Wert im Tupel repr√§sentiert das Topic\n",
    "    topic_dummies = pd.get_dummies(topics, prefix='topic', drop_first=True).astype(int)\n",
    "\n",
    "    # F√ºge Dummy-Variablen hinzu\n",
    "    X = pd.concat([X.reset_index(drop=True), topic_dummies.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y.values, X).fit(maxiter=100)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # Modellg√ºte-Kennzahlen berechnen\n",
    "    y_pred_prob = model.predict(X)  # Vorhergesagte Wahrscheinlichkeiten\n",
    "    y_pred = (y_pred_prob >= 0.5).astype(int)  # Bin√§re Vorhersagen\n",
    "\n",
    "    # AUC-ROC\n",
    "    auc_roc = roc_auc_score(y, y_pred_prob)\n",
    "    print(f\"AUC-ROC: {auc_roc}\")\n",
    "\n",
    "    # Pr√§zision, Recall und F1-Score\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(f\"Pr√§zision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "\n",
    "    # Brier-Score\n",
    "    brier_score = brier_score_loss(y, y_pred_prob)\n",
    "    print(f\"Brier-Score: {brier_score}\")\n",
    "\n",
    "    # Confusion-Matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    print(\"Confusion-Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    return model, auc_roc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531963\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2234\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2321\n",
      "Time:                        11:03:15   Log-Likelihood:                -1210.2\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                5.544e-128\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.9640      0.853      3.474      0.001       1.292       4.636\n",
      "issue attention Facebook     17.8797      2.495      7.166      0.000      12.989      22.770\n",
      "issue attention Bundestag     0.2034      1.100      0.185      0.853      -1.954       2.360\n",
      "Social Media Nutzung         -0.0088      0.007     -1.317      0.188      -0.022       0.004\n",
      "Landtagswahlen                0.0251      0.093      0.269      0.788      -0.158       0.208\n",
      "Komplexit√§t Reden             0.0782      0.051      1.541      0.123      -0.021       0.178\n",
      "Komplexit√§t Posts             0.1017      0.103      0.986      0.324      -0.100       0.304\n",
      "topic_1                       0.5719      1.243      0.460      0.646      -1.865       3.009\n",
      "topic_2                      -1.3852      0.806     -1.718      0.086      -2.965       0.195\n",
      "topic_3                      -0.9264      0.866     -1.070      0.285      -2.624       0.771\n",
      "topic_4                       0.0550      1.024      0.054      0.957      -1.952       2.062\n",
      "topic_6                      -1.5485      0.791     -1.958      0.050      -3.099       0.002\n",
      "topic_7                      -2.5263      0.771     -3.276      0.001      -4.038      -1.015\n",
      "topic_8                      -2.1628      0.773     -2.798      0.005      -3.678      -0.648\n",
      "topic_10                     -2.3594      0.771     -3.061      0.002      -3.870      -0.849\n",
      "topic_11                     -2.5599      0.773     -3.314      0.001      -4.074      -1.046\n",
      "topic_12                     -2.5351      0.775     -3.273      0.001      -4.053      -1.017\n",
      "topic_13                     -2.1448      0.775     -2.768      0.006      -3.663      -0.626\n",
      "topic_14                     -2.9686      0.772     -3.845      0.000      -4.482      -1.455\n",
      "topic_15                     -2.1168      0.775     -2.730      0.006      -3.637      -0.597\n",
      "topic_16                     -2.6350      0.772     -3.415      0.001      -4.147      -1.123\n",
      "topic_17                     -2.8526      0.772     -3.697      0.000      -4.365      -1.340\n",
      "topic_18                     -2.4579      0.772     -3.184      0.001      -3.971      -0.945\n",
      "topic_19                     -2.6413      0.772     -3.422      0.001      -4.154      -1.129\n",
      "topic_20                     -3.6015      0.782     -4.608      0.000      -5.133      -2.070\n",
      "topic_21                     -2.6181      0.772     -3.393      0.001      -4.130      -1.106\n",
      "topic_22                     -2.6215      0.772     -3.397      0.001      -4.134      -1.109\n",
      "topic_23                     -3.0582      0.774     -3.950      0.000      -4.576      -1.541\n",
      "topic_24                     -3.0894      0.774     -3.994      0.000      -4.606      -1.573\n",
      "topic_25                     -3.0505      0.774     -3.942      0.000      -4.567      -1.534\n",
      "topic_29                     -3.4992      0.782     -4.475      0.000      -5.032      -1.967\n",
      "topic_30                     -3.4206      0.780     -4.383      0.000      -4.950      -1.891\n",
      "topic_34                     -3.3082      0.778     -4.254      0.000      -4.833      -1.784\n",
      "topic_36                     -3.9038      0.795     -4.912      0.000      -5.461      -2.346\n",
      "topic_37                     -3.8975      0.795     -4.905      0.000      -5.455      -2.340\n",
      "topic_40                     -3.4868      0.783     -4.456      0.000      -5.020      -1.953\n",
      "topic_41                     -3.9915      0.799     -4.995      0.000      -5.558      -2.425\n",
      "topic_43                     -4.2714      0.810     -5.275      0.000      -5.859      -2.684\n",
      "topic_54                     -4.4563      0.824     -5.410      0.000      -6.071      -2.842\n",
      "topic_68                     -4.4618      0.824     -5.414      0.000      -6.077      -2.846\n",
      "topic_75                     -4.1049      0.804     -5.105      0.000      -5.681      -2.529\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.802870277561223\n",
      "Pr√§zision: 0.7438271604938271\n",
      "Recall: 0.6531165311653117\n",
      "F1-Score: 0.6955266955266955\n",
      "Brier-Score: 0.1799498314035293\n",
      "Confusion-Matrix:\n",
      "[[919 249]\n",
      " [384 723]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x168b712b710>,\n",
       " 0.802870277561223,\n",
       " 0.6955266955266955)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_FE_control_test(rede_relativ_reduced, post_relativ_reduced, post_common,1, social_media_usage,rede_komplex, posts_komplex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression f√ºr Lag 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532827\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2236\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2309\n",
      "Time:                        11:03:15   Log-Likelihood:                -1212.2\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.858e-128\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.6127      0.765      3.416      0.001       1.114       4.112\n",
      "issue attention Facebook     18.0170      2.497      7.216      0.000      13.123      22.911\n",
      "issue attention Bundestag     0.1522      1.100      0.138      0.890      -2.004       2.309\n",
      "Social Media Nutzung         -0.0035      0.003     -1.062      0.288      -0.010       0.003\n",
      "Landtagswahlen                0.0310      0.091      0.339      0.734      -0.148       0.210\n",
      "topic_1                       0.5645      1.243      0.454      0.650      -1.872       3.001\n",
      "topic_2                      -1.3730      0.806     -1.703      0.089      -2.953       0.207\n",
      "topic_3                      -0.9263      0.866     -1.070      0.285      -2.624       0.771\n",
      "topic_4                       0.0490      1.024      0.048      0.962      -1.957       2.055\n",
      "topic_6                      -1.5462      0.791     -1.956      0.050      -3.096       0.003\n",
      "topic_7                      -2.5193      0.771     -3.269      0.001      -4.030      -1.009\n",
      "topic_8                      -2.1518      0.773     -2.784      0.005      -3.666      -0.637\n",
      "topic_10                     -2.3487      0.770     -3.049      0.002      -3.859      -0.839\n",
      "topic_11                     -2.5479      0.772     -3.299      0.001      -4.062      -1.034\n",
      "topic_12                     -2.5259      0.774     -3.262      0.001      -4.044      -1.008\n",
      "topic_13                     -2.1375      0.775     -2.760      0.006      -3.656      -0.619\n",
      "topic_14                     -2.9563      0.772     -3.830      0.000      -4.469      -1.444\n",
      "topic_15                     -2.1085      0.775     -2.720      0.007      -3.628      -0.589\n",
      "topic_16                     -2.6254      0.771     -3.404      0.001      -4.137      -1.114\n",
      "topic_17                     -2.8409      0.771     -3.682      0.000      -4.353      -1.329\n",
      "topic_18                     -2.4470      0.772     -3.171      0.002      -3.960      -0.934\n",
      "topic_19                     -2.6323      0.771     -3.412      0.001      -4.144      -1.120\n",
      "topic_20                     -3.5903      0.781     -4.595      0.000      -5.122      -2.059\n",
      "topic_21                     -2.6067      0.771     -3.379      0.001      -4.119      -1.095\n",
      "topic_22                     -2.6095      0.771     -3.383      0.001      -4.121      -1.098\n",
      "topic_23                     -3.0455      0.774     -3.935      0.000      -4.562      -1.529\n",
      "topic_24                     -3.0769      0.773     -3.979      0.000      -4.593      -1.561\n",
      "topic_25                     -3.0377      0.774     -3.927      0.000      -4.554      -1.522\n",
      "topic_29                     -3.4850      0.782     -4.459      0.000      -5.017      -1.953\n",
      "topic_30                     -3.4069      0.780     -4.367      0.000      -4.936      -1.878\n",
      "topic_34                     -3.2957      0.777     -4.239      0.000      -4.820      -1.772\n",
      "topic_36                     -3.8889      0.794     -4.896      0.000      -5.446      -2.332\n",
      "topic_37                     -3.8850      0.794     -4.891      0.000      -5.442      -2.328\n",
      "topic_40                     -3.4735      0.782     -4.440      0.000      -5.007      -1.940\n",
      "topic_41                     -3.9773      0.799     -4.979      0.000      -5.543      -2.412\n",
      "topic_43                     -4.2527      0.809     -5.257      0.000      -5.838      -2.667\n",
      "topic_54                     -4.4408      0.823     -5.393      0.000      -6.055      -2.827\n",
      "topic_68                     -4.4467      0.824     -5.397      0.000      -6.062      -2.832\n",
      "topic_75                     -4.0882      0.804     -5.087      0.000      -5.663      -2.513\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8017635284800336\n",
      "Pr√§zision: 0.7450365726227796\n",
      "Recall: 0.6440831074977417\n",
      "F1-Score: 0.6908914728682171\n",
      "Brier-Score: 0.1803479069935199\n",
      "Confusion-Matrix:\n",
      "[[924 244]\n",
      " [394 713]]\n",
      "\n",
      "Regression f√ºr Lag 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529990\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2240\n",
      "Model:                          Logit   Df Residuals:                     2201\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2350\n",
      "Time:                        11:03:15   Log-Likelihood:                -1187.2\n",
      "converged:                       True   LL-Null:                       -1551.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                9.041e-129\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.2133      0.768      2.884      0.004       0.709       3.718\n",
      "issue attention Facebook     16.0225      2.489      6.437      0.000      11.144      20.901\n",
      "issue attention Bundestag     3.4426      1.309      2.629      0.009       0.877       6.009\n",
      "Social Media Nutzung          0.0010      0.003      0.283      0.777      -0.006       0.008\n",
      "Landtagswahlen                0.0094      0.099      0.095      0.924      -0.184       0.203\n",
      "topic_1                       0.6571      1.244      0.528      0.597      -1.780       3.094\n",
      "topic_2                      -1.4197      0.808     -1.758      0.079      -3.003       0.163\n",
      "topic_3                      -0.8324      0.866     -0.961      0.337      -2.530       0.865\n",
      "topic_4                       0.1873      1.023      0.183      0.855      -1.818       2.193\n",
      "topic_6                      -1.3923      0.795     -1.751      0.080      -2.951       0.166\n",
      "topic_7                      -2.4902      0.773     -3.220      0.001      -4.006      -0.974\n",
      "topic_8                      -2.1211      0.775     -2.738      0.006      -3.639      -0.603\n",
      "topic_10                     -2.3037      0.773     -2.982      0.003      -3.818      -0.789\n",
      "topic_11                     -2.3498      0.773     -3.039      0.002      -3.865      -0.834\n",
      "topic_12                     -2.3184      0.775     -2.992      0.003      -3.837      -0.800\n",
      "topic_13                     -1.9690      0.776     -2.537      0.011      -3.490      -0.448\n",
      "topic_14                     -2.8440      0.774     -3.676      0.000      -4.360      -1.328\n",
      "topic_15                     -1.9268      0.777     -2.480      0.013      -3.450      -0.404\n",
      "topic_16                     -2.4546      0.772     -3.179      0.001      -3.968      -0.941\n",
      "topic_17                     -2.7493      0.773     -3.558      0.000      -4.264      -1.235\n",
      "topic_18                     -2.3381      0.772     -3.027      0.002      -3.852      -0.824\n",
      "topic_19                     -2.4568      0.772     -3.181      0.001      -3.971      -0.943\n",
      "topic_20                     -3.5255      0.783     -4.500      0.000      -5.061      -1.990\n",
      "topic_21                     -2.4526      0.773     -3.172      0.002      -3.968      -0.937\n",
      "topic_22                     -2.4747      0.773     -3.202      0.001      -3.990      -0.960\n",
      "topic_23                     -2.9742      0.776     -3.834      0.000      -4.495      -1.454\n",
      "topic_24                     -3.0204      0.775     -3.896      0.000      -4.540      -1.501\n",
      "topic_25                     -2.9758      0.775     -3.839      0.000      -4.495      -1.457\n",
      "topic_29                     -3.4530      0.784     -4.402      0.000      -4.991      -1.915\n",
      "topic_30                     -3.3656      0.783     -4.298      0.000      -4.900      -1.831\n",
      "topic_34                     -3.2322      0.780     -4.146      0.000      -4.760      -1.704\n",
      "topic_36                     -3.7772      0.795     -4.749      0.000      -5.336      -2.218\n",
      "topic_37                     -3.7526      0.796     -4.717      0.000      -5.312      -2.193\n",
      "topic_40                     -3.3341      0.783     -4.257      0.000      -4.869      -1.799\n",
      "topic_41                     -3.9339      0.804     -4.893      0.000      -5.510      -2.358\n",
      "topic_43                     -4.1384      0.810     -5.109      0.000      -5.726      -2.551\n",
      "topic_54                     -4.4763      0.835     -5.361      0.000      -6.113      -2.840\n",
      "topic_68                     -4.3158      0.825     -5.233      0.000      -5.932      -2.699\n",
      "topic_75                     -3.9435      0.804     -4.903      0.000      -5.520      -2.367\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8051539688871161\n",
      "Pr√§zision: 0.7497371188222923\n",
      "Recall: 0.6541284403669725\n",
      "F1-Score: 0.6986771190592846\n",
      "Brier-Score: 0.178538625050786\n",
      "Confusion-Matrix:\n",
      "[[912 238]\n",
      " [377 713]]\n",
      "\n",
      "Regression f√ºr Lag 3:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538367\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2205\n",
      "Model:                          Logit   Df Residuals:                     2166\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2229\n",
      "Time:                        11:03:15   Log-Likelihood:                -1187.1\n",
      "converged:                       True   LL-Null:                       -1527.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.873e-119\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.6936      0.766      3.515      0.000       1.192       4.195\n",
      "issue attention Facebook      8.9319      2.233      4.000      0.000       4.555      13.309\n",
      "issue attention Bundestag     3.2748      1.275      2.569      0.010       0.776       5.773\n",
      "Social Media Nutzung         -0.0007      0.003     -0.201      0.841      -0.007       0.006\n",
      "Landtagswahlen               -0.0185      0.109     -0.171      0.864      -0.231       0.194\n",
      "topic_1                       0.7028      1.241      0.566      0.571      -1.729       3.134\n",
      "topic_2                      -1.5828      0.804     -1.968      0.049      -3.159      -0.007\n",
      "topic_3                      -0.8697      0.862     -1.010      0.313      -2.558       0.819\n",
      "topic_4                       0.1511      1.020      0.148      0.882      -1.848       2.150\n",
      "topic_6                      -1.5930      0.793     -2.010      0.044      -3.147      -0.039\n",
      "topic_7                      -2.6748      0.771     -3.469      0.001      -4.186      -1.164\n",
      "topic_8                      -2.3793      0.773     -3.078      0.002      -3.894      -0.864\n",
      "topic_10                     -2.5780      0.771     -3.342      0.001      -4.090      -1.066\n",
      "topic_11                     -2.6458      0.771     -3.432      0.001      -4.157      -1.135\n",
      "topic_12                     -2.4611      0.771     -3.190      0.001      -3.973      -0.949\n",
      "topic_13                     -2.1580      0.775     -2.784      0.005      -3.677      -0.639\n",
      "topic_14                     -3.1002      0.772     -4.014      0.000      -4.614      -1.587\n",
      "topic_15                     -2.1095      0.776     -2.719      0.007      -3.630      -0.589\n",
      "topic_16                     -2.6475      0.770     -3.439      0.001      -4.156      -1.138\n",
      "topic_17                     -2.9793      0.771     -3.866      0.000      -4.490      -1.469\n",
      "topic_18                     -2.6315      0.771     -3.413      0.001      -4.143      -1.120\n",
      "topic_19                     -2.6924      0.771     -3.492      0.000      -4.204      -1.181\n",
      "topic_20                     -3.8038      0.780     -4.879      0.000      -5.332      -2.276\n",
      "topic_21                     -2.7508      0.771     -3.566      0.000      -4.263      -1.239\n",
      "topic_22                     -2.7880      0.771     -3.616      0.000      -4.299      -1.277\n",
      "topic_23                     -3.2518      0.774     -4.199      0.000      -4.769      -1.734\n",
      "topic_24                     -3.2824      0.774     -4.243      0.000      -4.799      -1.766\n",
      "topic_25                     -3.3237      0.775     -4.290      0.000      -4.842      -1.805\n",
      "topic_29                     -3.8326      0.785     -4.881      0.000      -5.372      -2.294\n",
      "topic_30                     -3.6634      0.782     -4.686      0.000      -5.196      -2.131\n",
      "topic_34                     -3.5924      0.780     -4.608      0.000      -5.120      -2.064\n",
      "topic_36                     -4.0757      0.794     -5.131      0.000      -5.632      -2.519\n",
      "topic_37                     -4.0655      0.794     -5.118      0.000      -5.622      -2.509\n",
      "topic_40                     -3.6372      0.782     -4.652      0.000      -5.170      -2.105\n",
      "topic_41                     -4.2486      0.803     -5.292      0.000      -5.822      -2.675\n",
      "topic_43                     -4.4248      0.807     -5.480      0.000      -6.007      -2.842\n",
      "topic_54                     -4.7902      0.834     -5.746      0.000      -6.424      -3.156\n",
      "topic_68                     -4.6311      0.823     -5.626      0.000      -6.245      -3.018\n",
      "topic_75                     -4.2550      0.803     -5.301      0.000      -5.828      -2.682\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7979429387154295\n",
      "Pr√§zision: 0.7283349561830574\n",
      "Recall: 0.6964618249534451\n",
      "F1-Score: 0.7120418848167539\n",
      "Brier-Score: 0.18213012591484737\n",
      "Confusion-Matrix:\n",
      "[[852 279]\n",
      " [326 748]]\n",
      "\n",
      "Regression f√ºr Lag 4:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542423\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2170\n",
      "Model:                          Logit   Df Residuals:                     2131\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2171\n",
      "Time:                        11:03:15   Log-Likelihood:                -1177.1\n",
      "converged:                       True   LL-Null:                       -1503.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.918e-113\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.9972      0.766      3.913      0.000       1.496       4.499\n",
      "issue attention Facebook      6.5580      2.140      3.065      0.002       2.364      10.751\n",
      "issue attention Bundestag     1.4149      1.161      1.218      0.223      -0.861       3.691\n",
      "Social Media Nutzung         -0.0022      0.003     -0.649      0.516      -0.009       0.004\n",
      "Landtagswahlen                0.0457      0.123      0.371      0.711      -0.196       0.287\n",
      "topic_1                       0.6933      1.240      0.559      0.576      -1.736       3.123\n",
      "topic_2                      -1.6091      0.802     -2.007      0.045      -3.181      -0.037\n",
      "topic_3                      -0.9310      0.860     -1.083      0.279      -2.616       0.754\n",
      "topic_4                       0.0780      1.019      0.077      0.939      -1.920       2.076\n",
      "topic_6                      -1.5929      0.796     -2.000      0.045      -3.154      -0.032\n",
      "topic_7                      -2.7101      0.770     -3.519      0.000      -4.219      -1.201\n",
      "topic_8                      -2.5210      0.772     -3.265      0.001      -4.034      -1.008\n",
      "topic_10                     -2.7117      0.771     -3.518      0.000      -4.222      -1.201\n",
      "topic_11                     -2.8571      0.771     -3.705      0.000      -4.369      -1.346\n",
      "topic_12                     -2.5560      0.772     -3.311      0.001      -4.069      -1.043\n",
      "topic_13                     -2.3431      0.775     -3.024      0.002      -3.862      -0.824\n",
      "topic_14                     -3.2947      0.772     -4.265      0.000      -4.809      -1.781\n",
      "topic_15                     -2.2880      0.776     -2.950      0.003      -3.808      -0.768\n",
      "topic_16                     -2.7690      0.770     -3.595      0.000      -4.279      -1.259\n",
      "topic_17                     -3.1185      0.771     -4.046      0.000      -4.629      -1.608\n",
      "topic_18                     -2.7739      0.772     -3.595      0.000      -4.286      -1.261\n",
      "topic_19                     -2.9020      0.771     -3.762      0.000      -4.414      -1.390\n",
      "topic_20                     -4.0077      0.780     -5.136      0.000      -5.537      -2.478\n",
      "topic_21                     -2.8828      0.771     -3.740      0.000      -4.394      -1.372\n",
      "topic_22                     -2.9171      0.771     -3.783      0.000      -4.428      -1.406\n",
      "topic_23                     -3.4060      0.774     -4.399      0.000      -4.924      -1.888\n",
      "topic_24                     -3.4926      0.774     -4.511      0.000      -5.010      -1.975\n",
      "topic_25                     -3.4747      0.775     -4.484      0.000      -4.993      -1.956\n",
      "topic_29                     -3.9888      0.785     -5.080      0.000      -5.528      -2.450\n",
      "topic_30                     -3.8230      0.782     -4.892      0.000      -5.355      -2.291\n",
      "topic_34                     -3.8304      0.781     -4.903      0.000      -5.361      -2.299\n",
      "topic_36                     -4.2394      0.794     -5.337      0.000      -5.796      -2.683\n",
      "topic_37                     -4.2358      0.794     -5.332      0.000      -5.793      -2.679\n",
      "topic_40                     -3.8051      0.782     -4.864      0.000      -5.338      -2.272\n",
      "topic_41                     -4.4363      0.803     -5.525      0.000      -6.010      -2.863\n",
      "topic_43                     -4.5813      0.807     -5.676      0.000      -6.163      -2.999\n",
      "topic_54                     -4.9656      0.834     -5.956      0.000      -6.600      -3.332\n",
      "topic_68                     -4.8123      0.823     -5.845      0.000      -6.426      -3.199\n",
      "topic_75                     -4.4387      0.803     -5.529      0.000      -6.012      -2.865\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7916665604237476\n",
      "Pr√§zision: 0.7006673021925643\n",
      "Recall: 0.6940509915014165\n",
      "F1-Score: 0.6973434535104365\n",
      "Brier-Score: 0.18414490791117813\n",
      "Confusion-Matrix:\n",
      "[[797 314]\n",
      " [324 735]]\n",
      "\n",
      "Regression f√ºr Lag 5:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543758\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2135\n",
      "Model:                          Logit   Df Residuals:                     2096\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2152\n",
      "Time:                        11:03:15   Log-Likelihood:                -1160.9\n",
      "converged:                       True   LL-Null:                       -1479.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                9.588e-110\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.8805      0.765      3.765      0.000       1.381       4.380\n",
      "issue attention Facebook      5.7091      2.106      2.711      0.007       1.581       9.837\n",
      "issue attention Bundestag     0.2890      1.129      0.256      0.798      -1.925       2.502\n",
      "Social Media Nutzung          0.0015      0.003      0.454      0.650      -0.005       0.008\n",
      "Landtagswahlen             3.144e-05      0.124      0.000      1.000      -0.242       0.242\n",
      "topic_1                       0.6767      1.239      0.546      0.585      -1.753       3.106\n",
      "topic_2                      -1.6132      0.801     -2.014      0.044      -3.183      -0.043\n",
      "topic_3                      -0.9752      0.860     -1.135      0.257      -2.660       0.710\n",
      "topic_4                       0.0141      1.019      0.014      0.989      -1.984       2.012\n",
      "topic_6                      -1.6533      0.796     -2.076      0.038      -3.214      -0.093\n",
      "topic_7                      -2.6956      0.771     -3.498      0.000      -4.206      -1.185\n",
      "topic_8                      -2.5288      0.773     -3.272      0.001      -4.044      -1.014\n",
      "topic_10                     -2.7801      0.771     -3.605      0.000      -4.292      -1.269\n",
      "topic_11                     -2.9838      0.772     -3.864      0.000      -4.497      -1.470\n",
      "topic_12                     -2.5933      0.774     -3.353      0.001      -4.109      -1.077\n",
      "topic_13                     -2.4526      0.775     -3.163      0.002      -3.972      -0.933\n",
      "topic_14                     -3.3389      0.773     -4.319      0.000      -4.854      -1.824\n",
      "topic_15                     -2.3140      0.777     -2.976      0.003      -3.838      -0.790\n",
      "topic_16                     -2.8123      0.772     -3.645      0.000      -4.325      -1.300\n",
      "topic_17                     -3.2417      0.772     -4.200      0.000      -4.754      -1.729\n",
      "topic_18                     -2.8951      0.773     -3.746      0.000      -4.410      -1.380\n",
      "topic_19                     -3.0251      0.772     -3.916      0.000      -4.539      -1.511\n",
      "topic_20                     -4.1474      0.783     -5.298      0.000      -5.682      -2.613\n",
      "topic_21                     -2.9263      0.772     -3.793      0.000      -4.438      -1.414\n",
      "topic_22                     -2.9632      0.772     -3.839      0.000      -4.476      -1.450\n",
      "topic_23                     -3.4692      0.775     -4.476      0.000      -4.988      -1.950\n",
      "topic_24                     -3.5503      0.775     -4.581      0.000      -5.069      -2.031\n",
      "topic_25                     -3.5368      0.776     -4.560      0.000      -5.057      -2.017\n",
      "topic_29                     -4.1416      0.788     -5.255      0.000      -5.686      -2.597\n",
      "topic_30                     -3.8887      0.782     -4.971      0.000      -5.422      -2.355\n",
      "topic_34                     -3.8985      0.782     -4.986      0.000      -5.431      -2.366\n",
      "topic_36                     -4.3091      0.795     -5.420      0.000      -5.867      -2.751\n",
      "topic_37                     -4.3115      0.795     -5.423      0.000      -5.870      -2.753\n",
      "topic_40                     -3.8816      0.783     -4.957      0.000      -5.417      -2.347\n",
      "topic_41                     -4.5198      0.804     -5.624      0.000      -6.095      -2.945\n",
      "topic_43                     -4.6499      0.808     -5.757      0.000      -6.233      -3.067\n",
      "topic_54                     -5.0444      0.834     -6.046      0.000      -6.680      -3.409\n",
      "topic_68                     -4.8926      0.824     -5.939      0.000      -6.507      -3.278\n",
      "topic_75                     -4.6340      0.809     -5.728      0.000      -6.220      -3.048\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7906780836590566\n",
      "Pr√§zision: 0.699047619047619\n",
      "Recall: 0.7030651340996169\n",
      "F1-Score: 0.7010506208213945\n",
      "Brier-Score: 0.18471449796948208\n",
      "Confusion-Matrix:\n",
      "[[775 316]\n",
      " [310 734]]\n",
      "\n",
      "Regression f√ºr Lag 6:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541967\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2100\n",
      "Model:                          Logit   Df Residuals:                     2061\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2179\n",
      "Time:                        11:03:15   Log-Likelihood:                -1138.1\n",
      "converged:                       True   LL-Null:                       -1455.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.629e-109\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.9188      0.766      3.809      0.000       1.417       4.420\n",
      "issue attention Facebook      6.5474      2.158      3.034      0.002       2.318      10.777\n",
      "issue attention Bundestag     0.9592      1.161      0.826      0.409      -1.316       3.234\n",
      "Social Media Nutzung         -0.0010      0.003     -0.290      0.772      -0.008       0.006\n",
      "Landtagswahlen                0.0529      0.124      0.427      0.670      -0.190       0.296\n",
      "topic_1                       0.6863      1.240      0.553      0.580      -1.744       3.117\n",
      "topic_2                      -1.6020      0.802     -1.997      0.046      -3.174      -0.030\n",
      "topic_3                      -0.9683      0.861     -1.125      0.261      -2.655       0.718\n",
      "topic_4                       0.0446      1.020      0.044      0.965      -1.955       2.044\n",
      "topic_6                      -1.5026      0.802     -1.873      0.061      -3.075       0.070\n",
      "topic_7                      -2.5936      0.773     -3.357      0.001      -4.108      -1.079\n",
      "topic_8                      -2.4883      0.774     -3.216      0.001      -4.005      -0.972\n",
      "topic_10                     -2.6748      0.772     -3.463      0.001      -4.189      -1.161\n",
      "topic_11                     -2.9207      0.773     -3.779      0.000      -4.436      -1.406\n",
      "topic_12                     -2.4632      0.775     -3.177      0.001      -3.983      -0.944\n",
      "topic_13                     -2.3177      0.777     -2.983      0.003      -3.841      -0.795\n",
      "topic_14                     -3.2249      0.774     -4.168      0.000      -4.742      -1.708\n",
      "topic_15                     -2.2549      0.778     -2.898      0.004      -3.780      -0.730\n",
      "topic_16                     -2.7548      0.772     -3.567      0.000      -4.268      -1.241\n",
      "topic_17                     -3.1891      0.773     -4.127      0.000      -4.704      -1.675\n",
      "topic_18                     -2.8323      0.773     -3.662      0.000      -4.348      -1.317\n",
      "topic_19                     -2.8985      0.773     -3.749      0.000      -4.414      -1.383\n",
      "topic_20                     -4.1351      0.786     -5.264      0.000      -5.675      -2.596\n",
      "topic_21                     -2.8731      0.773     -3.719      0.000      -4.387      -1.359\n",
      "topic_22                     -2.8405      0.773     -3.675      0.000      -4.355      -1.326\n",
      "topic_23                     -3.3432      0.776     -4.310      0.000      -4.864      -1.823\n",
      "topic_24                     -3.4358      0.775     -4.431      0.000      -4.956      -1.916\n",
      "topic_25                     -3.4184      0.776     -4.405      0.000      -4.939      -1.897\n",
      "topic_29                     -4.0266      0.788     -5.107      0.000      -5.572      -2.481\n",
      "topic_30                     -3.8499      0.784     -4.908      0.000      -5.387      -2.313\n",
      "topic_34                     -3.7794      0.782     -4.831      0.000      -5.313      -2.246\n",
      "topic_36                     -4.1911      0.795     -5.270      0.000      -5.750      -2.632\n",
      "topic_37                     -4.2924      0.799     -5.372      0.000      -5.858      -2.726\n",
      "topic_40                     -3.8371      0.785     -4.887      0.000      -5.376      -2.298\n",
      "topic_41                     -4.3946      0.804     -5.466      0.000      -5.970      -2.819\n",
      "topic_43                     -4.5357      0.808     -5.614      0.000      -6.119      -2.952\n",
      "topic_54                     -4.9242      0.834     -5.901      0.000      -6.560      -3.289\n",
      "topic_68                     -4.7726      0.824     -5.792      0.000      -6.388      -3.158\n",
      "topic_75                     -4.5103      0.809     -5.573      0.000      -6.096      -2.924\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.793080590481445\n",
      "Pr√§zision: 0.703921568627451\n",
      "Recall: 0.6984435797665369\n",
      "F1-Score: 0.701171875\n",
      "Brier-Score: 0.18370561339915042\n",
      "Confusion-Matrix:\n",
      "[[770 302]\n",
      " [310 718]]\n",
      "\n",
      "Regression f√ºr Lag 7:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539719\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2065\n",
      "Model:                          Logit   Df Residuals:                     2026\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2211\n",
      "Time:                        11:03:15   Log-Likelihood:                -1114.5\n",
      "converged:                       True   LL-Null:                       -1430.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.181e-109\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.7178      0.766      3.546      0.000       1.216       4.220\n",
      "issue attention Facebook      7.2380      2.196      3.296      0.001       2.934      11.542\n",
      "issue attention Bundestag     1.1770      1.183      0.995      0.320      -1.141       3.495\n",
      "Social Media Nutzung          0.0011      0.003      0.316      0.752      -0.006       0.008\n",
      "Landtagswahlen                0.0440      0.125      0.353      0.724      -0.200       0.288\n",
      "topic_1                       0.6776      1.241      0.546      0.585      -1.754       3.109\n",
      "topic_2                      -1.5812      0.803     -1.968      0.049      -3.156      -0.007\n",
      "topic_3                      -0.9782      0.861     -1.136      0.256      -2.666       0.710\n",
      "topic_4                       0.0463      1.020      0.045      0.964      -1.954       2.046\n",
      "topic_6                      -1.4857      0.803     -1.851      0.064      -3.059       0.088\n",
      "topic_7                      -2.5036      0.774     -3.233      0.001      -4.021      -0.986\n",
      "topic_8                      -2.3919      0.776     -3.084      0.002      -3.912      -0.872\n",
      "topic_10                     -2.5822      0.774     -3.336      0.001      -4.099      -1.065\n",
      "topic_11                     -2.8942      0.774     -3.740      0.000      -4.411      -1.377\n",
      "topic_12                     -2.3666      0.777     -3.045      0.002      -3.890      -0.843\n",
      "topic_13                     -2.2124      0.779     -2.840      0.005      -3.739      -0.686\n",
      "topic_14                     -3.2057      0.775     -4.136      0.000      -4.725      -1.687\n",
      "topic_15                     -2.2279      0.779     -2.861      0.004      -3.754      -0.702\n",
      "topic_16                     -2.6605      0.774     -3.439      0.001      -4.177      -1.144\n",
      "topic_17                     -3.1018      0.774     -4.010      0.000      -4.618      -1.586\n",
      "topic_18                     -2.8024      0.774     -3.619      0.000      -4.320      -1.285\n",
      "topic_19                     -2.8688      0.774     -3.706      0.000      -4.386      -1.351\n",
      "topic_20                     -4.1575      0.789     -5.270      0.000      -5.704      -2.611\n",
      "topic_21                     -2.8502      0.774     -3.684      0.000      -4.367      -1.334\n",
      "topic_22                     -2.8130      0.774     -3.635      0.000      -4.330      -1.296\n",
      "topic_23                     -3.2483      0.777     -4.182      0.000      -4.771      -1.726\n",
      "topic_24                     -3.3495      0.776     -4.316      0.000      -4.871      -1.828\n",
      "topic_25                     -3.4016      0.778     -4.375      0.000      -4.926      -1.878\n",
      "topic_29                     -4.0329      0.792     -5.095      0.000      -5.584      -2.481\n",
      "topic_30                     -3.7605      0.785     -4.790      0.000      -5.299      -2.222\n",
      "topic_34                     -3.7738      0.785     -4.810      0.000      -5.311      -2.236\n",
      "topic_36                     -4.1003      0.796     -5.151      0.000      -5.660      -2.540\n",
      "topic_37                     -4.2048      0.800     -5.259      0.000      -5.772      -2.638\n",
      "topic_40                     -3.8309      0.788     -4.863      0.000      -5.375      -2.287\n",
      "topic_41                     -4.3016      0.805     -5.346      0.000      -5.879      -2.725\n",
      "topic_43                     -4.4503      0.809     -5.504      0.000      -6.035      -2.866\n",
      "topic_54                     -4.8392      0.835     -5.796      0.000      -6.476      -3.203\n",
      "topic_68                     -4.8392      0.835     -5.796      0.000      -6.476      -3.203\n",
      "topic_75                     -4.4203      0.810     -5.459      0.000      -6.008      -2.833\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7955047564345136\n",
      "Pr√§zision: 0.7105263157894737\n",
      "Recall: 0.6689791873141725\n",
      "F1-Score: 0.6891271056661562\n",
      "Brier-Score: 0.18269185211648123\n",
      "Confusion-Matrix:\n",
      "[[781 275]\n",
      " [334 675]]\n"
     ]
    }
   ],
   "source": [
    "# Schleife f√ºr logistische Regression mit Lags von -7 bis 7\n",
    "for n in range(1, 8):  # Einschlie√ülich 1 bis 7\n",
    "    try:\n",
    "        print(f\"\\nRegression f√ºr Lag {n}:\")\n",
    "        log_reg_FE_control(rede_relativ_reduced, post_relativ_reduced, post_common,n, social_media_usage)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Lag {n}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Troubleshooting\n",
    "Mit dem Code scheint etwas nicht funktionieren mit den durch die dummy-variablen erzeugten Werten. Daher hier nochmal ein trouble shooting. Das Problem lag darin, dass die hinzugef√ºgten Dummy-Variablen nicht 0/1, sondern True/False codiert und somit f√ºr die Funktion nicht lesbar waren. Auch mit funktionierenden Dummy.Variablen ergeben die Ergebnisse nicht viel Sinn, da die ganzen Dummies zu Fehlern in der Berechnung f√ºhren. Ich versuche es nochmal mit dem Ansatz Themen, die zu mehr als 90% aus 0 bestehen aus dem Datensatz zu l√∂schen und dann nochmal zu rechnen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.533088\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2238\n",
      "Method:                           MLE   Df Model:                           36\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2305\n",
      "Time:                        11:03:16   Log-Likelihood:                -1212.8\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.616e-129\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              2.3898      0.734      3.258      0.001       0.952       3.828\n",
      "posts_relative    18.2202      2.492      7.310      0.000      13.335      23.105\n",
      "reden_relativ      0.0838      1.097      0.076      0.939      -2.067       2.234\n",
      "topic_1            0.5684      1.243      0.457      0.648      -1.868       3.005\n",
      "topic_2           -1.3591      0.806     -1.686      0.092      -2.939       0.221\n",
      "topic_3           -0.9285      0.866     -1.072      0.284      -2.626       0.769\n",
      "topic_4            0.0447      1.024      0.044      0.965      -1.962       2.051\n",
      "topic_6           -1.5373      0.791     -1.945      0.052      -3.087       0.012\n",
      "topic_7           -2.5090      0.770     -3.257      0.001      -4.019      -0.999\n",
      "topic_8           -2.1421      0.773     -2.772      0.006      -3.657      -0.628\n",
      "topic_10          -2.3378      0.770     -3.035      0.002      -3.848      -0.828\n",
      "topic_11          -2.5397      0.772     -3.288      0.001      -4.054      -1.026\n",
      "topic_12          -2.5206      0.774     -3.255      0.001      -4.038      -1.003\n",
      "topic_13          -2.1305      0.774     -2.751      0.006      -3.648      -0.613\n",
      "topic_14          -2.9446      0.772     -3.815      0.000      -4.457      -1.432\n",
      "topic_15          -2.1016      0.775     -2.711      0.007      -3.621      -0.582\n",
      "topic_16          -2.6178      0.771     -3.394      0.001      -4.130      -1.106\n",
      "topic_17          -2.8315      0.772     -3.670      0.000      -4.344      -1.319\n",
      "topic_18          -2.4381      0.772     -3.159      0.002      -3.951      -0.925\n",
      "topic_19          -2.6233      0.771     -3.400      0.001      -4.135      -1.111\n",
      "topic_20          -3.5794      0.781     -4.580      0.000      -5.111      -2.048\n",
      "topic_21          -2.5972      0.771     -3.367      0.001      -4.109      -1.085\n",
      "topic_22          -2.5991      0.771     -3.370      0.001      -4.111      -1.087\n",
      "topic_23          -3.0346      0.774     -3.922      0.000      -4.551      -1.518\n",
      "topic_24          -3.0663      0.773     -3.966      0.000      -4.582      -1.551\n",
      "topic_25          -3.0265      0.773     -3.913      0.000      -4.543      -1.511\n",
      "topic_29          -3.4733      0.782     -4.444      0.000      -5.005      -1.941\n",
      "topic_30          -3.3949      0.780     -4.352      0.000      -4.924      -1.866\n",
      "topic_34          -3.2852      0.777     -4.225      0.000      -4.809      -1.761\n",
      "topic_36          -3.8755      0.794     -4.880      0.000      -5.432      -2.319\n",
      "topic_37          -3.8724      0.794     -4.875      0.000      -5.429      -2.316\n",
      "topic_40          -3.4611      0.782     -4.425      0.000      -4.994      -1.928\n",
      "topic_41          -3.9648      0.799     -4.963      0.000      -5.530      -2.399\n",
      "topic_43          -4.2400      0.809     -5.242      0.000      -5.825      -2.655\n",
      "topic_54          -4.4312      0.823     -5.382      0.000      -6.045      -2.817\n",
      "topic_68          -4.4341      0.824     -5.382      0.000      -6.049      -2.819\n",
      "topic_75          -4.0762      0.804     -5.072      0.000      -5.651      -2.501\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM_fixed_effects(rede_relativ_reduced, post_relativ_reduced,post_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.598166\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2270\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1366\n",
      "Time:                        11:03:16   Log-Likelihood:                -1360.8\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.031e-92\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 -0.6505      0.200     -3.260      0.001      -1.042      -0.259\n",
      "posts_relative        37.2377      2.573     14.471      0.000      32.194      42.281\n",
      "reden_relativ          3.6387      1.279      2.844      0.004       1.131       6.146\n",
      "social_media_usage    -0.0014      0.003     -0.478      0.633      -0.007       0.004\n",
      "interaction          -51.4108     25.653     -2.004      0.045    -101.690      -1.132\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Logistische Regression mit Interaktionseffekt\n",
    "def logistic_regression_with_interaction(relativ_rede, relativ_posts, post_to_shift, social_media_usage):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit einem Interaktionseffekt durch.\n",
    "    \n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit relativen Anteilen der Themen im Bundestag.\n",
    "    - relativ_posts: DataFrame mit relativen Anteilen der Themen auf Social Media.\n",
    "    - post_to_shift: DataFrame mit Themen auf Social Media (Zielvariable, t+1).\n",
    "    - social_media_usage: Series mit t√§glicher Social-Media-Aktivit√§t (Kontrollvariable).\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    posts_shifted_common = post_to_shift.shift(1).dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(posts_shifted_common.index)\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts = relativ_posts.loc[common_dates2]\n",
    "    social_media_usage = social_media_usage.loc[common_dates2]\n",
    "\n",
    "    y = (posts_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen\n",
    "    relative_reden = relativ_rede.stack()\n",
    "    relative_posts = relativ_posts.stack()\n",
    "\n",
    "    # Kontrollvariable hinzuf√ºgen\n",
    "    social_media_usage_stacked = social_media_usage.reindex(relativ_rede.index)\n",
    "    social_media_usage_stacked = social_media_usage_stacked.repeat(relativ_rede.shape[1])\n",
    "    social_media_usage_stacked.index = relative_reden.index\n",
    "\n",
    "    # Interaktionseffekt berechnen\n",
    "    interaction_effect = relative_reden * relative_posts\n",
    "\n",
    "    # DataFrame f√ºr die logistische Regression\n",
    "    X = pd.DataFrame({\n",
    "        'posts_relative': relative_posts, \n",
    "        'reden_relativ': relative_reden,\n",
    "        'social_media_usage': social_media_usage_stacked,\n",
    "        'interaction': interaction_effect,\n",
    "    }).dropna()\n",
    "\n",
    "    # Zielvariable und X ausrichten\n",
    "    y = y.reindex(X.index).dropna()\n",
    "    X = X.loc[y.index]\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y, X).fit()\n",
    "    print(model.summary())\n",
    "\n",
    "# Beispielaufruf\n",
    "logistic_regression_with_interaction(reden_relativ, post_relativ, post_common, social_media_usage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.598774\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2270\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1357\n",
      "Time:                        11:03:16   Log-Likelihood:                -1362.2\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.786e-91\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 -0.6280      0.199     -3.162      0.002      -1.017      -0.239\n",
      "posts_relative        35.6501      2.400     14.855      0.000      30.946      40.354\n",
      "reden_relativ          2.2386      1.027      2.179      0.029       0.225       4.252\n",
      "social_media_usage    -0.0014      0.003     -0.472      0.637      -0.007       0.004\n",
      "Landtagswahlen        -0.0017      0.085     -0.021      0.984      -0.168       0.165\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Beispielaufruf\n",
    "logistic_regression_with_control(reden_relativ, post_relativ, post_common, social_media_usage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532827\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2236\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2309\n",
      "Time:                        11:03:16   Log-Likelihood:                -1212.2\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.858e-128\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.6127      0.765      3.416      0.001       1.114       4.112\n",
      "issue attention Facebook     18.0170      2.497      7.216      0.000      13.123      22.911\n",
      "issue attention Bundestag     0.1522      1.100      0.138      0.890      -2.004       2.309\n",
      "Social Media Nutzung         -0.0035      0.003     -1.062      0.288      -0.010       0.003\n",
      "Landtagswahlen                0.0310      0.091      0.339      0.734      -0.148       0.210\n",
      "topic_1                       0.5645      1.243      0.454      0.650      -1.872       3.001\n",
      "topic_2                      -1.3730      0.806     -1.703      0.089      -2.953       0.207\n",
      "topic_3                      -0.9263      0.866     -1.070      0.285      -2.624       0.771\n",
      "topic_4                       0.0490      1.024      0.048      0.962      -1.957       2.055\n",
      "topic_6                      -1.5462      0.791     -1.956      0.050      -3.096       0.003\n",
      "topic_7                      -2.5193      0.771     -3.269      0.001      -4.030      -1.009\n",
      "topic_8                      -2.1518      0.773     -2.784      0.005      -3.666      -0.637\n",
      "topic_10                     -2.3487      0.770     -3.049      0.002      -3.859      -0.839\n",
      "topic_11                     -2.5479      0.772     -3.299      0.001      -4.062      -1.034\n",
      "topic_12                     -2.5259      0.774     -3.262      0.001      -4.044      -1.008\n",
      "topic_13                     -2.1375      0.775     -2.760      0.006      -3.656      -0.619\n",
      "topic_14                     -2.9563      0.772     -3.830      0.000      -4.469      -1.444\n",
      "topic_15                     -2.1085      0.775     -2.720      0.007      -3.628      -0.589\n",
      "topic_16                     -2.6254      0.771     -3.404      0.001      -4.137      -1.114\n",
      "topic_17                     -2.8409      0.771     -3.682      0.000      -4.353      -1.329\n",
      "topic_18                     -2.4470      0.772     -3.171      0.002      -3.960      -0.934\n",
      "topic_19                     -2.6323      0.771     -3.412      0.001      -4.144      -1.120\n",
      "topic_20                     -3.5903      0.781     -4.595      0.000      -5.122      -2.059\n",
      "topic_21                     -2.6067      0.771     -3.379      0.001      -4.119      -1.095\n",
      "topic_22                     -2.6095      0.771     -3.383      0.001      -4.121      -1.098\n",
      "topic_23                     -3.0455      0.774     -3.935      0.000      -4.562      -1.529\n",
      "topic_24                     -3.0769      0.773     -3.979      0.000      -4.593      -1.561\n",
      "topic_25                     -3.0377      0.774     -3.927      0.000      -4.554      -1.522\n",
      "topic_29                     -3.4850      0.782     -4.459      0.000      -5.017      -1.953\n",
      "topic_30                     -3.4069      0.780     -4.367      0.000      -4.936      -1.878\n",
      "topic_34                     -3.2957      0.777     -4.239      0.000      -4.820      -1.772\n",
      "topic_36                     -3.8889      0.794     -4.896      0.000      -5.446      -2.332\n",
      "topic_37                     -3.8850      0.794     -4.891      0.000      -5.442      -2.328\n",
      "topic_40                     -3.4735      0.782     -4.440      0.000      -5.007      -1.940\n",
      "topic_41                     -3.9773      0.799     -4.979      0.000      -5.543      -2.412\n",
      "topic_43                     -4.2527      0.809     -5.257      0.000      -5.838      -2.667\n",
      "topic_54                     -4.4408      0.823     -5.393      0.000      -6.055      -2.827\n",
      "topic_68                     -4.4467      0.824     -5.397      0.000      -6.062      -2.832\n",
      "topic_75                     -4.0882      0.804     -5.087      0.000      -5.663      -2.513\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8017635284800336\n",
      "Pr√§zision: 0.7450365726227796\n",
      "Recall: 0.6440831074977417\n",
      "F1-Score: 0.6908914728682171\n",
      "Brier-Score: 0.1803479069935199\n",
      "Confusion-Matrix:\n",
      "[[924 244]\n",
      " [394 713]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529990\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2240\n",
      "Model:                          Logit   Df Residuals:                     2201\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2350\n",
      "Time:                        11:03:16   Log-Likelihood:                -1187.2\n",
      "converged:                       True   LL-Null:                       -1551.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                9.041e-129\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.2133      0.768      2.884      0.004       0.709       3.718\n",
      "issue attention Facebook     16.0225      2.489      6.437      0.000      11.144      20.901\n",
      "issue attention Bundestag     3.4426      1.309      2.629      0.009       0.877       6.009\n",
      "Social Media Nutzung          0.0010      0.003      0.283      0.777      -0.006       0.008\n",
      "Landtagswahlen                0.0094      0.099      0.095      0.924      -0.184       0.203\n",
      "topic_1                       0.6571      1.244      0.528      0.597      -1.780       3.094\n",
      "topic_2                      -1.4197      0.808     -1.758      0.079      -3.003       0.163\n",
      "topic_3                      -0.8324      0.866     -0.961      0.337      -2.530       0.865\n",
      "topic_4                       0.1873      1.023      0.183      0.855      -1.818       2.193\n",
      "topic_6                      -1.3923      0.795     -1.751      0.080      -2.951       0.166\n",
      "topic_7                      -2.4902      0.773     -3.220      0.001      -4.006      -0.974\n",
      "topic_8                      -2.1211      0.775     -2.738      0.006      -3.639      -0.603\n",
      "topic_10                     -2.3037      0.773     -2.982      0.003      -3.818      -0.789\n",
      "topic_11                     -2.3498      0.773     -3.039      0.002      -3.865      -0.834\n",
      "topic_12                     -2.3184      0.775     -2.992      0.003      -3.837      -0.800\n",
      "topic_13                     -1.9690      0.776     -2.537      0.011      -3.490      -0.448\n",
      "topic_14                     -2.8440      0.774     -3.676      0.000      -4.360      -1.328\n",
      "topic_15                     -1.9268      0.777     -2.480      0.013      -3.450      -0.404\n",
      "topic_16                     -2.4546      0.772     -3.179      0.001      -3.968      -0.941\n",
      "topic_17                     -2.7493      0.773     -3.558      0.000      -4.264      -1.235\n",
      "topic_18                     -2.3381      0.772     -3.027      0.002      -3.852      -0.824\n",
      "topic_19                     -2.4568      0.772     -3.181      0.001      -3.971      -0.943\n",
      "topic_20                     -3.5255      0.783     -4.500      0.000      -5.061      -1.990\n",
      "topic_21                     -2.4526      0.773     -3.172      0.002      -3.968      -0.937\n",
      "topic_22                     -2.4747      0.773     -3.202      0.001      -3.990      -0.960\n",
      "topic_23                     -2.9742      0.776     -3.834      0.000      -4.495      -1.454\n",
      "topic_24                     -3.0204      0.775     -3.896      0.000      -4.540      -1.501\n",
      "topic_25                     -2.9758      0.775     -3.839      0.000      -4.495      -1.457\n",
      "topic_29                     -3.4530      0.784     -4.402      0.000      -4.991      -1.915\n",
      "topic_30                     -3.3656      0.783     -4.298      0.000      -4.900      -1.831\n",
      "topic_34                     -3.2322      0.780     -4.146      0.000      -4.760      -1.704\n",
      "topic_36                     -3.7772      0.795     -4.749      0.000      -5.336      -2.218\n",
      "topic_37                     -3.7526      0.796     -4.717      0.000      -5.312      -2.193\n",
      "topic_40                     -3.3341      0.783     -4.257      0.000      -4.869      -1.799\n",
      "topic_41                     -3.9339      0.804     -4.893      0.000      -5.510      -2.358\n",
      "topic_43                     -4.1384      0.810     -5.109      0.000      -5.726      -2.551\n",
      "topic_54                     -4.4763      0.835     -5.361      0.000      -6.113      -2.840\n",
      "topic_68                     -4.3158      0.825     -5.233      0.000      -5.932      -2.699\n",
      "topic_75                     -3.9435      0.804     -4.903      0.000      -5.520      -2.367\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8051539688871161\n",
      "Pr√§zision: 0.7497371188222923\n",
      "Recall: 0.6541284403669725\n",
      "F1-Score: 0.6986771190592846\n",
      "Brier-Score: 0.178538625050786\n",
      "Confusion-Matrix:\n",
      "[[912 238]\n",
      " [377 713]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538367\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2205\n",
      "Model:                          Logit   Df Residuals:                     2166\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2229\n",
      "Time:                        11:03:16   Log-Likelihood:                -1187.1\n",
      "converged:                       True   LL-Null:                       -1527.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.873e-119\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.6936      0.766      3.515      0.000       1.192       4.195\n",
      "issue attention Facebook      8.9319      2.233      4.000      0.000       4.555      13.309\n",
      "issue attention Bundestag     3.2748      1.275      2.569      0.010       0.776       5.773\n",
      "Social Media Nutzung         -0.0007      0.003     -0.201      0.841      -0.007       0.006\n",
      "Landtagswahlen               -0.0185      0.109     -0.171      0.864      -0.231       0.194\n",
      "topic_1                       0.7028      1.241      0.566      0.571      -1.729       3.134\n",
      "topic_2                      -1.5828      0.804     -1.968      0.049      -3.159      -0.007\n",
      "topic_3                      -0.8697      0.862     -1.010      0.313      -2.558       0.819\n",
      "topic_4                       0.1511      1.020      0.148      0.882      -1.848       2.150\n",
      "topic_6                      -1.5930      0.793     -2.010      0.044      -3.147      -0.039\n",
      "topic_7                      -2.6748      0.771     -3.469      0.001      -4.186      -1.164\n",
      "topic_8                      -2.3793      0.773     -3.078      0.002      -3.894      -0.864\n",
      "topic_10                     -2.5780      0.771     -3.342      0.001      -4.090      -1.066\n",
      "topic_11                     -2.6458      0.771     -3.432      0.001      -4.157      -1.135\n",
      "topic_12                     -2.4611      0.771     -3.190      0.001      -3.973      -0.949\n",
      "topic_13                     -2.1580      0.775     -2.784      0.005      -3.677      -0.639\n",
      "topic_14                     -3.1002      0.772     -4.014      0.000      -4.614      -1.587\n",
      "topic_15                     -2.1095      0.776     -2.719      0.007      -3.630      -0.589\n",
      "topic_16                     -2.6475      0.770     -3.439      0.001      -4.156      -1.138\n",
      "topic_17                     -2.9793      0.771     -3.866      0.000      -4.490      -1.469\n",
      "topic_18                     -2.6315      0.771     -3.413      0.001      -4.143      -1.120\n",
      "topic_19                     -2.6924      0.771     -3.492      0.000      -4.204      -1.181\n",
      "topic_20                     -3.8038      0.780     -4.879      0.000      -5.332      -2.276\n",
      "topic_21                     -2.7508      0.771     -3.566      0.000      -4.263      -1.239\n",
      "topic_22                     -2.7880      0.771     -3.616      0.000      -4.299      -1.277\n",
      "topic_23                     -3.2518      0.774     -4.199      0.000      -4.769      -1.734\n",
      "topic_24                     -3.2824      0.774     -4.243      0.000      -4.799      -1.766\n",
      "topic_25                     -3.3237      0.775     -4.290      0.000      -4.842      -1.805\n",
      "topic_29                     -3.8326      0.785     -4.881      0.000      -5.372      -2.294\n",
      "topic_30                     -3.6634      0.782     -4.686      0.000      -5.196      -2.131\n",
      "topic_34                     -3.5924      0.780     -4.608      0.000      -5.120      -2.064\n",
      "topic_36                     -4.0757      0.794     -5.131      0.000      -5.632      -2.519\n",
      "topic_37                     -4.0655      0.794     -5.118      0.000      -5.622      -2.509\n",
      "topic_40                     -3.6372      0.782     -4.652      0.000      -5.170      -2.105\n",
      "topic_41                     -4.2486      0.803     -5.292      0.000      -5.822      -2.675\n",
      "topic_43                     -4.4248      0.807     -5.480      0.000      -6.007      -2.842\n",
      "topic_54                     -4.7902      0.834     -5.746      0.000      -6.424      -3.156\n",
      "topic_68                     -4.6311      0.823     -5.626      0.000      -6.245      -3.018\n",
      "topic_75                     -4.2550      0.803     -5.301      0.000      -5.828      -2.682\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7979429387154295\n",
      "Pr√§zision: 0.7283349561830574\n",
      "Recall: 0.6964618249534451\n",
      "F1-Score: 0.7120418848167539\n",
      "Brier-Score: 0.18213012591484737\n",
      "Confusion-Matrix:\n",
      "[[852 279]\n",
      " [326 748]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542423\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2170\n",
      "Model:                          Logit   Df Residuals:                     2131\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2171\n",
      "Time:                        11:03:16   Log-Likelihood:                -1177.1\n",
      "converged:                       True   LL-Null:                       -1503.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.918e-113\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.9972      0.766      3.913      0.000       1.496       4.499\n",
      "issue attention Facebook      6.5580      2.140      3.065      0.002       2.364      10.751\n",
      "issue attention Bundestag     1.4149      1.161      1.218      0.223      -0.861       3.691\n",
      "Social Media Nutzung         -0.0022      0.003     -0.649      0.516      -0.009       0.004\n",
      "Landtagswahlen                0.0457      0.123      0.371      0.711      -0.196       0.287\n",
      "topic_1                       0.6933      1.240      0.559      0.576      -1.736       3.123\n",
      "topic_2                      -1.6091      0.802     -2.007      0.045      -3.181      -0.037\n",
      "topic_3                      -0.9310      0.860     -1.083      0.279      -2.616       0.754\n",
      "topic_4                       0.0780      1.019      0.077      0.939      -1.920       2.076\n",
      "topic_6                      -1.5929      0.796     -2.000      0.045      -3.154      -0.032\n",
      "topic_7                      -2.7101      0.770     -3.519      0.000      -4.219      -1.201\n",
      "topic_8                      -2.5210      0.772     -3.265      0.001      -4.034      -1.008\n",
      "topic_10                     -2.7117      0.771     -3.518      0.000      -4.222      -1.201\n",
      "topic_11                     -2.8571      0.771     -3.705      0.000      -4.369      -1.346\n",
      "topic_12                     -2.5560      0.772     -3.311      0.001      -4.069      -1.043\n",
      "topic_13                     -2.3431      0.775     -3.024      0.002      -3.862      -0.824\n",
      "topic_14                     -3.2947      0.772     -4.265      0.000      -4.809      -1.781\n",
      "topic_15                     -2.2880      0.776     -2.950      0.003      -3.808      -0.768\n",
      "topic_16                     -2.7690      0.770     -3.595      0.000      -4.279      -1.259\n",
      "topic_17                     -3.1185      0.771     -4.046      0.000      -4.629      -1.608\n",
      "topic_18                     -2.7739      0.772     -3.595      0.000      -4.286      -1.261\n",
      "topic_19                     -2.9020      0.771     -3.762      0.000      -4.414      -1.390\n",
      "topic_20                     -4.0077      0.780     -5.136      0.000      -5.537      -2.478\n",
      "topic_21                     -2.8828      0.771     -3.740      0.000      -4.394      -1.372\n",
      "topic_22                     -2.9171      0.771     -3.783      0.000      -4.428      -1.406\n",
      "topic_23                     -3.4060      0.774     -4.399      0.000      -4.924      -1.888\n",
      "topic_24                     -3.4926      0.774     -4.511      0.000      -5.010      -1.975\n",
      "topic_25                     -3.4747      0.775     -4.484      0.000      -4.993      -1.956\n",
      "topic_29                     -3.9888      0.785     -5.080      0.000      -5.528      -2.450\n",
      "topic_30                     -3.8230      0.782     -4.892      0.000      -5.355      -2.291\n",
      "topic_34                     -3.8304      0.781     -4.903      0.000      -5.361      -2.299\n",
      "topic_36                     -4.2394      0.794     -5.337      0.000      -5.796      -2.683\n",
      "topic_37                     -4.2358      0.794     -5.332      0.000      -5.793      -2.679\n",
      "topic_40                     -3.8051      0.782     -4.864      0.000      -5.338      -2.272\n",
      "topic_41                     -4.4363      0.803     -5.525      0.000      -6.010      -2.863\n",
      "topic_43                     -4.5813      0.807     -5.676      0.000      -6.163      -2.999\n",
      "topic_54                     -4.9656      0.834     -5.956      0.000      -6.600      -3.332\n",
      "topic_68                     -4.8123      0.823     -5.845      0.000      -6.426      -3.199\n",
      "topic_75                     -4.4387      0.803     -5.529      0.000      -6.012      -2.865\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7916665604237476\n",
      "Pr√§zision: 0.7006673021925643\n",
      "Recall: 0.6940509915014165\n",
      "F1-Score: 0.6973434535104365\n",
      "Brier-Score: 0.18414490791117813\n",
      "Confusion-Matrix:\n",
      "[[797 314]\n",
      " [324 735]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543758\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2135\n",
      "Model:                          Logit   Df Residuals:                     2096\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2152\n",
      "Time:                        11:03:16   Log-Likelihood:                -1160.9\n",
      "converged:                       True   LL-Null:                       -1479.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                9.588e-110\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.8805      0.765      3.765      0.000       1.381       4.380\n",
      "issue attention Facebook      5.7091      2.106      2.711      0.007       1.581       9.837\n",
      "issue attention Bundestag     0.2890      1.129      0.256      0.798      -1.925       2.502\n",
      "Social Media Nutzung          0.0015      0.003      0.454      0.650      -0.005       0.008\n",
      "Landtagswahlen             3.144e-05      0.124      0.000      1.000      -0.242       0.242\n",
      "topic_1                       0.6767      1.239      0.546      0.585      -1.753       3.106\n",
      "topic_2                      -1.6132      0.801     -2.014      0.044      -3.183      -0.043\n",
      "topic_3                      -0.9752      0.860     -1.135      0.257      -2.660       0.710\n",
      "topic_4                       0.0141      1.019      0.014      0.989      -1.984       2.012\n",
      "topic_6                      -1.6533      0.796     -2.076      0.038      -3.214      -0.093\n",
      "topic_7                      -2.6956      0.771     -3.498      0.000      -4.206      -1.185\n",
      "topic_8                      -2.5288      0.773     -3.272      0.001      -4.044      -1.014\n",
      "topic_10                     -2.7801      0.771     -3.605      0.000      -4.292      -1.269\n",
      "topic_11                     -2.9838      0.772     -3.864      0.000      -4.497      -1.470\n",
      "topic_12                     -2.5933      0.774     -3.353      0.001      -4.109      -1.077\n",
      "topic_13                     -2.4526      0.775     -3.163      0.002      -3.972      -0.933\n",
      "topic_14                     -3.3389      0.773     -4.319      0.000      -4.854      -1.824\n",
      "topic_15                     -2.3140      0.777     -2.976      0.003      -3.838      -0.790\n",
      "topic_16                     -2.8123      0.772     -3.645      0.000      -4.325      -1.300\n",
      "topic_17                     -3.2417      0.772     -4.200      0.000      -4.754      -1.729\n",
      "topic_18                     -2.8951      0.773     -3.746      0.000      -4.410      -1.380\n",
      "topic_19                     -3.0251      0.772     -3.916      0.000      -4.539      -1.511\n",
      "topic_20                     -4.1474      0.783     -5.298      0.000      -5.682      -2.613\n",
      "topic_21                     -2.9263      0.772     -3.793      0.000      -4.438      -1.414\n",
      "topic_22                     -2.9632      0.772     -3.839      0.000      -4.476      -1.450\n",
      "topic_23                     -3.4692      0.775     -4.476      0.000      -4.988      -1.950\n",
      "topic_24                     -3.5503      0.775     -4.581      0.000      -5.069      -2.031\n",
      "topic_25                     -3.5368      0.776     -4.560      0.000      -5.057      -2.017\n",
      "topic_29                     -4.1416      0.788     -5.255      0.000      -5.686      -2.597\n",
      "topic_30                     -3.8887      0.782     -4.971      0.000      -5.422      -2.355\n",
      "topic_34                     -3.8985      0.782     -4.986      0.000      -5.431      -2.366\n",
      "topic_36                     -4.3091      0.795     -5.420      0.000      -5.867      -2.751\n",
      "topic_37                     -4.3115      0.795     -5.423      0.000      -5.870      -2.753\n",
      "topic_40                     -3.8816      0.783     -4.957      0.000      -5.417      -2.347\n",
      "topic_41                     -4.5198      0.804     -5.624      0.000      -6.095      -2.945\n",
      "topic_43                     -4.6499      0.808     -5.757      0.000      -6.233      -3.067\n",
      "topic_54                     -5.0444      0.834     -6.046      0.000      -6.680      -3.409\n",
      "topic_68                     -4.8926      0.824     -5.939      0.000      -6.507      -3.278\n",
      "topic_75                     -4.6340      0.809     -5.728      0.000      -6.220      -3.048\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7906780836590566\n",
      "Pr√§zision: 0.699047619047619\n",
      "Recall: 0.7030651340996169\n",
      "F1-Score: 0.7010506208213945\n",
      "Brier-Score: 0.18471449796948208\n",
      "Confusion-Matrix:\n",
      "[[775 316]\n",
      " [310 734]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541967\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2100\n",
      "Model:                          Logit   Df Residuals:                     2061\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2179\n",
      "Time:                        11:03:16   Log-Likelihood:                -1138.1\n",
      "converged:                       True   LL-Null:                       -1455.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.629e-109\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.9188      0.766      3.809      0.000       1.417       4.420\n",
      "issue attention Facebook      6.5474      2.158      3.034      0.002       2.318      10.777\n",
      "issue attention Bundestag     0.9592      1.161      0.826      0.409      -1.316       3.234\n",
      "Social Media Nutzung         -0.0010      0.003     -0.290      0.772      -0.008       0.006\n",
      "Landtagswahlen                0.0529      0.124      0.427      0.670      -0.190       0.296\n",
      "topic_1                       0.6863      1.240      0.553      0.580      -1.744       3.117\n",
      "topic_2                      -1.6020      0.802     -1.997      0.046      -3.174      -0.030\n",
      "topic_3                      -0.9683      0.861     -1.125      0.261      -2.655       0.718\n",
      "topic_4                       0.0446      1.020      0.044      0.965      -1.955       2.044\n",
      "topic_6                      -1.5026      0.802     -1.873      0.061      -3.075       0.070\n",
      "topic_7                      -2.5936      0.773     -3.357      0.001      -4.108      -1.079\n",
      "topic_8                      -2.4883      0.774     -3.216      0.001      -4.005      -0.972\n",
      "topic_10                     -2.6748      0.772     -3.463      0.001      -4.189      -1.161\n",
      "topic_11                     -2.9207      0.773     -3.779      0.000      -4.436      -1.406\n",
      "topic_12                     -2.4632      0.775     -3.177      0.001      -3.983      -0.944\n",
      "topic_13                     -2.3177      0.777     -2.983      0.003      -3.841      -0.795\n",
      "topic_14                     -3.2249      0.774     -4.168      0.000      -4.742      -1.708\n",
      "topic_15                     -2.2549      0.778     -2.898      0.004      -3.780      -0.730\n",
      "topic_16                     -2.7548      0.772     -3.567      0.000      -4.268      -1.241\n",
      "topic_17                     -3.1891      0.773     -4.127      0.000      -4.704      -1.675\n",
      "topic_18                     -2.8323      0.773     -3.662      0.000      -4.348      -1.317\n",
      "topic_19                     -2.8985      0.773     -3.749      0.000      -4.414      -1.383\n",
      "topic_20                     -4.1351      0.786     -5.264      0.000      -5.675      -2.596\n",
      "topic_21                     -2.8731      0.773     -3.719      0.000      -4.387      -1.359\n",
      "topic_22                     -2.8405      0.773     -3.675      0.000      -4.355      -1.326\n",
      "topic_23                     -3.3432      0.776     -4.310      0.000      -4.864      -1.823\n",
      "topic_24                     -3.4358      0.775     -4.431      0.000      -4.956      -1.916\n",
      "topic_25                     -3.4184      0.776     -4.405      0.000      -4.939      -1.897\n",
      "topic_29                     -4.0266      0.788     -5.107      0.000      -5.572      -2.481\n",
      "topic_30                     -3.8499      0.784     -4.908      0.000      -5.387      -2.313\n",
      "topic_34                     -3.7794      0.782     -4.831      0.000      -5.313      -2.246\n",
      "topic_36                     -4.1911      0.795     -5.270      0.000      -5.750      -2.632\n",
      "topic_37                     -4.2924      0.799     -5.372      0.000      -5.858      -2.726\n",
      "topic_40                     -3.8371      0.785     -4.887      0.000      -5.376      -2.298\n",
      "topic_41                     -4.3946      0.804     -5.466      0.000      -5.970      -2.819\n",
      "topic_43                     -4.5357      0.808     -5.614      0.000      -6.119      -2.952\n",
      "topic_54                     -4.9242      0.834     -5.901      0.000      -6.560      -3.289\n",
      "topic_68                     -4.7726      0.824     -5.792      0.000      -6.388      -3.158\n",
      "topic_75                     -4.5103      0.809     -5.573      0.000      -6.096      -2.924\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.793080590481445\n",
      "Pr√§zision: 0.703921568627451\n",
      "Recall: 0.6984435797665369\n",
      "F1-Score: 0.701171875\n",
      "Brier-Score: 0.18370561339915042\n",
      "Confusion-Matrix:\n",
      "[[770 302]\n",
      " [310 718]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539719\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2065\n",
      "Model:                          Logit   Df Residuals:                     2026\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2211\n",
      "Time:                        11:03:16   Log-Likelihood:                -1114.5\n",
      "converged:                       True   LL-Null:                       -1430.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.181e-109\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.7178      0.766      3.546      0.000       1.216       4.220\n",
      "issue attention Facebook      7.2380      2.196      3.296      0.001       2.934      11.542\n",
      "issue attention Bundestag     1.1770      1.183      0.995      0.320      -1.141       3.495\n",
      "Social Media Nutzung          0.0011      0.003      0.316      0.752      -0.006       0.008\n",
      "Landtagswahlen                0.0440      0.125      0.353      0.724      -0.200       0.288\n",
      "topic_1                       0.6776      1.241      0.546      0.585      -1.754       3.109\n",
      "topic_2                      -1.5812      0.803     -1.968      0.049      -3.156      -0.007\n",
      "topic_3                      -0.9782      0.861     -1.136      0.256      -2.666       0.710\n",
      "topic_4                       0.0463      1.020      0.045      0.964      -1.954       2.046\n",
      "topic_6                      -1.4857      0.803     -1.851      0.064      -3.059       0.088\n",
      "topic_7                      -2.5036      0.774     -3.233      0.001      -4.021      -0.986\n",
      "topic_8                      -2.3919      0.776     -3.084      0.002      -3.912      -0.872\n",
      "topic_10                     -2.5822      0.774     -3.336      0.001      -4.099      -1.065\n",
      "topic_11                     -2.8942      0.774     -3.740      0.000      -4.411      -1.377\n",
      "topic_12                     -2.3666      0.777     -3.045      0.002      -3.890      -0.843\n",
      "topic_13                     -2.2124      0.779     -2.840      0.005      -3.739      -0.686\n",
      "topic_14                     -3.2057      0.775     -4.136      0.000      -4.725      -1.687\n",
      "topic_15                     -2.2279      0.779     -2.861      0.004      -3.754      -0.702\n",
      "topic_16                     -2.6605      0.774     -3.439      0.001      -4.177      -1.144\n",
      "topic_17                     -3.1018      0.774     -4.010      0.000      -4.618      -1.586\n",
      "topic_18                     -2.8024      0.774     -3.619      0.000      -4.320      -1.285\n",
      "topic_19                     -2.8688      0.774     -3.706      0.000      -4.386      -1.351\n",
      "topic_20                     -4.1575      0.789     -5.270      0.000      -5.704      -2.611\n",
      "topic_21                     -2.8502      0.774     -3.684      0.000      -4.367      -1.334\n",
      "topic_22                     -2.8130      0.774     -3.635      0.000      -4.330      -1.296\n",
      "topic_23                     -3.2483      0.777     -4.182      0.000      -4.771      -1.726\n",
      "topic_24                     -3.3495      0.776     -4.316      0.000      -4.871      -1.828\n",
      "topic_25                     -3.4016      0.778     -4.375      0.000      -4.926      -1.878\n",
      "topic_29                     -4.0329      0.792     -5.095      0.000      -5.584      -2.481\n",
      "topic_30                     -3.7605      0.785     -4.790      0.000      -5.299      -2.222\n",
      "topic_34                     -3.7738      0.785     -4.810      0.000      -5.311      -2.236\n",
      "topic_36                     -4.1003      0.796     -5.151      0.000      -5.660      -2.540\n",
      "topic_37                     -4.2048      0.800     -5.259      0.000      -5.772      -2.638\n",
      "topic_40                     -3.8309      0.788     -4.863      0.000      -5.375      -2.287\n",
      "topic_41                     -4.3016      0.805     -5.346      0.000      -5.879      -2.725\n",
      "topic_43                     -4.4503      0.809     -5.504      0.000      -6.035      -2.866\n",
      "topic_54                     -4.8392      0.835     -5.796      0.000      -6.476      -3.203\n",
      "topic_68                     -4.8392      0.835     -5.796      0.000      -6.476      -3.203\n",
      "topic_75                     -4.4203      0.810     -5.459      0.000      -6.008      -2.833\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7955047564345136\n",
      "Pr√§zision: 0.7105263157894737\n",
      "Recall: 0.6689791873141725\n",
      "F1-Score: 0.6891271056661562\n",
      "Brier-Score: 0.18269185211648123\n",
      "Confusion-Matrix:\n",
      "[[781 275]\n",
      " [334 675]]\n"
     ]
    }
   ],
   "source": [
    "from stargazer.stargazer import Stargazer\n",
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_relativ_reduced, post_relativ_reduced, post_common,lag, social_media_usage)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretation mit Interaktionseffekt (ChatGPT lol)\n",
    "Vergleich der Modelle: Mit und ohne Interaktionseffekt\n",
    "\n",
    "Hier ist die Interpretation der beiden Modelle und des Einflusses des Interaktionseffekts:\n",
    "Modell ohne Interaktionseffekt\n",
    "Ergebnisse:\n",
    "\n",
    "    posts_relative (Koeffizient: 35.6484, p < 0.001):\n",
    "        Die relative Aufmerksamkeit eines Themas auf Social Media (am gleichen Tag) hat einen starken und signifikanten positiven Einfluss darauf, ob das Thema am n√§chsten Tag auf Social Media wieder auftaucht.\n",
    "        Einheitenanstieg von posts_relative (bei konstanten anderen Variablen) f√ºhrt zu einer erheblichen Erh√∂hung der Wahrscheinlichkeit, dass das Thema erneut auf Social Media erscheint.\n",
    "\n",
    "    reden_relativ (Koeffizient: 2.2387, p = 0.029):\n",
    "        Die relative Aufmerksamkeit eines Themas im Bundestag am Vortag hat ebenfalls einen signifikanten positiven Einfluss.\n",
    "        Dieser Effekt ist moderat im Vergleich zu posts_relative, bleibt aber relevant.\n",
    "\n",
    "    social_media_usage (Koeffizient: -0.0014, p = 0.634):\n",
    "        Die allgemeine Social-Media-Aktivit√§t ist nicht signifikant. Dies deutet darauf hin, dass die Gesamtzahl der Posts keinen direkten Einfluss auf die Wahrscheinlichkeit hat, ob ein Thema auf Social Media erscheint.\n",
    "\n",
    "Pseudo-R¬≤:\n",
    "\n",
    "    0.1357: Das Modell erkl√§rt etwa 13.57% der Varianz in der Zielvariable.\n",
    "\n",
    "Modell mit Interaktionseffekt\n",
    "Ergebnisse:\n",
    "\n",
    "    posts_relative (Koeffizient: 37.2377, p < 0.001):\n",
    "        Die Bedeutung von posts_relative bleibt signifikant und √§hnlich stark wie im Basismodell.\n",
    "\n",
    "    reden_relativ (Koeffizient: 3.6387, p = 0.004):\n",
    "        Der Effekt von reden_relativ bleibt positiv und signifikant, aber der Koeffizient ist gr√∂√üer als im Basismodell. Das deutet darauf hin, dass der Effekt von reden_relativ isoliert von seiner Interaktion mit posts_relative st√§rker wahrgenommen wird.\n",
    "\n",
    "    social_media_usage (Koeffizient: -0.0014, p = 0.633):\n",
    "        Wie im Basismodell kein signifikanter Einfluss.\n",
    "\n",
    "    interaction (Koeffizient: -51.4108, p = 0.045):\n",
    "        Der Interaktionseffekt ist signifikant und negativ.\n",
    "        Das bedeutet, dass die gleichzeitige hohe Aufmerksamkeit eines Themas sowohl im Bundestag als auch auf Social Media (am gleichen Tag) die Wahrscheinlichkeit senkt, dass dieses Thema am n√§chsten Tag erneut auf Social Media erscheint.\n",
    "\n",
    "Pseudo-R¬≤:\n",
    "\n",
    "    0.1366: Das Modell erkl√§rt etwa 13.66% der Varianz in der Zielvariable, ein geringf√ºgiger Anstieg im Vergleich zum Basismodell.\n",
    "\n",
    "Interpretation des Interaktionseffekts\n",
    "\n",
    "Der Interaktionseffekt legt nahe:\n",
    "\n",
    "    Wenn ein Thema gleichzeitig hohe Aufmerksamkeit in Bundestagsreden und auf Social Media erh√§lt, sinkt die Wahrscheinlichkeit, dass das Thema am n√§chsten Tag erneut auf Social Media erscheint.\n",
    "    Dies k√∂nnte darauf hindeuten, dass Themen, die bereits vollst√§ndig behandelt und ausgesch√∂pft wirken (auf beiden Plattformen), weniger relevant erscheinen und dadurch weniger erneut gepostet werden.\n",
    "\n",
    "Vergleich der Modellg√ºte\n",
    "\n",
    "    Pseudo-R¬≤:\n",
    "        Modell mit Interaktion: 0.1366\n",
    "        Basismodell: 0.1357\n",
    "        Der Anstieg ist minimal, was bedeutet, dass der Interaktionseffekt nur wenig zus√§tzliche Erkl√§rungskraft bietet.\n",
    "\n",
    "    Log-Likelihood:\n",
    "        Modell mit Interaktion: -1360.8\n",
    "        Basismodell: -1362.2\n",
    "        Ein besserer Wert im Modell mit Interaktion, was ebenfalls auf eine geringf√ºgige Verbesserung hindeutet.\n",
    "\n",
    "Fazit\n",
    "\n",
    "    Der Interaktionseffekt ist statistisch signifikant, seine zus√§tzliche Erkl√§rungskraft ist jedoch marginal.\n",
    "    Inhaltlich ist der Effekt interessant, da er zeigt, dass eine gleichzeitige hohe Aufmerksamkeit eines Themas auf beiden Plattformen zu einer \"S√§ttigung\" f√ºhren k√∂nnte.\n",
    "    Ob der Interaktionseffekt behalten werden sollte, h√§ngt davon ab, wie wichtig diese Interpretation f√ºr deine Fragestellung ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pro/ Contra Interaktionseffekt\n",
    "Die Integration des Interaktionseffekts ver√§ndert die Interpretation des Modells auf subtile, aber inhaltlich wichtige Weise. Hier ist eine Analyse, wie sich die Interpretation ver√§ndert, und was f√ºr oder gegen das Behalten des Interaktionseffekts spricht:\n",
    "\n",
    "---\n",
    "\n",
    "### **Ver√§nderte Interpretation im Vergleich zum Basismodell**\n",
    "\n",
    "#### **Basismodell:**\n",
    "1. **`posts_relative` und `reden_relativ`:**\n",
    "   - Beide Variablen haben einen positiven und signifikanten Einfluss.\n",
    "   - Sie wirken additiv: Ein h√∂herer Wert von `posts_relative` oder `reden_relativ` f√ºhrt unabh√§ngig voneinander zu einer erh√∂hten Wahrscheinlichkeit, dass ein Thema am n√§chsten Tag auf Social Media auftaucht.\n",
    "   - Es wird angenommen, dass die Effekte voneinander unabh√§ngig sind, d.h., sie beeinflussen sich nicht gegenseitig.\n",
    "\n",
    "#### **Modell mit Interaktionseffekt:**\n",
    "1. **`posts_relative` und `reden_relativ`:**\n",
    "   - Die Haupteffekte bleiben bestehen, jedoch ist die Interpretation nuancierter:\n",
    "     - **`reden_relativ`:** Der Effekt h√§ngt jetzt davon ab, wie hoch `posts_relative` ist (und umgekehrt). \n",
    "     - Ein h√∂herer Wert von `reden_relativ` hat einen st√§rkeren positiven Effekt, wenn `posts_relative` niedrig ist, verliert jedoch an Wirkung (und wird sogar negativ), wenn `posts_relative` hoch ist.\n",
    "\n",
    "2. **Interaktionseffekt (`interaction`):**\n",
    "   - Die negative Signifikanz des Interaktionseffekts bedeutet, dass die gleichzeitige hohe Aufmerksamkeit eines Themas in Bundestagsreden und auf Social Media die Wahrscheinlichkeit verringert, dass das Thema am n√§chsten Tag erneut auf Social Media auftaucht.\n",
    "   - Dies kann darauf hindeuten, dass Themen, die bereits umfassend behandelt wurden (sowohl im Parlament als auch auf Social Media), f√ºr den n√§chsten Tag an Relevanz verlieren.\n",
    "\n",
    "---\n",
    "\n",
    "### **Argumente f√ºr das Behalten des Interaktionseffekts**\n",
    "1. **Inhaltliche Plausibilit√§t:**\n",
    "   - Die Interaktion zwischen `reden_relativ` und `posts_relative` macht inhaltlich Sinn, wenn man annimmt, dass Themen, die in beiden Arenen gleichzeitig sehr pr√§sent sind, schneller an Aufmerksamkeit verlieren.\n",
    "   - Dies f√ºgt eine zus√§tzliche Dimension hinzu und reflektiert die komplexe Dynamik zwischen Parlament und Social Media.\n",
    "\n",
    "2. **Signifikanz:**\n",
    "   - Der Interaktionseffekt ist statistisch signifikant (p = 0.045), was darauf hindeutet, dass er einen echten Einfluss hat.\n",
    "\n",
    "3. **Zus√§tzliche Erkl√§rungskraft:**\n",
    "   - Obwohl der Anstieg im Pseudo-R¬≤ gering ist (von 0.1357 auf 0.1366), zeigt der Log-Likelihood-Vergleich eine Verbesserung des Modells mit Interaktion.\n",
    "   - Das Modell mit Interaktion ist also statistisch etwas besser angepasst.\n",
    "\n",
    "4. **Neue Perspektive:**\n",
    "   - Die Ber√ºcksichtigung des Interaktionseffekts erm√∂glicht es, die Daten aus einer anderen Perspektive zu betrachten. Das Modell kann spezifische Hypothesen testen, wie `posts_relative` und `reden_relativ` gemeinsam wirken.\n",
    "\n",
    "---\n",
    "\n",
    "### **Argumente gegen das Behalten des Interaktionseffekts**\n",
    "1. **Geringf√ºgige Verbesserung:**\n",
    "   - Die zus√§tzliche Erkl√§rungskraft des Interaktionseffekts ist minimal. Der Pseudo-R¬≤-Wert steigt nur marginal, was darauf hindeutet, dass der Effekt f√ºr die Gesamtmodellg√ºte nicht entscheidend ist.\n",
    "\n",
    "2. **Komplexit√§t:**\n",
    "   - Das Modell wird komplexer, und die Interpretation wird schwieriger. Der negative Interaktionseffekt kann f√ºr Leser oder Anwender, die mit der Datenanalyse weniger vertraut sind, verwirrend sein.\n",
    "   - Es k√∂nnte schwerer sein, die Ergebnisse praktisch oder politisch zu interpretieren.\n",
    "\n",
    "3. **Robustheit:**\n",
    "   - Die Signifikanz des Interaktionseffekts k√∂nnte in anderen Stichproben oder bei einer gr√∂√üeren Anzahl von Variablen verschwinden. Dies k√∂nnte darauf hindeuten, dass der Effekt nur in diesem spezifischen Datensatz relevant ist.\n",
    "\n",
    "---\n",
    "\n",
    "### **Fazit**\n",
    "- **F√ºr das Behalten:**\n",
    "   - Wenn das Zusammenspiel von `reden_relativ` und `posts_relative` ein zentraler Bestandteil deiner Forschungsfrage ist, sollte der Interaktionseffekt beibehalten werden, da er wertvolle Erkenntnisse liefert.\n",
    "   - Das Modell mit Interaktion ist inhaltlich reicher und erm√∂glicht es, differenzierte Hypothesen zu testen.\n",
    "\n",
    "- **F√ºr das Ignorieren:**\n",
    "   - Wenn die zus√§tzliche Komplexit√§t die praktische Anwendbarkeit oder Verst√§ndlichkeit des Modells erschwert, k√∂nnte das Basismodell ausreichen. Insbesondere, wenn der Fokus auf der individuellen Wirkung von `reden_relativ` und `posts_relative` liegt.\n",
    "\n",
    "Empfehlung: Falls der Interaktionseffekt inhaltlich Sinn ergibt und du ihn testen m√∂chtest, behalte ihn bei, aber stelle sicher, dass die Ergebnisse robust sind (z. B. durch Sensitivit√§tsanalysen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Einbezug Social Media Nutzung als Kontrollvariable\n",
    "Im Folgenden der Versuch, Social Media Nutzung miteinzubeziehen. Dabei wird diese zuerst generell miteinbezogen und dann nochmal auf die einzelnen Parteien aufgeschl√ºsselt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression aufgesplittet nach Parteien 2\n",
    "Leider funktioniert mein Vorgehen nicht, da so scheinbar zu viele erkl√§rende Variablen herangezogen werden und das Modell nicht richtig rechnen kann. Deswegen folgend der Split in eine Regression mit Partei postings und eine mit Parteireden und dann √úberpr√ºfung, welches der Modelle besser passt. F√ºhrt zu den gleichen Ergebnissen wie zuvor, weshalb anschlie√üend nochmal geschaut wird, wie man die Daten bereinigen kann, um St√∂rfaktoren zu entfernen.\n",
    "Update: Auch diese Vorgehen funktioniert leider nicht, weshalb ich das jetzt erstmal nicht mehr weiterverfolge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufteilen der Daten nach einzelnen Parteien\n",
    "Hier bilde ich jetzt Subdatens√§tze f√ºr die einzelnen Parteien und f√ºhre f√ºr diese einzelne Regressionen durch. Prinzipiell muss ich nochmal nach Kontrollvariablen schauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Die Funktion aufrufen\n",
    "#post_party_relativ = post_party_relativ.drop(columns=['relative_post_Bundesregierung', 'relative_post_CSU'])\n",
    "# log_reg_single_party(post_party_relativ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AfD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\1352934036.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_afd[\"date\"] = pd.to_datetime(subset_reden_afd[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\1352934036.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_afd[\"date\"] = pd.to_datetime(subset_posts_afd[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_afd = subset_posts[subset_posts[\"partei\"] == \"AfD\"]\n",
    "subset_reden_afd = subset_reden[subset_reden[\"partei\"] == \"AfD\"]\n",
    "social_media_usage_afd = subset_posts_afd.groupby('date').size()\n",
    "subset_reden_afd[\"date\"] = pd.to_datetime(subset_reden_afd[\"date\"])\n",
    "subset_posts_afd[\"date\"] = pd.to_datetime(subset_posts_afd[\"date\"])\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_afd = subset_reden_afd.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_afd = subset_posts_afd.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "reden_komplexit√§t_t√§glich_afd = subset_reden_afd.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_afd = subset_posts_afd.groupby('date')['komplexit√§t'].sum()\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_afd = redethemen_t√§glich_afd.index.intersection(postthemen_t√§glich_afd.index)\n",
    "redethemen_t√§glich_aligned_afd = redethemen_t√§glich_afd.loc[common_dates_afd]\n",
    "postthemen_t√§glich_aligned_afd = postthemen_t√§glich_afd.loc[common_dates_afd]\n",
    "rede_komplex_afd = reden_komplexit√§t_t√§glich_afd.loc[common_dates_afd]\n",
    "posts_komplex_afd = posts_komplexit√§t_t√§glich_afd.loc[common_dates_afd]\n",
    "# Zielvariable: Facebookposts um einen Tag in die Zukunft gelaggt\n",
    "# # posts_shifted enth√§lt die Facebookposts mit lag t+1, Die Daten hier sind zwar die gleichen wie in den anderen Dataframes,\n",
    "# # die Werte jedoch die vom Vortag, weshalb die Analyse zul√§ssig ist\n",
    "# posts_shifted_afd=postthemen_t√§glich_aligned_afd.shift().dropna()\n",
    "# # Erneute Anpassung des Datums\n",
    "# common_dates2_afd = redethemen_t√§glich_afd.index.intersection(posts_shifted_afd.index)\n",
    "# redethemen_t√§glich_aligned_afd = redethemen_t√§glich_afd.loc[common_dates2]\n",
    "# postthemen_t√§glich_aligned_afd = postthemen_t√§glich_afd.loc[common_dates2]\n",
    "# rede_common_afd, post_common_afd = filter_common_topics(redethemen_t√§glich_aligned_afd, postthemen_t√§glich_aligned_afd)\n",
    "# posts_shifted_common_afd, post_common_afd = filter_common_topics(post_common_afd, posts_shifted_afd)\n",
    "# # Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "# reden_relativ_afd =  rede_common_afd.div(rede_common_afd.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "# post_relativ_afd = post_common_afd.div(post_common_afd.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 34, 35, 36, 37, 40, 43, 44, 46, 51, 52, 53, 54, 56, 58, 59, 61, 63, 64, 65, 68, 69, 70, 72, 74, 75, 77, 78, 84, 88, 90, 91, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 6, 7, 8, 10, 14, 15, 29}\n"
     ]
    }
   ],
   "source": [
    "rede_common_afd, post_common_afd = filter_common_topics(redethemen_t√§glich_aligned_afd, postthemen_t√§glich_aligned_afd)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_afd =  rede_common_afd.div(rede_common_afd.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_afd = post_common_afd.div(post_common_afd.sum(axis=1), axis=0)\n",
    "reden_relativ_afd_red = remove_near_constant(reden_relativ_afd)\n",
    "post_relativ_afd_red = remove_near_constant(post_relativ_afd)\n",
    "rede_reduced_afd, post_reduced_afd = filter_common_topics(reden_relativ_afd_red, post_relativ_afd_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.374519\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3965\n",
      "Model:                          Logit   Df Residuals:                     3962\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1704\n",
      "Time:                        11:03:16   Log-Likelihood:                -1485.0\n",
      "converged:                       True   LL-Null:                       -1790.0\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.502e-133\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -2.1491      0.055    -39.036      0.000      -2.257      -2.041\n",
      "posts_relative    21.0332      1.130     18.610      0.000      18.818      23.248\n",
      "reden_relativ      2.6245      0.654      4.016      0.000       1.344       3.905\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM(reden_relativ_afd,post_relativ_afd, post_common_afd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.488912\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      766\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2920\n",
      "Time:                        11:03:17   Log-Likelihood:                -381.35\n",
      "converged:                       True   LL-Null:                       -538.64\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.125e-59\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              1.3713      0.394      3.478      0.001       0.598       2.144\n",
      "posts_relative     4.8101      1.714      2.806      0.005       1.451       8.169\n",
      "reden_relativ     -0.1734      0.780     -0.222      0.824      -1.702       1.355\n",
      "topic_1           -0.8530      0.455     -1.877      0.061      -1.744       0.038\n",
      "topic_2           -1.5296      0.447     -3.419      0.001      -2.406      -0.653\n",
      "topic_3            0.0405      0.548      0.074      0.941      -1.034       1.115\n",
      "topic_4            0.4864      0.595      0.817      0.414      -0.680       1.653\n",
      "topic_6           -2.2093      0.464     -4.759      0.000      -3.119      -1.299\n",
      "topic_7           -1.8035      0.450     -4.006      0.000      -2.686      -0.921\n",
      "topic_8           -2.1458      0.461     -4.658      0.000      -3.049      -1.243\n",
      "topic_10          -3.3745      0.540     -6.247      0.000      -4.433      -2.316\n",
      "topic_14          -3.2276      0.529     -6.106      0.000      -4.264      -2.192\n",
      "topic_15          -2.9093      0.501     -5.803      0.000      -3.892      -1.927\n",
      "topic_29          -3.2409      0.528     -6.137      0.000      -4.276      -2.206\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM_fixed_effects(rede_reduced_afd,post_relativ_afd, post_common_afd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487541\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      764\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2940\n",
      "Time:                        11:03:17   Log-Likelihood:                -380.28\n",
      "converged:                       True   LL-Null:                       -538.64\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.855e-58\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.5478      0.562      2.754      0.006       0.446       2.649\n",
      "issue attention Facebook      4.7035      1.727      2.723      0.006       1.318       8.089\n",
      "issue attention Bundestag    -0.1011      0.785     -0.129      0.897      -1.639       1.437\n",
      "Social Media Nutzung         -0.0044      0.018     -0.242      0.809      -0.040       0.032\n",
      "Landtagswahlen               -0.2338      0.168     -1.395      0.163      -0.562       0.095\n",
      "topic_1                      -0.8557      0.455     -1.879      0.060      -1.748       0.037\n",
      "topic_2                      -1.5422      0.448     -3.440      0.001      -2.421      -0.664\n",
      "topic_3                       0.0565      0.549      0.103      0.918      -1.019       1.132\n",
      "topic_4                       0.4996      0.596      0.839      0.402      -0.668       1.667\n",
      "topic_6                      -2.2200      0.465     -4.774      0.000      -3.131      -1.308\n",
      "topic_7                      -1.8160      0.451     -4.024      0.000      -2.701      -0.931\n",
      "topic_8                      -2.1589      0.462     -4.675      0.000      -3.064      -1.254\n",
      "topic_10                     -3.3909      0.541     -6.264      0.000      -4.452      -2.330\n",
      "topic_14                     -3.2438      0.530     -6.122      0.000      -4.282      -2.205\n",
      "topic_15                     -2.9220      0.503     -5.815      0.000      -3.907      -1.937\n",
      "topic_29                     -3.2568      0.529     -6.154      0.000      -4.294      -2.220\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8382722250125565\n",
      "Pr√§zision: 0.81\n",
      "Recall: 0.6712707182320442\n",
      "F1-Score: 0.7341389728096677\n",
      "Brier-Score: 0.15880956358290138\n",
      "Confusion-Matrix:\n",
      "[[361  57]\n",
      " [119 243]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x168b28ffc80>,\n",
       " 0.8382722250125565,\n",
       " 0.7341389728096677)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_FE_control(rede_reduced_afd,post_reduced_afd, post_common_afd,1,social_media_usage_afd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression f√ºr Lag 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487541\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      764\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2940\n",
      "Time:                        11:03:17   Log-Likelihood:                -380.28\n",
      "converged:                       True   LL-Null:                       -538.64\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.855e-58\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.5478      0.562      2.754      0.006       0.446       2.649\n",
      "issue attention Facebook      4.7035      1.727      2.723      0.006       1.318       8.089\n",
      "issue attention Bundestag    -0.1011      0.785     -0.129      0.897      -1.639       1.437\n",
      "Social Media Nutzung         -0.0044      0.018     -0.242      0.809      -0.040       0.032\n",
      "Landtagswahlen               -0.2338      0.168     -1.395      0.163      -0.562       0.095\n",
      "topic_1                      -0.8557      0.455     -1.879      0.060      -1.748       0.037\n",
      "topic_2                      -1.5422      0.448     -3.440      0.001      -2.421      -0.664\n",
      "topic_3                       0.0565      0.549      0.103      0.918      -1.019       1.132\n",
      "topic_4                       0.4996      0.596      0.839      0.402      -0.668       1.667\n",
      "topic_6                      -2.2200      0.465     -4.774      0.000      -3.131      -1.308\n",
      "topic_7                      -1.8160      0.451     -4.024      0.000      -2.701      -0.931\n",
      "topic_8                      -2.1589      0.462     -4.675      0.000      -3.064      -1.254\n",
      "topic_10                     -3.3909      0.541     -6.264      0.000      -4.452      -2.330\n",
      "topic_14                     -3.2438      0.530     -6.122      0.000      -4.282      -2.205\n",
      "topic_15                     -2.9220      0.503     -5.815      0.000      -3.907      -1.937\n",
      "topic_29                     -3.2568      0.529     -6.154      0.000      -4.294      -2.220\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8382722250125565\n",
      "Pr√§zision: 0.81\n",
      "Recall: 0.6712707182320442\n",
      "F1-Score: 0.7341389728096677\n",
      "Brier-Score: 0.15880956358290138\n",
      "Confusion-Matrix:\n",
      "[[361  57]\n",
      " [119 243]]\n",
      "\n",
      "Regression f√ºr Lag 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.478863\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  768\n",
      "Model:                          Logit   Df Residuals:                      752\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.3067\n",
      "Time:                        11:03:17   Log-Likelihood:                -367.77\n",
      "converged:                       True   LL-Null:                       -530.44\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.966e-60\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.7108      0.582      2.940      0.003       0.570       2.851\n",
      "issue attention Facebook      7.2776      1.911      3.809      0.000       3.533      11.022\n",
      "issue attention Bundestag     0.5855      0.836      0.700      0.484      -1.053       2.224\n",
      "Social Media Nutzung         -0.0210      0.019     -1.118      0.264      -0.058       0.016\n",
      "Landtagswahlen               -0.0788      0.183     -0.430      0.667      -0.438       0.280\n",
      "topic_1                      -0.9143      0.473     -1.931      0.053      -1.842       0.014\n",
      "topic_2                      -1.5685      0.469     -3.344      0.001      -2.488      -0.649\n",
      "topic_3                      -0.1758      0.567     -0.310      0.757      -1.288       0.936\n",
      "topic_4                       0.3367      0.611      0.551      0.582      -0.862       1.535\n",
      "topic_6                      -2.0871      0.483     -4.325      0.000      -3.033      -1.141\n",
      "topic_7                      -1.7787      0.470     -3.783      0.000      -2.700      -0.857\n",
      "topic_8                      -2.1317      0.481     -4.434      0.000      -3.074      -1.189\n",
      "topic_10                     -3.2646      0.555     -5.886      0.000      -4.352      -2.178\n",
      "topic_14                     -3.1065      0.544     -5.715      0.000      -4.172      -2.041\n",
      "topic_15                     -2.7865      0.517     -5.392      0.000      -3.799      -1.774\n",
      "topic_29                     -3.2555      0.555     -5.865      0.000      -4.343      -2.168\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8472469279682675\n",
      "Pr√§zision: 0.8092105263157895\n",
      "Recall: 0.6890756302521008\n",
      "F1-Score: 0.7443267776096822\n",
      "Brier-Score: 0.15553482671685506\n",
      "Confusion-Matrix:\n",
      "[[353  58]\n",
      " [111 246]]\n",
      "\n",
      "Regression f√ºr Lag 3:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487074\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  756\n",
      "Model:                          Logit   Df Residuals:                      740\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2949\n",
      "Time:                        11:03:17   Log-Likelihood:                -368.23\n",
      "converged:                       True   LL-Null:                       -522.23\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.212e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.2301      0.589      2.088      0.037       0.076       2.384\n",
      "issue attention Facebook      4.5962      1.806      2.545      0.011       1.057       8.136\n",
      "issue attention Bundestag     1.1882      0.843      1.410      0.159      -0.464       2.840\n",
      "Social Media Nutzung          0.0088      0.020      0.451      0.652      -0.030       0.047\n",
      "Landtagswahlen               -0.2046      0.208     -0.982      0.326      -0.613       0.204\n",
      "topic_1                      -0.9736      0.472     -2.063      0.039      -1.898      -0.049\n",
      "topic_2                      -1.6998      0.469     -3.627      0.000      -2.618      -0.781\n",
      "topic_3                      -0.0465      0.563     -0.083      0.934      -1.150       1.057\n",
      "topic_4                       0.4085      0.608      0.672      0.502      -0.783       1.600\n",
      "topic_6                      -2.1916      0.483     -4.534      0.000      -3.139      -1.244\n",
      "topic_7                      -1.8716      0.471     -3.975      0.000      -2.794      -0.949\n",
      "topic_8                      -2.2379      0.482     -4.642      0.000      -3.183      -1.293\n",
      "topic_10                     -3.3920      0.557     -6.095      0.000      -4.483      -2.301\n",
      "topic_14                     -3.2466      0.545     -5.959      0.000      -4.314      -2.179\n",
      "topic_15                     -2.9038      0.518     -5.608      0.000      -3.919      -1.889\n",
      "topic_29                     -3.3805      0.556     -6.080      0.000      -4.470      -2.291\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.840557493249325\n",
      "Pr√§zision: 0.8082191780821918\n",
      "Recall: 0.6704545454545454\n",
      "F1-Score: 0.7329192546583851\n",
      "Brier-Score: 0.1591931620204858\n",
      "Confusion-Matrix:\n",
      "[[348  56]\n",
      " [116 236]]\n",
      "\n",
      "Regression f√ºr Lag 4:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497616\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  744\n",
      "Model:                          Logit   Df Residuals:                      728\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2799\n",
      "Time:                        11:03:17   Log-Likelihood:                -370.23\n",
      "converged:                       True   LL-Null:                       -514.15\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.860e-52\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.1148      0.593      3.569      0.000       0.953       3.276\n",
      "issue attention Facebook      0.2119      1.634      0.130      0.897      -2.990       3.414\n",
      "issue attention Bundestag     0.6354      0.830      0.765      0.444      -0.992       2.263\n",
      "Social Media Nutzung         -0.0128      0.019     -0.662      0.508      -0.051       0.025\n",
      "Landtagswahlen                0.0277      0.230      0.121      0.904      -0.422       0.478\n",
      "topic_1                      -1.1403      0.471     -2.422      0.015      -2.063      -0.218\n",
      "topic_2                      -1.7936      0.465     -3.857      0.000      -2.705      -0.882\n",
      "topic_3                       0.1520      0.562      0.270      0.787      -0.950       1.254\n",
      "topic_4                       0.5402      0.607      0.891      0.373      -0.649       1.729\n",
      "topic_6                      -2.5237      0.486     -5.192      0.000      -3.476      -1.571\n",
      "topic_7                      -2.0905      0.472     -4.430      0.000      -3.015      -1.166\n",
      "topic_8                      -2.5385      0.484     -5.244      0.000      -3.487      -1.590\n",
      "topic_10                     -3.7654      0.559     -6.738      0.000      -4.861      -2.670\n",
      "topic_14                     -3.6287      0.547     -6.634      0.000      -4.701      -2.557\n",
      "topic_15                     -3.2740      0.520     -6.293      0.000      -4.294      -2.254\n",
      "topic_29                     -3.7581      0.558     -6.730      0.000      -4.853      -2.664\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8322992859630791\n",
      "Pr√§zision: 0.7817589576547231\n",
      "Recall: 0.6896551724137931\n",
      "F1-Score: 0.732824427480916\n",
      "Brier-Score: 0.16264679435974463\n",
      "Confusion-Matrix:\n",
      "[[329  67]\n",
      " [108 240]]\n",
      "\n",
      "Regression f√ºr Lag 5:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496167\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  732\n",
      "Model:                          Logit   Df Residuals:                      716\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2823\n",
      "Time:                        11:03:17   Log-Likelihood:                -363.19\n",
      "converged:                       True   LL-Null:                       -506.06\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.115e-52\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.8630      0.594      3.138      0.002       0.700       3.026\n",
      "issue attention Facebook      3.4676      1.770      1.959      0.050      -0.001       6.937\n",
      "issue attention Bundestag     1.1327      0.868      1.305      0.192      -0.568       2.833\n",
      "Social Media Nutzung         -0.0188      0.020     -0.958      0.338      -0.057       0.020\n",
      "Landtagswahlen                0.0855      0.231      0.371      0.711      -0.366       0.537\n",
      "topic_1                      -1.0359      0.472     -2.194      0.028      -1.961      -0.110\n",
      "topic_2                      -1.6277      0.469     -3.473      0.001      -2.546      -0.709\n",
      "topic_3                      -0.0293      0.565     -0.052      0.959      -1.136       1.077\n",
      "topic_4                       0.4242      0.609      0.697      0.486      -0.770       1.618\n",
      "topic_6                      -2.2013      0.484     -4.544      0.000      -3.151      -1.252\n",
      "topic_7                      -1.8531      0.472     -3.923      0.000      -2.779      -0.927\n",
      "topic_8                      -2.2420      0.483     -4.644      0.000      -3.188      -1.296\n",
      "topic_10                     -3.4131      0.558     -6.118      0.000      -4.507      -2.320\n",
      "topic_14                     -3.2781      0.545     -6.010      0.000      -4.347      -2.209\n",
      "topic_15                     -2.9289      0.518     -5.649      0.000      -3.945      -1.913\n",
      "topic_29                     -3.4118      0.556     -6.132      0.000      -4.502      -2.321\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8346881742987293\n",
      "Pr√§zision: 0.8013468013468014\n",
      "Recall: 0.6918604651162791\n",
      "F1-Score: 0.7425897035881436\n",
      "Brier-Score: 0.1621544238689221\n",
      "Confusion-Matrix:\n",
      "[[329  59]\n",
      " [106 238]]\n",
      "\n",
      "Regression f√ºr Lag 6:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.498443\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  720\n",
      "Model:                          Logit   Df Residuals:                      704\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2791\n",
      "Time:                        11:03:17   Log-Likelihood:                -358.88\n",
      "converged:                       True   LL-Null:                       -497.84\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.124e-50\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.4096      0.601      2.347      0.019       0.232       2.587\n",
      "issue attention Facebook      1.4305      1.694      0.845      0.398      -1.889       4.750\n",
      "issue attention Bundestag     0.6186      0.842      0.735      0.463      -1.032       2.269\n",
      "Social Media Nutzung          0.0198      0.020      1.013      0.311      -0.019       0.058\n",
      "Landtagswahlen               -0.1267      0.231     -0.548      0.584      -0.580       0.326\n",
      "topic_1                      -1.2615      0.490     -2.572      0.010      -2.223      -0.300\n",
      "topic_2                      -1.8519      0.486     -3.814      0.000      -2.803      -0.900\n",
      "topic_3                      -0.0812      0.581     -0.140      0.889      -1.220       1.057\n",
      "topic_4                       0.3340      0.623      0.536      0.592      -0.887       1.555\n",
      "topic_6                      -2.4895      0.504     -4.940      0.000      -3.477      -1.502\n",
      "topic_7                      -2.0629      0.491     -4.199      0.000      -3.026      -1.100\n",
      "topic_8                      -2.5101      0.502     -5.000      0.000      -3.494      -1.526\n",
      "topic_10                     -3.7295      0.575     -6.485      0.000      -4.857      -2.602\n",
      "topic_14                     -3.5922      0.563     -6.382      0.000      -4.695      -2.489\n",
      "topic_15                     -3.3493      0.544     -6.160      0.000      -4.415      -2.284\n",
      "topic_29                     -3.7269      0.574     -6.497      0.000      -4.851      -2.603\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8336314155420839\n",
      "Pr√§zision: 0.7796610169491526\n",
      "Recall: 0.6784660766961652\n",
      "F1-Score: 0.7255520504731862\n",
      "Brier-Score: 0.16373320667622052\n",
      "Confusion-Matrix:\n",
      "[[316  65]\n",
      " [109 230]]\n",
      "\n",
      "Regression f√ºr Lag 7:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497060\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  708\n",
      "Model:                          Logit   Df Residuals:                      692\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2811\n",
      "Time:                        11:03:17   Log-Likelihood:                -351.92\n",
      "converged:                       True   LL-Null:                       -489.50\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.903e-50\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.3423      0.608      2.208      0.027       0.151       2.534\n",
      "issue attention Facebook      0.5105      1.734      0.294      0.768      -2.888       3.909\n",
      "issue attention Bundestag     2.2575      0.905      2.494      0.013       0.483       4.032\n",
      "Social Media Nutzung          0.0196      0.020      0.983      0.326      -0.019       0.059\n",
      "Landtagswahlen                0.0054      0.231      0.023      0.981      -0.447       0.457\n",
      "topic_1                      -1.2707      0.493     -2.579      0.010      -2.236      -0.305\n",
      "topic_2                      -1.9587      0.492     -3.980      0.000      -2.923      -0.994\n",
      "topic_3                      -0.0080      0.585     -0.014      0.989      -1.156       1.139\n",
      "topic_4                       0.4132      0.626      0.660      0.509      -0.813       1.639\n",
      "topic_6                      -2.5306      0.508     -4.977      0.000      -3.527      -1.534\n",
      "topic_7                      -2.0949      0.497     -4.216      0.000      -3.069      -1.121\n",
      "topic_8                      -2.5103      0.507     -4.953      0.000      -3.504      -1.517\n",
      "topic_10                     -3.7184      0.578     -6.429      0.000      -4.852      -2.585\n",
      "topic_14                     -3.5845      0.566     -6.336      0.000      -4.693      -2.476\n",
      "topic_15                     -3.3087      0.546     -6.062      0.000      -4.378      -2.239\n",
      "topic_29                     -3.6933      0.576     -6.416      0.000      -4.822      -2.565\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8332572572572573\n",
      "Pr√§zision: 0.8042704626334519\n",
      "Recall: 0.6786786786786787\n",
      "F1-Score: 0.7361563517915309\n",
      "Brier-Score: 0.1620826761395232\n",
      "Confusion-Matrix:\n",
      "[[320  55]\n",
      " [107 226]]\n"
     ]
    }
   ],
   "source": [
    "# Schleife f√ºr logistische Regression mit Lags von -7 bis 7\n",
    "for n in range(1, 8):  # Einschlie√ülich 1 bis 7\n",
    "    try:\n",
    "        print(f\"\\nRegression f√ºr Lag {n}:\")\n",
    "        log_reg_FE_control(rede_reduced_afd, post_reduced_afd, post_common_afd,n, social_media_usage_afd)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Lag {n}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487541\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      764\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2940\n",
      "Time:                        11:03:17   Log-Likelihood:                -380.28\n",
      "converged:                       True   LL-Null:                       -538.64\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.855e-58\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.5478      0.562      2.754      0.006       0.446       2.649\n",
      "issue attention Facebook      4.7035      1.727      2.723      0.006       1.318       8.089\n",
      "issue attention Bundestag    -0.1011      0.785     -0.129      0.897      -1.639       1.437\n",
      "Social Media Nutzung         -0.0044      0.018     -0.242      0.809      -0.040       0.032\n",
      "Landtagswahlen               -0.2338      0.168     -1.395      0.163      -0.562       0.095\n",
      "topic_1                      -0.8557      0.455     -1.879      0.060      -1.748       0.037\n",
      "topic_2                      -1.5422      0.448     -3.440      0.001      -2.421      -0.664\n",
      "topic_3                       0.0565      0.549      0.103      0.918      -1.019       1.132\n",
      "topic_4                       0.4996      0.596      0.839      0.402      -0.668       1.667\n",
      "topic_6                      -2.2200      0.465     -4.774      0.000      -3.131      -1.308\n",
      "topic_7                      -1.8160      0.451     -4.024      0.000      -2.701      -0.931\n",
      "topic_8                      -2.1589      0.462     -4.675      0.000      -3.064      -1.254\n",
      "topic_10                     -3.3909      0.541     -6.264      0.000      -4.452      -2.330\n",
      "topic_14                     -3.2438      0.530     -6.122      0.000      -4.282      -2.205\n",
      "topic_15                     -2.9220      0.503     -5.815      0.000      -3.907      -1.937\n",
      "topic_29                     -3.2568      0.529     -6.154      0.000      -4.294      -2.220\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8382722250125565\n",
      "Pr√§zision: 0.81\n",
      "Recall: 0.6712707182320442\n",
      "F1-Score: 0.7341389728096677\n",
      "Brier-Score: 0.15880956358290138\n",
      "Confusion-Matrix:\n",
      "[[361  57]\n",
      " [119 243]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x168b725a6c0>,\n",
       " 0.8382722250125565,\n",
       " 0.7341389728096677)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Anteil AfD an gesamten Postingverhalten\n",
    "# Wie sinnvoll? Der meiste Output kam eh von der AfD, dass hier dann hohe Werte rauskommen ist klar\n",
    "log_reg_FE_control(rede_reduced_afd,post_reduced_afd, post_common_afd,1,social_media_usage_afd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487541\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      764\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2940\n",
      "Time:                        11:03:17   Log-Likelihood:                -380.28\n",
      "converged:                       True   LL-Null:                       -538.64\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.855e-58\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.5478      0.562      2.754      0.006       0.446       2.649\n",
      "issue attention Facebook      4.7035      1.727      2.723      0.006       1.318       8.089\n",
      "issue attention Bundestag    -0.1011      0.785     -0.129      0.897      -1.639       1.437\n",
      "Social Media Nutzung         -0.0044      0.018     -0.242      0.809      -0.040       0.032\n",
      "Landtagswahlen               -0.2338      0.168     -1.395      0.163      -0.562       0.095\n",
      "topic_1                      -0.8557      0.455     -1.879      0.060      -1.748       0.037\n",
      "topic_2                      -1.5422      0.448     -3.440      0.001      -2.421      -0.664\n",
      "topic_3                       0.0565      0.549      0.103      0.918      -1.019       1.132\n",
      "topic_4                       0.4996      0.596      0.839      0.402      -0.668       1.667\n",
      "topic_6                      -2.2200      0.465     -4.774      0.000      -3.131      -1.308\n",
      "topic_7                      -1.8160      0.451     -4.024      0.000      -2.701      -0.931\n",
      "topic_8                      -2.1589      0.462     -4.675      0.000      -3.064      -1.254\n",
      "topic_10                     -3.3909      0.541     -6.264      0.000      -4.452      -2.330\n",
      "topic_14                     -3.2438      0.530     -6.122      0.000      -4.282      -2.205\n",
      "topic_15                     -2.9220      0.503     -5.815      0.000      -3.907      -1.937\n",
      "topic_29                     -3.2568      0.529     -6.154      0.000      -4.294      -2.220\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8382722250125565\n",
      "Pr√§zision: 0.81\n",
      "Recall: 0.6712707182320442\n",
      "F1-Score: 0.7341389728096677\n",
      "Brier-Score: 0.15880956358290138\n",
      "Confusion-Matrix:\n",
      "[[361  57]\n",
      " [119 243]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.478863\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  768\n",
      "Model:                          Logit   Df Residuals:                      752\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.3067\n",
      "Time:                        11:03:17   Log-Likelihood:                -367.77\n",
      "converged:                       True   LL-Null:                       -530.44\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.966e-60\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.7108      0.582      2.940      0.003       0.570       2.851\n",
      "issue attention Facebook      7.2776      1.911      3.809      0.000       3.533      11.022\n",
      "issue attention Bundestag     0.5855      0.836      0.700      0.484      -1.053       2.224\n",
      "Social Media Nutzung         -0.0210      0.019     -1.118      0.264      -0.058       0.016\n",
      "Landtagswahlen               -0.0788      0.183     -0.430      0.667      -0.438       0.280\n",
      "topic_1                      -0.9143      0.473     -1.931      0.053      -1.842       0.014\n",
      "topic_2                      -1.5685      0.469     -3.344      0.001      -2.488      -0.649\n",
      "topic_3                      -0.1758      0.567     -0.310      0.757      -1.288       0.936\n",
      "topic_4                       0.3367      0.611      0.551      0.582      -0.862       1.535\n",
      "topic_6                      -2.0871      0.483     -4.325      0.000      -3.033      -1.141\n",
      "topic_7                      -1.7787      0.470     -3.783      0.000      -2.700      -0.857\n",
      "topic_8                      -2.1317      0.481     -4.434      0.000      -3.074      -1.189\n",
      "topic_10                     -3.2646      0.555     -5.886      0.000      -4.352      -2.178\n",
      "topic_14                     -3.1065      0.544     -5.715      0.000      -4.172      -2.041\n",
      "topic_15                     -2.7865      0.517     -5.392      0.000      -3.799      -1.774\n",
      "topic_29                     -3.2555      0.555     -5.865      0.000      -4.343      -2.168\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8472469279682675\n",
      "Pr√§zision: 0.8092105263157895\n",
      "Recall: 0.6890756302521008\n",
      "F1-Score: 0.7443267776096822\n",
      "Brier-Score: 0.15553482671685506\n",
      "Confusion-Matrix:\n",
      "[[353  58]\n",
      " [111 246]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487074\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  756\n",
      "Model:                          Logit   Df Residuals:                      740\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2949\n",
      "Time:                        11:03:17   Log-Likelihood:                -368.23\n",
      "converged:                       True   LL-Null:                       -522.23\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.212e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.2301      0.589      2.088      0.037       0.076       2.384\n",
      "issue attention Facebook      4.5962      1.806      2.545      0.011       1.057       8.136\n",
      "issue attention Bundestag     1.1882      0.843      1.410      0.159      -0.464       2.840\n",
      "Social Media Nutzung          0.0088      0.020      0.451      0.652      -0.030       0.047\n",
      "Landtagswahlen               -0.2046      0.208     -0.982      0.326      -0.613       0.204\n",
      "topic_1                      -0.9736      0.472     -2.063      0.039      -1.898      -0.049\n",
      "topic_2                      -1.6998      0.469     -3.627      0.000      -2.618      -0.781\n",
      "topic_3                      -0.0465      0.563     -0.083      0.934      -1.150       1.057\n",
      "topic_4                       0.4085      0.608      0.672      0.502      -0.783       1.600\n",
      "topic_6                      -2.1916      0.483     -4.534      0.000      -3.139      -1.244\n",
      "topic_7                      -1.8716      0.471     -3.975      0.000      -2.794      -0.949\n",
      "topic_8                      -2.2379      0.482     -4.642      0.000      -3.183      -1.293\n",
      "topic_10                     -3.3920      0.557     -6.095      0.000      -4.483      -2.301\n",
      "topic_14                     -3.2466      0.545     -5.959      0.000      -4.314      -2.179\n",
      "topic_15                     -2.9038      0.518     -5.608      0.000      -3.919      -1.889\n",
      "topic_29                     -3.3805      0.556     -6.080      0.000      -4.470      -2.291\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.840557493249325\n",
      "Pr√§zision: 0.8082191780821918\n",
      "Recall: 0.6704545454545454\n",
      "F1-Score: 0.7329192546583851\n",
      "Brier-Score: 0.1591931620204858\n",
      "Confusion-Matrix:\n",
      "[[348  56]\n",
      " [116 236]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497616\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  744\n",
      "Model:                          Logit   Df Residuals:                      728\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2799\n",
      "Time:                        11:03:17   Log-Likelihood:                -370.23\n",
      "converged:                       True   LL-Null:                       -514.15\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.860e-52\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.1148      0.593      3.569      0.000       0.953       3.276\n",
      "issue attention Facebook      0.2119      1.634      0.130      0.897      -2.990       3.414\n",
      "issue attention Bundestag     0.6354      0.830      0.765      0.444      -0.992       2.263\n",
      "Social Media Nutzung         -0.0128      0.019     -0.662      0.508      -0.051       0.025\n",
      "Landtagswahlen                0.0277      0.230      0.121      0.904      -0.422       0.478\n",
      "topic_1                      -1.1403      0.471     -2.422      0.015      -2.063      -0.218\n",
      "topic_2                      -1.7936      0.465     -3.857      0.000      -2.705      -0.882\n",
      "topic_3                       0.1520      0.562      0.270      0.787      -0.950       1.254\n",
      "topic_4                       0.5402      0.607      0.891      0.373      -0.649       1.729\n",
      "topic_6                      -2.5237      0.486     -5.192      0.000      -3.476      -1.571\n",
      "topic_7                      -2.0905      0.472     -4.430      0.000      -3.015      -1.166\n",
      "topic_8                      -2.5385      0.484     -5.244      0.000      -3.487      -1.590\n",
      "topic_10                     -3.7654      0.559     -6.738      0.000      -4.861      -2.670\n",
      "topic_14                     -3.6287      0.547     -6.634      0.000      -4.701      -2.557\n",
      "topic_15                     -3.2740      0.520     -6.293      0.000      -4.294      -2.254\n",
      "topic_29                     -3.7581      0.558     -6.730      0.000      -4.853      -2.664\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8322992859630791\n",
      "Pr√§zision: 0.7817589576547231\n",
      "Recall: 0.6896551724137931\n",
      "F1-Score: 0.732824427480916\n",
      "Brier-Score: 0.16264679435974463\n",
      "Confusion-Matrix:\n",
      "[[329  67]\n",
      " [108 240]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496167\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  732\n",
      "Model:                          Logit   Df Residuals:                      716\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2823\n",
      "Time:                        11:03:17   Log-Likelihood:                -363.19\n",
      "converged:                       True   LL-Null:                       -506.06\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.115e-52\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.8630      0.594      3.138      0.002       0.700       3.026\n",
      "issue attention Facebook      3.4676      1.770      1.959      0.050      -0.001       6.937\n",
      "issue attention Bundestag     1.1327      0.868      1.305      0.192      -0.568       2.833\n",
      "Social Media Nutzung         -0.0188      0.020     -0.958      0.338      -0.057       0.020\n",
      "Landtagswahlen                0.0855      0.231      0.371      0.711      -0.366       0.537\n",
      "topic_1                      -1.0359      0.472     -2.194      0.028      -1.961      -0.110\n",
      "topic_2                      -1.6277      0.469     -3.473      0.001      -2.546      -0.709\n",
      "topic_3                      -0.0293      0.565     -0.052      0.959      -1.136       1.077\n",
      "topic_4                       0.4242      0.609      0.697      0.486      -0.770       1.618\n",
      "topic_6                      -2.2013      0.484     -4.544      0.000      -3.151      -1.252\n",
      "topic_7                      -1.8531      0.472     -3.923      0.000      -2.779      -0.927\n",
      "topic_8                      -2.2420      0.483     -4.644      0.000      -3.188      -1.296\n",
      "topic_10                     -3.4131      0.558     -6.118      0.000      -4.507      -2.320\n",
      "topic_14                     -3.2781      0.545     -6.010      0.000      -4.347      -2.209\n",
      "topic_15                     -2.9289      0.518     -5.649      0.000      -3.945      -1.913\n",
      "topic_29                     -3.4118      0.556     -6.132      0.000      -4.502      -2.321\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8346881742987293\n",
      "Pr√§zision: 0.8013468013468014\n",
      "Recall: 0.6918604651162791\n",
      "F1-Score: 0.7425897035881436\n",
      "Brier-Score: 0.1621544238689221\n",
      "Confusion-Matrix:\n",
      "[[329  59]\n",
      " [106 238]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.498443\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  720\n",
      "Model:                          Logit   Df Residuals:                      704\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2791\n",
      "Time:                        11:03:17   Log-Likelihood:                -358.88\n",
      "converged:                       True   LL-Null:                       -497.84\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.124e-50\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.4096      0.601      2.347      0.019       0.232       2.587\n",
      "issue attention Facebook      1.4305      1.694      0.845      0.398      -1.889       4.750\n",
      "issue attention Bundestag     0.6186      0.842      0.735      0.463      -1.032       2.269\n",
      "Social Media Nutzung          0.0198      0.020      1.013      0.311      -0.019       0.058\n",
      "Landtagswahlen               -0.1267      0.231     -0.548      0.584      -0.580       0.326\n",
      "topic_1                      -1.2615      0.490     -2.572      0.010      -2.223      -0.300\n",
      "topic_2                      -1.8519      0.486     -3.814      0.000      -2.803      -0.900\n",
      "topic_3                      -0.0812      0.581     -0.140      0.889      -1.220       1.057\n",
      "topic_4                       0.3340      0.623      0.536      0.592      -0.887       1.555\n",
      "topic_6                      -2.4895      0.504     -4.940      0.000      -3.477      -1.502\n",
      "topic_7                      -2.0629      0.491     -4.199      0.000      -3.026      -1.100\n",
      "topic_8                      -2.5101      0.502     -5.000      0.000      -3.494      -1.526\n",
      "topic_10                     -3.7295      0.575     -6.485      0.000      -4.857      -2.602\n",
      "topic_14                     -3.5922      0.563     -6.382      0.000      -4.695      -2.489\n",
      "topic_15                     -3.3493      0.544     -6.160      0.000      -4.415      -2.284\n",
      "topic_29                     -3.7269      0.574     -6.497      0.000      -4.851      -2.603\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8336314155420839\n",
      "Pr√§zision: 0.7796610169491526\n",
      "Recall: 0.6784660766961652\n",
      "F1-Score: 0.7255520504731862\n",
      "Brier-Score: 0.16373320667622052\n",
      "Confusion-Matrix:\n",
      "[[316  65]\n",
      " [109 230]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497060\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  708\n",
      "Model:                          Logit   Df Residuals:                      692\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2811\n",
      "Time:                        11:03:18   Log-Likelihood:                -351.92\n",
      "converged:                       True   LL-Null:                       -489.50\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.903e-50\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.3423      0.608      2.208      0.027       0.151       2.534\n",
      "issue attention Facebook      0.5105      1.734      0.294      0.768      -2.888       3.909\n",
      "issue attention Bundestag     2.2575      0.905      2.494      0.013       0.483       4.032\n",
      "Social Media Nutzung          0.0196      0.020      0.983      0.326      -0.019       0.059\n",
      "Landtagswahlen                0.0054      0.231      0.023      0.981      -0.447       0.457\n",
      "topic_1                      -1.2707      0.493     -2.579      0.010      -2.236      -0.305\n",
      "topic_2                      -1.9587      0.492     -3.980      0.000      -2.923      -0.994\n",
      "topic_3                      -0.0080      0.585     -0.014      0.989      -1.156       1.139\n",
      "topic_4                       0.4132      0.626      0.660      0.509      -0.813       1.639\n",
      "topic_6                      -2.5306      0.508     -4.977      0.000      -3.527      -1.534\n",
      "topic_7                      -2.0949      0.497     -4.216      0.000      -3.069      -1.121\n",
      "topic_8                      -2.5103      0.507     -4.953      0.000      -3.504      -1.517\n",
      "topic_10                     -3.7184      0.578     -6.429      0.000      -4.852      -2.585\n",
      "topic_14                     -3.5845      0.566     -6.336      0.000      -4.693      -2.476\n",
      "topic_15                     -3.3087      0.546     -6.062      0.000      -4.378      -2.239\n",
      "topic_29                     -3.6933      0.576     -6.416      0.000      -4.822      -2.565\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8332572572572573\n",
      "Pr√§zision: 0.8042704626334519\n",
      "Recall: 0.6786786786786787\n",
      "F1-Score: 0.7361563517915309\n",
      "Brier-Score: 0.1620826761395232\n",
      "Confusion-Matrix:\n",
      "[[320  55]\n",
      " [107 226]]\n"
     ]
    }
   ],
   "source": [
    "models_afd = []\n",
    "metrics_afd = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model_afd, auc_roc_afd, f1_afd = log_reg_FE_control(rede_reduced_afd,post_reduced_afd, post_common_afd,lag,social_media_usage_afd)\n",
    "    models_afd.append(model_afd)\n",
    "    metrics_afd.append((auc_roc_afd, f1_afd))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models_afd)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - AfD\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes_afd = [f\"Lag {i}: AUC-ROC = {metrics_afd[i-1][0]:.3f}, F1-Score = {metrics_afd[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes_afd)\n",
    "\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_afd.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486842\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      762\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2950\n",
      "Time:                        11:03:18   Log-Likelihood:                -379.74\n",
      "converged:                       True   LL-Null:                       -538.64\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.346e-57\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.3009      0.781      1.665      0.096      -0.230       2.832\n",
      "issue attention Facebook      4.7548      1.738      2.735      0.006       1.348       8.162\n",
      "issue attention Bundestag    -0.1122      0.785     -0.143      0.886      -1.651       1.427\n",
      "Social Media Nutzung          0.0067      0.030      0.220      0.826      -0.053       0.066\n",
      "Landtagswahlen               -0.2482      0.172     -1.441      0.150      -0.586       0.089\n",
      "Komplexit√§t Reden            -0.0892      0.093     -0.961      0.336      -0.271       0.093\n",
      "Komplexit√§t Posts            -0.0599      0.154     -0.389      0.697      -0.361       0.242\n",
      "topic_1                      -0.8558      0.455     -1.879      0.060      -1.749       0.037\n",
      "topic_2                      -1.5396      0.449     -3.429      0.001      -2.420      -0.660\n",
      "topic_3                       0.0546      0.549      0.099      0.921      -1.022       1.131\n",
      "topic_4                       0.4998      0.596      0.838      0.402      -0.668       1.668\n",
      "topic_6                      -2.2194      0.466     -4.766      0.000      -3.132      -1.307\n",
      "topic_7                      -1.8151      0.452     -4.018      0.000      -2.700      -0.930\n",
      "topic_8                      -2.1593      0.462     -4.669      0.000      -3.066      -1.253\n",
      "topic_10                     -3.3914      0.542     -6.257      0.000      -4.454      -2.329\n",
      "topic_14                     -3.2451      0.531     -6.117      0.000      -4.285      -2.205\n",
      "topic_15                     -2.9237      0.503     -5.810      0.000      -3.910      -1.937\n",
      "topic_29                     -3.2580      0.530     -6.149      0.000      -4.297      -2.220\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8381466599698645\n",
      "Pr√§zision: 0.8187919463087249\n",
      "Recall: 0.6740331491712708\n",
      "F1-Score: 0.7393939393939394\n",
      "Brier-Score: 0.1584297234773644\n",
      "Confusion-Matrix:\n",
      "[[364  54]\n",
      " [118 244]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.476572\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  768\n",
      "Model:                          Logit   Df Residuals:                      750\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.3100\n",
      "Time:                        11:03:18   Log-Likelihood:                -366.01\n",
      "converged:                       True   LL-Null:                       -530.44\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.207e-59\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.8717      0.798      1.093      0.274      -0.692       2.435\n",
      "issue attention Facebook      7.3767      1.936      3.809      0.000       3.581      11.172\n",
      "issue attention Bundestag     0.5623      0.843      0.667      0.505      -1.091       2.215\n",
      "Social Media Nutzung          0.0161      0.031      0.523      0.601      -0.044       0.076\n",
      "Landtagswahlen               -0.0537      0.188     -0.286      0.775      -0.422       0.314\n",
      "Komplexit√§t Reden            -0.1101      0.094     -1.170      0.242      -0.294       0.074\n",
      "Komplexit√§t Posts            -0.2295      0.158     -1.454      0.146      -0.539       0.080\n",
      "topic_1                      -0.9154      0.474     -1.932      0.053      -1.844       0.013\n",
      "topic_2                      -1.5633      0.471     -3.320      0.001      -2.486      -0.640\n",
      "topic_3                      -0.1773      0.568     -0.312      0.755      -1.290       0.936\n",
      "topic_4                       0.3307      0.612      0.541      0.589      -0.868       1.530\n",
      "topic_6                      -2.0906      0.484     -4.322      0.000      -3.039      -1.143\n",
      "topic_7                      -1.7792      0.471     -3.778      0.000      -2.702      -0.856\n",
      "topic_8                      -2.1383      0.483     -4.430      0.000      -3.084      -1.192\n",
      "topic_10                     -3.2729      0.556     -5.887      0.000      -4.363      -2.183\n",
      "topic_14                     -3.1161      0.545     -5.718      0.000      -4.184      -2.048\n",
      "topic_15                     -2.7966      0.518     -5.396      0.000      -3.812      -1.781\n",
      "topic_29                     -3.2668      0.556     -5.871      0.000      -4.357      -2.176\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8470560973781239\n",
      "Pr√§zision: 0.8118811881188119\n",
      "Recall: 0.6890756302521008\n",
      "F1-Score: 0.7454545454545455\n",
      "Brier-Score: 0.15503638009391532\n",
      "Confusion-Matrix:\n",
      "[[354  57]\n",
      " [111 246]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487036\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  756\n",
      "Model:                          Logit   Df Residuals:                      738\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2949\n",
      "Time:                        11:03:18   Log-Likelihood:                -368.20\n",
      "converged:                       True   LL-Null:                       -522.23\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.438e-55\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.1028      0.797      1.383      0.167      -0.460       2.666\n",
      "issue attention Facebook      4.5870      1.810      2.534      0.011       1.040       8.135\n",
      "issue attention Bundestag     1.1871      0.844      1.407      0.159      -0.466       2.840\n",
      "Social Media Nutzung          0.0145      0.031      0.469      0.639      -0.046       0.075\n",
      "Landtagswahlen               -0.1987      0.219     -0.908      0.364      -0.628       0.230\n",
      "Komplexit√§t Reden            -0.0058      0.096     -0.060      0.952      -0.194       0.182\n",
      "Komplexit√§t Posts            -0.0353      0.154     -0.229      0.819      -0.338       0.267\n",
      "topic_1                      -0.9742      0.472     -2.064      0.039      -1.899      -0.049\n",
      "topic_2                      -1.6998      0.469     -3.625      0.000      -2.619      -0.781\n",
      "topic_3                      -0.0468      0.563     -0.083      0.934      -1.150       1.057\n",
      "topic_4                       0.4076      0.608      0.670      0.503      -0.784       1.599\n",
      "topic_6                      -2.1925      0.484     -4.534      0.000      -3.140      -1.245\n",
      "topic_7                      -1.8723      0.471     -3.975      0.000      -2.795      -0.949\n",
      "topic_8                      -2.2389      0.482     -4.641      0.000      -3.185      -1.293\n",
      "topic_10                     -3.3931      0.557     -6.094      0.000      -4.484      -2.302\n",
      "topic_14                     -3.2478      0.545     -5.958      0.000      -4.316      -2.179\n",
      "topic_15                     -2.9049      0.518     -5.607      0.000      -3.920      -1.890\n",
      "topic_29                     -3.3817      0.556     -6.079      0.000      -4.472      -2.291\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8408739311431143\n",
      "Pr√§zision: 0.8088737201365188\n",
      "Recall: 0.6732954545454546\n",
      "F1-Score: 0.7348837209302326\n",
      "Brier-Score: 0.159253407583426\n",
      "Confusion-Matrix:\n",
      "[[348  56]\n",
      " [115 237]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497561\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  744\n",
      "Model:                          Logit   Df Residuals:                      726\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2800\n",
      "Time:                        11:03:18   Log-Likelihood:                -370.19\n",
      "converged:                       True   LL-Null:                       -514.15\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.459e-51\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.2080      0.797      2.770      0.006       0.646       3.770\n",
      "issue attention Facebook      0.2029      1.635      0.124      0.901      -3.001       3.407\n",
      "issue attention Bundestag     0.6360      0.830      0.766      0.444      -0.992       2.264\n",
      "Social Media Nutzung         -0.0170      0.031     -0.556      0.578      -0.077       0.043\n",
      "Landtagswahlen                0.0378      0.238      0.159      0.874      -0.428       0.504\n",
      "Komplexit√§t Reden             0.0233      0.095      0.244      0.807      -0.164       0.210\n",
      "Komplexit√§t Posts             0.0208      0.149      0.140      0.889      -0.271       0.313\n",
      "topic_1                      -1.1411      0.471     -2.423      0.015      -2.064      -0.218\n",
      "topic_2                      -1.7946      0.465     -3.858      0.000      -2.706      -0.883\n",
      "topic_3                       0.1525      0.562      0.271      0.786      -0.950       1.255\n",
      "topic_4                       0.5403      0.606      0.891      0.373      -0.648       1.729\n",
      "topic_6                      -2.5251      0.486     -5.194      0.000      -3.478      -1.572\n",
      "topic_7                      -2.0917      0.472     -4.432      0.000      -3.017      -1.167\n",
      "topic_8                      -2.5398      0.484     -5.246      0.000      -3.489      -1.591\n",
      "topic_10                     -3.7670      0.559     -6.740      0.000      -4.862      -2.672\n",
      "topic_14                     -3.6304      0.547     -6.636      0.000      -4.703      -2.558\n",
      "topic_15                     -3.2757      0.520     -6.295      0.000      -4.296      -2.256\n",
      "topic_29                     -3.7597      0.559     -6.731      0.000      -4.854      -2.665\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8325423778009984\n",
      "Pr√§zision: 0.7792207792207793\n",
      "Recall: 0.6896551724137931\n",
      "F1-Score: 0.7317073170731707\n",
      "Brier-Score: 0.16262652322600185\n",
      "Confusion-Matrix:\n",
      "[[328  68]\n",
      " [108 240]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490178\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  732\n",
      "Model:                          Logit   Df Residuals:                      714\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2910\n",
      "Time:                        11:03:18   Log-Likelihood:                -358.81\n",
      "converged:                       True   LL-Null:                       -506.06\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.534e-52\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.1891      0.798      2.743      0.006       0.625       3.753\n",
      "issue attention Facebook      3.8165      1.818      2.100      0.036       0.254       7.379\n",
      "issue attention Bundestag     1.1569      0.875      1.322      0.186      -0.559       2.872\n",
      "Social Media Nutzung         -0.0326      0.031     -1.059      0.289      -0.093       0.028\n",
      "Landtagswahlen               -0.1040      0.241     -0.432      0.666      -0.576       0.368\n",
      "Komplexit√§t Reden            -0.2781      0.100     -2.780      0.005      -0.474      -0.082\n",
      "Komplexit√§t Posts             0.1568      0.151      1.040      0.298      -0.139       0.452\n",
      "topic_1                      -1.0293      0.475     -2.169      0.030      -1.959      -0.099\n",
      "topic_2                      -1.6272      0.471     -3.452      0.001      -2.551      -0.703\n",
      "topic_3                      -0.0213      0.568     -0.037      0.970      -1.134       1.091\n",
      "topic_4                       0.4389      0.612      0.718      0.473      -0.760       1.638\n",
      "topic_6                      -2.1971      0.488     -4.502      0.000      -3.154      -1.241\n",
      "topic_7                      -1.8486      0.475     -3.893      0.000      -2.779      -0.918\n",
      "topic_8                      -2.2424      0.486     -4.612      0.000      -3.195      -1.289\n",
      "topic_10                     -3.4236      0.561     -6.100      0.000      -4.524      -2.324\n",
      "topic_14                     -3.2850      0.549     -5.987      0.000      -4.360      -2.210\n",
      "topic_15                     -2.9344      0.522     -5.623      0.000      -3.957      -1.912\n",
      "topic_29                     -3.4222      0.560     -6.114      0.000      -4.519      -2.325\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8387452049868137\n",
      "Pr√§zision: 0.7973421926910299\n",
      "Recall: 0.6976744186046512\n",
      "F1-Score: 0.7441860465116279\n",
      "Brier-Score: 0.1597876851192986\n",
      "Confusion-Matrix:\n",
      "[[327  61]\n",
      " [104 240]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495609\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  720\n",
      "Model:                          Logit   Df Residuals:                      702\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2832\n",
      "Time:                        11:03:18   Log-Likelihood:                -356.84\n",
      "converged:                       True   LL-Null:                       -497.84\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.744e-50\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.5302      0.813      1.881      0.060      -0.064       3.124\n",
      "issue attention Facebook      1.3051      1.684      0.775      0.438      -1.995       4.605\n",
      "issue attention Bundestag     0.6235      0.844      0.739      0.460      -1.031       2.278\n",
      "Social Media Nutzung          0.0146      0.031      0.467      0.640      -0.047       0.076\n",
      "Landtagswahlen               -0.0106      0.241     -0.044      0.965      -0.484       0.463\n",
      "Komplexit√§t Reden             0.1956      0.097      2.015      0.044       0.005       0.386\n",
      "Komplexit√§t Posts            -0.0155      0.154     -0.101      0.920      -0.318       0.287\n",
      "topic_1                      -1.2754      0.492     -2.594      0.009      -2.239      -0.312\n",
      "topic_2                      -1.8732      0.487     -3.848      0.000      -2.827      -0.919\n",
      "topic_3                      -0.0779      0.582     -0.134      0.894      -1.219       1.063\n",
      "topic_4                       0.3356      0.624      0.538      0.591      -0.887       1.558\n",
      "topic_6                      -2.5217      0.505     -4.992      0.000      -3.512      -1.532\n",
      "topic_7                      -2.0890      0.493     -4.239      0.000      -3.055      -1.123\n",
      "topic_8                      -2.5415      0.503     -5.050      0.000      -3.528      -1.555\n",
      "topic_10                     -3.7707      0.577     -6.539      0.000      -4.901      -2.640\n",
      "topic_14                     -3.6337      0.565     -6.437      0.000      -4.740      -2.527\n",
      "topic_15                     -3.3886      0.545     -6.215      0.000      -4.457      -2.320\n",
      "topic_29                     -3.7678      0.575     -6.551      0.000      -4.895      -2.640\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8364573897289388\n",
      "Pr√§zision: 0.7966101694915254\n",
      "Recall: 0.6932153392330384\n",
      "F1-Score: 0.7413249211356467\n",
      "Brier-Score: 0.16223299759173837\n",
      "Confusion-Matrix:\n",
      "[[321  60]\n",
      " [104 235]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496159\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  708\n",
      "Model:                          Logit   Df Residuals:                      690\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2824\n",
      "Time:                        11:03:18   Log-Likelihood:                -351.28\n",
      "converged:                       True   LL-Null:                       -489.50\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.991e-49\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.7981      0.811      0.984      0.325      -0.791       2.387\n",
      "issue attention Facebook      0.5360      1.737      0.309      0.758      -2.868       3.940\n",
      "issue attention Bundestag     2.2584      0.911      2.480      0.013       0.474       4.043\n",
      "Social Media Nutzung          0.0439      0.031      1.406      0.160      -0.017       0.105\n",
      "Landtagswahlen                0.0012      0.240      0.005      0.996      -0.470       0.472\n",
      "Komplexit√§t Reden            -0.0610      0.098     -0.620      0.535      -0.254       0.132\n",
      "Komplexit√§t Posts            -0.1411      0.153     -0.920      0.357      -0.442       0.159\n",
      "topic_1                      -1.2711      0.493     -2.578      0.010      -2.237      -0.305\n",
      "topic_2                      -1.9599      0.493     -3.979      0.000      -2.925      -0.994\n",
      "topic_3                      -0.0131      0.586     -0.022      0.982      -1.161       1.135\n",
      "topic_4                       0.4132      0.626      0.660      0.509      -0.814       1.640\n",
      "topic_6                      -2.5337      0.509     -4.976      0.000      -3.532      -1.536\n",
      "topic_7                      -2.0968      0.497     -4.216      0.000      -3.071      -1.122\n",
      "topic_8                      -2.5120      0.508     -4.949      0.000      -3.507      -1.517\n",
      "topic_10                     -3.7243      0.579     -6.431      0.000      -4.859      -2.589\n",
      "topic_14                     -3.5894      0.566     -6.336      0.000      -4.700      -2.479\n",
      "topic_15                     -3.3123      0.546     -6.062      0.000      -4.383      -2.241\n",
      "topic_29                     -3.6980      0.576     -6.418      0.000      -4.827      -2.569\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.834930930930931\n",
      "Pr√§zision: 0.8028169014084507\n",
      "Recall: 0.6846846846846847\n",
      "F1-Score: 0.7390599675850892\n",
      "Brier-Score: 0.16185694679274276\n",
      "Confusion-Matrix:\n",
      "[[319  56]\n",
      " [105 228]]\n"
     ]
    }
   ],
   "source": [
    "models_afd_complex = []\n",
    "metrics_afd_complex = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model_afd, auc_roc_afd, f1_afd = log_reg_FE_control_test(rede_reduced_afd,post_reduced_afd, post_common_afd,lag,social_media_usage_afd, rede_komplex_afd, posts_komplex_afd)\n",
    "    models_afd_complex.append(model_afd)\n",
    "    metrics_afd_complex.append((auc_roc_afd, f1_afd))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models_afd_complex)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - AfD\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes_afd = [f\"Lag {i}: AUC-ROC = {metrics_afd_complex[i-1][0]:.3f}, F1-Score = {metrics_afd_complex[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes_afd)\n",
    "\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_afd_complex.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\577048389.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_spd[\"date\"] = pd.to_datetime(subset_reden_spd[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\577048389.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_afd[\"date\"] = pd.to_datetime(subset_posts_spd[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_spd = subset_posts[subset_posts[\"partei\"] == \"SPD\"]\n",
    "subset_reden_spd = subset_reden[subset_reden[\"partei\"] == \"SPD\"]\n",
    "social_media_usage_spd = subset_posts_spd.groupby('date').size()\n",
    "subset_reden_spd[\"date\"] = pd.to_datetime(subset_reden_spd[\"date\"])\n",
    "subset_posts_afd[\"date\"] = pd.to_datetime(subset_posts_spd[\"date\"])\n",
    "reden_komplexit√§t_t√§glich_spd = subset_reden_spd.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_spd = subset_posts_spd.groupby('date')['komplexit√§t'].sum()\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_spd = subset_reden_spd.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_spd = subset_posts_spd.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_spd = redethemen_t√§glich_spd.index.intersection(postthemen_t√§glich_spd.index)\n",
    "redethemen_t√§glich_aligned_spd = redethemen_t√§glich_spd.loc[common_dates_spd]\n",
    "postthemen_t√§glich_aligned_spd = postthemen_t√§glich_spd.loc[common_dates_spd]\n",
    "rede_komplex_spd = reden_komplexit√§t_t√§glich_spd.loc[common_dates_spd]\n",
    "posts_komplex_spd = posts_komplexit√§t_t√§glich_spd.loc[common_dates_spd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 68, 69, 70, 75, 77, 78, 79, 80, 83, 84, 90, 91, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 4, 6, 7, 8, 15, 19, 24}\n"
     ]
    }
   ],
   "source": [
    "rede_common_spd, post_common_spd = filter_common_topics(redethemen_t√§glich_aligned_spd, postthemen_t√§glich_aligned_spd)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_spd =  rede_common_spd.div(rede_common_spd.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_spd = post_common_spd.div(post_common_spd.sum(axis=1), axis=0)\n",
    "reden_relativ_spd_red = remove_near_constant(reden_relativ_spd)\n",
    "post_relativ_spd_red = remove_near_constant(post_relativ_spd)\n",
    "rede_reduced_spd, post_reduced_spd = filter_common_topics(reden_relativ_spd_red, post_relativ_spd_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541385\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  640\n",
      "Model:                          Logit   Df Residuals:                      637\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                0.009090\n",
      "Time:                        11:03:18   Log-Likelihood:                -346.49\n",
      "converged:                       True   LL-Null:                       -349.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04165\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -1.3009      0.113    -11.540      0.000      -1.522      -1.080\n",
      "posts_relative     2.2617      0.904      2.502      0.012       0.490       4.033\n",
      "reden_relativ      0.2865      0.955      0.300      0.764      -1.586       2.159\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM(rede_reduced_spd,post_reduced_spd, post_common_spd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.504419\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  640\n",
      "Model:                          Logit   Df Residuals:                      628\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07675\n",
      "Time:                        11:03:18   Log-Likelihood:                -322.83\n",
      "converged:                       True   LL-Null:                       -349.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.353e-07\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -0.7140      0.283     -2.523      0.012      -1.269      -0.159\n",
      "posts_relative     0.4276      0.983      0.435      0.664      -1.499       2.354\n",
      "reden_relativ     -0.3621      1.084     -0.334      0.738      -2.487       1.763\n",
      "topic_1            0.6947      0.368      1.888      0.059      -0.027       1.416\n",
      "topic_2           -0.5333      0.406     -1.313      0.189      -1.329       0.263\n",
      "topic_4           -0.4023      0.397     -1.013      0.311      -1.181       0.376\n",
      "topic_6            0.2457      0.374      0.658      0.511      -0.486       0.978\n",
      "topic_7           -1.3739      0.484     -2.837      0.005      -2.323      -0.425\n",
      "topic_8           -1.0872      0.449     -2.419      0.016      -1.968      -0.206\n",
      "topic_15          -0.8662      0.431     -2.011      0.044      -1.710      -0.022\n",
      "topic_19          -1.2390      0.468     -2.647      0.008      -2.157      -0.321\n",
      "topic_24          -1.2331      0.469     -2.632      0.008      -2.151      -0.315\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM_fixed_effects(rede_reduced_spd,post_reduced_spd, post_common_spd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression f√ºr Lag 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503442\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  640\n",
      "Model:                          Logit   Df Residuals:                      626\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07854\n",
      "Time:                        11:03:18   Log-Likelihood:                -322.20\n",
      "converged:                       True   LL-Null:                       -349.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.167e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9336      0.350     -2.669      0.008      -1.619      -0.248\n",
      "issue attention Facebook      0.4655      0.990      0.470      0.638      -1.474       2.405\n",
      "issue attention Bundestag    -0.3017      1.082     -0.279      0.780      -2.422       1.818\n",
      "Social Media Nutzung          0.0266      0.024      1.124      0.261      -0.020       0.073\n",
      "Landtagswahlen               -0.0180      0.179     -0.100      0.920      -0.369       0.333\n",
      "topic_1                       0.6960      0.369      1.888      0.059      -0.026       1.418\n",
      "topic_2                      -0.5358      0.407     -1.316      0.188      -1.333       0.262\n",
      "topic_4                      -0.3990      0.398     -1.003      0.316      -1.178       0.380\n",
      "topic_6                       0.2486      0.374      0.665      0.506      -0.484       0.981\n",
      "topic_7                      -1.3726      0.485     -2.832      0.005      -2.323      -0.423\n",
      "topic_8                      -1.0862      0.450     -2.414      0.016      -1.968      -0.204\n",
      "topic_15                     -0.8630      0.431     -2.002      0.045      -1.708      -0.018\n",
      "topic_19                     -1.2360      0.469     -2.638      0.008      -2.154      -0.318\n",
      "topic_24                     -1.2299      0.469     -2.623      0.009      -2.149      -0.311\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6894527282330476\n",
      "Pr√§zision: 0.6551724137931034\n",
      "Recall: 0.12582781456953643\n",
      "F1-Score: 0.2111111111111111\n",
      "Brier-Score: 0.16383941163170915\n",
      "Confusion-Matrix:\n",
      "[[479  10]\n",
      " [132  19]]\n",
      "\n",
      "Regression f√ºr Lag 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497403\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  630\n",
      "Model:                          Logit   Df Residuals:                      616\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08443\n",
      "Time:                        11:03:18   Log-Likelihood:                -313.36\n",
      "converged:                       True   LL-Null:                       -342.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.297e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9888      0.356     -2.780      0.005      -1.686      -0.292\n",
      "issue attention Facebook      0.4245      1.015      0.418      0.676      -1.565       2.414\n",
      "issue attention Bundestag    -0.9950      1.178     -0.845      0.398      -3.304       1.314\n",
      "Social Media Nutzung          0.0444      0.024      1.865      0.062      -0.002       0.091\n",
      "Landtagswahlen               -0.0704      0.200     -0.353      0.724      -0.461       0.321\n",
      "topic_1                       0.6424      0.372      1.725      0.084      -0.087       1.372\n",
      "topic_2                      -0.6156      0.415     -1.484      0.138      -1.429       0.197\n",
      "topic_4                      -0.5250      0.405     -1.296      0.195      -1.319       0.269\n",
      "topic_6                       0.2271      0.377      0.603      0.547      -0.511       0.966\n",
      "topic_7                      -1.4095      0.487     -2.893      0.004      -2.364      -0.455\n",
      "topic_8                      -1.1139      0.453     -2.461      0.014      -2.001      -0.227\n",
      "topic_15                     -0.9116      0.434     -2.101      0.036      -1.762      -0.061\n",
      "topic_19                     -1.2901      0.471     -2.738      0.006      -2.214      -0.367\n",
      "topic_24                     -1.4346      0.490     -2.928      0.003      -2.395      -0.474\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6979549583808679\n",
      "Pr√§zision: 0.6071428571428571\n",
      "Recall: 0.11564625850340136\n",
      "F1-Score: 0.19428571428571428\n",
      "Brier-Score: 0.16155193540824397\n",
      "Confusion-Matrix:\n",
      "[[472  11]\n",
      " [130  17]]\n",
      "\n",
      "Regression f√ºr Lag 3:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.499766\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  620\n",
      "Model:                          Logit   Df Residuals:                      606\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08116\n",
      "Time:                        11:03:18   Log-Likelihood:                -309.85\n",
      "converged:                       True   LL-Null:                       -337.23\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.488e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9422      0.359     -2.626      0.009      -1.645      -0.239\n",
      "issue attention Facebook      0.3525      1.012      0.348      0.728      -1.632       2.337\n",
      "issue attention Bundestag     0.5371      1.070      0.502      0.616      -1.559       2.634\n",
      "Social Media Nutzung          0.0258      0.024      1.064      0.287      -0.022       0.073\n",
      "Landtagswahlen               -0.3422      0.233     -1.466      0.143      -0.800       0.115\n",
      "topic_1                       0.7389      0.376      1.963      0.050       0.001       1.477\n",
      "topic_2                      -0.6060      0.419     -1.448      0.148      -1.426       0.214\n",
      "topic_4                      -0.3698      0.408     -0.906      0.365      -1.170       0.430\n",
      "topic_6                       0.3007      0.382      0.788      0.431      -0.448       1.049\n",
      "topic_7                      -1.2898      0.489     -2.636      0.008      -2.249      -0.331\n",
      "topic_8                      -1.0137      0.455     -2.229      0.026      -1.905      -0.122\n",
      "topic_15                     -0.7528      0.436     -1.725      0.084      -1.608       0.102\n",
      "topic_19                     -1.1263      0.474     -2.378      0.017      -2.054      -0.198\n",
      "topic_24                     -1.2762      0.492     -2.593      0.010      -2.241      -0.312\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6921742286751362\n",
      "Pr√§zision: 0.6111111111111112\n",
      "Recall: 0.15172413793103448\n",
      "F1-Score: 0.2430939226519337\n",
      "Brier-Score: 0.16226462744611936\n",
      "Confusion-Matrix:\n",
      "[[461  14]\n",
      " [123  22]]\n",
      "\n",
      "Regression f√ºr Lag 4:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500512\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  610\n",
      "Model:                          Logit   Df Residuals:                      596\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07761\n",
      "Time:                        11:03:18   Log-Likelihood:                -305.31\n",
      "converged:                       True   LL-Null:                       -331.00\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.729e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7890      0.370     -2.134      0.033      -1.514      -0.064\n",
      "issue attention Facebook      0.4408      1.004      0.439      0.661      -1.527       2.409\n",
      "issue attention Bundestag     0.1975      1.112      0.178      0.859      -1.983       2.378\n",
      "Social Media Nutzung          0.0048      0.026      0.186      0.852      -0.046       0.056\n",
      "Landtagswahlen               -0.0470      0.258     -0.182      0.855      -0.552       0.458\n",
      "topic_1                       0.6693      0.377      1.775      0.076      -0.070       1.408\n",
      "topic_2                      -0.5878      0.417     -1.409      0.159      -1.405       0.230\n",
      "topic_4                      -0.3894      0.409     -0.952      0.341      -1.191       0.412\n",
      "topic_6                       0.2845      0.382      0.744      0.457      -0.465       1.034\n",
      "topic_7                      -1.2979      0.489     -2.653      0.008      -2.257      -0.339\n",
      "topic_8                      -1.1520      0.469     -2.455      0.014      -2.072      -0.232\n",
      "topic_15                     -0.8857      0.447     -1.983      0.047      -1.761      -0.010\n",
      "topic_19                     -1.1447      0.474     -2.416      0.016      -2.074      -0.216\n",
      "topic_24                     -1.2928      0.492     -2.626      0.009      -2.258      -0.328\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6896818947875285\n",
      "Pr√§zision: 0.5263157894736842\n",
      "Recall: 0.07042253521126761\n",
      "F1-Score: 0.12422360248447205\n",
      "Brier-Score: 0.16288835169985136\n",
      "Confusion-Matrix:\n",
      "[[459   9]\n",
      " [132  10]]\n",
      "\n",
      "Regression f√ºr Lag 5:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.501326\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  600\n",
      "Model:                          Logit   Df Residuals:                      586\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07721\n",
      "Time:                        11:03:18   Log-Likelihood:                -300.80\n",
      "converged:                       True   LL-Null:                       -325.96\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.611e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6047      0.377     -1.606      0.108      -1.343       0.133\n",
      "issue attention Facebook      0.2627      1.007      0.261      0.794      -1.710       2.236\n",
      "issue attention Bundestag     0.4468      1.157      0.386      0.699      -1.821       2.714\n",
      "Social Media Nutzung         -0.0235      0.027     -0.881      0.378      -0.076       0.029\n",
      "Landtagswahlen               -0.1615      0.261     -0.620      0.535      -0.672       0.349\n",
      "topic_1                       0.7669      0.383      2.005      0.045       0.017       1.517\n",
      "topic_2                      -0.5200      0.420     -1.237      0.216      -1.344       0.304\n",
      "topic_4                      -0.3026      0.414     -0.731      0.465      -1.114       0.509\n",
      "topic_6                       0.3089      0.389      0.793      0.428      -0.454       1.072\n",
      "topic_7                      -1.2280      0.493     -2.491      0.013      -2.194      -0.262\n",
      "topic_8                      -1.0852      0.473     -2.295      0.022      -2.012      -0.158\n",
      "topic_15                     -0.8046      0.452     -1.782      0.075      -1.690       0.080\n",
      "topic_19                     -1.0647      0.479     -2.225      0.026      -2.003      -0.127\n",
      "topic_24                     -1.2157      0.497     -2.447      0.014      -2.189      -0.242\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6894565217391304\n",
      "Pr√§zision: 0.5666666666666667\n",
      "Recall: 0.12142857142857143\n",
      "F1-Score: 0.2\n",
      "Brier-Score: 0.16297713587145982\n",
      "Confusion-Matrix:\n",
      "[[447  13]\n",
      " [123  17]]\n",
      "\n",
      "Regression f√ºr Lag 6:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503067\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  590\n",
      "Model:                          Logit   Df Residuals:                      576\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07854\n",
      "Time:                        11:03:19   Log-Likelihood:                -296.81\n",
      "converged:                       True   LL-Null:                       -322.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.354e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7911      0.376     -2.106      0.035      -1.527      -0.055\n",
      "issue attention Facebook      0.3058      1.014      0.301      0.763      -1.682       2.294\n",
      "issue attention Bundestag     0.2467      1.171      0.211      0.833      -2.049       2.542\n",
      "Social Media Nutzung          0.0077      0.026      0.297      0.766      -0.043       0.058\n",
      "Landtagswahlen               -0.2687      0.266     -1.008      0.313      -0.791       0.254\n",
      "topic_1                       0.7723      0.385      2.006      0.045       0.018       1.527\n",
      "topic_2                      -0.5185      0.422     -1.230      0.219      -1.345       0.308\n",
      "topic_4                      -0.4085      0.420     -0.972      0.331      -1.232       0.415\n",
      "topic_6                       0.3018      0.391      0.772      0.440      -0.465       1.068\n",
      "topic_7                      -1.2387      0.494     -2.505      0.012      -2.208      -0.270\n",
      "topic_8                      -1.0932      0.474     -2.306      0.021      -2.022      -0.164\n",
      "topic_15                     -0.8215      0.453     -1.815      0.070      -1.709       0.066\n",
      "topic_19                     -1.0827      0.480     -2.257      0.024      -2.023      -0.143\n",
      "topic_24                     -1.2330      0.498     -2.477      0.013      -2.209      -0.257\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6910941313468072\n",
      "Pr√§zision: 0.5652173913043478\n",
      "Recall: 0.18705035971223022\n",
      "F1-Score: 0.2810810810810811\n",
      "Brier-Score: 0.16393095546573688\n",
      "Confusion-Matrix:\n",
      "[[431  20]\n",
      " [113  26]]\n",
      "\n",
      "Regression f√ºr Lag 7:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.501050\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  580\n",
      "Model:                          Logit   Df Residuals:                      566\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08681\n",
      "Time:                        11:03:19   Log-Likelihood:                -290.61\n",
      "converged:                       True   LL-Null:                       -318.24\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.646e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7314      0.375     -1.951      0.051      -1.466       0.004\n",
      "issue attention Facebook     -2.2703      1.135     -2.000      0.045      -4.495      -0.045\n",
      "issue attention Bundestag     0.6134      1.165      0.527      0.598      -1.669       2.896\n",
      "Social Media Nutzung          0.0228      0.025      0.897      0.370      -0.027       0.072\n",
      "Landtagswahlen               -0.4561      0.276     -1.653      0.098      -0.997       0.085\n",
      "topic_1                       0.8403      0.393      2.140      0.032       0.071       1.610\n",
      "topic_2                      -0.5835      0.425     -1.372      0.170      -1.417       0.250\n",
      "topic_4                      -0.4128      0.425     -0.971      0.331      -1.246       0.420\n",
      "topic_6                       0.3800      0.397      0.957      0.339      -0.398       1.158\n",
      "topic_7                      -1.3555      0.498     -2.723      0.006      -2.331      -0.380\n",
      "topic_8                      -1.1945      0.477     -2.503      0.012      -2.130      -0.259\n",
      "topic_15                     -0.8867      0.457     -1.941      0.052      -1.782       0.009\n",
      "topic_19                     -1.1658      0.484     -2.407      0.016      -2.115      -0.216\n",
      "topic_24                     -1.3370      0.501     -2.667      0.008      -2.320      -0.354\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.698480228211686\n",
      "Pr√§zision: 0.6285714285714286\n",
      "Recall: 0.15942028985507245\n",
      "F1-Score: 0.2543352601156069\n",
      "Brier-Score: 0.1633835239303988\n",
      "Confusion-Matrix:\n",
      "[[429  13]\n",
      " [116  22]]\n"
     ]
    }
   ],
   "source": [
    "# Schleife f√ºr logistische Regression mit Lags von -7 bis 7\n",
    "for n in range(1, 8):  # Einschlie√ülich 1 bis 7\n",
    "    try:\n",
    "        print(f\"\\nRegression f√ºr Lag {n}:\")\n",
    "        log_reg_FE_control(rede_reduced_spd, post_reduced_spd, post_common_spd,n, social_media_usage_spd)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Lag {n}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503442\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  640\n",
      "Model:                          Logit   Df Residuals:                      626\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07854\n",
      "Time:                        11:03:19   Log-Likelihood:                -322.20\n",
      "converged:                       True   LL-Null:                       -349.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.167e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9336      0.350     -2.669      0.008      -1.619      -0.248\n",
      "issue attention Facebook      0.4655      0.990      0.470      0.638      -1.474       2.405\n",
      "issue attention Bundestag    -0.3017      1.082     -0.279      0.780      -2.422       1.818\n",
      "Social Media Nutzung          0.0266      0.024      1.124      0.261      -0.020       0.073\n",
      "Landtagswahlen               -0.0180      0.179     -0.100      0.920      -0.369       0.333\n",
      "topic_1                       0.6960      0.369      1.888      0.059      -0.026       1.418\n",
      "topic_2                      -0.5358      0.407     -1.316      0.188      -1.333       0.262\n",
      "topic_4                      -0.3990      0.398     -1.003      0.316      -1.178       0.380\n",
      "topic_6                       0.2486      0.374      0.665      0.506      -0.484       0.981\n",
      "topic_7                      -1.3726      0.485     -2.832      0.005      -2.323      -0.423\n",
      "topic_8                      -1.0862      0.450     -2.414      0.016      -1.968      -0.204\n",
      "topic_15                     -0.8630      0.431     -2.002      0.045      -1.708      -0.018\n",
      "topic_19                     -1.2360      0.469     -2.638      0.008      -2.154      -0.318\n",
      "topic_24                     -1.2299      0.469     -2.623      0.009      -2.149      -0.311\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6894527282330476\n",
      "Pr√§zision: 0.6551724137931034\n",
      "Recall: 0.12582781456953643\n",
      "F1-Score: 0.2111111111111111\n",
      "Brier-Score: 0.16383941163170915\n",
      "Confusion-Matrix:\n",
      "[[479  10]\n",
      " [132  19]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497403\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  630\n",
      "Model:                          Logit   Df Residuals:                      616\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08443\n",
      "Time:                        11:03:19   Log-Likelihood:                -313.36\n",
      "converged:                       True   LL-Null:                       -342.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.297e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9888      0.356     -2.780      0.005      -1.686      -0.292\n",
      "issue attention Facebook      0.4245      1.015      0.418      0.676      -1.565       2.414\n",
      "issue attention Bundestag    -0.9950      1.178     -0.845      0.398      -3.304       1.314\n",
      "Social Media Nutzung          0.0444      0.024      1.865      0.062      -0.002       0.091\n",
      "Landtagswahlen               -0.0704      0.200     -0.353      0.724      -0.461       0.321\n",
      "topic_1                       0.6424      0.372      1.725      0.084      -0.087       1.372\n",
      "topic_2                      -0.6156      0.415     -1.484      0.138      -1.429       0.197\n",
      "topic_4                      -0.5250      0.405     -1.296      0.195      -1.319       0.269\n",
      "topic_6                       0.2271      0.377      0.603      0.547      -0.511       0.966\n",
      "topic_7                      -1.4095      0.487     -2.893      0.004      -2.364      -0.455\n",
      "topic_8                      -1.1139      0.453     -2.461      0.014      -2.001      -0.227\n",
      "topic_15                     -0.9116      0.434     -2.101      0.036      -1.762      -0.061\n",
      "topic_19                     -1.2901      0.471     -2.738      0.006      -2.214      -0.367\n",
      "topic_24                     -1.4346      0.490     -2.928      0.003      -2.395      -0.474\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6979549583808679\n",
      "Pr√§zision: 0.6071428571428571\n",
      "Recall: 0.11564625850340136\n",
      "F1-Score: 0.19428571428571428\n",
      "Brier-Score: 0.16155193540824397\n",
      "Confusion-Matrix:\n",
      "[[472  11]\n",
      " [130  17]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.499766\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  620\n",
      "Model:                          Logit   Df Residuals:                      606\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08116\n",
      "Time:                        11:03:19   Log-Likelihood:                -309.85\n",
      "converged:                       True   LL-Null:                       -337.23\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.488e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9422      0.359     -2.626      0.009      -1.645      -0.239\n",
      "issue attention Facebook      0.3525      1.012      0.348      0.728      -1.632       2.337\n",
      "issue attention Bundestag     0.5371      1.070      0.502      0.616      -1.559       2.634\n",
      "Social Media Nutzung          0.0258      0.024      1.064      0.287      -0.022       0.073\n",
      "Landtagswahlen               -0.3422      0.233     -1.466      0.143      -0.800       0.115\n",
      "topic_1                       0.7389      0.376      1.963      0.050       0.001       1.477\n",
      "topic_2                      -0.6060      0.419     -1.448      0.148      -1.426       0.214\n",
      "topic_4                      -0.3698      0.408     -0.906      0.365      -1.170       0.430\n",
      "topic_6                       0.3007      0.382      0.788      0.431      -0.448       1.049\n",
      "topic_7                      -1.2898      0.489     -2.636      0.008      -2.249      -0.331\n",
      "topic_8                      -1.0137      0.455     -2.229      0.026      -1.905      -0.122\n",
      "topic_15                     -0.7528      0.436     -1.725      0.084      -1.608       0.102\n",
      "topic_19                     -1.1263      0.474     -2.378      0.017      -2.054      -0.198\n",
      "topic_24                     -1.2762      0.492     -2.593      0.010      -2.241      -0.312\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6921742286751362\n",
      "Pr√§zision: 0.6111111111111112\n",
      "Recall: 0.15172413793103448\n",
      "F1-Score: 0.2430939226519337\n",
      "Brier-Score: 0.16226462744611936\n",
      "Confusion-Matrix:\n",
      "[[461  14]\n",
      " [123  22]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500512\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  610\n",
      "Model:                          Logit   Df Residuals:                      596\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07761\n",
      "Time:                        11:03:19   Log-Likelihood:                -305.31\n",
      "converged:                       True   LL-Null:                       -331.00\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.729e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7890      0.370     -2.134      0.033      -1.514      -0.064\n",
      "issue attention Facebook      0.4408      1.004      0.439      0.661      -1.527       2.409\n",
      "issue attention Bundestag     0.1975      1.112      0.178      0.859      -1.983       2.378\n",
      "Social Media Nutzung          0.0048      0.026      0.186      0.852      -0.046       0.056\n",
      "Landtagswahlen               -0.0470      0.258     -0.182      0.855      -0.552       0.458\n",
      "topic_1                       0.6693      0.377      1.775      0.076      -0.070       1.408\n",
      "topic_2                      -0.5878      0.417     -1.409      0.159      -1.405       0.230\n",
      "topic_4                      -0.3894      0.409     -0.952      0.341      -1.191       0.412\n",
      "topic_6                       0.2845      0.382      0.744      0.457      -0.465       1.034\n",
      "topic_7                      -1.2979      0.489     -2.653      0.008      -2.257      -0.339\n",
      "topic_8                      -1.1520      0.469     -2.455      0.014      -2.072      -0.232\n",
      "topic_15                     -0.8857      0.447     -1.983      0.047      -1.761      -0.010\n",
      "topic_19                     -1.1447      0.474     -2.416      0.016      -2.074      -0.216\n",
      "topic_24                     -1.2928      0.492     -2.626      0.009      -2.258      -0.328\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6896818947875285\n",
      "Pr√§zision: 0.5263157894736842\n",
      "Recall: 0.07042253521126761\n",
      "F1-Score: 0.12422360248447205\n",
      "Brier-Score: 0.16288835169985136\n",
      "Confusion-Matrix:\n",
      "[[459   9]\n",
      " [132  10]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.501326\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  600\n",
      "Model:                          Logit   Df Residuals:                      586\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07721\n",
      "Time:                        11:03:19   Log-Likelihood:                -300.80\n",
      "converged:                       True   LL-Null:                       -325.96\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.611e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6047      0.377     -1.606      0.108      -1.343       0.133\n",
      "issue attention Facebook      0.2627      1.007      0.261      0.794      -1.710       2.236\n",
      "issue attention Bundestag     0.4468      1.157      0.386      0.699      -1.821       2.714\n",
      "Social Media Nutzung         -0.0235      0.027     -0.881      0.378      -0.076       0.029\n",
      "Landtagswahlen               -0.1615      0.261     -0.620      0.535      -0.672       0.349\n",
      "topic_1                       0.7669      0.383      2.005      0.045       0.017       1.517\n",
      "topic_2                      -0.5200      0.420     -1.237      0.216      -1.344       0.304\n",
      "topic_4                      -0.3026      0.414     -0.731      0.465      -1.114       0.509\n",
      "topic_6                       0.3089      0.389      0.793      0.428      -0.454       1.072\n",
      "topic_7                      -1.2280      0.493     -2.491      0.013      -2.194      -0.262\n",
      "topic_8                      -1.0852      0.473     -2.295      0.022      -2.012      -0.158\n",
      "topic_15                     -0.8046      0.452     -1.782      0.075      -1.690       0.080\n",
      "topic_19                     -1.0647      0.479     -2.225      0.026      -2.003      -0.127\n",
      "topic_24                     -1.2157      0.497     -2.447      0.014      -2.189      -0.242\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6894565217391304\n",
      "Pr√§zision: 0.5666666666666667\n",
      "Recall: 0.12142857142857143\n",
      "F1-Score: 0.2\n",
      "Brier-Score: 0.16297713587145982\n",
      "Confusion-Matrix:\n",
      "[[447  13]\n",
      " [123  17]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503067\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  590\n",
      "Model:                          Logit   Df Residuals:                      576\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07854\n",
      "Time:                        11:03:19   Log-Likelihood:                -296.81\n",
      "converged:                       True   LL-Null:                       -322.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.354e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7911      0.376     -2.106      0.035      -1.527      -0.055\n",
      "issue attention Facebook      0.3058      1.014      0.301      0.763      -1.682       2.294\n",
      "issue attention Bundestag     0.2467      1.171      0.211      0.833      -2.049       2.542\n",
      "Social Media Nutzung          0.0077      0.026      0.297      0.766      -0.043       0.058\n",
      "Landtagswahlen               -0.2687      0.266     -1.008      0.313      -0.791       0.254\n",
      "topic_1                       0.7723      0.385      2.006      0.045       0.018       1.527\n",
      "topic_2                      -0.5185      0.422     -1.230      0.219      -1.345       0.308\n",
      "topic_4                      -0.4085      0.420     -0.972      0.331      -1.232       0.415\n",
      "topic_6                       0.3018      0.391      0.772      0.440      -0.465       1.068\n",
      "topic_7                      -1.2387      0.494     -2.505      0.012      -2.208      -0.270\n",
      "topic_8                      -1.0932      0.474     -2.306      0.021      -2.022      -0.164\n",
      "topic_15                     -0.8215      0.453     -1.815      0.070      -1.709       0.066\n",
      "topic_19                     -1.0827      0.480     -2.257      0.024      -2.023      -0.143\n",
      "topic_24                     -1.2330      0.498     -2.477      0.013      -2.209      -0.257\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6910941313468072\n",
      "Pr√§zision: 0.5652173913043478\n",
      "Recall: 0.18705035971223022\n",
      "F1-Score: 0.2810810810810811\n",
      "Brier-Score: 0.16393095546573688\n",
      "Confusion-Matrix:\n",
      "[[431  20]\n",
      " [113  26]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.501050\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  580\n",
      "Model:                          Logit   Df Residuals:                      566\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08681\n",
      "Time:                        11:03:19   Log-Likelihood:                -290.61\n",
      "converged:                       True   LL-Null:                       -318.24\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.646e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7314      0.375     -1.951      0.051      -1.466       0.004\n",
      "issue attention Facebook     -2.2703      1.135     -2.000      0.045      -4.495      -0.045\n",
      "issue attention Bundestag     0.6134      1.165      0.527      0.598      -1.669       2.896\n",
      "Social Media Nutzung          0.0228      0.025      0.897      0.370      -0.027       0.072\n",
      "Landtagswahlen               -0.4561      0.276     -1.653      0.098      -0.997       0.085\n",
      "topic_1                       0.8403      0.393      2.140      0.032       0.071       1.610\n",
      "topic_2                      -0.5835      0.425     -1.372      0.170      -1.417       0.250\n",
      "topic_4                      -0.4128      0.425     -0.971      0.331      -1.246       0.420\n",
      "topic_6                       0.3800      0.397      0.957      0.339      -0.398       1.158\n",
      "topic_7                      -1.3555      0.498     -2.723      0.006      -2.331      -0.380\n",
      "topic_8                      -1.1945      0.477     -2.503      0.012      -2.130      -0.259\n",
      "topic_15                     -0.8867      0.457     -1.941      0.052      -1.782       0.009\n",
      "topic_19                     -1.1658      0.484     -2.407      0.016      -2.115      -0.216\n",
      "topic_24                     -1.3370      0.501     -2.667      0.008      -2.320      -0.354\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.698480228211686\n",
      "Pr√§zision: 0.6285714285714286\n",
      "Recall: 0.15942028985507245\n",
      "F1-Score: 0.2543352601156069\n",
      "Brier-Score: 0.1633835239303988\n",
      "Confusion-Matrix:\n",
      "[[429  13]\n",
      " [116  22]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_spd, post_reduced_spd, post_common_spd,lag, social_media_usage_spd)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - SPD\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_spd.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500824\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  640\n",
      "Model:                          Logit   Df Residuals:                      624\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08333\n",
      "Time:                        11:03:19   Log-Likelihood:                -320.53\n",
      "converged:                       True   LL-Null:                       -349.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.978e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.6471      0.531     -3.103      0.002      -2.688      -0.607\n",
      "issue attention Facebook      0.5459      0.994      0.549      0.583      -1.403       2.494\n",
      "issue attention Bundestag    -0.3419      1.096     -0.312      0.755      -2.490       1.806\n",
      "Social Media Nutzung          0.1126      0.053      2.114      0.035       0.008       0.217\n",
      "Landtagswahlen                0.0142      0.183      0.078      0.938      -0.344       0.372\n",
      "Komplexit√§t Reden             0.0287      0.100      0.288      0.773      -0.166       0.224\n",
      "Komplexit√§t Posts            -0.3957      0.223     -1.775      0.076      -0.833       0.041\n",
      "topic_1                       0.6974      0.370      1.884      0.060      -0.028       1.423\n",
      "topic_2                      -0.5377      0.408     -1.318      0.188      -1.337       0.262\n",
      "topic_4                      -0.4040      0.399     -1.012      0.312      -1.186       0.378\n",
      "topic_6                       0.2471      0.375      0.659      0.510      -0.488       0.983\n",
      "topic_7                      -1.3768      0.486     -2.835      0.005      -2.329      -0.425\n",
      "topic_8                      -1.0897      0.451     -2.416      0.016      -1.974      -0.206\n",
      "topic_15                     -0.8680      0.432     -2.007      0.045      -1.715      -0.020\n",
      "topic_19                     -1.2425      0.470     -2.644      0.008      -2.164      -0.321\n",
      "topic_24                     -1.2355      0.470     -2.627      0.009      -2.157      -0.314\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6938474248026111\n",
      "Pr√§zision: 0.5806451612903226\n",
      "Recall: 0.11920529801324503\n",
      "F1-Score: 0.1978021978021978\n",
      "Brier-Score: 0.1629585381439104\n",
      "Confusion-Matrix:\n",
      "[[476  13]\n",
      " [133  18]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.493172\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  630\n",
      "Model:                          Logit   Df Residuals:                      614\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09222\n",
      "Time:                        11:03:19   Log-Likelihood:                -310.70\n",
      "converged:                       True   LL-Null:                       -342.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.257e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.4098      0.552     -2.553      0.011      -2.492      -0.328\n",
      "issue attention Facebook      0.5708      1.021      0.559      0.576      -1.430       2.572\n",
      "issue attention Bundestag    -0.8240      1.171     -0.704      0.482      -3.119       1.471\n",
      "Social Media Nutzung          0.0954      0.058      1.646      0.100      -0.018       0.209\n",
      "Landtagswahlen               -0.1417      0.205     -0.692      0.489      -0.543       0.259\n",
      "Komplexit√§t Reden            -0.2092      0.103     -2.032      0.042      -0.411      -0.007\n",
      "Komplexit√§t Posts            -0.2600      0.238     -1.093      0.274      -0.726       0.206\n",
      "topic_1                       0.6456      0.375      1.723      0.085      -0.089       1.380\n",
      "topic_2                      -0.6241      0.417     -1.496      0.135      -1.442       0.194\n",
      "topic_4                      -0.5218      0.407     -1.281      0.200      -1.320       0.277\n",
      "topic_6                       0.2359      0.379      0.623      0.533      -0.506       0.978\n",
      "topic_7                      -1.4082      0.489     -2.881      0.004      -2.366      -0.450\n",
      "topic_8                      -1.1120      0.454     -2.447      0.014      -2.003      -0.221\n",
      "topic_15                     -0.9054      0.436     -2.077      0.038      -1.760      -0.051\n",
      "topic_19                     -1.2852      0.473     -2.717      0.007      -2.212      -0.358\n",
      "topic_24                     -1.4300      0.492     -2.907      0.004      -2.394      -0.466\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7055816115265983\n",
      "Pr√§zision: 0.625\n",
      "Recall: 0.1360544217687075\n",
      "F1-Score: 0.22346368715083798\n",
      "Brier-Score: 0.1602214689682647\n",
      "Confusion-Matrix:\n",
      "[[471  12]\n",
      " [127  20]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.492120\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  620\n",
      "Model:                          Logit   Df Residuals:                      604\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09522\n",
      "Time:                        11:03:19   Log-Likelihood:                -305.11\n",
      "converged:                       True   LL-Null:                       -337.23\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.675e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.5681      0.563     -2.784      0.005      -2.672      -0.464\n",
      "issue attention Facebook      0.2608      1.020      0.256      0.798      -1.738       2.260\n",
      "issue attention Bundestag     0.3175      1.091      0.291      0.771      -1.822       2.457\n",
      "Social Media Nutzung          0.1020      0.059      1.737      0.082      -0.013       0.217\n",
      "Landtagswahlen               -0.2796      0.244     -1.146      0.252      -0.758       0.199\n",
      "Komplexit√§t Reden             0.2895      0.104      2.780      0.005       0.085       0.494\n",
      "Komplexit√§t Posts            -0.3172      0.241     -1.315      0.188      -0.790       0.156\n",
      "topic_1                       0.7582      0.381      1.991      0.046       0.012       1.504\n",
      "topic_2                      -0.6082      0.422     -1.442      0.149      -1.435       0.219\n",
      "topic_4                      -0.3893      0.413     -0.944      0.345      -1.198       0.419\n",
      "topic_6                       0.3000      0.386      0.776      0.437      -0.457       1.057\n",
      "topic_7                      -1.3216      0.493     -2.680      0.007      -2.288      -0.355\n",
      "topic_8                      -1.0368      0.459     -2.261      0.024      -1.936      -0.138\n",
      "topic_15                     -0.7832      0.440     -1.779      0.075      -1.646       0.080\n",
      "topic_19                     -1.1619      0.478     -2.433      0.015      -2.098      -0.226\n",
      "topic_24                     -1.3141      0.496     -2.650      0.008      -2.286      -0.342\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7098656987295825\n",
      "Pr√§zision: 0.631578947368421\n",
      "Recall: 0.16551724137931034\n",
      "F1-Score: 0.26229508196721313\n",
      "Brier-Score: 0.15964803281916867\n",
      "Confusion-Matrix:\n",
      "[[461  14]\n",
      " [121  24]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.499418\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  610\n",
      "Model:                          Logit   Df Residuals:                      594\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07962\n",
      "Time:                        11:03:19   Log-Likelihood:                -304.64\n",
      "converged:                       True   LL-Null:                       -331.00\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.310e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.2367      0.555     -2.230      0.026      -2.324      -0.150\n",
      "issue attention Facebook      0.4490      1.005      0.447      0.655      -1.522       2.420\n",
      "issue attention Bundestag     0.1467      1.118      0.131      0.896      -2.045       2.339\n",
      "Social Media Nutzung          0.0622      0.059      1.062      0.288      -0.053       0.177\n",
      "Landtagswahlen               -0.0817      0.262     -0.312      0.755      -0.595       0.432\n",
      "Komplexit√§t Reden             0.0414      0.103      0.403      0.687      -0.160       0.243\n",
      "Komplexit√§t Posts            -0.2541      0.235     -1.083      0.279      -0.714       0.206\n",
      "topic_1                       0.6706      0.378      1.776      0.076      -0.070       1.411\n",
      "topic_2                      -0.5882      0.418     -1.408      0.159      -1.407       0.230\n",
      "topic_4                      -0.3935      0.410     -0.961      0.337      -1.196       0.409\n",
      "topic_6                       0.2829      0.383      0.739      0.460      -0.468       1.034\n",
      "topic_7                      -1.3021      0.490     -2.659      0.008      -2.262      -0.342\n",
      "topic_8                      -1.1550      0.470     -2.459      0.014      -2.076      -0.234\n",
      "topic_15                     -0.8909      0.447     -1.992      0.046      -1.767      -0.014\n",
      "topic_19                     -1.1503      0.475     -2.424      0.015      -2.080      -0.220\n",
      "topic_24                     -1.2984      0.493     -2.634      0.008      -2.264      -0.332\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6930450222703746\n",
      "Pr√§zision: 0.64\n",
      "Recall: 0.11267605633802817\n",
      "F1-Score: 0.19161676646706588\n",
      "Brier-Score: 0.16243808592842546\n",
      "Confusion-Matrix:\n",
      "[[459   9]\n",
      " [126  16]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.494867\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  600\n",
      "Model:                          Logit   Df Residuals:                      584\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08910\n",
      "Time:                        11:03:19   Log-Likelihood:                -296.92\n",
      "converged:                       True   LL-Null:                       -325.96\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.361e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.0509      0.564     -1.864      0.062      -2.156       0.054\n",
      "issue attention Facebook      0.4253      1.019      0.417      0.676      -1.572       2.423\n",
      "issue attention Bundestag     0.6719      1.157      0.581      0.562      -1.596       2.940\n",
      "Social Media Nutzung          0.0304      0.059      0.512      0.609      -0.086       0.147\n",
      "Landtagswahlen               -0.2743      0.267     -1.027      0.304      -0.798       0.249\n",
      "Komplexit√§t Reden            -0.2707      0.107     -2.528      0.011      -0.481      -0.061\n",
      "Komplexit√§t Posts            -0.2548      0.238     -1.072      0.284      -0.721       0.211\n",
      "topic_1                       0.7768      0.386      2.012      0.044       0.020       1.533\n",
      "topic_2                      -0.5329      0.424     -1.258      0.209      -1.363       0.298\n",
      "topic_4                      -0.2967      0.417     -0.712      0.477      -1.114       0.521\n",
      "topic_6                       0.3186      0.392      0.812      0.417      -0.450       1.088\n",
      "topic_7                      -1.2302      0.495     -2.484      0.013      -2.201      -0.260\n",
      "topic_8                      -1.0919      0.475     -2.297      0.022      -2.024      -0.160\n",
      "topic_15                     -0.7966      0.454     -1.754      0.079      -1.687       0.094\n",
      "topic_19                     -1.0586      0.481     -2.201      0.028      -2.001      -0.116\n",
      "topic_24                     -1.2093      0.499     -2.422      0.015      -2.188      -0.231\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6992546583850932\n",
      "Pr√§zision: 0.6764705882352942\n",
      "Recall: 0.16428571428571428\n",
      "F1-Score: 0.26436781609195403\n",
      "Brier-Score: 0.1611573552884109\n",
      "Confusion-Matrix:\n",
      "[[449  11]\n",
      " [117  23]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.499954\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  590\n",
      "Model:                          Logit   Df Residuals:                      574\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08424\n",
      "Time:                        11:03:19   Log-Likelihood:                -294.97\n",
      "converged:                       True   LL-Null:                       -322.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.366e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9029      0.558     -1.617      0.106      -1.997       0.191\n",
      "issue attention Facebook      0.2065      1.018      0.203      0.839      -1.790       2.203\n",
      "issue attention Bundestag     0.0752      1.188      0.063      0.950      -2.253       2.403\n",
      "Social Media Nutzung          0.0228      0.059      0.385      0.700      -0.093       0.139\n",
      "Landtagswahlen               -0.2414      0.271     -0.891      0.373      -0.772       0.289\n",
      "Komplexit√§t Reden             0.1968      0.104      1.895      0.058      -0.007       0.400\n",
      "Komplexit√§t Posts            -0.0557      0.239     -0.233      0.816      -0.524       0.412\n",
      "topic_1                       0.7810      0.387      2.019      0.043       0.023       1.539\n",
      "topic_2                      -0.5212      0.423     -1.232      0.218      -1.350       0.308\n",
      "topic_4                      -0.4218      0.422     -0.999      0.318      -1.250       0.406\n",
      "topic_6                       0.2990      0.393      0.761      0.447      -0.471       1.069\n",
      "topic_7                      -1.2579      0.496     -2.534      0.011      -2.231      -0.285\n",
      "topic_8                      -1.1076      0.476     -2.328      0.020      -2.040      -0.175\n",
      "topic_15                     -0.8416      0.454     -1.852      0.064      -1.732       0.049\n",
      "topic_19                     -1.1052      0.482     -2.295      0.022      -2.049      -0.161\n",
      "topic_24                     -1.2569      0.500     -2.516      0.012      -2.236      -0.278\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7009682719456364\n",
      "Pr√§zision: 0.5142857142857142\n",
      "Recall: 0.12949640287769784\n",
      "F1-Score: 0.20689655172413793\n",
      "Brier-Score: 0.1633031447104077\n",
      "Confusion-Matrix:\n",
      "[[434  17]\n",
      " [121  18]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500959\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  580\n",
      "Model:                          Logit   Df Residuals:                      564\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08698\n",
      "Time:                        11:03:19   Log-Likelihood:                -290.56\n",
      "converged:                       True   LL-Null:                       -318.24\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.554e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.8566      0.554     -1.546      0.122      -1.943       0.230\n",
      "issue attention Facebook     -2.2719      1.138     -1.996      0.046      -4.503      -0.041\n",
      "issue attention Bundestag     0.5989      1.169      0.512      0.608      -1.692       2.890\n",
      "Social Media Nutzung          0.0391      0.059      0.665      0.506      -0.076       0.154\n",
      "Landtagswahlen               -0.4664      0.280     -1.668      0.095      -1.014       0.081\n",
      "Komplexit√§t Reden             0.0114      0.104      0.109      0.913      -0.193       0.216\n",
      "Komplexit√§t Posts            -0.0723      0.238     -0.303      0.762      -0.540       0.395\n",
      "topic_1                       0.8401      0.393      2.139      0.032       0.070       1.610\n",
      "topic_2                      -0.5828      0.425     -1.370      0.171      -1.417       0.251\n",
      "topic_4                      -0.4136      0.425     -0.973      0.331      -1.247       0.420\n",
      "topic_6                       0.3796      0.397      0.956      0.339      -0.399       1.158\n",
      "topic_7                      -1.3567      0.498     -2.725      0.006      -2.333      -0.381\n",
      "topic_8                      -1.1958      0.477     -2.505      0.012      -2.132      -0.260\n",
      "topic_15                     -0.8879      0.457     -1.943      0.052      -1.784       0.008\n",
      "topic_19                     -1.1671      0.484     -2.409      0.016      -2.117      -0.217\n",
      "topic_24                     -1.3382      0.501     -2.669      0.008      -2.321      -0.355\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6991442061774542\n",
      "Pr√§zision: 0.6388888888888888\n",
      "Recall: 0.16666666666666666\n",
      "F1-Score: 0.26436781609195403\n",
      "Brier-Score: 0.16338285981334172\n",
      "Confusion-Matrix:\n",
      "[[429  13]\n",
      " [115  23]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_spd, post_reduced_spd, post_common_spd,lag, social_media_usage_spd,rede_komplex_spd,posts_komplex_spd)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - SPD\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_spd_complex.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log_reg_FE_control_test() missing 7 required positional arguments: 'relativ_rede', 'relativ_posts', 'post_to_shift', 'shifts', 'social_media_usage', 'complexity_rede', and 'complexity_post'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlog_reg_FE_control_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: log_reg_FE_control_test() missing 7 required positional arguments: 'relativ_rede', 'relativ_posts', 'post_to_shift', 'shifts', 'social_media_usage', 'complexity_rede', and 'complexity_post'"
     ]
    }
   ],
   "source": [
    "log_reg_FE_control_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\3344225774.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_cdu[\"date\"] = pd.to_datetime(subset_reden_cdu[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\3344225774.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_cdu[\"date\"] = pd.to_datetime(subset_posts_cdu[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_cdu = subset_posts[subset_posts[\"partei\"] == \"CDU\"]\n",
    "subset_reden_cdu = subset_reden[subset_reden[\"partei\"] == \"CDU\"]\n",
    "social_media_usage_cdu = subset_posts_cdu.groupby('date').size()\n",
    "subset_reden_cdu[\"date\"] = pd.to_datetime(subset_reden_cdu[\"date\"])\n",
    "subset_posts_cdu[\"date\"] = pd.to_datetime(subset_posts_cdu[\"date\"])\n",
    "reden_komplexit√§t_t√§glich_cdu = subset_reden_cdu.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_cdu = subset_posts_cdu.groupby('date')['komplexit√§t'].sum()\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_cdu = subset_reden_cdu.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_cdu = subset_posts_cdu.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_cdu = redethemen_t√§glich_cdu.index.intersection(postthemen_t√§glich_cdu.index)\n",
    "redethemen_t√§glich_aligned_cdu = redethemen_t√§glich_cdu.loc[common_dates_cdu]\n",
    "postthemen_t√§glich_aligned_cdu = postthemen_t√§glich_cdu.loc[common_dates_cdu]\n",
    "rede_komplex_cdu = reden_komplexit√§t_t√§glich_cdu.loc[common_dates_cdu]\n",
    "posts_komplex_cdu = posts_komplexit√§t_t√§glich_cdu.loc[common_dates_cdu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 52, 54, 56, 58, 68, 69, 70, 74, 75, 77, 78, 80, 83, 84, 90, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 6, 8, 10, 12, 14, 15, 20, 22}\n"
     ]
    }
   ],
   "source": [
    "rede_common_cdu, post_common_cdu = filter_common_topics(redethemen_t√§glich_aligned_cdu, postthemen_t√§glich_aligned_cdu)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_cdu =  rede_common_cdu.div(rede_common_cdu.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_cdu = post_common_cdu.div(post_common_cdu.sum(axis=1), axis=0)\n",
    "reden_relativ_cdu_red = remove_near_constant(reden_relativ_cdu)\n",
    "post_relativ_cdu_red = remove_near_constant(post_relativ_cdu)\n",
    "rede_reduced_cdu, post_reduced_cdu = filter_common_topics(reden_relativ_cdu_red, post_relativ_cdu_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.585608\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  845\n",
      "Model:                          Logit   Df Residuals:                      842\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02739\n",
      "Time:                        18:29:04   Log-Likelihood:                -494.84\n",
      "converged:                       True   LL-Null:                       -508.77\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.876e-07\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -1.1468      0.095    -12.118      0.000      -1.332      -0.961\n",
      "posts_relative     4.3575      0.902      4.833      0.000       2.590       6.125\n",
      "reden_relativ      0.9633      0.789      1.221      0.222      -0.583       2.510\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM(rede_reduced_cdu,post_reduced_cdu, post_common_cdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         Current function value: 0.566685\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  845\n",
      "Model:                          Logit   Df Residuals:                      830\n",
      "Method:                           MLE   Df Model:                           14\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05882\n",
      "Time:                        18:29:04   Log-Likelihood:                -478.85\n",
      "converged:                       True   LL-Null:                       -508.77\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.247e-07\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -0.5218      0.265     -1.967      0.049      -1.042      -0.002\n",
      "posts_relative     3.5677      0.911      3.914      0.000       1.781       5.354\n",
      "reden_relativ      0.2899      0.839      0.346      0.730      -1.354       1.934\n",
      "topic_1            0.2934      0.358      0.820      0.412      -0.408       0.995\n",
      "topic_2           -0.3518      0.369     -0.954      0.340      -1.075       0.371\n",
      "topic_3           -0.5312      0.373     -1.423      0.155      -1.263       0.201\n",
      "topic_4           -0.1478      0.363     -0.407      0.684      -0.860       0.564\n",
      "topic_6           -0.7246      0.386     -1.879      0.060      -1.481       0.031\n",
      "topic_8           -0.8763      0.397     -2.208      0.027      -1.654      -0.098\n",
      "topic_10          -0.7387      0.386     -1.916      0.055      -1.494       0.017\n",
      "topic_12          -0.5274      0.377     -1.399      0.162      -1.267       0.212\n",
      "topic_14          -1.4155      0.443     -3.196      0.001      -2.284      -0.547\n",
      "topic_15          -0.8066      0.394     -2.046      0.041      -1.579      -0.034\n",
      "topic_20          -1.2291      0.424     -2.900      0.004      -2.060      -0.398\n",
      "topic_22          -0.7969      0.393     -2.030      0.042      -1.566      -0.028\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM_fixed_effects(rede_reduced_cdu,post_reduced_cdu, post_common_cdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression f√ºr Lag 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563633\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  845\n",
      "Model:                          Logit   Df Residuals:                      828\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06389\n",
      "Time:                        18:29:04   Log-Likelihood:                -476.27\n",
      "converged:                       True   LL-Null:                       -508.77\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.346e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5468      0.326     -1.677      0.094      -1.186       0.092\n",
      "issue attention Facebook      3.5345      0.912      3.874      0.000       1.746       5.323\n",
      "issue attention Bundestag     0.3080      0.843      0.365      0.715      -1.344       1.960\n",
      "Social Media Nutzung         -0.0049      0.013     -0.365      0.715      -0.031       0.021\n",
      "Landtagswahlen                0.3085      0.138      2.236      0.025       0.038       0.579\n",
      "topic_1                       0.2952      0.358      0.825      0.410      -0.406       0.997\n",
      "topic_2                      -0.3564      0.370     -0.963      0.335      -1.082       0.369\n",
      "topic_3                      -0.5328      0.373     -1.427      0.154      -1.265       0.199\n",
      "topic_4                      -0.1482      0.364     -0.407      0.684      -0.861       0.565\n",
      "topic_6                      -0.7308      0.386     -1.892      0.059      -1.488       0.026\n",
      "topic_8                      -0.8867      0.398     -2.227      0.026      -1.667      -0.106\n",
      "topic_10                     -0.7456      0.386     -1.930      0.054      -1.503       0.012\n",
      "topic_12                     -0.5373      0.380     -1.415      0.157      -1.282       0.207\n",
      "topic_14                     -1.4325      0.444     -3.224      0.001      -2.303      -0.562\n",
      "topic_15                     -0.8162      0.396     -2.062      0.039      -1.592      -0.040\n",
      "topic_20                     -1.2307      0.424     -2.905      0.004      -2.061      -0.400\n",
      "topic_22                     -0.8016      0.393     -2.039      0.041      -1.572      -0.031\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6735272108843536\n",
      "Pr√§zision: 0.49295774647887325\n",
      "Recall: 0.14285714285714285\n",
      "F1-Score: 0.22151898734177214\n",
      "Brier-Score: 0.19003218549491768\n",
      "Confusion-Matrix:\n",
      "[[564  36]\n",
      " [210  35]]\n",
      "\n",
      "Regression f√ºr Lag 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.562363\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  832\n",
      "Model:                          Logit   Df Residuals:                      815\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06727\n",
      "Time:                        18:29:04   Log-Likelihood:                -467.89\n",
      "converged:                       True   LL-Null:                       -501.63\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.730e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.0610      0.335     -3.171      0.002      -1.717      -0.405\n",
      "issue attention Facebook      2.7605      0.916      3.014      0.003       0.966       4.555\n",
      "issue attention Bundestag     1.9183      0.845      2.269      0.023       0.261       3.575\n",
      "Social Media Nutzung          0.0297      0.013      2.202      0.028       0.003       0.056\n",
      "Landtagswahlen                0.3458      0.155      2.232      0.026       0.042       0.650\n",
      "topic_1                       0.3256      0.362      0.900      0.368      -0.384       1.035\n",
      "topic_2                      -0.4283      0.374     -1.145      0.252      -1.162       0.305\n",
      "topic_3                      -0.5903      0.380     -1.554      0.120      -1.335       0.154\n",
      "topic_4                      -0.1431      0.368     -0.388      0.698      -0.865       0.579\n",
      "topic_6                      -0.7187      0.389     -1.848      0.065      -1.481       0.044\n",
      "topic_8                      -0.8582      0.401     -2.142      0.032      -1.643      -0.073\n",
      "topic_10                     -0.7476      0.390     -1.919      0.055      -1.511       0.016\n",
      "topic_12                     -0.4325      0.381     -1.136      0.256      -1.179       0.314\n",
      "topic_14                     -1.3736      0.446     -3.081      0.002      -2.247      -0.500\n",
      "topic_15                     -0.7390      0.397     -1.860      0.063      -1.518       0.040\n",
      "topic_20                     -1.2864      0.437     -2.946      0.003      -2.142      -0.431\n",
      "topic_22                     -0.7406      0.396     -1.870      0.062      -1.517       0.036\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6772972405098753\n",
      "Pr√§zision: 0.5324675324675324\n",
      "Recall: 0.16942148760330578\n",
      "F1-Score: 0.25705329153605017\n",
      "Brier-Score: 0.1894008685281736\n",
      "Confusion-Matrix:\n",
      "[[554  36]\n",
      " [201  41]]\n",
      "\n",
      "Regression f√ºr Lag 3:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.562518\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  819\n",
      "Model:                          Logit   Df Residuals:                      802\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06495\n",
      "Time:                        18:29:04   Log-Likelihood:                -460.70\n",
      "converged:                       True   LL-Null:                       -492.70\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.092e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7377      0.337     -2.190      0.029      -1.398      -0.078\n",
      "issue attention Facebook      2.9976      0.924      3.246      0.001       1.188       4.808\n",
      "issue attention Bundestag     1.9044      0.852      2.236      0.025       0.235       3.574\n",
      "Social Media Nutzung          0.0102      0.014      0.736      0.462      -0.017       0.037\n",
      "Landtagswahlen                0.1936      0.174      1.114      0.265      -0.147       0.534\n",
      "topic_1                       0.2643      0.363      0.728      0.467      -0.447       0.976\n",
      "topic_2                      -0.4159      0.375     -1.109      0.268      -1.151       0.319\n",
      "topic_3                      -0.6796      0.385     -1.767      0.077      -1.433       0.074\n",
      "topic_4                      -0.1463      0.369     -0.396      0.692      -0.870       0.577\n",
      "topic_6                      -0.8046      0.394     -2.041      0.041      -1.577      -0.032\n",
      "topic_8                      -0.8467      0.401     -2.112      0.035      -1.633      -0.061\n",
      "topic_10                     -0.7430      0.390     -1.907      0.056      -1.506       0.020\n",
      "topic_12                     -0.4372      0.381     -1.147      0.251      -1.184       0.310\n",
      "topic_14                     -1.3537      0.446     -3.035      0.002      -2.228      -0.480\n",
      "topic_15                     -0.7289      0.398     -1.833      0.067      -1.508       0.050\n",
      "topic_20                     -1.4105      0.449     -3.142      0.002      -2.290      -0.531\n",
      "topic_22                     -0.8241      0.402     -2.052      0.040      -1.611      -0.037\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6653979439442053\n",
      "Pr√§zision: 0.6\n",
      "Recall: 0.16455696202531644\n",
      "F1-Score: 0.2582781456953642\n",
      "Brier-Score: 0.18927346765784567\n",
      "Confusion-Matrix:\n",
      "[[556  26]\n",
      " [198  39]]\n",
      "\n",
      "Regression f√ºr Lag 4:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.564724\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  806\n",
      "Model:                          Logit   Df Residuals:                      789\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06261\n",
      "Time:                        18:29:04   Log-Likelihood:                -455.17\n",
      "converged:                       True   LL-Null:                       -485.57\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.838e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2465      0.343     -0.719      0.472      -0.918       0.425\n",
      "issue attention Facebook      3.3098      0.930      3.558      0.000       1.487       5.133\n",
      "issue attention Bundestag     0.1326      0.883      0.150      0.881      -1.598       1.864\n",
      "Social Media Nutzung         -0.0160      0.015     -1.094      0.274      -0.045       0.013\n",
      "Landtagswahlen                0.2081      0.196      1.064      0.287      -0.175       0.591\n",
      "topic_1                       0.1900      0.365      0.521      0.602      -0.525       0.905\n",
      "topic_2                      -0.3308      0.373     -0.886      0.375      -1.062       0.401\n",
      "topic_3                      -0.7903      0.388     -2.037      0.042      -1.551      -0.030\n",
      "topic_4                      -0.2305      0.371     -0.621      0.534      -0.958       0.497\n",
      "topic_6                      -0.8398      0.396     -2.123      0.034      -1.615      -0.065\n",
      "topic_8                      -0.9069      0.402     -2.254      0.024      -1.696      -0.118\n",
      "topic_10                     -0.8587      0.396     -2.171      0.030      -1.634      -0.083\n",
      "topic_12                     -0.5425      0.384     -1.413      0.158      -1.295       0.210\n",
      "topic_14                     -1.4389      0.448     -3.214      0.001      -2.316      -0.561\n",
      "topic_15                     -0.8408      0.400     -2.101      0.036      -1.625      -0.056\n",
      "topic_20                     -1.5100      0.450     -3.357      0.001      -2.392      -0.628\n",
      "topic_22                     -0.9207      0.403     -2.284      0.022      -1.711      -0.130\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6729387065925528\n",
      "Pr√§zision: 0.5238095238095238\n",
      "Recall: 0.14102564102564102\n",
      "F1-Score: 0.2222222222222222\n",
      "Brier-Score: 0.19075861870679106\n",
      "Confusion-Matrix:\n",
      "[[542  30]\n",
      " [201  33]]\n",
      "\n",
      "Regression f√ºr Lag 5:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.570703\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  793\n",
      "Model:                          Logit   Df Residuals:                      776\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05580\n",
      "Time:                        18:29:04   Log-Likelihood:                -452.57\n",
      "converged:                       True   LL-Null:                       -479.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.286e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2535      0.343     -0.739      0.460      -0.926       0.419\n",
      "issue attention Facebook      2.4125      0.933      2.586      0.010       0.584       4.241\n",
      "issue attention Bundestag    -0.1468      0.913     -0.161      0.872      -1.937       1.643\n",
      "Social Media Nutzung         -0.0105      0.014     -0.730      0.465      -0.039       0.018\n",
      "Landtagswahlen                0.1320      0.197      0.672      0.502      -0.253       0.517\n",
      "topic_1                       0.2645      0.367      0.722      0.470      -0.454       0.983\n",
      "topic_2                      -0.2853      0.374     -0.764      0.445      -1.018       0.447\n",
      "topic_3                      -0.7373      0.388     -1.902      0.057      -1.497       0.022\n",
      "topic_4                      -0.1978      0.372     -0.532      0.595      -0.927       0.531\n",
      "topic_6                      -0.8235      0.396     -2.078      0.038      -1.600      -0.047\n",
      "topic_8                      -0.9007      0.403     -2.235      0.025      -1.691      -0.111\n",
      "topic_10                     -0.8361      0.396     -2.111      0.035      -1.613      -0.060\n",
      "topic_12                     -0.5062      0.383     -1.321      0.187      -1.258       0.245\n",
      "topic_14                     -1.4376      0.448     -3.207      0.001      -2.316      -0.559\n",
      "topic_15                     -0.8280      0.401     -2.067      0.039      -1.613      -0.043\n",
      "topic_20                     -1.6293      0.464     -3.510      0.000      -2.539      -0.720\n",
      "topic_22                     -0.9160      0.404     -2.266      0.023      -1.708      -0.124\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6539392402729117\n",
      "Pr√§zision: 0.6153846153846154\n",
      "Recall: 0.13793103448275862\n",
      "F1-Score: 0.22535211267605634\n",
      "Brier-Score: 0.19298203730002328\n",
      "Confusion-Matrix:\n",
      "[[541  20]\n",
      " [200  32]]\n",
      "\n",
      "Regression f√ºr Lag 6:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.570302\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      763\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05611\n",
      "Time:                        18:29:04   Log-Likelihood:                -444.84\n",
      "converged:                       True   LL-Null:                       -471.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.865e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2074      0.346     -0.599      0.549      -0.886       0.472\n",
      "issue attention Facebook      1.9716      0.942      2.094      0.036       0.126       3.817\n",
      "issue attention Bundestag    -0.6439      0.941     -0.684      0.494      -2.489       1.201\n",
      "Social Media Nutzung         -0.0124      0.014     -0.862      0.388      -0.041       0.016\n",
      "Landtagswahlen                0.1677      0.196      0.854      0.393      -0.217       0.553\n",
      "topic_1                       0.3442      0.370      0.930      0.352      -0.381       1.069\n",
      "topic_2                      -0.2966      0.378     -0.784      0.433      -1.038       0.445\n",
      "topic_3                      -0.7670      0.393     -1.949      0.051      -1.538       0.004\n",
      "topic_4                      -0.1586      0.375     -0.423      0.672      -0.893       0.576\n",
      "topic_6                      -0.7907      0.399     -1.983      0.047      -1.572      -0.009\n",
      "topic_8                      -0.8803      0.406     -2.170      0.030      -1.675      -0.085\n",
      "topic_10                     -0.7988      0.399     -2.003      0.045      -1.580      -0.017\n",
      "topic_12                     -0.4743      0.386     -1.230      0.219      -1.230       0.282\n",
      "topic_14                     -1.4252      0.450     -3.164      0.002      -2.308      -0.542\n",
      "topic_15                     -0.8161      0.403     -2.025      0.043      -1.606      -0.026\n",
      "topic_20                     -1.7634      0.484     -3.642      0.000      -2.712      -0.814\n",
      "topic_22                     -0.9013      0.407     -2.216      0.027      -1.699      -0.104\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6557216183574879\n",
      "Pr√§zision: 0.5490196078431373\n",
      "Recall: 0.12280701754385964\n",
      "F1-Score: 0.2007168458781362\n",
      "Brier-Score: 0.1930846829919863\n",
      "Confusion-Matrix:\n",
      "[[529  23]\n",
      " [200  28]]\n",
      "\n",
      "Regression f√ºr Lag 7:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566621\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  767\n",
      "Model:                          Logit   Df Residuals:                      750\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06185\n",
      "Time:                        18:29:04   Log-Likelihood:                -434.60\n",
      "converged:                       True   LL-Null:                       -463.25\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.482e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4239      0.348     -1.217      0.224      -1.106       0.259\n",
      "issue attention Facebook      2.6258      0.941      2.791      0.005       0.782       4.470\n",
      "issue attention Bundestag     0.8608      0.897      0.960      0.337      -0.898       2.619\n",
      "Social Media Nutzung         -0.0046      0.014     -0.321      0.748      -0.033       0.023\n",
      "Landtagswahlen                0.1170      0.199      0.587      0.557      -0.274       0.508\n",
      "topic_1                       0.2687      0.374      0.719      0.472      -0.464       1.001\n",
      "topic_2                      -0.3254      0.381     -0.854      0.393      -1.073       0.422\n",
      "topic_3                      -0.8602      0.403     -2.137      0.033      -1.649      -0.071\n",
      "topic_4                      -0.0829      0.378     -0.219      0.826      -0.823       0.658\n",
      "topic_6                      -0.7493      0.401     -1.871      0.061      -1.534       0.036\n",
      "topic_8                      -0.8082      0.407     -1.985      0.047      -1.606      -0.010\n",
      "topic_10                     -0.7604      0.400     -1.899      0.058      -1.545       0.024\n",
      "topic_12                     -0.3873      0.389     -0.996      0.319      -1.149       0.375\n",
      "topic_14                     -1.4750      0.467     -3.161      0.002      -2.389      -0.561\n",
      "topic_15                     -0.7092      0.405     -1.751      0.080      -1.503       0.084\n",
      "topic_20                     -1.6853      0.487     -3.462      0.001      -2.639      -0.731\n",
      "topic_22                     -0.9025      0.415     -2.177      0.029      -1.715      -0.090\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6666872204682979\n",
      "Pr√§zision: 0.5192307692307693\n",
      "Recall: 0.12053571428571429\n",
      "F1-Score: 0.1956521739130435\n",
      "Brier-Score: 0.19172194516502064\n",
      "Confusion-Matrix:\n",
      "[[518  25]\n",
      " [197  27]]\n"
     ]
    }
   ],
   "source": [
    "# Schleife f√ºr logistische Regression mit Lags von -7 bis 7\n",
    "for n in range(1, 8):  # Einschlie√ülich 1 bis 7\n",
    "    try:\n",
    "        print(f\"\\nRegression f√ºr Lag {n}:\")\n",
    "        log_reg_FE_control(rede_reduced_cdu, post_reduced_cdu, post_common_cdu,n, social_media_usage_cdu)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Lag {n}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563633\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  845\n",
      "Model:                          Logit   Df Residuals:                      828\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06389\n",
      "Time:                        18:29:04   Log-Likelihood:                -476.27\n",
      "converged:                       True   LL-Null:                       -508.77\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.346e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5468      0.326     -1.677      0.094      -1.186       0.092\n",
      "issue attention Facebook      3.5345      0.912      3.874      0.000       1.746       5.323\n",
      "issue attention Bundestag     0.3080      0.843      0.365      0.715      -1.344       1.960\n",
      "Social Media Nutzung         -0.0049      0.013     -0.365      0.715      -0.031       0.021\n",
      "Landtagswahlen                0.3085      0.138      2.236      0.025       0.038       0.579\n",
      "topic_1                       0.2952      0.358      0.825      0.410      -0.406       0.997\n",
      "topic_2                      -0.3564      0.370     -0.963      0.335      -1.082       0.369\n",
      "topic_3                      -0.5328      0.373     -1.427      0.154      -1.265       0.199\n",
      "topic_4                      -0.1482      0.364     -0.407      0.684      -0.861       0.565\n",
      "topic_6                      -0.7308      0.386     -1.892      0.059      -1.488       0.026\n",
      "topic_8                      -0.8867      0.398     -2.227      0.026      -1.667      -0.106\n",
      "topic_10                     -0.7456      0.386     -1.930      0.054      -1.503       0.012\n",
      "topic_12                     -0.5373      0.380     -1.415      0.157      -1.282       0.207\n",
      "topic_14                     -1.4325      0.444     -3.224      0.001      -2.303      -0.562\n",
      "topic_15                     -0.8162      0.396     -2.062      0.039      -1.592      -0.040\n",
      "topic_20                     -1.2307      0.424     -2.905      0.004      -2.061      -0.400\n",
      "topic_22                     -0.8016      0.393     -2.039      0.041      -1.572      -0.031\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6735272108843536\n",
      "Pr√§zision: 0.49295774647887325\n",
      "Recall: 0.14285714285714285\n",
      "F1-Score: 0.22151898734177214\n",
      "Brier-Score: 0.19003218549491768\n",
      "Confusion-Matrix:\n",
      "[[564  36]\n",
      " [210  35]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.562363\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  832\n",
      "Model:                          Logit   Df Residuals:                      815\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06727\n",
      "Time:                        18:29:04   Log-Likelihood:                -467.89\n",
      "converged:                       True   LL-Null:                       -501.63\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.730e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.0610      0.335     -3.171      0.002      -1.717      -0.405\n",
      "issue attention Facebook      2.7605      0.916      3.014      0.003       0.966       4.555\n",
      "issue attention Bundestag     1.9183      0.845      2.269      0.023       0.261       3.575\n",
      "Social Media Nutzung          0.0297      0.013      2.202      0.028       0.003       0.056\n",
      "Landtagswahlen                0.3458      0.155      2.232      0.026       0.042       0.650\n",
      "topic_1                       0.3256      0.362      0.900      0.368      -0.384       1.035\n",
      "topic_2                      -0.4283      0.374     -1.145      0.252      -1.162       0.305\n",
      "topic_3                      -0.5903      0.380     -1.554      0.120      -1.335       0.154\n",
      "topic_4                      -0.1431      0.368     -0.388      0.698      -0.865       0.579\n",
      "topic_6                      -0.7187      0.389     -1.848      0.065      -1.481       0.044\n",
      "topic_8                      -0.8582      0.401     -2.142      0.032      -1.643      -0.073\n",
      "topic_10                     -0.7476      0.390     -1.919      0.055      -1.511       0.016\n",
      "topic_12                     -0.4325      0.381     -1.136      0.256      -1.179       0.314\n",
      "topic_14                     -1.3736      0.446     -3.081      0.002      -2.247      -0.500\n",
      "topic_15                     -0.7390      0.397     -1.860      0.063      -1.518       0.040\n",
      "topic_20                     -1.2864      0.437     -2.946      0.003      -2.142      -0.431\n",
      "topic_22                     -0.7406      0.396     -1.870      0.062      -1.517       0.036\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6772972405098753\n",
      "Pr√§zision: 0.5324675324675324\n",
      "Recall: 0.16942148760330578\n",
      "F1-Score: 0.25705329153605017\n",
      "Brier-Score: 0.1894008685281736\n",
      "Confusion-Matrix:\n",
      "[[554  36]\n",
      " [201  41]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.562518\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  819\n",
      "Model:                          Logit   Df Residuals:                      802\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06495\n",
      "Time:                        18:29:04   Log-Likelihood:                -460.70\n",
      "converged:                       True   LL-Null:                       -492.70\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.092e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7377      0.337     -2.190      0.029      -1.398      -0.078\n",
      "issue attention Facebook      2.9976      0.924      3.246      0.001       1.188       4.808\n",
      "issue attention Bundestag     1.9044      0.852      2.236      0.025       0.235       3.574\n",
      "Social Media Nutzung          0.0102      0.014      0.736      0.462      -0.017       0.037\n",
      "Landtagswahlen                0.1936      0.174      1.114      0.265      -0.147       0.534\n",
      "topic_1                       0.2643      0.363      0.728      0.467      -0.447       0.976\n",
      "topic_2                      -0.4159      0.375     -1.109      0.268      -1.151       0.319\n",
      "topic_3                      -0.6796      0.385     -1.767      0.077      -1.433       0.074\n",
      "topic_4                      -0.1463      0.369     -0.396      0.692      -0.870       0.577\n",
      "topic_6                      -0.8046      0.394     -2.041      0.041      -1.577      -0.032\n",
      "topic_8                      -0.8467      0.401     -2.112      0.035      -1.633      -0.061\n",
      "topic_10                     -0.7430      0.390     -1.907      0.056      -1.506       0.020\n",
      "topic_12                     -0.4372      0.381     -1.147      0.251      -1.184       0.310\n",
      "topic_14                     -1.3537      0.446     -3.035      0.002      -2.228      -0.480\n",
      "topic_15                     -0.7289      0.398     -1.833      0.067      -1.508       0.050\n",
      "topic_20                     -1.4105      0.449     -3.142      0.002      -2.290      -0.531\n",
      "topic_22                     -0.8241      0.402     -2.052      0.040      -1.611      -0.037\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6653979439442053\n",
      "Pr√§zision: 0.6\n",
      "Recall: 0.16455696202531644\n",
      "F1-Score: 0.2582781456953642\n",
      "Brier-Score: 0.18927346765784567\n",
      "Confusion-Matrix:\n",
      "[[556  26]\n",
      " [198  39]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.564724\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  806\n",
      "Model:                          Logit   Df Residuals:                      789\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06261\n",
      "Time:                        18:29:04   Log-Likelihood:                -455.17\n",
      "converged:                       True   LL-Null:                       -485.57\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.838e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2465      0.343     -0.719      0.472      -0.918       0.425\n",
      "issue attention Facebook      3.3098      0.930      3.558      0.000       1.487       5.133\n",
      "issue attention Bundestag     0.1326      0.883      0.150      0.881      -1.598       1.864\n",
      "Social Media Nutzung         -0.0160      0.015     -1.094      0.274      -0.045       0.013\n",
      "Landtagswahlen                0.2081      0.196      1.064      0.287      -0.175       0.591\n",
      "topic_1                       0.1900      0.365      0.521      0.602      -0.525       0.905\n",
      "topic_2                      -0.3308      0.373     -0.886      0.375      -1.062       0.401\n",
      "topic_3                      -0.7903      0.388     -2.037      0.042      -1.551      -0.030\n",
      "topic_4                      -0.2305      0.371     -0.621      0.534      -0.958       0.497\n",
      "topic_6                      -0.8398      0.396     -2.123      0.034      -1.615      -0.065\n",
      "topic_8                      -0.9069      0.402     -2.254      0.024      -1.696      -0.118\n",
      "topic_10                     -0.8587      0.396     -2.171      0.030      -1.634      -0.083\n",
      "topic_12                     -0.5425      0.384     -1.413      0.158      -1.295       0.210\n",
      "topic_14                     -1.4389      0.448     -3.214      0.001      -2.316      -0.561\n",
      "topic_15                     -0.8408      0.400     -2.101      0.036      -1.625      -0.056\n",
      "topic_20                     -1.5100      0.450     -3.357      0.001      -2.392      -0.628\n",
      "topic_22                     -0.9207      0.403     -2.284      0.022      -1.711      -0.130\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6729387065925528\n",
      "Pr√§zision: 0.5238095238095238\n",
      "Recall: 0.14102564102564102\n",
      "F1-Score: 0.2222222222222222\n",
      "Brier-Score: 0.19075861870679106\n",
      "Confusion-Matrix:\n",
      "[[542  30]\n",
      " [201  33]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.570703\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  793\n",
      "Model:                          Logit   Df Residuals:                      776\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05580\n",
      "Time:                        18:29:05   Log-Likelihood:                -452.57\n",
      "converged:                       True   LL-Null:                       -479.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.286e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2535      0.343     -0.739      0.460      -0.926       0.419\n",
      "issue attention Facebook      2.4125      0.933      2.586      0.010       0.584       4.241\n",
      "issue attention Bundestag    -0.1468      0.913     -0.161      0.872      -1.937       1.643\n",
      "Social Media Nutzung         -0.0105      0.014     -0.730      0.465      -0.039       0.018\n",
      "Landtagswahlen                0.1320      0.197      0.672      0.502      -0.253       0.517\n",
      "topic_1                       0.2645      0.367      0.722      0.470      -0.454       0.983\n",
      "topic_2                      -0.2853      0.374     -0.764      0.445      -1.018       0.447\n",
      "topic_3                      -0.7373      0.388     -1.902      0.057      -1.497       0.022\n",
      "topic_4                      -0.1978      0.372     -0.532      0.595      -0.927       0.531\n",
      "topic_6                      -0.8235      0.396     -2.078      0.038      -1.600      -0.047\n",
      "topic_8                      -0.9007      0.403     -2.235      0.025      -1.691      -0.111\n",
      "topic_10                     -0.8361      0.396     -2.111      0.035      -1.613      -0.060\n",
      "topic_12                     -0.5062      0.383     -1.321      0.187      -1.258       0.245\n",
      "topic_14                     -1.4376      0.448     -3.207      0.001      -2.316      -0.559\n",
      "topic_15                     -0.8280      0.401     -2.067      0.039      -1.613      -0.043\n",
      "topic_20                     -1.6293      0.464     -3.510      0.000      -2.539      -0.720\n",
      "topic_22                     -0.9160      0.404     -2.266      0.023      -1.708      -0.124\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6539392402729117\n",
      "Pr√§zision: 0.6153846153846154\n",
      "Recall: 0.13793103448275862\n",
      "F1-Score: 0.22535211267605634\n",
      "Brier-Score: 0.19298203730002328\n",
      "Confusion-Matrix:\n",
      "[[541  20]\n",
      " [200  32]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.570302\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      763\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05611\n",
      "Time:                        18:29:05   Log-Likelihood:                -444.84\n",
      "converged:                       True   LL-Null:                       -471.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.865e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2074      0.346     -0.599      0.549      -0.886       0.472\n",
      "issue attention Facebook      1.9716      0.942      2.094      0.036       0.126       3.817\n",
      "issue attention Bundestag    -0.6439      0.941     -0.684      0.494      -2.489       1.201\n",
      "Social Media Nutzung         -0.0124      0.014     -0.862      0.388      -0.041       0.016\n",
      "Landtagswahlen                0.1677      0.196      0.854      0.393      -0.217       0.553\n",
      "topic_1                       0.3442      0.370      0.930      0.352      -0.381       1.069\n",
      "topic_2                      -0.2966      0.378     -0.784      0.433      -1.038       0.445\n",
      "topic_3                      -0.7670      0.393     -1.949      0.051      -1.538       0.004\n",
      "topic_4                      -0.1586      0.375     -0.423      0.672      -0.893       0.576\n",
      "topic_6                      -0.7907      0.399     -1.983      0.047      -1.572      -0.009\n",
      "topic_8                      -0.8803      0.406     -2.170      0.030      -1.675      -0.085\n",
      "topic_10                     -0.7988      0.399     -2.003      0.045      -1.580      -0.017\n",
      "topic_12                     -0.4743      0.386     -1.230      0.219      -1.230       0.282\n",
      "topic_14                     -1.4252      0.450     -3.164      0.002      -2.308      -0.542\n",
      "topic_15                     -0.8161      0.403     -2.025      0.043      -1.606      -0.026\n",
      "topic_20                     -1.7634      0.484     -3.642      0.000      -2.712      -0.814\n",
      "topic_22                     -0.9013      0.407     -2.216      0.027      -1.699      -0.104\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6557216183574879\n",
      "Pr√§zision: 0.5490196078431373\n",
      "Recall: 0.12280701754385964\n",
      "F1-Score: 0.2007168458781362\n",
      "Brier-Score: 0.1930846829919863\n",
      "Confusion-Matrix:\n",
      "[[529  23]\n",
      " [200  28]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566621\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  767\n",
      "Model:                          Logit   Df Residuals:                      750\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06185\n",
      "Time:                        18:29:05   Log-Likelihood:                -434.60\n",
      "converged:                       True   LL-Null:                       -463.25\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.482e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4239      0.348     -1.217      0.224      -1.106       0.259\n",
      "issue attention Facebook      2.6258      0.941      2.791      0.005       0.782       4.470\n",
      "issue attention Bundestag     0.8608      0.897      0.960      0.337      -0.898       2.619\n",
      "Social Media Nutzung         -0.0046      0.014     -0.321      0.748      -0.033       0.023\n",
      "Landtagswahlen                0.1170      0.199      0.587      0.557      -0.274       0.508\n",
      "topic_1                       0.2687      0.374      0.719      0.472      -0.464       1.001\n",
      "topic_2                      -0.3254      0.381     -0.854      0.393      -1.073       0.422\n",
      "topic_3                      -0.8602      0.403     -2.137      0.033      -1.649      -0.071\n",
      "topic_4                      -0.0829      0.378     -0.219      0.826      -0.823       0.658\n",
      "topic_6                      -0.7493      0.401     -1.871      0.061      -1.534       0.036\n",
      "topic_8                      -0.8082      0.407     -1.985      0.047      -1.606      -0.010\n",
      "topic_10                     -0.7604      0.400     -1.899      0.058      -1.545       0.024\n",
      "topic_12                     -0.3873      0.389     -0.996      0.319      -1.149       0.375\n",
      "topic_14                     -1.4750      0.467     -3.161      0.002      -2.389      -0.561\n",
      "topic_15                     -0.7092      0.405     -1.751      0.080      -1.503       0.084\n",
      "topic_20                     -1.6853      0.487     -3.462      0.001      -2.639      -0.731\n",
      "topic_22                     -0.9025      0.415     -2.177      0.029      -1.715      -0.090\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6666872204682979\n",
      "Pr√§zision: 0.5192307692307693\n",
      "Recall: 0.12053571428571429\n",
      "F1-Score: 0.1956521739130435\n",
      "Brier-Score: 0.19172194516502064\n",
      "Confusion-Matrix:\n",
      "[[518  25]\n",
      " [197  27]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_cdu, post_reduced_cdu, post_common_cdu,lag, social_media_usage_cdu)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - CDU\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_cdu.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563529\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  845\n",
      "Model:                          Logit   Df Residuals:                      826\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06406\n",
      "Time:                        18:29:05   Log-Likelihood:                -476.18\n",
      "converged:                       True   LL-Null:                       -508.77\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.899e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7274      0.574     -1.267      0.205      -1.852       0.398\n",
      "issue attention Facebook      3.5416      0.913      3.881      0.000       1.753       5.330\n",
      "issue attention Bundestag     0.2993      0.843      0.355      0.723      -1.354       1.952\n",
      "Social Media Nutzung          0.0085      0.037      0.227      0.820      -0.065       0.082\n",
      "Landtagswahlen                0.3053      0.138      2.205      0.027       0.034       0.577\n",
      "Komplexit√§t Reden             0.0161      0.080      0.202      0.840      -0.140       0.172\n",
      "Komplexit√§t Posts            -0.0868      0.227     -0.383      0.702      -0.531       0.358\n",
      "topic_1                       0.2954      0.358      0.825      0.409      -0.406       0.997\n",
      "topic_2                      -0.3555      0.370     -0.961      0.337      -1.081       0.370\n",
      "topic_3                      -0.5322      0.373     -1.426      0.154      -1.264       0.199\n",
      "topic_4                      -0.1487      0.364     -0.409      0.683      -0.862       0.564\n",
      "topic_6                      -0.7319      0.386     -1.894      0.058      -1.489       0.025\n",
      "topic_8                      -0.8870      0.398     -2.228      0.026      -1.667      -0.107\n",
      "topic_10                     -0.7460      0.386     -1.931      0.054      -1.503       0.011\n",
      "topic_12                     -0.5381      0.380     -1.417      0.156      -1.282       0.206\n",
      "topic_14                     -1.4334      0.444     -3.226      0.001      -2.304      -0.562\n",
      "topic_15                     -0.8168      0.396     -2.063      0.039      -1.593      -0.041\n",
      "topic_20                     -1.2302      0.424     -2.903      0.004      -2.061      -0.400\n",
      "topic_22                     -0.8025      0.393     -2.042      0.041      -1.573      -0.032\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6729115646258503\n",
      "Pr√§zision: 0.5217391304347826\n",
      "Recall: 0.1469387755102041\n",
      "F1-Score: 0.22929936305732485\n",
      "Brier-Score: 0.18990910316304552\n",
      "Confusion-Matrix:\n",
      "[[567  33]\n",
      " [209  36]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.560597\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  832\n",
      "Model:                          Logit   Df Residuals:                      813\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.07020\n",
      "Time:                        18:29:05   Log-Likelihood:                -466.42\n",
      "converged:                       True   LL-Null:                       -501.63\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.818e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7926      0.566     -1.400      0.162      -1.902       0.317\n",
      "issue attention Facebook      2.7691      0.919      3.014      0.003       0.968       4.570\n",
      "issue attention Bundestag     1.9657      0.846      2.323      0.020       0.307       3.624\n",
      "Social Media Nutzung          0.0096      0.037      0.259      0.796      -0.063       0.082\n",
      "Landtagswahlen                0.3297      0.157      2.094      0.036       0.021       0.638\n",
      "Komplexit√§t Reden            -0.1365      0.082     -1.655      0.098      -0.298       0.025\n",
      "Komplexit√§t Posts             0.1161      0.219      0.529      0.597      -0.314       0.546\n",
      "topic_1                       0.3264      0.362      0.901      0.368      -0.384       1.037\n",
      "topic_2                      -0.4339      0.375     -1.157      0.247      -1.169       0.301\n",
      "topic_3                      -0.5953      0.381     -1.563      0.118      -1.342       0.151\n",
      "topic_4                      -0.1414      0.369     -0.383      0.702      -0.865       0.582\n",
      "topic_6                      -0.7211      0.390     -1.850      0.064      -1.485       0.043\n",
      "topic_8                      -0.8614      0.401     -2.146      0.032      -1.648      -0.075\n",
      "topic_10                     -0.7497      0.390     -1.921      0.055      -1.515       0.015\n",
      "topic_12                     -0.4322      0.381     -1.133      0.257      -1.180       0.316\n",
      "topic_14                     -1.3767      0.446     -3.084      0.002      -2.252      -0.502\n",
      "topic_15                     -0.7400      0.398     -1.859      0.063      -1.520       0.040\n",
      "topic_20                     -1.2910      0.437     -2.953      0.003      -2.148      -0.434\n",
      "topic_22                     -0.7413      0.397     -1.868      0.062      -1.519       0.036\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6790656954755568\n",
      "Pr√§zision: 0.5176470588235295\n",
      "Recall: 0.18181818181818182\n",
      "F1-Score: 0.2691131498470948\n",
      "Brier-Score: 0.18871756563787212\n",
      "Confusion-Matrix:\n",
      "[[549  41]\n",
      " [198  44]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.561995\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  819\n",
      "Model:                          Logit   Df Residuals:                      800\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06582\n",
      "Time:                        18:29:05   Log-Likelihood:                -460.27\n",
      "converged:                       True   LL-Null:                       -492.70\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.276e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6448      0.571     -1.130      0.259      -1.763       0.474\n",
      "issue attention Facebook      2.9993      0.925      3.244      0.001       1.187       4.812\n",
      "issue attention Bundestag     1.9229      0.852      2.257      0.024       0.253       3.593\n",
      "Social Media Nutzung          0.0037      0.037      0.101      0.920      -0.069       0.077\n",
      "Landtagswahlen                0.1600      0.179      0.893      0.372      -0.191       0.511\n",
      "Komplexit√§t Reden            -0.0774      0.084     -0.919      0.358      -0.242       0.088\n",
      "Komplexit√§t Posts             0.0337      0.221      0.153      0.879      -0.399       0.466\n",
      "topic_1                       0.2649      0.363      0.729      0.466      -0.447       0.977\n",
      "topic_2                      -0.4181      0.376     -1.113      0.266      -1.154       0.318\n",
      "topic_3                      -0.6812      0.385     -1.770      0.077      -1.436       0.073\n",
      "topic_4                      -0.1451      0.369     -0.393      0.695      -0.869       0.579\n",
      "topic_6                      -0.8052      0.394     -2.041      0.041      -1.578      -0.032\n",
      "topic_8                      -0.8480      0.401     -2.114      0.035      -1.634      -0.062\n",
      "topic_10                     -0.7433      0.390     -1.907      0.056      -1.507       0.021\n",
      "topic_12                     -0.4359      0.381     -1.144      0.253      -1.183       0.311\n",
      "topic_14                     -1.3557      0.446     -3.038      0.002      -2.230      -0.481\n",
      "topic_15                     -0.7292      0.398     -1.833      0.067      -1.509       0.051\n",
      "topic_20                     -1.4117      0.449     -3.144      0.002      -2.292      -0.532\n",
      "topic_22                     -0.8244      0.402     -2.051      0.040      -1.612      -0.037\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6668479127698754\n",
      "Pr√§zision: 0.6086956521739131\n",
      "Recall: 0.17721518987341772\n",
      "F1-Score: 0.27450980392156865\n",
      "Brier-Score: 0.1890990137144435\n",
      "Confusion-Matrix:\n",
      "[[555  27]\n",
      " [195  42]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563990\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  806\n",
      "Model:                          Logit   Df Residuals:                      787\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06382\n",
      "Time:                        18:29:05   Log-Likelihood:                -454.58\n",
      "converged:                       True   LL-Null:                       -485.57\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.748e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.2210      0.584      0.379      0.705      -0.923       1.365\n",
      "issue attention Facebook      3.2923      0.932      3.534      0.000       1.466       5.118\n",
      "issue attention Bundestag     0.1406      0.886      0.159      0.874      -1.596       1.877\n",
      "Social Media Nutzung         -0.0512      0.038     -1.339      0.181      -0.126       0.024\n",
      "Landtagswahlen                0.2529      0.203      1.247      0.212      -0.145       0.650\n",
      "Komplexit√§t Reden             0.0270      0.084      0.322      0.747      -0.137       0.191\n",
      "Komplexit√§t Posts             0.2261      0.223      1.012      0.311      -0.212       0.664\n",
      "topic_1                       0.1906      0.365      0.522      0.602      -0.525       0.906\n",
      "topic_2                      -0.3326      0.374     -0.890      0.373      -1.065       0.400\n",
      "topic_3                      -0.7941      0.389     -2.041      0.041      -1.557      -0.032\n",
      "topic_4                      -0.2311      0.371     -0.622      0.534      -0.959       0.497\n",
      "topic_6                      -0.8404      0.396     -2.123      0.034      -1.616      -0.065\n",
      "topic_8                      -0.9088      0.403     -2.257      0.024      -1.698      -0.120\n",
      "topic_10                     -0.8606      0.396     -2.173      0.030      -1.637      -0.085\n",
      "topic_12                     -0.5440      0.384     -1.415      0.157      -1.297       0.209\n",
      "topic_14                     -1.4399      0.448     -3.214      0.001      -2.318      -0.562\n",
      "topic_15                     -0.8421      0.400     -2.103      0.035      -1.627      -0.057\n",
      "topic_20                     -1.5147      0.450     -3.366      0.001      -2.397      -0.633\n",
      "topic_22                     -0.9210      0.403     -2.283      0.022      -1.712      -0.130\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6744665590819436\n",
      "Pr√§zision: 0.4925373134328358\n",
      "Recall: 0.14102564102564102\n",
      "F1-Score: 0.21926910299003322\n",
      "Brier-Score: 0.19058925584250183\n",
      "Confusion-Matrix:\n",
      "[[538  34]\n",
      " [201  33]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.569534\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  793\n",
      "Model:                          Logit   Df Residuals:                      774\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05773\n",
      "Time:                        18:29:05   Log-Likelihood:                -451.64\n",
      "converged:                       True   LL-Null:                       -479.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.132e-05\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.2048      0.583      0.351      0.725      -0.938       1.347\n",
      "issue attention Facebook      2.3997      0.936      2.565      0.010       0.566       4.234\n",
      "issue attention Bundestag    -0.1074      0.914     -0.118      0.906      -1.899       1.684\n",
      "Social Media Nutzung         -0.0441      0.038     -1.160      0.246      -0.118       0.030\n",
      "Landtagswahlen                0.1085      0.204      0.531      0.596      -0.292       0.509\n",
      "Komplexit√§t Reden            -0.0894      0.085     -1.054      0.292      -0.256       0.077\n",
      "Komplexit√§t Posts             0.2075      0.224      0.925      0.355      -0.232       0.647\n",
      "topic_1                       0.2659      0.367      0.724      0.469      -0.454       0.986\n",
      "topic_2                      -0.2880      0.374     -0.769      0.442      -1.022       0.446\n",
      "topic_3                      -0.7402      0.389     -1.905      0.057      -1.502       0.021\n",
      "topic_4                      -0.1960      0.373     -0.526      0.599      -0.926       0.534\n",
      "topic_6                      -0.8229      0.397     -2.074      0.038      -1.600      -0.045\n",
      "topic_8                      -0.9025      0.404     -2.236      0.025      -1.694      -0.111\n",
      "topic_10                     -0.8374      0.397     -2.111      0.035      -1.615      -0.060\n",
      "topic_12                     -0.5041      0.384     -1.313      0.189      -1.256       0.248\n",
      "topic_14                     -1.4399      0.449     -3.208      0.001      -2.319      -0.560\n",
      "topic_15                     -0.8285      0.401     -2.065      0.039      -1.615      -0.042\n",
      "topic_20                     -1.6320      0.465     -3.513      0.000      -2.543      -0.721\n",
      "topic_22                     -0.9160      0.405     -2.262      0.024      -1.709      -0.122\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6563786956788985\n",
      "Pr√§zision: 0.6037735849056604\n",
      "Recall: 0.13793103448275862\n",
      "F1-Score: 0.22456140350877193\n",
      "Brier-Score: 0.19257524124776002\n",
      "Confusion-Matrix:\n",
      "[[540  21]\n",
      " [200  32]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.568358\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      761\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05933\n",
      "Time:                        18:29:05   Log-Likelihood:                -443.32\n",
      "converged:                       True   LL-Null:                       -471.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.170e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1703      0.588      0.289      0.772      -0.983       1.324\n",
      "issue attention Facebook      1.9689      0.945      2.083      0.037       0.116       3.822\n",
      "issue attention Bundestag    -0.5916      0.941     -0.628      0.530      -2.436       1.253\n",
      "Social Media Nutzung         -0.0398      0.038     -1.039      0.299      -0.115       0.035\n",
      "Landtagswahlen                0.1131      0.205      0.553      0.580      -0.288       0.514\n",
      "Komplexit√§t Reden            -0.1379      0.086     -1.604      0.109      -0.306       0.031\n",
      "Komplexit√§t Posts             0.1650      0.229      0.722      0.470      -0.283       0.613\n",
      "topic_1                       0.3469      0.371      0.935      0.350      -0.380       1.074\n",
      "topic_2                      -0.2997      0.379     -0.790      0.430      -1.043       0.444\n",
      "topic_3                      -0.7695      0.395     -1.950      0.051      -1.543       0.004\n",
      "topic_4                      -0.1557      0.376     -0.414      0.679      -0.892       0.581\n",
      "topic_6                      -0.7899      0.399     -1.978      0.048      -1.573      -0.007\n",
      "topic_8                      -0.8823      0.407     -2.169      0.030      -1.679      -0.085\n",
      "topic_10                     -0.8005      0.400     -2.002      0.045      -1.584      -0.017\n",
      "topic_12                     -0.4711      0.387     -1.219      0.223      -1.229       0.287\n",
      "topic_14                     -1.4285      0.451     -3.165      0.002      -2.313      -0.544\n",
      "topic_15                     -0.8169      0.404     -2.022      0.043      -1.609      -0.025\n",
      "topic_20                     -1.7662      0.485     -3.643      0.000      -2.717      -0.816\n",
      "topic_22                     -0.9019      0.408     -2.211      0.027      -1.701      -0.103\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6626382532418001\n",
      "Pr√§zision: 0.4909090909090909\n",
      "Recall: 0.11842105263157894\n",
      "F1-Score: 0.19081272084805653\n",
      "Brier-Score: 0.19232725362488176\n",
      "Confusion-Matrix:\n",
      "[[524  28]\n",
      " [201  27]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.562511\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  767\n",
      "Model:                          Logit   Df Residuals:                      748\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.06865\n",
      "Time:                        18:29:05   Log-Likelihood:                -431.45\n",
      "converged:                       True   LL-Null:                       -463.25\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.283e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.0837      0.587      0.143      0.887      -1.067       1.235\n",
      "issue attention Facebook      2.6118      0.945      2.764      0.006       0.760       4.464\n",
      "issue attention Bundestag     0.8526      0.905      0.943      0.346      -0.920       2.626\n",
      "Social Media Nutzung         -0.0438      0.038     -1.160      0.246      -0.118       0.030\n",
      "Landtagswahlen                0.2465      0.206      1.195      0.232      -0.158       0.651\n",
      "Komplexit√§t Reden             0.1813      0.085      2.132      0.033       0.015       0.348\n",
      "Komplexit√§t Posts             0.2711      0.224      1.208      0.227      -0.169       0.711\n",
      "topic_1                       0.2719      0.376      0.724      0.469      -0.464       1.008\n",
      "topic_2                      -0.3285      0.383     -0.858      0.391      -1.079       0.422\n",
      "topic_3                      -0.8726      0.405     -2.153      0.031      -1.667      -0.078\n",
      "topic_4                      -0.0855      0.380     -0.225      0.822      -0.830       0.659\n",
      "topic_6                      -0.7574      0.402     -1.882      0.060      -1.546       0.031\n",
      "topic_8                      -0.8169      0.409     -1.998      0.046      -1.618      -0.015\n",
      "topic_10                     -0.7685      0.402     -1.910      0.056      -1.557       0.020\n",
      "topic_12                     -0.3933      0.391     -1.005      0.315      -1.160       0.373\n",
      "topic_14                     -1.4853      0.468     -3.173      0.002      -2.403      -0.568\n",
      "topic_15                     -0.7167      0.407     -1.763      0.078      -1.514       0.080\n",
      "topic_20                     -1.7042      0.489     -3.487      0.000      -2.662      -0.746\n",
      "topic_22                     -0.9103      0.416     -2.187      0.029      -1.726      -0.094\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6776095106550908\n",
      "Pr√§zision: 0.5373134328358209\n",
      "Recall: 0.16071428571428573\n",
      "F1-Score: 0.24742268041237114\n",
      "Brier-Score: 0.19013618572004748\n",
      "Confusion-Matrix:\n",
      "[[512  31]\n",
      " [188  36]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_cdu, post_reduced_cdu, post_common_cdu,lag, social_media_usage_cdu,rede_komplex_cdu,posts_komplex_cdu)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - CDU\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_cdu_complex.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B√ºndnis 90/ DIE GR√úNEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\982104320.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_gruen[\"date\"] = pd.to_datetime(subset_reden_gruen[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\982104320.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_gruen[\"date\"] = pd.to_datetime(subset_posts_gruen[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_gruen = subset_posts[subset_posts[\"partei\"] == \"B√úNDNIS 90/DIE GR√úNEN\"]\n",
    "subset_reden_gruen = subset_reden[subset_reden[\"partei\"] == \"B√úNDNIS 90/DIE GR√úNEN\"]\n",
    "social_media_usage_gruen = subset_posts_gruen.groupby('date').size()\n",
    "subset_reden_gruen[\"date\"] = pd.to_datetime(subset_reden_gruen[\"date\"])\n",
    "subset_posts_gruen[\"date\"] = pd.to_datetime(subset_posts_gruen[\"date\"])\n",
    "reden_komplexit√§t_t√§glich_gruen = subset_reden_gruen.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_gruen = subset_posts_gruen.groupby('date')['komplexit√§t'].sum()\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_gruen = subset_reden_gruen.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_gruen = subset_posts_gruen.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_gruen = redethemen_t√§glich_gruen.index.intersection(postthemen_t√§glich_gruen.index)\n",
    "redethemen_t√§glich_aligned_gruen = redethemen_t√§glich_gruen.loc[common_dates_gruen]\n",
    "postthemen_t√§glich_aligned_gruen = postthemen_t√§glich_gruen.loc[common_dates_gruen]\n",
    "rede_komplex_gruen = reden_komplexit√§t_t√§glich_gruen.loc[common_dates_gruen]\n",
    "posts_komplex_gruen = posts_komplexit√§t_t√§glich_gruen.loc[common_dates_gruen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 41, 44, 46, 53, 54, 56, 58, 59, 61, 63, 65, 69, 70, 75, 79, 80, 81, 84, 90, 91, 92}\n",
      "Gemeinsame Topics: {1, 2, 6, 15, 24, 25}\n"
     ]
    }
   ],
   "source": [
    "rede_common_gruen, post_common_gruen = filter_common_topics(redethemen_t√§glich_aligned_gruen, postthemen_t√§glich_aligned_gruen)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_gruen =  rede_common_gruen.div(rede_common_gruen.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_gruen = post_common_gruen.div(post_common_gruen.sum(axis=1), axis=0)\n",
    "reden_relativ_gruen_red = remove_near_constant(reden_relativ_gruen)\n",
    "post_relativ_gruen_red = remove_near_constant(post_relativ_gruen)\n",
    "rede_reduced_gruen, post_reduced_gruen = filter_common_topics(reden_relativ_gruen_red, post_relativ_gruen_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.449798\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  384\n",
      "Model:                          Logit   Df Residuals:                      381\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                0.001693\n",
      "Time:                        18:29:05   Log-Likelihood:                -172.72\n",
      "converged:                       True   LL-Null:                       -173.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7461\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -1.5605      0.156    -10.024      0.000      -1.866      -1.255\n",
      "posts_relative    -0.0611      0.877     -0.070      0.944      -1.779       1.657\n",
      "reden_relativ     -0.9918      1.372     -0.723      0.470      -3.682       1.698\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM(rede_reduced_gruen,post_reduced_gruen, post_common_gruen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.446520\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  384\n",
      "Model:                          Logit   Df Residuals:                      376\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                0.008969\n",
      "Time:                        18:29:05   Log-Likelihood:                -171.46\n",
      "converged:                       True   LL-Null:                       -173.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.8753\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -1.3112      0.324     -4.048      0.000      -1.946      -0.676\n",
      "posts_relative    -0.1572      0.893     -0.176      0.860      -1.907       1.592\n",
      "reden_relativ     -0.8552      1.483     -0.577      0.564      -3.761       2.051\n",
      "topic_2           -0.5271      0.498     -1.059      0.289      -1.502       0.448\n",
      "topic_6           -0.0930      0.447     -0.208      0.835      -0.968       0.782\n",
      "topic_15          -0.1369      0.451     -0.304      0.761      -1.020       0.746\n",
      "topic_24          -0.6105      0.492     -1.241      0.215      -1.575       0.354\n",
      "topic_25          -0.2372      0.457     -0.519      0.604      -1.133       0.659\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM_fixed_effects(rede_reduced_gruen,post_reduced_gruen, post_common_gruen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression f√ºr Lag 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.439438\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  384\n",
      "Model:                          Logit   Df Residuals:                      374\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02469\n",
      "Time:                        18:29:05   Log-Likelihood:                -168.74\n",
      "converged:                       True   LL-Null:                       -173.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4805\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.8715      0.423     -4.429      0.000      -2.700      -1.043\n",
      "issue attention Facebook     -0.1129      0.936     -0.121      0.904      -1.947       1.721\n",
      "issue attention Bundestag    -0.8498      1.435     -0.592      0.554      -3.662       1.962\n",
      "Social Media Nutzung          0.0951      0.052      1.830      0.067      -0.007       0.197\n",
      "Landtagswahlen                0.3671      0.230      1.595      0.111      -0.084       0.818\n",
      "topic_2                      -0.5263      0.503     -1.047      0.295      -1.511       0.459\n",
      "topic_6                      -0.0979      0.451     -0.217      0.828      -0.981       0.786\n",
      "topic_15                     -0.1386      0.454     -0.305      0.760      -1.029       0.752\n",
      "topic_24                     -0.6176      0.496     -1.246      0.213      -1.589       0.354\n",
      "topic_25                     -0.2399      0.461     -0.520      0.603      -1.143       0.663\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.607861328125\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.13562702347507194\n",
      "Confusion-Matrix:\n",
      "[[320   0]\n",
      " [ 64   0]]\n",
      "\n",
      "Regression f√ºr Lag 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.448585\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  378\n",
      "Model:                          Logit   Df Residuals:                      368\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.01365\n",
      "Time:                        18:29:05   Log-Likelihood:                -169.57\n",
      "converged:                       True   LL-Null:                       -171.91\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.8602\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.2777      0.428     -2.985      0.003      -2.117      -0.439\n",
      "issue attention Facebook      0.4590      0.790      0.581      0.561      -1.090       2.008\n",
      "issue attention Bundestag     0.3043      1.319      0.231      0.818      -2.280       2.889\n",
      "Social Media Nutzung         -0.0424      0.060     -0.711      0.477      -0.159       0.074\n",
      "Landtagswahlen                0.2394      0.258      0.930      0.353      -0.265       0.744\n",
      "topic_2                      -0.5915      0.502     -1.179      0.238      -1.575       0.392\n",
      "topic_6                      -0.1087      0.449     -0.242      0.809      -0.988       0.771\n",
      "topic_15                     -0.0825      0.453     -0.182      0.855      -0.970       0.805\n",
      "topic_24                     -0.5662      0.493     -1.147      0.251      -1.533       0.401\n",
      "topic_25                     -0.1881      0.459     -0.409      0.682      -1.089       0.712\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5734972133757962\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.13898589898376723\n",
      "Confusion-Matrix:\n",
      "[[314   0]\n",
      " [ 64   0]]\n",
      "\n",
      "Regression f√ºr Lag 3:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.442644\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  372\n",
      "Model:                          Logit   Df Residuals:                      362\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02686\n",
      "Time:                        18:29:05   Log-Likelihood:                -164.66\n",
      "converged:                       True   LL-Null:                       -169.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4290\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.4737      0.432     -3.409      0.001      -2.321      -0.626\n",
      "issue attention Facebook      1.6862      0.720      2.342      0.019       0.275       3.097\n",
      "issue attention Bundestag     1.2202      1.240      0.984      0.325      -1.211       3.651\n",
      "Social Media Nutzung         -0.0053      0.058     -0.092      0.926      -0.118       0.108\n",
      "Landtagswahlen               -0.1226      0.319     -0.384      0.701      -0.748       0.503\n",
      "topic_2                      -0.6330      0.509     -1.244      0.214      -1.631       0.365\n",
      "topic_6                      -0.1505      0.456     -0.330      0.741      -1.044       0.743\n",
      "topic_15                     -0.0202      0.456     -0.044      0.965      -0.915       0.874\n",
      "topic_24                     -0.5278      0.498     -1.059      0.290      -1.504       0.449\n",
      "topic_25                     -0.2618      0.473     -0.554      0.580      -1.188       0.665\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5929264909847434\n",
      "Pr√§zision: 0.3333333333333333\n",
      "Recall: 0.015873015873015872\n",
      "F1-Score: 0.030303030303030304\n",
      "Brier-Score: 0.1363757386717731\n",
      "Confusion-Matrix:\n",
      "[[307   2]\n",
      " [ 62   1]]\n",
      "\n",
      "Regression f√ºr Lag 4:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.441951\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  366\n",
      "Model:                          Logit   Df Residuals:                      356\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02853\n",
      "Time:                        18:29:05   Log-Likelihood:                -161.75\n",
      "converged:                       True   LL-Null:                       -166.51\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3923\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.5137      0.435     -3.480      0.001      -2.366      -0.661\n",
      "issue attention Facebook     -1.9999      1.356     -1.475      0.140      -4.658       0.658\n",
      "issue attention Bundestag     1.8046      1.306      1.382      0.167      -0.755       4.364\n",
      "Social Media Nutzung          0.0427      0.055      0.782      0.434      -0.064       0.150\n",
      "Landtagswahlen               -0.5349      0.413     -1.294      0.196      -1.345       0.275\n",
      "topic_2                      -0.6828      0.521     -1.311      0.190      -1.704       0.338\n",
      "topic_6                      -0.0127      0.461     -0.028      0.978      -0.916       0.890\n",
      "topic_15                      0.0668      0.464      0.144      0.885      -0.842       0.975\n",
      "topic_24                     -0.4603      0.504     -0.914      0.361      -1.447       0.527\n",
      "topic_25                     -0.1645      0.479     -0.344      0.731      -1.103       0.774\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6186067487266553\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.13669205242563653\n",
      "Confusion-Matrix:\n",
      "[[304   0]\n",
      " [ 62   0]]\n",
      "\n",
      "Regression f√ºr Lag 5:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.435549\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  360\n",
      "Model:                          Logit   Df Residuals:                      350\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05190\n",
      "Time:                        18:29:05   Log-Likelihood:                -156.80\n",
      "converged:                       True   LL-Null:                       -165.38\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04616\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.7487      0.456     -3.834      0.000      -2.643      -0.855\n",
      "issue attention Facebook      1.8234      0.785      2.324      0.020       0.285       3.361\n",
      "issue attention Bundestag    -3.9796      2.182     -1.824      0.068      -8.257       0.298\n",
      "Social Media Nutzung          0.1110      0.054      2.051      0.040       0.005       0.217\n",
      "Landtagswahlen               -0.5304      0.420     -1.262      0.207      -1.354       0.293\n",
      "topic_2                      -0.3484      0.512     -0.680      0.496      -1.352       0.655\n",
      "topic_6                      -0.0096      0.470     -0.021      0.984      -0.930       0.911\n",
      "topic_15                     -0.1290      0.472     -0.273      0.785      -1.054       0.796\n",
      "topic_24                     -0.6058      0.513     -1.181      0.238      -1.611       0.400\n",
      "topic_25                     -0.3654      0.489     -0.747      0.455      -1.325       0.594\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6756332539510717\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1371224261519812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion-Matrix:\n",
      "[[297   1]\n",
      " [ 62   0]]\n",
      "\n",
      "Regression f√ºr Lag 6:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.455196\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  354\n",
      "Model:                          Logit   Df Residuals:                      344\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                0.009454\n",
      "Time:                        18:29:05   Log-Likelihood:                -161.14\n",
      "converged:                       True   LL-Null:                       -162.68\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9612\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.2674      0.443     -2.858      0.004      -2.137      -0.398\n",
      "issue attention Facebook     -0.3643      0.998     -0.365      0.715      -2.320       1.591\n",
      "issue attention Bundestag    -0.5684      1.589     -0.358      0.721      -3.682       2.546\n",
      "Social Media Nutzung          0.0025      0.059      0.042      0.966      -0.113       0.118\n",
      "Landtagswahlen               -0.3130      0.381     -0.821      0.412      -1.061       0.435\n",
      "topic_2                      -0.4696      0.506     -0.928      0.353      -1.461       0.522\n",
      "topic_6                       0.0082      0.459      0.018      0.986      -0.891       0.907\n",
      "topic_15                     -0.1335      0.470     -0.284      0.776      -1.054       0.787\n",
      "topic_24                     -0.5097      0.502     -1.015      0.310      -1.494       0.475\n",
      "topic_25                     -0.2414      0.477     -0.506      0.613      -1.177       0.694\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5638113355340458\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.14148589064415534\n",
      "Confusion-Matrix:\n",
      "[[293   0]\n",
      " [ 61   0]]\n",
      "\n",
      "Regression f√ºr Lag 7:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.454717\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  348\n",
      "Model:                          Logit   Df Residuals:                      338\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.01083\n",
      "Time:                        18:29:05   Log-Likelihood:                -158.24\n",
      "converged:                       True   LL-Null:                       -159.97\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9431\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.3870      0.454     -3.056      0.002      -2.276      -0.498\n",
      "issue attention Facebook     -0.3554      0.992     -0.358      0.720      -2.299       1.588\n",
      "issue attention Bundestag     1.2789      1.363      0.939      0.348      -1.392       3.950\n",
      "Social Media Nutzung         -0.0128      0.062     -0.206      0.837      -0.134       0.108\n",
      "Landtagswahlen               -0.3220      0.381     -0.844      0.398      -1.069       0.425\n",
      "topic_2                      -0.4712      0.520     -0.906      0.365      -1.490       0.548\n",
      "topic_6                       0.0877      0.468      0.187      0.851      -0.830       1.006\n",
      "topic_15                      0.0525      0.478      0.110      0.913      -0.885       0.990\n",
      "topic_24                     -0.3444      0.510     -0.675      0.499      -1.344       0.655\n",
      "topic_25                     -0.0727      0.486     -0.150      0.881      -1.025       0.880\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5891493055555556\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1413457888641364\n",
      "Confusion-Matrix:\n",
      "[[288   0]\n",
      " [ 60   0]]\n"
     ]
    }
   ],
   "source": [
    "# Schleife f√ºr logistische Regression mit Lags von -7 bis 7\n",
    "for n in range(1, 8):  # Einschlie√ülich 1 bis 7\n",
    "    try:\n",
    "        print(f\"\\nRegression f√ºr Lag {n}:\")\n",
    "        log_reg_FE_control(rede_reduced_gruen, post_reduced_gruen, post_common_gruen,n, social_media_usage_gruen)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Lag {n}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.439438\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  384\n",
      "Model:                          Logit   Df Residuals:                      374\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02469\n",
      "Time:                        18:29:06   Log-Likelihood:                -168.74\n",
      "converged:                       True   LL-Null:                       -173.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4805\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.8715      0.423     -4.429      0.000      -2.700      -1.043\n",
      "issue attention Facebook     -0.1129      0.936     -0.121      0.904      -1.947       1.721\n",
      "issue attention Bundestag    -0.8498      1.435     -0.592      0.554      -3.662       1.962\n",
      "Social Media Nutzung          0.0951      0.052      1.830      0.067      -0.007       0.197\n",
      "Landtagswahlen                0.3671      0.230      1.595      0.111      -0.084       0.818\n",
      "topic_2                      -0.5263      0.503     -1.047      0.295      -1.511       0.459\n",
      "topic_6                      -0.0979      0.451     -0.217      0.828      -0.981       0.786\n",
      "topic_15                     -0.1386      0.454     -0.305      0.760      -1.029       0.752\n",
      "topic_24                     -0.6176      0.496     -1.246      0.213      -1.589       0.354\n",
      "topic_25                     -0.2399      0.461     -0.520      0.603      -1.143       0.663\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.607861328125\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.13562702347507194\n",
      "Confusion-Matrix:\n",
      "[[320   0]\n",
      " [ 64   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.448585\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  378\n",
      "Model:                          Logit   Df Residuals:                      368\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.01365\n",
      "Time:                        18:29:06   Log-Likelihood:                -169.57\n",
      "converged:                       True   LL-Null:                       -171.91\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.8602\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.2777      0.428     -2.985      0.003      -2.117      -0.439\n",
      "issue attention Facebook      0.4590      0.790      0.581      0.561      -1.090       2.008\n",
      "issue attention Bundestag     0.3043      1.319      0.231      0.818      -2.280       2.889\n",
      "Social Media Nutzung         -0.0424      0.060     -0.711      0.477      -0.159       0.074\n",
      "Landtagswahlen                0.2394      0.258      0.930      0.353      -0.265       0.744\n",
      "topic_2                      -0.5915      0.502     -1.179      0.238      -1.575       0.392\n",
      "topic_6                      -0.1087      0.449     -0.242      0.809      -0.988       0.771\n",
      "topic_15                     -0.0825      0.453     -0.182      0.855      -0.970       0.805\n",
      "topic_24                     -0.5662      0.493     -1.147      0.251      -1.533       0.401\n",
      "topic_25                     -0.1881      0.459     -0.409      0.682      -1.089       0.712\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5734972133757962\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.13898589898376723\n",
      "Confusion-Matrix:\n",
      "[[314   0]\n",
      " [ 64   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.442644\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  372\n",
      "Model:                          Logit   Df Residuals:                      362\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02686\n",
      "Time:                        18:29:06   Log-Likelihood:                -164.66\n",
      "converged:                       True   LL-Null:                       -169.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4290\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.4737      0.432     -3.409      0.001      -2.321      -0.626\n",
      "issue attention Facebook      1.6862      0.720      2.342      0.019       0.275       3.097\n",
      "issue attention Bundestag     1.2202      1.240      0.984      0.325      -1.211       3.651\n",
      "Social Media Nutzung         -0.0053      0.058     -0.092      0.926      -0.118       0.108\n",
      "Landtagswahlen               -0.1226      0.319     -0.384      0.701      -0.748       0.503\n",
      "topic_2                      -0.6330      0.509     -1.244      0.214      -1.631       0.365\n",
      "topic_6                      -0.1505      0.456     -0.330      0.741      -1.044       0.743\n",
      "topic_15                     -0.0202      0.456     -0.044      0.965      -0.915       0.874\n",
      "topic_24                     -0.5278      0.498     -1.059      0.290      -1.504       0.449\n",
      "topic_25                     -0.2618      0.473     -0.554      0.580      -1.188       0.665\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5929264909847434\n",
      "Pr√§zision: 0.3333333333333333\n",
      "Recall: 0.015873015873015872\n",
      "F1-Score: 0.030303030303030304\n",
      "Brier-Score: 0.1363757386717731\n",
      "Confusion-Matrix:\n",
      "[[307   2]\n",
      " [ 62   1]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.441951\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  366\n",
      "Model:                          Logit   Df Residuals:                      356\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02853\n",
      "Time:                        18:29:06   Log-Likelihood:                -161.75\n",
      "converged:                       True   LL-Null:                       -166.51\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3923\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.5137      0.435     -3.480      0.001      -2.366      -0.661\n",
      "issue attention Facebook     -1.9999      1.356     -1.475      0.140      -4.658       0.658\n",
      "issue attention Bundestag     1.8046      1.306      1.382      0.167      -0.755       4.364\n",
      "Social Media Nutzung          0.0427      0.055      0.782      0.434      -0.064       0.150\n",
      "Landtagswahlen               -0.5349      0.413     -1.294      0.196      -1.345       0.275\n",
      "topic_2                      -0.6828      0.521     -1.311      0.190      -1.704       0.338\n",
      "topic_6                      -0.0127      0.461     -0.028      0.978      -0.916       0.890\n",
      "topic_15                      0.0668      0.464      0.144      0.885      -0.842       0.975\n",
      "topic_24                     -0.4603      0.504     -0.914      0.361      -1.447       0.527\n",
      "topic_25                     -0.1645      0.479     -0.344      0.731      -1.103       0.774\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6186067487266553\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.13669205242563653\n",
      "Confusion-Matrix:\n",
      "[[304   0]\n",
      " [ 62   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.435549\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  360\n",
      "Model:                          Logit   Df Residuals:                      350\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05190\n",
      "Time:                        18:29:06   Log-Likelihood:                -156.80\n",
      "converged:                       True   LL-Null:                       -165.38\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04616\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.7487      0.456     -3.834      0.000      -2.643      -0.855\n",
      "issue attention Facebook      1.8234      0.785      2.324      0.020       0.285       3.361\n",
      "issue attention Bundestag    -3.9796      2.182     -1.824      0.068      -8.257       0.298\n",
      "Social Media Nutzung          0.1110      0.054      2.051      0.040       0.005       0.217\n",
      "Landtagswahlen               -0.5304      0.420     -1.262      0.207      -1.354       0.293\n",
      "topic_2                      -0.3484      0.512     -0.680      0.496      -1.352       0.655\n",
      "topic_6                      -0.0096      0.470     -0.021      0.984      -0.930       0.911\n",
      "topic_15                     -0.1290      0.472     -0.273      0.785      -1.054       0.796\n",
      "topic_24                     -0.6058      0.513     -1.181      0.238      -1.611       0.400\n",
      "topic_25                     -0.3654      0.489     -0.747      0.455      -1.325       0.594\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6756332539510717\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1371224261519812\n",
      "Confusion-Matrix:\n",
      "[[297   1]\n",
      " [ 62   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.455196\n",
      "         Iterations 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  354\n",
      "Model:                          Logit   Df Residuals:                      344\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                0.009454\n",
      "Time:                        18:29:06   Log-Likelihood:                -161.14\n",
      "converged:                       True   LL-Null:                       -162.68\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9612\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.2674      0.443     -2.858      0.004      -2.137      -0.398\n",
      "issue attention Facebook     -0.3643      0.998     -0.365      0.715      -2.320       1.591\n",
      "issue attention Bundestag    -0.5684      1.589     -0.358      0.721      -3.682       2.546\n",
      "Social Media Nutzung          0.0025      0.059      0.042      0.966      -0.113       0.118\n",
      "Landtagswahlen               -0.3130      0.381     -0.821      0.412      -1.061       0.435\n",
      "topic_2                      -0.4696      0.506     -0.928      0.353      -1.461       0.522\n",
      "topic_6                       0.0082      0.459      0.018      0.986      -0.891       0.907\n",
      "topic_15                     -0.1335      0.470     -0.284      0.776      -1.054       0.787\n",
      "topic_24                     -0.5097      0.502     -1.015      0.310      -1.494       0.475\n",
      "topic_25                     -0.2414      0.477     -0.506      0.613      -1.177       0.694\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5638113355340458\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.14148589064415534\n",
      "Confusion-Matrix:\n",
      "[[293   0]\n",
      " [ 61   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.454717\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  348\n",
      "Model:                          Logit   Df Residuals:                      338\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.01083\n",
      "Time:                        18:29:06   Log-Likelihood:                -158.24\n",
      "converged:                       True   LL-Null:                       -159.97\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9431\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.3870      0.454     -3.056      0.002      -2.276      -0.498\n",
      "issue attention Facebook     -0.3554      0.992     -0.358      0.720      -2.299       1.588\n",
      "issue attention Bundestag     1.2789      1.363      0.939      0.348      -1.392       3.950\n",
      "Social Media Nutzung         -0.0128      0.062     -0.206      0.837      -0.134       0.108\n",
      "Landtagswahlen               -0.3220      0.381     -0.844      0.398      -1.069       0.425\n",
      "topic_2                      -0.4712      0.520     -0.906      0.365      -1.490       0.548\n",
      "topic_6                       0.0877      0.468      0.187      0.851      -0.830       1.006\n",
      "topic_15                      0.0525      0.478      0.110      0.913      -0.885       0.990\n",
      "topic_24                     -0.3444      0.510     -0.675      0.499      -1.344       0.655\n",
      "topic_25                     -0.0727      0.486     -0.150      0.881      -1.025       0.880\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5891493055555556\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1413457888641364\n",
      "Confusion-Matrix:\n",
      "[[288   0]\n",
      " [ 60   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_gruen, post_reduced_gruen, post_common_gruen,lag, social_media_usage_gruen)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - B√úNDNIS 90/ DIE GR√úNEN\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_gruen.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.439180\n",
      "         Iterations 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  384\n",
      "Model:                          Logit   Df Residuals:                      372\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02526\n",
      "Time:                        18:29:06   Log-Likelihood:                -168.65\n",
      "converged:                       True   LL-Null:                       -173.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6458\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.6912      0.684     -2.474      0.013      -3.031      -0.351\n",
      "issue attention Facebook     -0.1240      0.940     -0.132      0.895      -1.967       1.719\n",
      "issue attention Bundestag    -0.8558      1.444     -0.593      0.553      -3.687       1.975\n",
      "Social Media Nutzung          0.0543      0.134      0.405      0.685      -0.208       0.317\n",
      "Landtagswahlen                0.3775      0.234      1.611      0.107      -0.082       0.837\n",
      "Komplexit√§t Reden             0.0234      0.148      0.158      0.875      -0.267       0.313\n",
      "Komplexit√§t Posts             0.1117      0.343      0.326      0.744      -0.560       0.783\n",
      "topic_2                      -0.5270      0.503     -1.049      0.294      -1.512       0.458\n",
      "topic_6                      -0.0985      0.451     -0.219      0.827      -0.982       0.785\n",
      "topic_15                     -0.1395      0.455     -0.307      0.759      -1.031       0.752\n",
      "topic_24                     -0.6190      0.496     -1.248      0.212      -1.591       0.353\n",
      "topic_25                     -0.2407      0.461     -0.522      0.602      -1.144       0.663\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.606982421875\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.13557891803850955\n",
      "Confusion-Matrix:\n",
      "[[320   0]\n",
      " [ 64   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.446817\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  378\n",
      "Model:                          Logit   Df Residuals:                      366\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.01754\n",
      "Time:                        18:29:06   Log-Likelihood:                -168.90\n",
      "converged:                       True   LL-Null:                       -171.91\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.8713\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7411      0.757     -0.978      0.328      -2.225       0.743\n",
      "issue attention Facebook      0.4561      0.788      0.579      0.563      -1.088       2.001\n",
      "issue attention Bundestag     0.3330      1.308      0.255      0.799      -2.231       2.897\n",
      "Social Media Nutzung         -0.1664      0.156     -1.065      0.287      -0.473       0.140\n",
      "Landtagswahlen                0.2469      0.259      0.953      0.340      -0.261       0.754\n",
      "Komplexit√§t Reden            -0.1534      0.152     -1.008      0.314      -0.452       0.145\n",
      "Komplexit√§t Posts             0.3371      0.387      0.870      0.384      -0.422       1.097\n",
      "topic_2                      -0.5957      0.504     -1.183      0.237      -1.583       0.391\n",
      "topic_6                      -0.1089      0.450     -0.242      0.809      -0.991       0.773\n",
      "topic_15                     -0.0785      0.454     -0.173      0.863      -0.968       0.811\n",
      "topic_24                     -0.5646      0.494     -1.142      0.253      -1.534       0.404\n",
      "topic_25                     -0.1876      0.460     -0.408      0.683      -1.090       0.714\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5852408439490445\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1383616039445147\n",
      "Confusion-Matrix:\n",
      "[[314   0]\n",
      " [ 64   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.439807\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  372\n",
      "Model:                          Logit   Df Residuals:                      360\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.03310\n",
      "Time:                        18:29:06   Log-Likelihood:                -163.61\n",
      "converged:                       True   LL-Null:                       -169.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4266\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7115      0.774     -0.919      0.358      -2.229       0.806\n",
      "issue attention Facebook      1.6817      0.723      2.326      0.020       0.264       3.099\n",
      "issue attention Bundestag     1.2746      1.257      1.014      0.310      -1.188       3.737\n",
      "Social Media Nutzung         -0.1806      0.159     -1.135      0.256      -0.492       0.131\n",
      "Landtagswahlen               -0.1352      0.324     -0.418      0.676      -0.770       0.499\n",
      "Komplexit√§t Reden             0.0516      0.147      0.352      0.725      -0.236       0.340\n",
      "Komplexit√§t Posts             0.4613      0.388      1.189      0.234      -0.299       1.222\n",
      "topic_2                      -0.6426      0.512     -1.256      0.209      -1.645       0.360\n",
      "topic_6                      -0.1496      0.458     -0.327      0.744      -1.047       0.748\n",
      "topic_15                     -0.0093      0.459     -0.020      0.984      -0.908       0.889\n",
      "topic_24                     -0.5202      0.500     -1.040      0.298      -1.501       0.460\n",
      "topic_25                     -0.2528      0.474     -0.533      0.594      -1.183       0.677\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5989109775517543\n",
      "Pr√§zision: 0.3333333333333333\n",
      "Recall: 0.015873015873015872\n",
      "F1-Score: 0.030303030303030304\n",
      "Brier-Score: 0.13540878642600002\n",
      "Confusion-Matrix:\n",
      "[[307   2]\n",
      " [ 62   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.440610\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  366\n",
      "Model:                          Logit   Df Residuals:                      354\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.03148\n",
      "Time:                        18:29:06   Log-Likelihood:                -161.26\n",
      "converged:                       True   LL-Null:                       -166.51\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4875\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.1168      0.752     -2.816      0.005      -3.590      -0.643\n",
      "issue attention Facebook     -1.9864      1.356     -1.465      0.143      -4.644       0.671\n",
      "issue attention Bundestag     1.8419      1.307      1.409      0.159      -0.720       4.404\n",
      "Social Media Nutzung          0.1755      0.144      1.215      0.224      -0.108       0.459\n",
      "Landtagswahlen               -0.5049      0.415     -1.216      0.224      -1.319       0.309\n",
      "Komplexit√§t Reden             0.0375      0.155      0.241      0.809      -0.267       0.342\n",
      "Komplexit√§t Posts            -0.3659      0.372     -0.984      0.325      -1.095       0.363\n",
      "topic_2                      -0.6816      0.521     -1.308      0.191      -1.703       0.340\n",
      "topic_6                      -0.0121      0.462     -0.026      0.979      -0.917       0.893\n",
      "topic_15                      0.0747      0.464      0.161      0.872      -0.835       0.985\n",
      "topic_24                     -0.4568      0.504     -0.906      0.365      -1.445       0.531\n",
      "topic_25                     -0.1583      0.480     -0.330      0.741      -1.098       0.782\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6191638370118845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1361789630791754\n",
      "Confusion-Matrix:\n",
      "[[304   0]\n",
      " [ 62   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.435410\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  360\n",
      "Model:                          Logit   Df Residuals:                      348\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05220\n",
      "Time:                        18:29:06   Log-Likelihood:                -156.75\n",
      "converged:                       True   LL-Null:                       -165.38\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1002\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.7413      0.742     -2.346      0.019      -3.196      -0.287\n",
      "issue attention Facebook      1.8198      0.785      2.317      0.021       0.280       3.359\n",
      "issue attention Bundestag    -3.9050      2.180     -1.791      0.073      -8.178       0.368\n",
      "Social Media Nutzung          0.1079      0.141      0.764      0.445      -0.169       0.385\n",
      "Landtagswahlen               -0.5259      0.421     -1.249      0.212      -1.351       0.300\n",
      "Komplexit√§t Reden            -0.0479      0.158     -0.302      0.762      -0.358       0.262\n",
      "Komplexit√§t Posts             0.0096      0.356      0.027      0.978      -0.687       0.706\n",
      "topic_2                      -0.3471      0.512     -0.677      0.498      -1.351       0.657\n",
      "topic_6                      -0.0045      0.470     -0.010      0.992      -0.926       0.917\n",
      "topic_15                     -0.1252      0.472     -0.265      0.791      -1.051       0.801\n",
      "topic_24                     -0.6021      0.513     -1.173      0.241      -1.608       0.404\n",
      "topic_25                     -0.3623      0.490     -0.740      0.460      -1.322       0.598\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6753085083351376\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.13708969775395508\n",
      "Confusion-Matrix:\n",
      "[[297   1]\n",
      " [ 62   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.454003\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  354\n",
      "Model:                          Logit   Df Residuals:                      342\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.01205\n",
      "Time:                        18:29:06   Log-Likelihood:                -160.72\n",
      "converged:                       True   LL-Null:                       -162.68\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9722\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.3409      0.750     -1.789      0.074      -2.810       0.128\n",
      "issue attention Facebook     -0.3601      0.990     -0.364      0.716      -2.300       1.580\n",
      "issue attention Bundestag    -0.5386      1.570     -0.343      0.732      -3.617       2.539\n",
      "Social Media Nutzung          0.0176      0.148      0.119      0.905      -0.273       0.308\n",
      "Landtagswahlen               -0.3130      0.383     -0.817      0.414      -1.064       0.438\n",
      "Komplexit√§t Reden            -0.1292      0.156     -0.826      0.409      -0.436       0.177\n",
      "Komplexit√§t Posts            -0.0491      0.364     -0.135      0.893      -0.762       0.664\n",
      "topic_2                      -0.4727      0.507     -0.933      0.351      -1.466       0.520\n",
      "topic_6                       0.0079      0.459      0.017      0.986      -0.892       0.908\n",
      "topic_15                     -0.1335      0.471     -0.284      0.777      -1.056       0.789\n",
      "topic_24                     -0.5106      0.503     -1.015      0.310      -1.496       0.475\n",
      "topic_25                     -0.2405      0.478     -0.503      0.615      -1.177       0.696\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5775191629832708\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1412279544906006\n",
      "Confusion-Matrix:\n",
      "[[293   0]\n",
      " [ 61   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.454046\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  348\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.01228\n",
      "Time:                        18:29:06   Log-Likelihood:                -158.01\n",
      "converged:                       True   LL-Null:                       -159.97\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9719\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.8059      0.769     -2.348      0.019      -3.313      -0.298\n",
      "issue attention Facebook     -0.3628      0.993     -0.365      0.715      -2.309       1.583\n",
      "issue attention Bundestag     1.2716      1.363      0.933      0.351      -1.400       3.943\n",
      "Social Media Nutzung          0.0827      0.153      0.539      0.590      -0.218       0.383\n",
      "Landtagswahlen               -0.3006      0.383     -0.784      0.433      -1.052       0.450\n",
      "Komplexit√§t Reden             0.0162      0.154      0.105      0.916      -0.286       0.318\n",
      "Komplexit√§t Posts            -0.2497      0.369     -0.677      0.499      -0.973       0.474\n",
      "topic_2                      -0.4684      0.520     -0.902      0.367      -1.487       0.550\n",
      "topic_6                       0.0883      0.469      0.188      0.851      -0.830       1.007\n",
      "topic_15                      0.0528      0.479      0.110      0.912      -0.886       0.991\n",
      "topic_24                     -0.3455      0.510     -0.677      0.498      -1.345       0.654\n",
      "topic_25                     -0.0716      0.486     -0.147      0.883      -1.025       0.882\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5836226851851851\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1411120634816237\n",
      "Confusion-Matrix:\n",
      "[[288   0]\n",
      " [ 60   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_gruen, post_reduced_gruen, post_common_gruen,lag, social_media_usage_gruen, rede_komplex_gruen, posts_komplex_gruen)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - B√úNDNIS 90/ DIE GR√úNEN\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_gruen_complex.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Linke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\3515888887.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_linke[\"date\"] = pd.to_datetime(subset_reden_linke[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\3515888887.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_linke[\"date\"] = pd.to_datetime(subset_posts_linke[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_linke = subset_posts[subset_posts[\"partei\"] == \"DIE LINKE.\"]\n",
    "subset_reden_linke = subset_reden[subset_reden[\"partei\"] == \"DIE LINKE.\"]\n",
    "social_media_usage_linke = subset_posts_linke.groupby('date').size()\n",
    "subset_reden_linke[\"date\"] = pd.to_datetime(subset_reden_linke[\"date\"])\n",
    "subset_posts_linke[\"date\"] = pd.to_datetime(subset_posts_linke[\"date\"])\n",
    "reden_komplexit√§t_t√§glich_linke = subset_reden_linke.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_linke = subset_posts_linke.groupby('date')['komplexit√§t'].sum()\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_linke = subset_reden_linke.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_linke = subset_posts_linke.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_linke = redethemen_t√§glich_linke.index.intersection(postthemen_t√§glich_linke.index)\n",
    "redethemen_t√§glich_aligned_linke = redethemen_t√§glich_linke.loc[common_dates_linke]\n",
    "postthemen_t√§glich_aligned_linke = postthemen_t√§glich_linke.loc[common_dates_linke]\n",
    "rede_komplex_linke = reden_komplexit√§t_t√§glich_linke.loc[common_dates_linke]\n",
    "posts_komplex_linke = posts_komplexit√§t_t√§glich_linke.loc[common_dates_linke]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2022-05-31    119\n",
       "2022-06-01    191\n",
       "2022-06-02    127\n",
       "2022-06-03    123\n",
       "2022-06-22     92\n",
       "             ... \n",
       "2023-04-27     86\n",
       "2023-04-28     42\n",
       "2023-05-10     71\n",
       "2023-05-11    127\n",
       "2023-05-12    285\n",
       "Name: komplexit√§t, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_komplex_linke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 34, 35, 36, 40, 43, 52, 53, 54, 55, 56, 58, 64, 68, 74, 75, 79, 85, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 6, 8}\n"
     ]
    }
   ],
   "source": [
    "rede_common_linke, post_common_linke = filter_common_topics(redethemen_t√§glich_aligned_linke, postthemen_t√§glich_aligned_linke)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_linke =  rede_common_linke.div(rede_common_linke.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_linke = post_common_linke.div(post_common_linke.sum(axis=1), axis=0)\n",
    "reden_relativ_linke_red = remove_near_constant(reden_relativ_linke)\n",
    "post_relativ_linke_red = remove_near_constant(post_relativ_linke)\n",
    "rede_reduced_linke, post_reduced_linke = filter_common_topics(reden_relativ_linke_red, post_relativ_linke_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Topic</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Topic              0         1         2    6         8\n",
       "date                                                   \n",
       "2022-05-31  0.000000  0.000000  0.500000  0.0  0.000000\n",
       "2022-06-01  0.000000  0.000000  0.000000  0.5  0.250000\n",
       "2022-06-02  0.000000  0.333333  0.666667  0.0  0.000000\n",
       "2022-06-03  0.000000  0.200000  0.600000  0.0  0.000000\n",
       "2022-06-22  0.000000  0.000000  0.000000  0.0  0.000000\n",
       "...              ...       ...       ...  ...       ...\n",
       "2023-04-27  1.000000  0.000000  0.000000  0.0  0.000000\n",
       "2023-04-28  0.000000  0.000000  0.000000  0.0  0.000000\n",
       "2023-05-10  0.000000  0.000000  0.000000  0.0  0.500000\n",
       "2023-05-11  0.500000  0.000000  0.000000  0.0  0.000000\n",
       "2023-05-12  0.666667  0.000000  0.000000  0.0  0.166667\n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_reduced_linke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.393246\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  295\n",
      "Model:                          Logit   Df Residuals:                      292\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                0.009163\n",
      "Time:                        18:29:06   Log-Likelihood:                -116.01\n",
      "converged:                       True   LL-Null:                       -117.08\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3421\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -1.8982      0.198     -9.591      0.000      -2.286      -1.510\n",
      "posts_relative    -0.8406      0.919     -0.915      0.360      -2.641       0.960\n",
      "reden_relativ      1.1469      0.920      1.246      0.213      -0.657       2.951\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM(rede_reduced_linke,post_reduced_linke, post_common_linke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.387441\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  295\n",
      "Model:                          Logit   Df Residuals:                      288\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02379\n",
      "Time:                        18:29:06   Log-Likelihood:                -114.29\n",
      "converged:                       True   LL-Null:                       -117.08\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4729\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -2.0545      0.417     -4.921      0.000      -2.873      -1.236\n",
      "posts_relative    -1.0345      0.913     -1.133      0.257      -2.824       0.755\n",
      "reden_relativ      1.1311      0.927      1.220      0.223      -0.686       2.948\n",
      "topic_1            0.0160      0.572      0.028      0.978      -1.104       1.136\n",
      "topic_2            0.7013      0.521      1.346      0.178      -0.320       1.723\n",
      "topic_6            0.1702      0.556      0.306      0.760      -0.920       1.260\n",
      "topic_8           -0.1868      0.592     -0.316      0.752      -1.347       0.973\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM_fixed_effects(rede_reduced_linke,post_reduced_linke, post_common_linke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression f√ºr Lag 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.379926\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  295\n",
      "Model:                          Logit   Df Residuals:                      286\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.04272\n",
      "Time:                        18:29:06   Log-Likelihood:                -112.08\n",
      "converged:                       True   LL-Null:                       -117.08\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2647\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.7960      0.581     -4.817      0.000      -3.934      -1.658\n",
      "issue attention Facebook     -1.2538      1.001     -1.253      0.210      -3.215       0.708\n",
      "issue attention Bundestag     1.1382      0.948      1.200      0.230      -0.720       2.997\n",
      "Social Media Nutzung          0.2526      0.148      1.712      0.087      -0.037       0.542\n",
      "Landtagswahlen                0.2246      0.292      0.769      0.442      -0.348       0.797\n",
      "topic_1                       0.0210      0.576      0.037      0.971      -1.108       1.150\n",
      "topic_2                       0.7175      0.526      1.363      0.173      -0.314       1.749\n",
      "topic_6                       0.1816      0.561      0.324      0.746      -0.917       1.280\n",
      "topic_8                      -0.1870      0.596     -0.314      0.754      -1.355       0.981\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6389705882352942\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.11303858082276579\n",
      "Confusion-Matrix:\n",
      "[[255   0]\n",
      " [ 40   0]]\n",
      "\n",
      "Regression f√ºr Lag 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.375681\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  290\n",
      "Model:                          Logit   Df Residuals:                      281\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.04848\n",
      "Time:                        18:29:06   Log-Likelihood:                -108.95\n",
      "converged:                       True   LL-Null:                       -114.50\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1960\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.9032      0.605     -4.800      0.000      -4.089      -1.718\n",
      "issue attention Facebook      1.3562      0.608      2.231      0.026       0.165       2.548\n",
      "issue attention Bundestag     0.8634      1.004      0.860      0.390      -1.104       2.831\n",
      "Social Media Nutzung          0.1947      0.147      1.321      0.187      -0.094       0.484\n",
      "Landtagswahlen               -0.0485      0.344     -0.141      0.888      -0.723       0.626\n",
      "topic_1                       0.2444      0.599      0.408      0.683      -0.929       1.417\n",
      "topic_2                       0.7180      0.553      1.298      0.194      -0.366       1.802\n",
      "topic_6                       0.3889      0.584      0.666      0.505      -0.755       1.533\n",
      "topic_8                       0.0927      0.619      0.150      0.881      -1.120       1.305\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6457247931351517\n",
      "Pr√§zision: 1.0\n",
      "Recall: 0.02564102564102564\n",
      "F1-Score: 0.05\n",
      "Brier-Score: 0.11107569056199423\n",
      "Confusion-Matrix:\n",
      "[[251   0]\n",
      " [ 38   1]]\n",
      "\n",
      "Regression f√ºr Lag 3:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.381776\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  285\n",
      "Model:                          Logit   Df Residuals:                      276\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02775\n",
      "Time:                        18:29:06   Log-Likelihood:                -108.81\n",
      "converged:                       True   LL-Null:                       -111.91\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6235\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.2343      0.589     -3.796      0.000      -3.388      -1.081\n",
      "issue attention Facebook     -0.0765      0.736     -0.104      0.917      -1.518       1.365\n",
      "issue attention Bundestag     0.5916      1.042      0.568      0.570      -1.451       2.634\n",
      "Social Media Nutzung          0.0572      0.152      0.375      0.708      -0.242       0.356\n",
      "Landtagswahlen               -0.5862      0.479     -1.225      0.221      -1.524       0.352\n",
      "topic_1                       0.1879      0.593      0.317      0.752      -0.975       1.351\n",
      "topic_2                       0.8306      0.544      1.527      0.127      -0.236       1.897\n",
      "topic_6                       0.3437      0.578      0.595      0.552      -0.789       1.477\n",
      "topic_8                      -0.2030      0.640     -0.317      0.751      -1.456       1.050\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.625506072874494\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.11344598916471275\n",
      "Confusion-Matrix:\n",
      "[[247   0]\n",
      " [ 38   0]]\n",
      "\n",
      "Regression f√ºr Lag 4:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.381740\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  280\n",
      "Model:                          Logit   Df Residuals:                      271\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.03870\n",
      "Time:                        18:29:06   Log-Likelihood:                -106.89\n",
      "converged:                       True   LL-Null:                       -111.19\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3767\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.8428      0.593     -3.106      0.002      -3.006      -0.680\n",
      "issue attention Facebook      0.3617      0.665      0.544      0.587      -0.942       1.666\n",
      "issue attention Bundestag     0.3932      1.081      0.364      0.716      -1.725       2.511\n",
      "Social Media Nutzung         -0.0915      0.162     -0.565      0.572      -0.409       0.226\n",
      "Landtagswahlen               -1.0237      0.629     -1.628      0.104      -2.256       0.209\n",
      "topic_1                       0.1963      0.596      0.329      0.742      -0.972       1.364\n",
      "topic_2                       0.8125      0.547      1.485      0.138      -0.260       1.885\n",
      "topic_6                       0.3496      0.581      0.602      0.547      -0.789       1.488\n",
      "topic_8                      -0.1792      0.642     -0.279      0.780      -1.437       1.079\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6440300130491519\n",
      "Pr√§zision: 0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.11370889701446807\n",
      "Confusion-Matrix:\n",
      "[[242   0]\n",
      " [ 38   0]]\n",
      "\n",
      "Regression f√ºr Lag 5:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.378094\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  275\n",
      "Model:                          Logit   Df Residuals:                      266\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.04265\n",
      "Time:                        18:29:07   Log-Likelihood:                -103.98\n",
      "converged:                       True   LL-Null:                       -108.61\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3206\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.0544      0.622     -3.302      0.001      -3.274      -0.835\n",
      "issue attention Facebook     -1.2369      1.046     -1.183      0.237      -3.287       0.813\n",
      "issue attention Bundestag    -0.8405      1.418     -0.593      0.553      -3.620       1.939\n",
      "Social Media Nutzung          0.0048      0.160      0.030      0.976      -0.309       0.318\n",
      "Landtagswahlen               -0.7343      0.561     -1.308      0.191      -1.834       0.366\n",
      "topic_1                       0.3264      0.624      0.523      0.601      -0.896       1.549\n",
      "topic_2                       1.0601      0.578      1.833      0.067      -0.073       2.194\n",
      "topic_6                       0.4942      0.610      0.810      0.418      -0.702       1.690\n",
      "topic_8                      -0.0632      0.667     -0.095      0.925      -1.371       1.245\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6440495116965705\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1124761159226722\n",
      "Confusion-Matrix:\n",
      "[[238   0]\n",
      " [ 37   0]]\n",
      "\n",
      "Regression f√ºr Lag 6:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.374665\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  270\n",
      "Model:                          Logit   Df Residuals:                      261\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.04586\n",
      "Time:                        18:29:07   Log-Likelihood:                -101.16\n",
      "converged:                       True   LL-Null:                       -106.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2848\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.9317      0.654     -4.482      0.000      -4.214      -1.650\n",
      "issue attention Facebook      0.6713      0.686      0.978      0.328      -0.673       2.016\n",
      "issue attention Bundestag     0.9972      1.084      0.920      0.358      -1.128       3.122\n",
      "Social Media Nutzung          0.1952      0.155      1.263      0.206      -0.108       0.498\n",
      "Landtagswahlen               -0.1242      0.490     -0.254      0.800      -1.084       0.835\n",
      "topic_1                       0.4306      0.625      0.689      0.491      -0.794       1.656\n",
      "topic_2                       1.0210      0.581      1.756      0.079      -0.118       2.160\n",
      "topic_6                       0.5653      0.611      0.926      0.355      -0.631       1.762\n",
      "topic_8                      -0.2166      0.705     -0.307      0.759      -1.599       1.166\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6486229819563153\n",
      "Pr√§zision: 1.0\n",
      "Recall: 0.027777777777777776\n",
      "F1-Score: 0.05405405405405406\n",
      "Brier-Score: 0.11061302232010631\n",
      "Confusion-Matrix:\n",
      "[[234   0]\n",
      " [ 35   1]]\n",
      "\n",
      "Regression f√ºr Lag 7:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.368542\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  265\n",
      "Model:                          Logit   Df Residuals:                      256\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05578\n",
      "Time:                        18:29:07   Log-Likelihood:                -97.664\n",
      "converged:                       True   LL-Null:                       -103.43\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1730\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.4058      0.678     -3.549      0.000      -3.734      -1.077\n",
      "issue attention Facebook      0.6230      0.791      0.787      0.431      -0.928       2.174\n",
      "issue attention Bundestag    -3.6805      2.141     -1.719      0.086      -7.876       0.515\n",
      "Social Media Nutzung          0.0467      0.165      0.284      0.776      -0.276       0.369\n",
      "Landtagswahlen               -0.0812      0.492     -0.165      0.869      -1.046       0.883\n",
      "topic_1                       0.5940      0.664      0.895      0.371      -0.707       1.895\n",
      "topic_2                       1.1820      0.622      1.901      0.057      -0.036       2.401\n",
      "topic_6                       0.7243      0.651      1.113      0.266      -0.552       2.000\n",
      "topic_8                      -0.0522      0.741     -0.070      0.944      -1.504       1.400\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6850931677018633\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.10899739568285839\n",
      "Confusion-Matrix:\n",
      "[[230   0]\n",
      " [ 35   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Schleife f√ºr logistische Regression mit Lags von -7 bis 7\n",
    "for n in range(1, 8):  # Einschlie√ülich 1 bis 7\n",
    "    try:\n",
    "        print(f\"\\nRegression f√ºr Lag {n}:\")\n",
    "        log_reg_FE_control(rede_reduced_linke, post_reduced_linke, post_common_linke,n, social_media_usage_linke)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Lag {n}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.379926\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  295\n",
      "Model:                          Logit   Df Residuals:                      286\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.04272\n",
      "Time:                        18:29:07   Log-Likelihood:                -112.08\n",
      "converged:                       True   LL-Null:                       -117.08\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2647\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.7960      0.581     -4.817      0.000      -3.934      -1.658\n",
      "issue attention Facebook     -1.2538      1.001     -1.253      0.210      -3.215       0.708\n",
      "issue attention Bundestag     1.1382      0.948      1.200      0.230      -0.720       2.997\n",
      "Social Media Nutzung          0.2526      0.148      1.712      0.087      -0.037       0.542\n",
      "Landtagswahlen                0.2246      0.292      0.769      0.442      -0.348       0.797\n",
      "topic_1                       0.0210      0.576      0.037      0.971      -1.108       1.150\n",
      "topic_2                       0.7175      0.526      1.363      0.173      -0.314       1.749\n",
      "topic_6                       0.1816      0.561      0.324      0.746      -0.917       1.280\n",
      "topic_8                      -0.1870      0.596     -0.314      0.754      -1.355       0.981\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6389705882352942\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.11303858082276579\n",
      "Confusion-Matrix:\n",
      "[[255   0]\n",
      " [ 40   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.375681\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  290\n",
      "Model:                          Logit   Df Residuals:                      281\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.04848\n",
      "Time:                        18:29:07   Log-Likelihood:                -108.95\n",
      "converged:                       True   LL-Null:                       -114.50\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1960\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.9032      0.605     -4.800      0.000      -4.089      -1.718\n",
      "issue attention Facebook      1.3562      0.608      2.231      0.026       0.165       2.548\n",
      "issue attention Bundestag     0.8634      1.004      0.860      0.390      -1.104       2.831\n",
      "Social Media Nutzung          0.1947      0.147      1.321      0.187      -0.094       0.484\n",
      "Landtagswahlen               -0.0485      0.344     -0.141      0.888      -0.723       0.626\n",
      "topic_1                       0.2444      0.599      0.408      0.683      -0.929       1.417\n",
      "topic_2                       0.7180      0.553      1.298      0.194      -0.366       1.802\n",
      "topic_6                       0.3889      0.584      0.666      0.505      -0.755       1.533\n",
      "topic_8                       0.0927      0.619      0.150      0.881      -1.120       1.305\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6457247931351517\n",
      "Pr√§zision: 1.0\n",
      "Recall: 0.02564102564102564\n",
      "F1-Score: 0.05\n",
      "Brier-Score: 0.11107569056199423\n",
      "Confusion-Matrix:\n",
      "[[251   0]\n",
      " [ 38   1]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.381776\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  285\n",
      "Model:                          Logit   Df Residuals:                      276\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02775\n",
      "Time:                        18:29:07   Log-Likelihood:                -108.81\n",
      "converged:                       True   LL-Null:                       -111.91\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6235\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.2343      0.589     -3.796      0.000      -3.388      -1.081\n",
      "issue attention Facebook     -0.0765      0.736     -0.104      0.917      -1.518       1.365\n",
      "issue attention Bundestag     0.5916      1.042      0.568      0.570      -1.451       2.634\n",
      "Social Media Nutzung          0.0572      0.152      0.375      0.708      -0.242       0.356\n",
      "Landtagswahlen               -0.5862      0.479     -1.225      0.221      -1.524       0.352\n",
      "topic_1                       0.1879      0.593      0.317      0.752      -0.975       1.351\n",
      "topic_2                       0.8306      0.544      1.527      0.127      -0.236       1.897\n",
      "topic_6                       0.3437      0.578      0.595      0.552      -0.789       1.477\n",
      "topic_8                      -0.2030      0.640     -0.317      0.751      -1.456       1.050\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.625506072874494\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.11344598916471275\n",
      "Confusion-Matrix:\n",
      "[[247   0]\n",
      " [ 38   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.381740\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  280\n",
      "Model:                          Logit   Df Residuals:                      271\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.03870\n",
      "Time:                        18:29:07   Log-Likelihood:                -106.89\n",
      "converged:                       True   LL-Null:                       -111.19\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3767\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.8428      0.593     -3.106      0.002      -3.006      -0.680\n",
      "issue attention Facebook      0.3617      0.665      0.544      0.587      -0.942       1.666\n",
      "issue attention Bundestag     0.3932      1.081      0.364      0.716      -1.725       2.511\n",
      "Social Media Nutzung         -0.0915      0.162     -0.565      0.572      -0.409       0.226\n",
      "Landtagswahlen               -1.0237      0.629     -1.628      0.104      -2.256       0.209\n",
      "topic_1                       0.1963      0.596      0.329      0.742      -0.972       1.364\n",
      "topic_2                       0.8125      0.547      1.485      0.138      -0.260       1.885\n",
      "topic_6                       0.3496      0.581      0.602      0.547      -0.789       1.488\n",
      "topic_8                      -0.1792      0.642     -0.279      0.780      -1.437       1.079\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6440300130491519\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.11370889701446807\n",
      "Confusion-Matrix:\n",
      "[[242   0]\n",
      " [ 38   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.378094\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  275\n",
      "Model:                          Logit   Df Residuals:                      266\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.04265\n",
      "Time:                        18:29:07   Log-Likelihood:                -103.98\n",
      "converged:                       True   LL-Null:                       -108.61\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3206\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.0544      0.622     -3.302      0.001      -3.274      -0.835\n",
      "issue attention Facebook     -1.2369      1.046     -1.183      0.237      -3.287       0.813\n",
      "issue attention Bundestag    -0.8405      1.418     -0.593      0.553      -3.620       1.939\n",
      "Social Media Nutzung          0.0048      0.160      0.030      0.976      -0.309       0.318\n",
      "Landtagswahlen               -0.7343      0.561     -1.308      0.191      -1.834       0.366\n",
      "topic_1                       0.3264      0.624      0.523      0.601      -0.896       1.549\n",
      "topic_2                       1.0601      0.578      1.833      0.067      -0.073       2.194\n",
      "topic_6                       0.4942      0.610      0.810      0.418      -0.702       1.690\n",
      "topic_8                      -0.0632      0.667     -0.095      0.925      -1.371       1.245\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6440495116965705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1124761159226722\n",
      "Confusion-Matrix:\n",
      "[[238   0]\n",
      " [ 37   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.374665\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  270\n",
      "Model:                          Logit   Df Residuals:                      261\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.04586\n",
      "Time:                        18:29:07   Log-Likelihood:                -101.16\n",
      "converged:                       True   LL-Null:                       -106.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2848\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.9317      0.654     -4.482      0.000      -4.214      -1.650\n",
      "issue attention Facebook      0.6713      0.686      0.978      0.328      -0.673       2.016\n",
      "issue attention Bundestag     0.9972      1.084      0.920      0.358      -1.128       3.122\n",
      "Social Media Nutzung          0.1952      0.155      1.263      0.206      -0.108       0.498\n",
      "Landtagswahlen               -0.1242      0.490     -0.254      0.800      -1.084       0.835\n",
      "topic_1                       0.4306      0.625      0.689      0.491      -0.794       1.656\n",
      "topic_2                       1.0210      0.581      1.756      0.079      -0.118       2.160\n",
      "topic_6                       0.5653      0.611      0.926      0.355      -0.631       1.762\n",
      "topic_8                      -0.2166      0.705     -0.307      0.759      -1.599       1.166\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6486229819563153\n",
      "Pr√§zision: 1.0\n",
      "Recall: 0.027777777777777776\n",
      "F1-Score: 0.05405405405405406\n",
      "Brier-Score: 0.11061302232010631\n",
      "Confusion-Matrix:\n",
      "[[234   0]\n",
      " [ 35   1]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.368542\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  265\n",
      "Model:                          Logit   Df Residuals:                      256\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.05578\n",
      "Time:                        18:29:07   Log-Likelihood:                -97.664\n",
      "converged:                       True   LL-Null:                       -103.43\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1730\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.4058      0.678     -3.549      0.000      -3.734      -1.077\n",
      "issue attention Facebook      0.6230      0.791      0.787      0.431      -0.928       2.174\n",
      "issue attention Bundestag    -3.6805      2.141     -1.719      0.086      -7.876       0.515\n",
      "Social Media Nutzung          0.0467      0.165      0.284      0.776      -0.276       0.369\n",
      "Landtagswahlen               -0.0812      0.492     -0.165      0.869      -1.046       0.883\n",
      "topic_1                       0.5940      0.664      0.895      0.371      -0.707       1.895\n",
      "topic_2                       1.1820      0.622      1.901      0.057      -0.036       2.401\n",
      "topic_6                       0.7243      0.651      1.113      0.266      -0.552       2.000\n",
      "topic_8                      -0.0522      0.741     -0.070      0.944      -1.504       1.400\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6850931677018633\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.10899739568285839\n",
      "Confusion-Matrix:\n",
      "[[230   0]\n",
      " [ 35   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_linke, post_reduced_linke, post_common_linke,lag, social_media_usage_linke)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - DIE LINKE\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_linke.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 300 elements, new values have 295 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[581], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m):  \u001b[38;5;66;03m# F√ºr Lags 1 bis 7 \u001b[39;00m\n\u001b[0;32m      6\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m----> 7\u001b[0m     model, auc_roc, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mlog_reg_FE_control_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrede_reduced_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_reduced_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_common_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43msocial_media_usage_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrede_komplex_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposts_komplex_linke\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[0;32m      9\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mappend((auc_roc, f1))\n",
      "Cell \u001b[1;32mIn[535], line 64\u001b[0m, in \u001b[0;36mlog_reg_FE_control_test\u001b[1;34m(relativ_rede, relativ_posts, post_to_shift, shifts, social_media_usage, complexity_rede, complexity_post)\u001b[0m\n\u001b[0;32m     62\u001b[0m complexity_post_stacked \u001b[38;5;241m=\u001b[39m complexity_post_z\u001b[38;5;241m.\u001b[39mreindex(relativ_posts\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     63\u001b[0m complexity_post_stacked \u001b[38;5;241m=\u001b[39m complexity_post_stacked\u001b[38;5;241m.\u001b[39mrepeat(relativ_posts\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 64\u001b[0m \u001b[43mcomplexity_post_stacked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m \u001b[38;5;241m=\u001b[39m relative_posts\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Zielvariable und unabh√§ngige Variablen zusammenf√ºhren\u001b[39;00m\n\u001b[0;32m     67\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue attention Facebook\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_posts,\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue attention Bundestag\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_reden,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKomplexit√§t Posts\u001b[39m\u001b[38;5;124m'\u001b[39m: complexity_post_stacked\n\u001b[0;32m     74\u001b[0m })\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 300 elements, new values have 295 elements"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7 \n",
    "    models.append(model)\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_linke, post_reduced_linke, post_common_linke,lag,social_media_usage_linke, rede_komplex_linke, posts_komplex_linke)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - DIE LINKE\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_linke_complex.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\1557700233.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_fdp[\"date\"] = pd.to_datetime(subset_reden_fdp[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_13360\\1557700233.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_fdp[\"date\"] = pd.to_datetime(subset_posts_fdp[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_fdp = subset_posts[subset_posts[\"partei\"] == \"FDP\"]\n",
    "subset_reden_fdp = subset_reden[subset_reden[\"partei\"] == \"FDP\"]\n",
    "social_media_usage_fdp = subset_posts_fdp.groupby('date').size()\n",
    "subset_reden_fdp[\"date\"] = pd.to_datetime(subset_reden_fdp[\"date\"])\n",
    "subset_posts_fdp[\"date\"] = pd.to_datetime(subset_posts_fdp[\"date\"])\n",
    "reden_komplexit√§t_t√§glich_fdp = subset_reden_fdp.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_fdp = subset_posts_fdp.groupby('date')['komplexit√§t'].sum()\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_fdp = subset_reden_fdp.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_fdp = subset_posts_fdp.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_fdp = redethemen_t√§glich_fdp.index.intersection(postthemen_t√§glich_fdp.index)\n",
    "redethemen_t√§glich_aligned_fdp = redethemen_t√§glich_fdp.loc[common_dates_fdp]\n",
    "postthemen_t√§glich_aligned_fdp = postthemen_t√§glich_fdp.loc[common_dates_fdp]\n",
    "rede_komplex_fdp = reden_komplexit√§t_t√§glich_fdp.loc[common_dates_fdp]\n",
    "posts_komplex_fdp = posts_komplexit√§t_t√§glich_fdp.loc[common_dates_fdp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 36, 37, 39, 40, 41, 43, 44, 45, 46, 52, 53, 54, 56, 58, 59, 60, 61, 63, 64, 65, 69, 70, 72, 74, 75, 77, 78, 79, 80, 83, 90, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 34, 6, 7, 8, 10, 43, 14, 15, 22, 23}\n"
     ]
    }
   ],
   "source": [
    "rede_common_fdp, post_common_fdp = filter_common_topics(redethemen_t√§glich_aligned_fdp, postthemen_t√§glich_aligned_fdp)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_fdp =  rede_common_fdp.div(rede_common_fdp.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_fdp = post_common_fdp.div(post_common_fdp.sum(axis=1), axis=0)\n",
    "reden_relativ_fdp_red = remove_near_constant(reden_relativ_fdp)\n",
    "post_relativ_fdp_red = remove_near_constant(post_relativ_fdp)\n",
    "rede_reduced_fdp, post_reduced_fdp = filter_common_topics(reden_relativ_fdp_red, post_relativ_fdp_red)\n",
    "fdp_common_topics = post_common_fdp.loc[:, rede_reduced_fdp.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Topic</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>72</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>83</th>\n",
       "      <th>90</th>\n",
       "      <th>92</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-03</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-10</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows √ó 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Topic       0   1   2   3   4   5   6   7   8   9   ...  72  74  75  77  78  \\\n",
       "date                                                ...                       \n",
       "2022-05-31   0   1   0   1   0   0   1   0   0   0  ...   0   0   0   0   0   \n",
       "2022-06-01   0   7   0   0   0   0   3   0   0   0  ...   0   0   0   0   0   \n",
       "2022-06-02   1   2   0   0   0   0   0   0   1   2  ...   0   0   0   0   0   \n",
       "2022-06-03   0   1   4   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "2022-06-22   0   0   0   0   0   0   1   1   0   1  ...   0   0   0   0   0   \n",
       "...         ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..   \n",
       "2023-04-27   0   0   1   0   1   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "2023-04-28   0   0   1   0   0   0   0   0   0   1  ...   0   0   0   0   0   \n",
       "2023-05-10   0   2   1   1   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "2023-05-11   0   3   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "2023-05-12   1   2   0   1   0   0   0   0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "Topic       79  80  83  90  92  \n",
       "date                            \n",
       "2022-05-31   0   0   0   0   0  \n",
       "2022-06-01   0   0   0   0   0  \n",
       "2022-06-02   0   0   0   0   0  \n",
       "2022-06-03   3   0   0   0   0  \n",
       "2022-06-22   0   0   0   0   0  \n",
       "...         ..  ..  ..  ..  ..  \n",
       "2023-04-27   0   0   0   0   0  \n",
       "2023-04-28   0   0   0   0   0  \n",
       "2023-05-10   0   0   0   0   0  \n",
       "2023-05-11   0   0   0   0   0  \n",
       "2023-05-12   0   0   0   0   0  \n",
       "\n",
       "[66 rows x 65 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_common_fdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.523590\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      972\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.02628\n",
      "Time:                        17:49:53   Log-Likelihood:                -510.50\n",
      "converged:                       True   LL-Null:                       -524.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.037e-06\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -1.4418      0.092    -15.691      0.000      -1.622      -1.262\n",
      "posts_relative     3.6565      0.827      4.420      0.000       2.035       5.278\n",
      "reden_relativ      1.5716      0.853      1.842      0.065      -0.100       3.244\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM(rede_reduced_fdp,post_reduced_fdp, post_common_fdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.489450\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      958\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08977\n",
      "Time:                        17:49:55   Log-Likelihood:                -477.21\n",
      "converged:                       True   LL-Null:                       -524.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.306e-13\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -0.7549      0.271     -2.787      0.005      -1.286      -0.224\n",
      "posts_relative     1.9725      0.886      2.226      0.026       0.235       3.710\n",
      "reden_relativ      0.5083      0.931      0.546      0.585      -1.316       2.333\n",
      "topic_1            1.0841      0.372      2.917      0.004       0.356       1.812\n",
      "topic_2           -0.2674      0.379     -0.705      0.481      -1.010       0.476\n",
      "topic_3           -1.1332      0.446     -2.543      0.011      -2.007      -0.260\n",
      "topic_4           -1.4057      0.480     -2.927      0.003      -2.347      -0.464\n",
      "topic_6           -0.0266      0.371     -0.072      0.943      -0.754       0.701\n",
      "topic_7           -0.9169      0.423     -2.169      0.030      -1.745      -0.088\n",
      "topic_8           -1.0008      0.434     -2.307      0.021      -1.851      -0.151\n",
      "topic_10          -0.4119      0.385     -1.070      0.285      -1.167       0.343\n",
      "topic_14          -1.1236      0.446     -2.517      0.012      -1.999      -0.249\n",
      "topic_15          -0.6344      0.402     -1.579      0.114      -1.422       0.153\n",
      "topic_22          -1.1144      0.447     -2.493      0.013      -1.991      -0.238\n",
      "topic_23          -1.0414      0.435     -2.395      0.017      -1.894      -0.189\n",
      "topic_34          -0.9195      0.424     -2.169      0.030      -1.750      -0.089\n",
      "topic_43          -1.0318      0.435     -2.372      0.018      -1.884      -0.179\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM_fixed_effects(rede_reduced_fdp,post_reduced_fdp, fdp_common_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression f√ºr Lag 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486901\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      956\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09451\n",
      "Time:                        17:49:57   Log-Likelihood:                -474.73\n",
      "converged:                       True   LL-Null:                       -524.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.235e-13\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7349      0.338     -2.172      0.030      -1.398      -0.072\n",
      "issue attention Facebook      1.9987      0.892      2.242      0.025       0.251       3.746\n",
      "issue attention Bundestag     0.4200      0.932      0.450      0.652      -1.407       2.247\n",
      "Social Media Nutzung         -0.0124      0.022     -0.568      0.570      -0.055       0.030\n",
      "Landtagswahlen                0.3410      0.152      2.237      0.025       0.042       0.640\n",
      "topic_1                       1.0935      0.373      2.931      0.003       0.362       1.825\n",
      "topic_2                      -0.2675      0.381     -0.702      0.482      -1.014       0.479\n",
      "topic_3                      -1.1381      0.447     -2.547      0.011      -2.014      -0.262\n",
      "topic_4                      -1.4142      0.481     -2.937      0.003      -2.358      -0.470\n",
      "topic_6                      -0.0287      0.372     -0.077      0.938      -0.759       0.701\n",
      "topic_7                      -0.9260      0.424     -2.183      0.029      -1.758      -0.094\n",
      "topic_8                      -1.0081      0.435     -2.317      0.020      -1.861      -0.155\n",
      "topic_10                     -0.4150      0.386     -1.074      0.283      -1.172       0.342\n",
      "topic_14                     -1.1340      0.448     -2.533      0.011      -2.011      -0.257\n",
      "topic_15                     -0.6424      0.403     -1.593      0.111      -1.433       0.148\n",
      "topic_22                     -1.1229      0.448     -2.505      0.012      -2.001      -0.244\n",
      "topic_23                     -1.0479      0.436     -2.404      0.016      -1.902      -0.194\n",
      "topic_34                     -0.9250      0.425     -2.176      0.030      -1.758      -0.092\n",
      "topic_43                     -1.0399      0.436     -2.385      0.017      -1.894      -0.185\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7010870861559012\n",
      "Pr√§zision: 0.6323529411764706\n",
      "Recall: 0.19282511210762332\n",
      "F1-Score: 0.29553264604810997\n",
      "Brier-Score: 0.15662972269018055\n",
      "Confusion-Matrix:\n",
      "[[727  25]\n",
      " [180  43]]\n",
      "\n",
      "Regression f√ºr Lag 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.492911\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  960\n",
      "Model:                          Logit   Df Residuals:                      941\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08852\n",
      "Time:                        17:49:57   Log-Likelihood:                -473.19\n",
      "converged:                       True   LL-Null:                       -519.15\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.536e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9516      0.344     -2.768      0.006      -1.625      -0.278\n",
      "issue attention Facebook     -0.4225      0.984     -0.429      0.668      -2.351       1.506\n",
      "issue attention Bundestag     1.7848      0.959      1.862      0.063      -0.094       3.664\n",
      "Social Media Nutzung          0.0260      0.022      1.186      0.235      -0.017       0.069\n",
      "Landtagswahlen                0.1405      0.159      0.882      0.378      -0.172       0.453\n",
      "topic_1                       1.1559      0.375      3.079      0.002       0.420       1.892\n",
      "topic_2                      -0.3170      0.381     -0.833      0.405      -1.063       0.429\n",
      "topic_3                      -1.2286      0.447     -2.746      0.006      -2.106      -0.352\n",
      "topic_4                      -1.4697      0.482     -3.049      0.002      -2.414      -0.525\n",
      "topic_6                      -0.0322      0.373     -0.086      0.931      -0.764       0.699\n",
      "topic_7                      -0.9922      0.424     -2.338      0.019      -1.824      -0.161\n",
      "topic_8                      -1.0885      0.436     -2.499      0.012      -1.942      -0.235\n",
      "topic_10                     -0.4562      0.388     -1.177      0.239      -1.216       0.304\n",
      "topic_14                     -1.1900      0.448     -2.654      0.008      -2.069      -0.311\n",
      "topic_15                     -0.6175      0.403     -1.531      0.126      -1.408       0.173\n",
      "topic_22                     -1.1763      0.449     -2.621      0.009      -2.056      -0.297\n",
      "topic_23                     -1.0367      0.436     -2.378      0.017      -1.891      -0.182\n",
      "topic_34                     -0.9320      0.425     -2.191      0.028      -1.766      -0.098\n",
      "topic_43                     -1.0415      0.436     -2.387      0.017      -1.896      -0.186\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6808241167997264\n",
      "Pr√§zision: 0.6363636363636364\n",
      "Recall: 0.1891891891891892\n",
      "F1-Score: 0.2916666666666667\n",
      "Brier-Score: 0.15854931315441181\n",
      "Confusion-Matrix:\n",
      "[[714  24]\n",
      " [180  42]]\n",
      "\n",
      "Regression f√ºr Lag 3:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496445\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  945\n",
      "Model:                          Logit   Df Residuals:                      926\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08300\n",
      "Time:                        17:49:57   Log-Likelihood:                -469.14\n",
      "converged:                       True   LL-Null:                       -511.60\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.164e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5594      0.343     -1.631      0.103      -1.232       0.113\n",
      "issue attention Facebook     -0.4326      0.974     -0.444      0.657      -2.342       1.476\n",
      "issue attention Bundestag     0.8096      0.966      0.838      0.402      -1.083       2.702\n",
      "Social Media Nutzung         -0.0059      0.022     -0.264      0.791      -0.050       0.038\n",
      "Landtagswahlen                0.1566      0.179      0.875      0.382      -0.194       0.507\n",
      "topic_1                       1.1186      0.375      2.980      0.003       0.383       1.854\n",
      "topic_2                      -0.3803      0.384     -0.991      0.321      -1.132       0.371\n",
      "topic_3                      -1.3837      0.462     -2.993      0.003      -2.290      -0.478\n",
      "topic_4                      -1.5139      0.482     -3.142      0.002      -2.458      -0.569\n",
      "topic_6                      -0.0565      0.373     -0.152      0.880      -0.788       0.675\n",
      "topic_7                      -1.0067      0.424     -2.373      0.018      -1.838      -0.175\n",
      "topic_8                      -1.1162      0.436     -2.562      0.010      -1.970      -0.262\n",
      "topic_10                     -0.4491      0.387     -1.161      0.246      -1.207       0.309\n",
      "topic_14                     -1.2243      0.448     -2.730      0.006      -2.103      -0.345\n",
      "topic_15                     -0.6691      0.404     -1.658      0.097      -1.460       0.122\n",
      "topic_22                     -1.2238      0.449     -2.727      0.006      -2.103      -0.344\n",
      "topic_23                     -1.0877      0.436     -2.495      0.013      -1.942      -0.233\n",
      "topic_34                     -0.9784      0.425     -2.300      0.021      -1.812      -0.145\n",
      "topic_43                     -1.0902      0.436     -2.500      0.012      -1.945      -0.236\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6803715863491704\n",
      "Pr√§zision: 0.6349206349206349\n",
      "Recall: 0.182648401826484\n",
      "F1-Score: 0.28368794326241137\n",
      "Brier-Score: 0.1601938607741985\n",
      "Confusion-Matrix:\n",
      "[[703  23]\n",
      " [179  40]]\n",
      "\n",
      "Regression f√ºr Lag 4:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496524\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  930\n",
      "Model:                          Logit   Df Residuals:                      911\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08605\n",
      "Time:                        17:49:57   Log-Likelihood:                -461.77\n",
      "converged:                       True   LL-Null:                       -505.24\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.068e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3902      0.344     -1.136      0.256      -1.064       0.283\n",
      "issue attention Facebook     -1.5739      1.045     -1.506      0.132      -3.622       0.474\n",
      "issue attention Bundestag     0.2459      0.982      0.250      0.802      -1.680       2.171\n",
      "Social Media Nutzung         -0.0042      0.022     -0.188      0.851      -0.048       0.040\n",
      "Landtagswahlen               -0.1005      0.214     -0.469      0.639      -0.520       0.319\n",
      "topic_1                       1.2223      0.382      3.199      0.001       0.473       1.971\n",
      "topic_2                      -0.4779      0.389     -1.229      0.219      -1.240       0.284\n",
      "topic_3                      -1.4449      0.464     -3.117      0.002      -2.354      -0.536\n",
      "topic_4                      -1.5930      0.483     -3.296      0.001      -2.540      -0.646\n",
      "topic_6                      -0.0871      0.375     -0.232      0.816      -0.823       0.648\n",
      "topic_7                      -1.0604      0.426     -2.488      0.013      -1.896      -0.225\n",
      "topic_8                      -1.1864      0.437     -2.714      0.007      -2.043      -0.330\n",
      "topic_10                     -0.4717      0.389     -1.213      0.225      -1.234       0.290\n",
      "topic_14                     -1.3022      0.450     -2.893      0.004      -2.184      -0.420\n",
      "topic_15                     -0.7244      0.406     -1.786      0.074      -1.519       0.071\n",
      "topic_22                     -1.3055      0.450     -2.898      0.004      -2.188      -0.423\n",
      "topic_23                     -1.1517      0.438     -2.630      0.009      -2.010      -0.293\n",
      "topic_34                     -1.1553      0.437     -2.642      0.008      -2.012      -0.298\n",
      "topic_43                     -1.1597      0.438     -2.647      0.008      -2.018      -0.301\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6846420330788969\n",
      "Pr√§zision: 0.6557377049180327\n",
      "Recall: 0.18433179723502305\n",
      "F1-Score: 0.28776978417266186\n",
      "Brier-Score: 0.1601298402260904\n",
      "Confusion-Matrix:\n",
      "[[692  21]\n",
      " [177  40]]\n",
      "\n",
      "Regression f√ºr Lag 5:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.493828\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  915\n",
      "Model:                          Logit   Df Residuals:                      896\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09210\n",
      "Time:                        17:49:57   Log-Likelihood:                -451.85\n",
      "converged:                       True   LL-Null:                       -497.69\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.225e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7358      0.344     -2.138      0.033      -1.410      -0.061\n",
      "issue attention Facebook     -1.2064      1.046     -1.153      0.249      -3.257       0.844\n",
      "issue attention Bundestag     0.0429      0.998      0.043      0.966      -1.914       2.000\n",
      "Social Media Nutzung          0.0386      0.022      1.772      0.076      -0.004       0.081\n",
      "Landtagswahlen               -0.3085      0.216     -1.426      0.154      -0.733       0.116\n",
      "topic_1                       1.2303      0.386      3.186      0.001       0.473       1.987\n",
      "topic_2                      -0.5594      0.395     -1.415      0.157      -1.334       0.215\n",
      "topic_3                      -1.4463      0.466     -3.106      0.002      -2.359      -0.534\n",
      "topic_4                      -1.7733      0.509     -3.484      0.000      -2.771      -0.776\n",
      "topic_6                      -0.0902      0.378     -0.239      0.811      -0.831       0.651\n",
      "topic_7                      -1.0624      0.428     -2.480      0.013      -1.902      -0.223\n",
      "topic_8                      -1.1868      0.439     -2.702      0.007      -2.048      -0.326\n",
      "topic_10                     -0.5569      0.395     -1.409      0.159      -1.332       0.218\n",
      "topic_14                     -1.3121      0.453     -2.899      0.004      -2.199      -0.425\n",
      "topic_15                     -0.7351      0.408     -1.802      0.072      -1.535       0.064\n",
      "topic_22                     -1.3110      0.453     -2.897      0.004      -2.198      -0.424\n",
      "topic_23                     -1.1645      0.440     -2.645      0.008      -2.028      -0.302\n",
      "topic_34                     -1.1663      0.440     -2.654      0.008      -2.028      -0.305\n",
      "topic_43                     -1.1703      0.440     -2.658      0.008      -2.033      -0.307\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6846527657418641\n",
      "Pr√§zision: 0.6612903225806451\n",
      "Recall: 0.19158878504672897\n",
      "F1-Score: 0.2971014492753623\n",
      "Brier-Score: 0.15915679093904422\n",
      "Confusion-Matrix:\n",
      "[[680  21]\n",
      " [173  41]]\n",
      "\n",
      "Regression f√ºr Lag 6:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.494772\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      881\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09366\n",
      "Time:                        17:49:57   Log-Likelihood:                -445.30\n",
      "converged:                       True   LL-Null:                       -491.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.217e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6143      0.347     -1.772      0.076      -1.294       0.065\n",
      "issue attention Facebook      0.9797      0.955      1.026      0.305      -0.893       2.852\n",
      "issue attention Bundestag    -1.0137      1.029     -0.985      0.324      -3.030       1.003\n",
      "Social Media Nutzung          0.0217      0.022      0.975      0.329      -0.022       0.065\n",
      "Landtagswahlen               -0.3031      0.220     -1.380      0.168      -0.734       0.127\n",
      "topic_1                       1.1458      0.386      2.967      0.003       0.389       1.903\n",
      "topic_2                      -0.5161      0.396     -1.302      0.193      -1.293       0.261\n",
      "topic_3                      -1.3748      0.466     -2.948      0.003      -2.289      -0.461\n",
      "topic_4                      -1.7255      0.510     -3.386      0.001      -2.724      -0.727\n",
      "topic_6                      -0.0791      0.380     -0.208      0.835      -0.823       0.665\n",
      "topic_7                      -1.0009      0.429     -2.333      0.020      -1.842      -0.160\n",
      "topic_8                      -1.2436      0.453     -2.748      0.006      -2.131      -0.357\n",
      "topic_10                     -0.5258      0.396     -1.327      0.184      -1.302       0.251\n",
      "topic_14                     -1.2605      0.453     -2.781      0.005      -2.149      -0.372\n",
      "topic_15                     -0.8442      0.415     -2.035      0.042      -1.657      -0.031\n",
      "topic_22                     -1.2613      0.454     -2.781      0.005      -2.150      -0.372\n",
      "topic_23                     -1.1654      0.441     -2.645      0.008      -2.029      -0.302\n",
      "topic_34                     -1.1564      0.440     -2.628      0.009      -2.019      -0.294\n",
      "topic_43                     -1.1587      0.441     -2.629      0.009      -2.022      -0.295\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6916822071083809\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.18867924528301888\n",
      "F1-Score: 0.29411764705882354\n",
      "Brier-Score: 0.1595568516878259\n",
      "Confusion-Matrix:\n",
      "[[668  20]\n",
      " [172  40]]\n",
      "\n",
      "Regression f√ºr Lag 7:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495247\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  885\n",
      "Model:                          Logit   Df Residuals:                      866\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09832\n",
      "Time:                        17:49:57   Log-Likelihood:                -438.29\n",
      "converged:                       True   LL-Null:                       -486.09\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.416e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7256      0.348     -2.083      0.037      -1.408      -0.043\n",
      "issue attention Facebook      2.0826      0.926      2.249      0.025       0.267       3.898\n",
      "issue attention Bundestag    -0.7857      1.028     -0.764      0.445      -2.801       1.230\n",
      "Social Media Nutzung          0.0281      0.022      1.265      0.206      -0.015       0.072\n",
      "Landtagswahlen               -0.3416      0.221     -1.547      0.122      -0.775       0.091\n",
      "topic_1                       1.1200      0.391      2.862      0.004       0.353       1.887\n",
      "topic_2                      -0.4963      0.399     -1.244      0.214      -1.278       0.286\n",
      "topic_3                      -1.3303      0.468     -2.840      0.005      -2.248      -0.412\n",
      "topic_4                      -1.6762      0.511     -3.278      0.001      -2.679      -0.674\n",
      "topic_6                      -0.1269      0.384     -0.330      0.741      -0.880       0.627\n",
      "topic_7                      -0.9644      0.431     -2.236      0.025      -1.810      -0.119\n",
      "topic_8                      -1.1890      0.455     -2.616      0.009      -2.080      -0.298\n",
      "topic_10                     -0.5134      0.399     -1.287      0.198      -1.296       0.269\n",
      "topic_14                     -1.2051      0.455     -2.648      0.008      -2.097      -0.313\n",
      "topic_15                     -0.8224      0.417     -1.970      0.049      -1.641      -0.004\n",
      "topic_22                     -1.2009      0.456     -2.636      0.008      -2.094      -0.308\n",
      "topic_23                     -1.1347      0.444     -2.558      0.011      -2.004      -0.265\n",
      "topic_34                     -1.1298      0.443     -2.553      0.011      -1.997      -0.262\n",
      "topic_43                     -1.1259      0.444     -2.538      0.011      -1.995      -0.257\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6948964236994951\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.20853080568720378\n",
      "F1-Score: 0.3176895306859206\n",
      "Brier-Score: 0.1599712301537721\n",
      "Confusion-Matrix:\n",
      "[[652  22]\n",
      " [167  44]]\n"
     ]
    }
   ],
   "source": [
    "# Schleife f√ºr logistische Regression mit Lags von -7 bis 7\n",
    "for n in range(1, 8):  # Einschlie√ülich 1 bis 7\n",
    "    try:\n",
    "        print(f\"\\nRegression f√ºr Lag {n}:\")\n",
    "        log_reg_FE_control(rede_reduced_fdp, post_reduced_fdp, post_common_fdp,n, social_media_usage_fdp)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Lag {n}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486901\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      956\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09451\n",
      "Time:                        18:29:24   Log-Likelihood:                -474.73\n",
      "converged:                       True   LL-Null:                       -524.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.235e-13\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7349      0.338     -2.172      0.030      -1.398      -0.072\n",
      "issue attention Facebook      1.9987      0.892      2.242      0.025       0.251       3.746\n",
      "issue attention Bundestag     0.4200      0.932      0.450      0.652      -1.407       2.247\n",
      "Social Media Nutzung         -0.0124      0.022     -0.568      0.570      -0.055       0.030\n",
      "Landtagswahlen                0.3410      0.152      2.237      0.025       0.042       0.640\n",
      "topic_1                       1.0935      0.373      2.931      0.003       0.362       1.825\n",
      "topic_2                      -0.2675      0.381     -0.702      0.482      -1.014       0.479\n",
      "topic_3                      -1.1381      0.447     -2.547      0.011      -2.014      -0.262\n",
      "topic_4                      -1.4142      0.481     -2.937      0.003      -2.358      -0.470\n",
      "topic_6                      -0.0287      0.372     -0.077      0.938      -0.759       0.701\n",
      "topic_7                      -0.9260      0.424     -2.183      0.029      -1.758      -0.094\n",
      "topic_8                      -1.0081      0.435     -2.317      0.020      -1.861      -0.155\n",
      "topic_10                     -0.4150      0.386     -1.074      0.283      -1.172       0.342\n",
      "topic_14                     -1.1340      0.448     -2.533      0.011      -2.011      -0.257\n",
      "topic_15                     -0.6424      0.403     -1.593      0.111      -1.433       0.148\n",
      "topic_22                     -1.1229      0.448     -2.505      0.012      -2.001      -0.244\n",
      "topic_23                     -1.0479      0.436     -2.404      0.016      -1.902      -0.194\n",
      "topic_34                     -0.9250      0.425     -2.176      0.030      -1.758      -0.092\n",
      "topic_43                     -1.0399      0.436     -2.385      0.017      -1.894      -0.185\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7010870861559012\n",
      "Pr√§zision: 0.6323529411764706\n",
      "Recall: 0.19282511210762332\n",
      "F1-Score: 0.29553264604810997\n",
      "Brier-Score: 0.15662972269018055\n",
      "Confusion-Matrix:\n",
      "[[727  25]\n",
      " [180  43]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.492911\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  960\n",
      "Model:                          Logit   Df Residuals:                      941\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08852\n",
      "Time:                        18:29:24   Log-Likelihood:                -473.19\n",
      "converged:                       True   LL-Null:                       -519.15\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.536e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9516      0.344     -2.768      0.006      -1.625      -0.278\n",
      "issue attention Facebook     -0.4225      0.984     -0.429      0.668      -2.351       1.506\n",
      "issue attention Bundestag     1.7848      0.959      1.862      0.063      -0.094       3.664\n",
      "Social Media Nutzung          0.0260      0.022      1.186      0.235      -0.017       0.069\n",
      "Landtagswahlen                0.1405      0.159      0.882      0.378      -0.172       0.453\n",
      "topic_1                       1.1559      0.375      3.079      0.002       0.420       1.892\n",
      "topic_2                      -0.3170      0.381     -0.833      0.405      -1.063       0.429\n",
      "topic_3                      -1.2286      0.447     -2.746      0.006      -2.106      -0.352\n",
      "topic_4                      -1.4697      0.482     -3.049      0.002      -2.414      -0.525\n",
      "topic_6                      -0.0322      0.373     -0.086      0.931      -0.764       0.699\n",
      "topic_7                      -0.9922      0.424     -2.338      0.019      -1.824      -0.161\n",
      "topic_8                      -1.0885      0.436     -2.499      0.012      -1.942      -0.235\n",
      "topic_10                     -0.4562      0.388     -1.177      0.239      -1.216       0.304\n",
      "topic_14                     -1.1900      0.448     -2.654      0.008      -2.069      -0.311\n",
      "topic_15                     -0.6175      0.403     -1.531      0.126      -1.408       0.173\n",
      "topic_22                     -1.1763      0.449     -2.621      0.009      -2.056      -0.297\n",
      "topic_23                     -1.0367      0.436     -2.378      0.017      -1.891      -0.182\n",
      "topic_34                     -0.9320      0.425     -2.191      0.028      -1.766      -0.098\n",
      "topic_43                     -1.0415      0.436     -2.387      0.017      -1.896      -0.186\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6808241167997264\n",
      "Pr√§zision: 0.6363636363636364\n",
      "Recall: 0.1891891891891892\n",
      "F1-Score: 0.2916666666666667\n",
      "Brier-Score: 0.15854931315441181\n",
      "Confusion-Matrix:\n",
      "[[714  24]\n",
      " [180  42]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496445\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  945\n",
      "Model:                          Logit   Df Residuals:                      926\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08300\n",
      "Time:                        18:29:24   Log-Likelihood:                -469.14\n",
      "converged:                       True   LL-Null:                       -511.60\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.164e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5594      0.343     -1.631      0.103      -1.232       0.113\n",
      "issue attention Facebook     -0.4326      0.974     -0.444      0.657      -2.342       1.476\n",
      "issue attention Bundestag     0.8096      0.966      0.838      0.402      -1.083       2.702\n",
      "Social Media Nutzung         -0.0059      0.022     -0.264      0.791      -0.050       0.038\n",
      "Landtagswahlen                0.1566      0.179      0.875      0.382      -0.194       0.507\n",
      "topic_1                       1.1186      0.375      2.980      0.003       0.383       1.854\n",
      "topic_2                      -0.3803      0.384     -0.991      0.321      -1.132       0.371\n",
      "topic_3                      -1.3837      0.462     -2.993      0.003      -2.290      -0.478\n",
      "topic_4                      -1.5139      0.482     -3.142      0.002      -2.458      -0.569\n",
      "topic_6                      -0.0565      0.373     -0.152      0.880      -0.788       0.675\n",
      "topic_7                      -1.0067      0.424     -2.373      0.018      -1.838      -0.175\n",
      "topic_8                      -1.1162      0.436     -2.562      0.010      -1.970      -0.262\n",
      "topic_10                     -0.4491      0.387     -1.161      0.246      -1.207       0.309\n",
      "topic_14                     -1.2243      0.448     -2.730      0.006      -2.103      -0.345\n",
      "topic_15                     -0.6691      0.404     -1.658      0.097      -1.460       0.122\n",
      "topic_22                     -1.2238      0.449     -2.727      0.006      -2.103      -0.344\n",
      "topic_23                     -1.0877      0.436     -2.495      0.013      -1.942      -0.233\n",
      "topic_34                     -0.9784      0.425     -2.300      0.021      -1.812      -0.145\n",
      "topic_43                     -1.0902      0.436     -2.500      0.012      -1.945      -0.236\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6803715863491704\n",
      "Pr√§zision: 0.6349206349206349\n",
      "Recall: 0.182648401826484\n",
      "F1-Score: 0.28368794326241137\n",
      "Brier-Score: 0.1601938607741985\n",
      "Confusion-Matrix:\n",
      "[[703  23]\n",
      " [179  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496524\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  930\n",
      "Model:                          Logit   Df Residuals:                      911\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08605\n",
      "Time:                        18:29:24   Log-Likelihood:                -461.77\n",
      "converged:                       True   LL-Null:                       -505.24\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.068e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3902      0.344     -1.136      0.256      -1.064       0.283\n",
      "issue attention Facebook     -1.5739      1.045     -1.506      0.132      -3.622       0.474\n",
      "issue attention Bundestag     0.2459      0.982      0.250      0.802      -1.680       2.171\n",
      "Social Media Nutzung         -0.0042      0.022     -0.188      0.851      -0.048       0.040\n",
      "Landtagswahlen               -0.1005      0.214     -0.469      0.639      -0.520       0.319\n",
      "topic_1                       1.2223      0.382      3.199      0.001       0.473       1.971\n",
      "topic_2                      -0.4779      0.389     -1.229      0.219      -1.240       0.284\n",
      "topic_3                      -1.4449      0.464     -3.117      0.002      -2.354      -0.536\n",
      "topic_4                      -1.5930      0.483     -3.296      0.001      -2.540      -0.646\n",
      "topic_6                      -0.0871      0.375     -0.232      0.816      -0.823       0.648\n",
      "topic_7                      -1.0604      0.426     -2.488      0.013      -1.896      -0.225\n",
      "topic_8                      -1.1864      0.437     -2.714      0.007      -2.043      -0.330\n",
      "topic_10                     -0.4717      0.389     -1.213      0.225      -1.234       0.290\n",
      "topic_14                     -1.3022      0.450     -2.893      0.004      -2.184      -0.420\n",
      "topic_15                     -0.7244      0.406     -1.786      0.074      -1.519       0.071\n",
      "topic_22                     -1.3055      0.450     -2.898      0.004      -2.188      -0.423\n",
      "topic_23                     -1.1517      0.438     -2.630      0.009      -2.010      -0.293\n",
      "topic_34                     -1.1553      0.437     -2.642      0.008      -2.012      -0.298\n",
      "topic_43                     -1.1597      0.438     -2.647      0.008      -2.018      -0.301\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6846420330788969\n",
      "Pr√§zision: 0.6557377049180327\n",
      "Recall: 0.18433179723502305\n",
      "F1-Score: 0.28776978417266186\n",
      "Brier-Score: 0.1601298402260904\n",
      "Confusion-Matrix:\n",
      "[[692  21]\n",
      " [177  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.493828\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  915\n",
      "Model:                          Logit   Df Residuals:                      896\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09210\n",
      "Time:                        18:29:24   Log-Likelihood:                -451.85\n",
      "converged:                       True   LL-Null:                       -497.69\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.225e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7358      0.344     -2.138      0.033      -1.410      -0.061\n",
      "issue attention Facebook     -1.2064      1.046     -1.153      0.249      -3.257       0.844\n",
      "issue attention Bundestag     0.0429      0.998      0.043      0.966      -1.914       2.000\n",
      "Social Media Nutzung          0.0386      0.022      1.772      0.076      -0.004       0.081\n",
      "Landtagswahlen               -0.3085      0.216     -1.426      0.154      -0.733       0.116\n",
      "topic_1                       1.2303      0.386      3.186      0.001       0.473       1.987\n",
      "topic_2                      -0.5594      0.395     -1.415      0.157      -1.334       0.215\n",
      "topic_3                      -1.4463      0.466     -3.106      0.002      -2.359      -0.534\n",
      "topic_4                      -1.7733      0.509     -3.484      0.000      -2.771      -0.776\n",
      "topic_6                      -0.0902      0.378     -0.239      0.811      -0.831       0.651\n",
      "topic_7                      -1.0624      0.428     -2.480      0.013      -1.902      -0.223\n",
      "topic_8                      -1.1868      0.439     -2.702      0.007      -2.048      -0.326\n",
      "topic_10                     -0.5569      0.395     -1.409      0.159      -1.332       0.218\n",
      "topic_14                     -1.3121      0.453     -2.899      0.004      -2.199      -0.425\n",
      "topic_15                     -0.7351      0.408     -1.802      0.072      -1.535       0.064\n",
      "topic_22                     -1.3110      0.453     -2.897      0.004      -2.198      -0.424\n",
      "topic_23                     -1.1645      0.440     -2.645      0.008      -2.028      -0.302\n",
      "topic_34                     -1.1663      0.440     -2.654      0.008      -2.028      -0.305\n",
      "topic_43                     -1.1703      0.440     -2.658      0.008      -2.033      -0.307\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6846527657418641\n",
      "Pr√§zision: 0.6612903225806451\n",
      "Recall: 0.19158878504672897\n",
      "F1-Score: 0.2971014492753623\n",
      "Brier-Score: 0.15915679093904422\n",
      "Confusion-Matrix:\n",
      "[[680  21]\n",
      " [173  41]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.494772\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      881\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09366\n",
      "Time:                        18:29:24   Log-Likelihood:                -445.30\n",
      "converged:                       True   LL-Null:                       -491.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.217e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6143      0.347     -1.772      0.076      -1.294       0.065\n",
      "issue attention Facebook      0.9797      0.955      1.026      0.305      -0.893       2.852\n",
      "issue attention Bundestag    -1.0137      1.029     -0.985      0.324      -3.030       1.003\n",
      "Social Media Nutzung          0.0217      0.022      0.975      0.329      -0.022       0.065\n",
      "Landtagswahlen               -0.3031      0.220     -1.380      0.168      -0.734       0.127\n",
      "topic_1                       1.1458      0.386      2.967      0.003       0.389       1.903\n",
      "topic_2                      -0.5161      0.396     -1.302      0.193      -1.293       0.261\n",
      "topic_3                      -1.3748      0.466     -2.948      0.003      -2.289      -0.461\n",
      "topic_4                      -1.7255      0.510     -3.386      0.001      -2.724      -0.727\n",
      "topic_6                      -0.0791      0.380     -0.208      0.835      -0.823       0.665\n",
      "topic_7                      -1.0009      0.429     -2.333      0.020      -1.842      -0.160\n",
      "topic_8                      -1.2436      0.453     -2.748      0.006      -2.131      -0.357\n",
      "topic_10                     -0.5258      0.396     -1.327      0.184      -1.302       0.251\n",
      "topic_14                     -1.2605      0.453     -2.781      0.005      -2.149      -0.372\n",
      "topic_15                     -0.8442      0.415     -2.035      0.042      -1.657      -0.031\n",
      "topic_22                     -1.2613      0.454     -2.781      0.005      -2.150      -0.372\n",
      "topic_23                     -1.1654      0.441     -2.645      0.008      -2.029      -0.302\n",
      "topic_34                     -1.1564      0.440     -2.628      0.009      -2.019      -0.294\n",
      "topic_43                     -1.1587      0.441     -2.629      0.009      -2.022      -0.295\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6916822071083809\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.18867924528301888\n",
      "F1-Score: 0.29411764705882354\n",
      "Brier-Score: 0.1595568516878259\n",
      "Confusion-Matrix:\n",
      "[[668  20]\n",
      " [172  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495247\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  885\n",
      "Model:                          Logit   Df Residuals:                      866\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09832\n",
      "Time:                        18:29:24   Log-Likelihood:                -438.29\n",
      "converged:                       True   LL-Null:                       -486.09\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.416e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7256      0.348     -2.083      0.037      -1.408      -0.043\n",
      "issue attention Facebook      2.0826      0.926      2.249      0.025       0.267       3.898\n",
      "issue attention Bundestag    -0.7857      1.028     -0.764      0.445      -2.801       1.230\n",
      "Social Media Nutzung          0.0281      0.022      1.265      0.206      -0.015       0.072\n",
      "Landtagswahlen               -0.3416      0.221     -1.547      0.122      -0.775       0.091\n",
      "topic_1                       1.1200      0.391      2.862      0.004       0.353       1.887\n",
      "topic_2                      -0.4963      0.399     -1.244      0.214      -1.278       0.286\n",
      "topic_3                      -1.3303      0.468     -2.840      0.005      -2.248      -0.412\n",
      "topic_4                      -1.6762      0.511     -3.278      0.001      -2.679      -0.674\n",
      "topic_6                      -0.1269      0.384     -0.330      0.741      -0.880       0.627\n",
      "topic_7                      -0.9644      0.431     -2.236      0.025      -1.810      -0.119\n",
      "topic_8                      -1.1890      0.455     -2.616      0.009      -2.080      -0.298\n",
      "topic_10                     -0.5134      0.399     -1.287      0.198      -1.296       0.269\n",
      "topic_14                     -1.2051      0.455     -2.648      0.008      -2.097      -0.313\n",
      "topic_15                     -0.8224      0.417     -1.970      0.049      -1.641      -0.004\n",
      "topic_22                     -1.2009      0.456     -2.636      0.008      -2.094      -0.308\n",
      "topic_23                     -1.1347      0.444     -2.558      0.011      -2.004      -0.265\n",
      "topic_34                     -1.1298      0.443     -2.553      0.011      -1.997      -0.262\n",
      "topic_43                     -1.1259      0.444     -2.538      0.011      -1.995      -0.257\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6948964236994951\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.20853080568720378\n",
      "F1-Score: 0.3176895306859206\n",
      "Brier-Score: 0.1599712301537721\n",
      "Confusion-Matrix:\n",
      "[[652  22]\n",
      " [167  44]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_fdp, post_reduced_fdp, post_common_fdp,lag, social_media_usage_fdp)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - FDP\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_fdp.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486164\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      954\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09588\n",
      "Time:                        18:29:27   Log-Likelihood:                -474.01\n",
      "converged:                       True   LL-Null:                       -524.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.009e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5522      0.511     -1.082      0.279      -1.553       0.448\n",
      "issue attention Facebook      2.0246      0.893      2.268      0.023       0.275       3.774\n",
      "issue attention Bundestag     0.4642      0.929      0.499      0.617      -1.357       2.286\n",
      "Social Media Nutzung         -0.0311      0.044     -0.703      0.482      -0.118       0.056\n",
      "Landtagswahlen                0.3124      0.156      1.999      0.046       0.006       0.619\n",
      "Komplexit√§t Reden            -0.0927      0.084     -1.098      0.272      -0.258       0.073\n",
      "Komplexit√§t Posts             0.0734      0.182      0.403      0.687      -0.283       0.430\n",
      "topic_1                       1.0929      0.374      2.925      0.003       0.361       1.825\n",
      "topic_2                      -0.2688      0.382     -0.704      0.481      -1.017       0.479\n",
      "topic_3                      -1.1365      0.447     -2.541      0.011      -2.013      -0.260\n",
      "topic_4                      -1.4135      0.482     -2.933      0.003      -2.358      -0.469\n",
      "topic_6                      -0.0258      0.373     -0.069      0.945      -0.757       0.705\n",
      "topic_7                      -0.9246      0.425     -2.177      0.030      -1.757      -0.092\n",
      "topic_8                      -1.0060      0.436     -2.310      0.021      -1.860      -0.152\n",
      "topic_10                     -0.4137      0.387     -1.069      0.285      -1.172       0.345\n",
      "topic_14                     -1.1319      0.448     -2.526      0.012      -2.010      -0.254\n",
      "topic_15                     -0.6387      0.404     -1.582      0.114      -1.430       0.152\n",
      "topic_22                     -1.1211      0.449     -2.499      0.012      -2.001      -0.242\n",
      "topic_23                     -1.0461      0.436     -2.398      0.016      -1.901      -0.191\n",
      "topic_34                     -0.9258      0.426     -2.175      0.030      -1.760      -0.091\n",
      "topic_43                     -1.0358      0.436     -2.374      0.018      -1.891      -0.181\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7014776738860796\n",
      "Pr√§zision: 0.6417910447761194\n",
      "Recall: 0.19282511210762332\n",
      "F1-Score: 0.296551724137931\n",
      "Brier-Score: 0.1563796601995902\n",
      "Confusion-Matrix:\n",
      "[[728  24]\n",
      " [180  43]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.492283\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  960\n",
      "Model:                          Logit   Df Residuals:                      939\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08968\n",
      "Time:                        18:29:27   Log-Likelihood:                -472.59\n",
      "converged:                       True   LL-Null:                       -519.15\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.101e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.3405      0.494     -2.713      0.007      -2.309      -0.372\n",
      "issue attention Facebook     -0.4015      0.984     -0.408      0.683      -2.330       1.527\n",
      "issue attention Bundestag     1.7845      0.959      1.861      0.063      -0.095       3.664\n",
      "Social Media Nutzung          0.0655      0.042      1.557      0.119      -0.017       0.148\n",
      "Landtagswahlen                0.1833      0.164      1.119      0.263      -0.138       0.505\n",
      "Komplexit√§t Reden            -0.0034      0.083     -0.041      0.968      -0.166       0.159\n",
      "Komplexit√§t Posts            -0.1836      0.168     -1.095      0.274      -0.512       0.145\n",
      "topic_1                       1.1554      0.376      3.076      0.002       0.419       1.892\n",
      "topic_2                      -0.3182      0.381     -0.835      0.404      -1.065       0.429\n",
      "topic_3                      -1.2299      0.448     -2.747      0.006      -2.107      -0.352\n",
      "topic_4                      -1.4716      0.482     -3.051      0.002      -2.417      -0.526\n",
      "topic_6                      -0.0321      0.373     -0.086      0.932      -0.764       0.700\n",
      "topic_7                      -0.9936      0.425     -2.339      0.019      -1.826      -0.161\n",
      "topic_8                      -1.0886      0.436     -2.498      0.012      -1.943      -0.235\n",
      "topic_10                     -0.4584      0.388     -1.181      0.238      -1.219       0.303\n",
      "topic_14                     -1.1913      0.449     -2.655      0.008      -2.071      -0.312\n",
      "topic_15                     -0.6186      0.404     -1.532      0.125      -1.410       0.173\n",
      "topic_22                     -1.1763      0.449     -2.619      0.009      -2.057      -0.296\n",
      "topic_23                     -1.0378      0.436     -2.379      0.017      -1.893      -0.183\n",
      "topic_34                     -0.9328      0.426     -2.191      0.028      -1.767      -0.098\n",
      "topic_43                     -1.0416      0.436     -2.387      0.017      -1.897      -0.186\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.685911521277375\n",
      "Pr√§zision: 0.6323529411764706\n",
      "Recall: 0.19369369369369369\n",
      "F1-Score: 0.296551724137931\n",
      "Brier-Score: 0.15844801483941817\n",
      "Confusion-Matrix:\n",
      "[[713  25]\n",
      " [179  43]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496043\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  945\n",
      "Model:                          Logit   Df Residuals:                      924\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08374\n",
      "Time:                        18:29:28   Log-Likelihood:                -468.76\n",
      "converged:                       True   LL-Null:                       -511.60\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.174e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.8844      0.505     -1.750      0.080      -1.875       0.106\n",
      "issue attention Facebook     -0.4185      0.974     -0.430      0.667      -2.328       1.491\n",
      "issue attention Bundestag     0.8118      0.966      0.840      0.401      -1.081       2.705\n",
      "Social Media Nutzung          0.0269      0.044      0.618      0.537      -0.058       0.112\n",
      "Landtagswahlen                0.2048      0.188      1.088      0.277      -0.164       0.574\n",
      "Komplexit√§t Reden             0.0035      0.084      0.042      0.967      -0.161       0.168\n",
      "Komplexit√§t Posts            -0.1514      0.174     -0.868      0.385      -0.493       0.190\n",
      "topic_1                       1.1187      0.376      2.979      0.003       0.383       1.855\n",
      "topic_2                      -0.3808      0.384     -0.992      0.321      -1.133       0.371\n",
      "topic_3                      -1.3844      0.462     -2.994      0.003      -2.291      -0.478\n",
      "topic_4                      -1.5148      0.482     -3.142      0.002      -2.460      -0.570\n",
      "topic_6                      -0.0564      0.373     -0.151      0.880      -0.788       0.676\n",
      "topic_7                      -1.0076      0.425     -2.373      0.018      -1.840      -0.175\n",
      "topic_8                      -1.1162      0.436     -2.561      0.010      -1.970      -0.262\n",
      "topic_10                     -0.4503      0.387     -1.163      0.245      -1.209       0.309\n",
      "topic_14                     -1.2246      0.449     -2.730      0.006      -2.104      -0.345\n",
      "topic_15                     -0.6694      0.404     -1.658      0.097      -1.461       0.122\n",
      "topic_22                     -1.2239      0.449     -2.725      0.006      -2.104      -0.344\n",
      "topic_23                     -1.0882      0.436     -2.495      0.013      -1.943      -0.233\n",
      "topic_34                     -0.9789      0.426     -2.300      0.021      -1.813      -0.145\n",
      "topic_43                     -1.0903      0.436     -2.499      0.012      -1.945      -0.235\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6794218649760368\n",
      "Pr√§zision: 0.6349206349206349\n",
      "Recall: 0.182648401826484\n",
      "F1-Score: 0.28368794326241137\n",
      "Brier-Score: 0.16009217278784518\n",
      "Confusion-Matrix:\n",
      "[[703  23]\n",
      " [179  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495553\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  930\n",
      "Model:                          Logit   Df Residuals:                      909\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.08784\n",
      "Time:                        18:29:28   Log-Likelihood:                -460.86\n",
      "converged:                       True   LL-Null:                       -505.24\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.221e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1038      0.507      0.205      0.838      -0.890       1.097\n",
      "issue attention Facebook     -1.5979      1.048     -1.525      0.127      -3.652       0.456\n",
      "issue attention Bundestag     0.2457      0.986      0.249      0.803      -1.688       2.179\n",
      "Social Media Nutzung         -0.0546      0.044     -1.233      0.217      -0.141       0.032\n",
      "Landtagswahlen               -0.1779      0.223     -0.799      0.424      -0.614       0.259\n",
      "Komplexit√§t Reden            -0.0107      0.084     -0.127      0.899      -0.176       0.154\n",
      "Komplexit√§t Posts             0.2311      0.174      1.331      0.183      -0.109       0.571\n",
      "topic_1                       1.2270      0.383      3.207      0.001       0.477       1.977\n",
      "topic_2                      -0.4794      0.389     -1.231      0.218      -1.243       0.284\n",
      "topic_3                      -1.4494      0.464     -3.123      0.002      -2.359      -0.540\n",
      "topic_4                      -1.5958      0.484     -3.299      0.001      -2.544      -0.648\n",
      "topic_6                      -0.0883      0.376     -0.235      0.814      -0.825       0.648\n",
      "topic_7                      -1.0619      0.427     -2.489      0.013      -1.898      -0.226\n",
      "topic_8                      -1.1908      0.438     -2.721      0.007      -2.049      -0.333\n",
      "topic_10                     -0.4724      0.389     -1.214      0.225      -1.235       0.290\n",
      "topic_14                     -1.3063      0.451     -2.899      0.004      -2.189      -0.423\n",
      "topic_15                     -0.7279      0.406     -1.792      0.073      -1.524       0.068\n",
      "topic_22                     -1.3086      0.451     -2.903      0.004      -2.192      -0.425\n",
      "topic_23                     -1.1550      0.438     -2.635      0.008      -2.014      -0.296\n",
      "topic_34                     -1.1581      0.438     -2.646      0.008      -2.016      -0.300\n",
      "topic_43                     -1.1640      0.439     -2.653      0.008      -2.024      -0.304\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.685627678207871\n",
      "Pr√§zision: 0.6557377049180327\n",
      "Recall: 0.18433179723502305\n",
      "F1-Score: 0.28776978417266186\n",
      "Brier-Score: 0.15973311846659516\n",
      "Confusion-Matrix:\n",
      "[[692  21]\n",
      " [177  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.493633\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  915\n",
      "Model:                          Logit   Df Residuals:                      894\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09246\n",
      "Time:                        18:29:28   Log-Likelihood:                -451.67\n",
      "converged:                       True   LL-Null:                       -497.69\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.268e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5277      0.492     -1.073      0.283      -1.492       0.436\n",
      "issue attention Facebook     -1.2140      1.048     -1.159      0.247      -3.268       0.840\n",
      "issue attention Bundestag     0.0458      1.000      0.046      0.963      -1.914       2.006\n",
      "Social Media Nutzung          0.0174      0.042      0.418      0.676      -0.064       0.099\n",
      "Landtagswahlen               -0.3459      0.226     -1.532      0.125      -0.788       0.097\n",
      "Komplexit√§t Reden            -0.0096      0.085     -0.113      0.910      -0.176       0.156\n",
      "Komplexit√§t Posts             0.1001      0.172      0.583      0.560      -0.236       0.437\n",
      "topic_1                       1.2315      0.386      3.188      0.001       0.474       1.989\n",
      "topic_2                      -0.5598      0.395     -1.416      0.157      -1.335       0.215\n",
      "topic_3                      -1.4473      0.466     -3.107      0.002      -2.360      -0.534\n",
      "topic_4                      -1.7736      0.509     -3.484      0.000      -2.771      -0.776\n",
      "topic_6                      -0.0905      0.378     -0.239      0.811      -0.832       0.651\n",
      "topic_7                      -1.0625      0.428     -2.480      0.013      -1.902      -0.223\n",
      "topic_8                      -1.1877      0.439     -2.703      0.007      -2.049      -0.327\n",
      "topic_10                     -0.5572      0.395     -1.409      0.159      -1.332       0.218\n",
      "topic_14                     -1.3129      0.453     -2.901      0.004      -2.200      -0.426\n",
      "topic_15                     -0.7359      0.408     -1.803      0.071      -1.536       0.064\n",
      "topic_22                     -1.3113      0.453     -2.897      0.004      -2.198      -0.424\n",
      "topic_23                     -1.1651      0.440     -2.646      0.008      -2.028      -0.302\n",
      "topic_34                     -1.1666      0.440     -2.654      0.008      -2.028      -0.305\n",
      "topic_43                     -1.1712      0.440     -2.659      0.008      -2.034      -0.308\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6858226565520552\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.18691588785046728\n",
      "F1-Score: 0.291970802919708\n",
      "Brier-Score: 0.15915997754696548\n",
      "Confusion-Matrix:\n",
      "[[681  20]\n",
      " [174  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.494771\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      879\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09366\n",
      "Time:                        18:29:28   Log-Likelihood:                -445.29\n",
      "converged:                       True   LL-Null:                       -491.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.257e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6201      0.498     -1.246      0.213      -1.596       0.355\n",
      "issue attention Facebook      0.9812      0.956      1.027      0.305      -0.892       2.854\n",
      "issue attention Bundestag    -1.0106      1.030     -0.981      0.326      -3.029       1.008\n",
      "Social Media Nutzung          0.0222      0.043      0.522      0.602      -0.061       0.106\n",
      "Landtagswahlen               -0.3017      0.228     -1.324      0.186      -0.748       0.145\n",
      "Komplexit√§t Reden            -0.0046      0.086     -0.054      0.957      -0.174       0.165\n",
      "Komplexit√§t Posts            -0.0039      0.175     -0.022      0.982      -0.346       0.338\n",
      "topic_1                       1.1457      0.386      2.966      0.003       0.389       1.903\n",
      "topic_2                      -0.5160      0.396     -1.302      0.193      -1.293       0.261\n",
      "topic_3                      -1.3747      0.466     -2.947      0.003      -2.289      -0.460\n",
      "topic_4                      -1.7252      0.510     -3.385      0.001      -2.724      -0.726\n",
      "topic_6                      -0.0789      0.380     -0.208      0.835      -0.823       0.665\n",
      "topic_7                      -1.0008      0.429     -2.332      0.020      -1.842      -0.160\n",
      "topic_8                      -1.2435      0.453     -2.747      0.006      -2.131      -0.356\n",
      "topic_10                     -0.5257      0.396     -1.327      0.185      -1.302       0.251\n",
      "topic_14                     -1.2603      0.453     -2.781      0.005      -2.149      -0.372\n",
      "topic_15                     -0.8440      0.415     -2.035      0.042      -1.657      -0.031\n",
      "topic_22                     -1.2611      0.454     -2.780      0.005      -2.150      -0.372\n",
      "topic_23                     -1.1653      0.441     -2.644      0.008      -2.029      -0.302\n",
      "topic_34                     -1.1563      0.440     -2.628      0.009      -2.019      -0.294\n",
      "topic_43                     -1.1584      0.441     -2.629      0.009      -2.022      -0.295\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6915519416410706\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.18867924528301888\n",
      "F1-Score: 0.29411764705882354\n",
      "Brier-Score: 0.1595508543977772\n",
      "Confusion-Matrix:\n",
      "[[668  20]\n",
      " [172  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495094\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  885\n",
      "Model:                          Logit   Df Residuals:                      864\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09860\n",
      "Time:                        18:29:28   Log-Likelihood:                -438.16\n",
      "converged:                       True   LL-Null:                       -486.09\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.898e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.8892      0.495     -1.795      0.073      -1.860       0.082\n",
      "issue attention Facebook      2.0949      0.927      2.260      0.024       0.278       3.912\n",
      "issue attention Bundestag    -0.7715      1.027     -0.751      0.453      -2.785       1.242\n",
      "Social Media Nutzung          0.0446      0.042      1.057      0.290      -0.038       0.127\n",
      "Landtagswahlen               -0.3113      0.229     -1.359      0.174      -0.760       0.138\n",
      "Komplexit√§t Reden            -0.0170      0.087     -0.195      0.846      -0.188       0.154\n",
      "Komplexit√§t Posts            -0.0855      0.176     -0.487      0.626      -0.429       0.258\n",
      "topic_1                       1.1195      0.391      2.860      0.004       0.352       1.887\n",
      "topic_2                      -0.4962      0.399     -1.243      0.214      -1.279       0.286\n",
      "topic_3                      -1.3300      0.469     -2.839      0.005      -2.248      -0.412\n",
      "topic_4                      -1.6746      0.512     -3.274      0.001      -2.677      -0.672\n",
      "topic_6                      -0.1264      0.385     -0.329      0.742      -0.880       0.627\n",
      "topic_7                      -0.9627      0.431     -2.232      0.026      -1.808      -0.117\n",
      "topic_8                      -1.1887      0.455     -2.614      0.009      -2.080      -0.297\n",
      "topic_10                     -0.5125      0.399     -1.284      0.199      -1.295       0.270\n",
      "topic_14                     -1.2045      0.455     -2.646      0.008      -2.097      -0.312\n",
      "topic_15                     -0.8221      0.418     -1.968      0.049      -1.641      -0.004\n",
      "topic_22                     -1.1995      0.456     -2.632      0.008      -2.093      -0.306\n",
      "topic_23                     -1.1343      0.444     -2.556      0.011      -2.004      -0.265\n",
      "topic_34                     -1.1297      0.443     -2.552      0.011      -1.997      -0.262\n",
      "topic_43                     -1.1253      0.444     -2.536      0.011      -1.995      -0.256\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6964644831029294\n",
      "Pr√§zision: 0.671875\n",
      "Recall: 0.2037914691943128\n",
      "F1-Score: 0.31272727272727274\n",
      "Brier-Score: 0.15996630794207758\n",
      "Confusion-Matrix:\n",
      "[[653  21]\n",
      " [168  43]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_fdp, post_reduced_fdp, post_common_fdp,lag, social_media_usage_fdp, rede_komplex_fdp, posts_komplex_fdp)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - FDP\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_fdp_complex.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vergleiche der beiden Modelle mit unterschiedlichen Zielvariablen √ºber die Lags hinweg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534749\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      954\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1025\n",
      "Time:                        10:58:40   Log-Likelihood:                -521.38\n",
      "converged:                       True   LL-Null:                       -580.94\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.149e-16\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9291      0.473     -1.963      0.050      -1.857      -0.001\n",
      "issue attention Facebook      1.6040      0.887      1.808      0.071      -0.134       3.342\n",
      "issue attention Bundestag    -0.9213      0.880     -1.047      0.295      -2.646       0.803\n",
      "Social Media Nutzung          0.0644      0.040      1.615      0.106      -0.014       0.143\n",
      "Landtagswahlen                0.1502      0.151      0.995      0.320      -0.146       0.446\n",
      "Komplexit√§t Reden            -0.1766      0.081     -2.194      0.028      -0.334      -0.019\n",
      "Komplexit√§t Posts            -0.3950      0.171     -2.307      0.021      -0.731      -0.059\n",
      "topic_1                       0.0445      0.361      0.123      0.902      -0.663       0.752\n",
      "topic_2                       0.3596      0.357      1.007      0.314      -0.340       1.060\n",
      "topic_3                      -0.4770      0.370     -1.291      0.197      -1.201       0.247\n",
      "topic_4                      -1.5958      0.443     -3.605      0.000      -2.464      -0.728\n",
      "topic_6                      -0.6795      0.374     -1.817      0.069      -1.413       0.054\n",
      "topic_7                       0.0452      0.358      0.126      0.900      -0.656       0.746\n",
      "topic_8                      -0.9546      0.392     -2.438      0.015      -1.722      -0.187\n",
      "topic_10                      0.1495      0.356      0.420      0.674      -0.548       0.847\n",
      "topic_14                     -1.1525      0.404     -2.855      0.004      -1.944      -0.361\n",
      "topic_15                     -1.6493      0.442     -3.728      0.000      -2.517      -0.782\n",
      "topic_22                     -1.4716      0.431     -3.417      0.001      -2.316      -0.628\n",
      "topic_23                     -1.7790      0.458     -3.886      0.000      -2.676      -0.882\n",
      "topic_34                     -1.3941      0.420     -3.321      0.001      -2.217      -0.571\n",
      "topic_43                     -1.9203      0.476     -4.031      0.000      -2.854      -0.987\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7168314984138832\n",
      "Pr√§zision: 0.576271186440678\n",
      "Recall: 0.2463768115942029\n",
      "F1-Score: 0.34517766497461927\n",
      "Brier-Score: 0.17838251691503612\n",
      "Confusion-Matrix:\n",
      "[[649  50]\n",
      " [208  68]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486164\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      954\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.09588\n",
      "Time:                        10:58:40   Log-Likelihood:                -474.01\n",
      "converged:                       True   LL-Null:                       -524.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.009e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5522      0.511     -1.082      0.279      -1.553       0.448\n",
      "issue attention Facebook      2.0246      0.893      2.268      0.023       0.275       3.774\n",
      "issue attention Bundestag     0.4642      0.929      0.499      0.617      -1.357       2.286\n",
      "Social Media Nutzung         -0.0311      0.044     -0.703      0.482      -0.118       0.056\n",
      "Landtagswahlen                0.3124      0.156      1.999      0.046       0.006       0.619\n",
      "Komplexit√§t Reden            -0.0927      0.084     -1.098      0.272      -0.258       0.073\n",
      "Komplexit√§t Posts             0.0734      0.182      0.403      0.687      -0.283       0.430\n",
      "topic_1                       1.0929      0.374      2.925      0.003       0.361       1.825\n",
      "topic_2                      -0.2688      0.382     -0.704      0.481      -1.017       0.479\n",
      "topic_3                      -1.1365      0.447     -2.541      0.011      -2.013      -0.260\n",
      "topic_4                      -1.4135      0.482     -2.933      0.003      -2.358      -0.469\n",
      "topic_6                      -0.0258      0.373     -0.069      0.945      -0.757       0.705\n",
      "topic_7                      -0.9246      0.425     -2.177      0.030      -1.757      -0.092\n",
      "topic_8                      -1.0060      0.436     -2.310      0.021      -1.860      -0.152\n",
      "topic_10                     -0.4137      0.387     -1.069      0.285      -1.172       0.345\n",
      "topic_14                     -1.1319      0.448     -2.526      0.012      -2.010      -0.254\n",
      "topic_15                     -0.6387      0.404     -1.582      0.114      -1.430       0.152\n",
      "topic_22                     -1.1211      0.449     -2.499      0.012      -2.001      -0.242\n",
      "topic_23                     -1.0461      0.436     -2.398      0.016      -1.901      -0.191\n",
      "topic_34                     -0.9258      0.426     -2.175      0.030      -1.760      -0.091\n",
      "topic_43                     -1.0358      0.436     -2.374      0.018      -1.891      -0.181\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7014776738860796\n",
      "Pr√§zision: 0.6417910447761194\n",
      "Recall: 0.19282511210762332\n",
      "F1-Score: 0.296551724137931\n",
      "Brier-Score: 0.1563796601995902\n",
      "Confusion-Matrix:\n",
      "[[728  24]\n",
      " [180  43]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536560\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  960\n",
      "Model:                          Logit   Df Residuals:                      939\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.09690\n",
      "Time:                        10:58:40   Log-Likelihood:                -515.10\n",
      "converged:                       True   LL-Null:                       -570.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.569e-14\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1289      0.479      0.269      0.788      -0.810       1.068\n",
      "issue attention Facebook      0.2001      0.922      0.217      0.828      -1.608       2.008\n",
      "issue attention Bundestag     0.9544      0.885      1.078      0.281      -0.781       2.690\n",
      "Social Media Nutzung         -0.0469      0.041     -1.131      0.258      -0.128       0.034\n",
      "Landtagswahlen               -0.0274      0.160     -0.171      0.864      -0.342       0.287\n",
      "Komplexit√§t Reden            -0.1619      0.080     -2.014      0.044      -0.319      -0.004\n",
      "Komplexit√§t Posts             0.0862      0.160      0.539      0.590      -0.227       0.400\n",
      "topic_1                       0.0914      0.362      0.253      0.800      -0.617       0.800\n",
      "topic_2                       0.3083      0.358      0.862      0.389      -0.393       1.009\n",
      "topic_3                      -0.5198      0.373     -1.393      0.163      -1.251       0.211\n",
      "topic_4                      -1.6593      0.458     -3.621      0.000      -2.557      -0.761\n",
      "topic_6                      -0.5893      0.374     -1.574      0.115      -1.323       0.144\n",
      "topic_7                       0.0836      0.359      0.233      0.816      -0.620       0.787\n",
      "topic_8                      -0.9079      0.392     -2.315      0.021      -1.676      -0.139\n",
      "topic_10                      0.1921      0.357      0.538      0.590      -0.507       0.892\n",
      "topic_14                     -1.0787      0.404     -2.669      0.008      -1.871      -0.286\n",
      "topic_15                     -1.5178      0.442     -3.430      0.001      -2.385      -0.651\n",
      "topic_22                     -1.3950      0.431     -3.235      0.001      -2.240      -0.550\n",
      "topic_23                     -1.6562      0.458     -3.620      0.000      -2.553      -0.759\n",
      "topic_34                     -1.4001      0.430     -3.257      0.001      -2.243      -0.558\n",
      "topic_43                     -1.8062      0.477     -3.790      0.000      -2.740      -0.872\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.71\n",
      "Pr√§zision: 0.52\n",
      "Recall: 0.1925925925925926\n",
      "F1-Score: 0.2810810810810811\n",
      "Brier-Score: 0.17894072233185288\n",
      "Confusion-Matrix:\n",
      "[[642  48]\n",
      " [218  52]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.492283\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  960\n",
      "Model:                          Logit   Df Residuals:                      939\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.08968\n",
      "Time:                        10:58:40   Log-Likelihood:                -472.59\n",
      "converged:                       True   LL-Null:                       -519.15\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.101e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.3405      0.494     -2.713      0.007      -2.309      -0.372\n",
      "issue attention Facebook     -0.4015      0.984     -0.408      0.683      -2.330       1.527\n",
      "issue attention Bundestag     1.7845      0.959      1.861      0.063      -0.095       3.664\n",
      "Social Media Nutzung          0.0655      0.042      1.557      0.119      -0.017       0.148\n",
      "Landtagswahlen                0.1833      0.164      1.119      0.263      -0.138       0.505\n",
      "Komplexit√§t Reden            -0.0034      0.083     -0.041      0.968      -0.166       0.159\n",
      "Komplexit√§t Posts            -0.1836      0.168     -1.095      0.274      -0.512       0.145\n",
      "topic_1                       1.1554      0.376      3.076      0.002       0.419       1.892\n",
      "topic_2                      -0.3182      0.381     -0.835      0.404      -1.065       0.429\n",
      "topic_3                      -1.2299      0.448     -2.747      0.006      -2.107      -0.352\n",
      "topic_4                      -1.4716      0.482     -3.051      0.002      -2.417      -0.526\n",
      "topic_6                      -0.0321      0.373     -0.086      0.932      -0.764       0.700\n",
      "topic_7                      -0.9936      0.425     -2.339      0.019      -1.826      -0.161\n",
      "topic_8                      -1.0886      0.436     -2.498      0.012      -1.943      -0.235\n",
      "topic_10                     -0.4584      0.388     -1.181      0.238      -1.219       0.303\n",
      "topic_14                     -1.1913      0.449     -2.655      0.008      -2.071      -0.312\n",
      "topic_15                     -0.6186      0.404     -1.532      0.125      -1.410       0.173\n",
      "topic_22                     -1.1763      0.449     -2.619      0.009      -2.057      -0.296\n",
      "topic_23                     -1.0378      0.436     -2.379      0.017      -1.893      -0.183\n",
      "topic_34                     -0.9328      0.426     -2.191      0.028      -1.767      -0.098\n",
      "topic_43                     -1.0416      0.436     -2.387      0.017      -1.897      -0.186\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.685911521277375\n",
      "Pr√§zision: 0.6323529411764706\n",
      "Recall: 0.19369369369369369\n",
      "F1-Score: 0.296551724137931\n",
      "Brier-Score: 0.15844801483941817\n",
      "Confusion-Matrix:\n",
      "[[713  25]\n",
      " [179  43]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.524735\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  945\n",
      "Model:                          Logit   Df Residuals:                      924\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1126\n",
      "Time:                        10:58:40   Log-Likelihood:                -495.88\n",
      "converged:                       True   LL-Null:                       -558.82\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.285e-17\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.5394      0.510      1.058      0.290      -0.460       1.538\n",
      "issue attention Facebook      0.1756      0.935      0.188      0.851      -1.656       2.008\n",
      "issue attention Bundestag    -0.5178      0.925     -0.560      0.575      -2.330       1.295\n",
      "Social Media Nutzung         -0.0841      0.045     -1.853      0.064      -0.173       0.005\n",
      "Landtagswahlen                0.2081      0.183      1.137      0.256      -0.151       0.567\n",
      "Komplexit√§t Reden             0.3012      0.080      3.781      0.000       0.145       0.457\n",
      "Komplexit√§t Posts             0.3013      0.171      1.762      0.078      -0.034       0.636\n",
      "topic_1                       0.1325      0.367      0.361      0.718      -0.587       0.852\n",
      "topic_2                       0.2713      0.363      0.747      0.455      -0.440       0.983\n",
      "topic_3                      -0.5569      0.378     -1.474      0.140      -1.297       0.184\n",
      "topic_4                      -1.9098      0.481     -3.967      0.000      -2.854      -0.966\n",
      "topic_6                      -0.6432      0.379     -1.695      0.090      -1.387       0.100\n",
      "topic_7                      -0.0003      0.365     -0.001      0.999      -0.716       0.715\n",
      "topic_8                      -0.9686      0.397     -2.440      0.015      -1.747      -0.190\n",
      "topic_10                      0.1320      0.363      0.363      0.716      -0.580       0.844\n",
      "topic_14                     -1.1649      0.409     -2.846      0.004      -1.967      -0.363\n",
      "topic_15                     -1.7626      0.462     -3.816      0.000      -2.668      -0.857\n",
      "topic_22                     -1.6192      0.448     -3.613      0.000      -2.498      -0.741\n",
      "topic_23                     -1.7623      0.462     -3.813      0.000      -2.668      -0.856\n",
      "topic_34                     -1.6203      0.447     -3.624      0.000      -2.497      -0.744\n",
      "topic_43                     -1.9154      0.481     -3.983      0.000      -2.858      -0.973\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.726235741444867\n",
      "Pr√§zision: 0.6\n",
      "Recall: 0.2623574144486692\n",
      "F1-Score: 0.36507936507936506\n",
      "Brier-Score: 0.17374928918115196\n",
      "Confusion-Matrix:\n",
      "[[636  46]\n",
      " [194  69]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496043\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  945\n",
      "Model:                          Logit   Df Residuals:                      924\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.08374\n",
      "Time:                        10:58:40   Log-Likelihood:                -468.76\n",
      "converged:                       True   LL-Null:                       -511.60\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.174e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.8844      0.505     -1.750      0.080      -1.875       0.106\n",
      "issue attention Facebook     -0.4185      0.974     -0.430      0.667      -2.328       1.491\n",
      "issue attention Bundestag     0.8118      0.966      0.840      0.401      -1.081       2.705\n",
      "Social Media Nutzung          0.0269      0.044      0.618      0.537      -0.058       0.112\n",
      "Landtagswahlen                0.2048      0.188      1.088      0.277      -0.164       0.574\n",
      "Komplexit√§t Reden             0.0035      0.084      0.042      0.967      -0.161       0.168\n",
      "Komplexit√§t Posts            -0.1514      0.174     -0.868      0.385      -0.493       0.190\n",
      "topic_1                       1.1187      0.376      2.979      0.003       0.383       1.855\n",
      "topic_2                      -0.3808      0.384     -0.992      0.321      -1.133       0.371\n",
      "topic_3                      -1.3844      0.462     -2.994      0.003      -2.291      -0.478\n",
      "topic_4                      -1.5148      0.482     -3.142      0.002      -2.460      -0.570\n",
      "topic_6                      -0.0564      0.373     -0.151      0.880      -0.788       0.676\n",
      "topic_7                      -1.0076      0.425     -2.373      0.018      -1.840      -0.175\n",
      "topic_8                      -1.1162      0.436     -2.561      0.010      -1.970      -0.262\n",
      "topic_10                     -0.4503      0.387     -1.163      0.245      -1.209       0.309\n",
      "topic_14                     -1.2246      0.449     -2.730      0.006      -2.104      -0.345\n",
      "topic_15                     -0.6694      0.404     -1.658      0.097      -1.461       0.122\n",
      "topic_22                     -1.2239      0.449     -2.725      0.006      -2.104      -0.344\n",
      "topic_23                     -1.0882      0.436     -2.495      0.013      -1.943      -0.233\n",
      "topic_34                     -0.9789      0.426     -2.300      0.021      -1.813      -0.145\n",
      "topic_43                     -1.0903      0.436     -2.499      0.012      -1.945      -0.235\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6794218649760368\n",
      "Pr√§zision: 0.6349206349206349\n",
      "Recall: 0.182648401826484\n",
      "F1-Score: 0.28368794326241137\n",
      "Brier-Score: 0.16009217278784518\n",
      "Confusion-Matrix:\n",
      "[[703  23]\n",
      " [179  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535776\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  930\n",
      "Model:                          Logit   Df Residuals:                      909\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.09735\n",
      "Time:                        10:58:40   Log-Likelihood:                -498.27\n",
      "converged:                       True   LL-Null:                       -552.01\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.641e-14\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3274      0.483     -0.679      0.497      -1.273       0.618\n",
      "issue attention Facebook     -0.5422      0.964     -0.563      0.574      -2.431       1.347\n",
      "issue attention Bundestag    -0.0640      0.917     -0.070      0.944      -1.860       1.732\n",
      "Social Media Nutzung          0.0160      0.041      0.385      0.700      -0.065       0.097\n",
      "Landtagswahlen                0.0844      0.208      0.405      0.685      -0.324       0.493\n",
      "Komplexit√§t Reden            -0.0170      0.080     -0.211      0.832      -0.174       0.140\n",
      "Komplexit√§t Posts            -0.1697      0.166     -1.019      0.308      -0.496       0.157\n",
      "topic_1                       0.0986      0.366      0.270      0.788      -0.618       0.815\n",
      "topic_2                       0.2494      0.361      0.690      0.490      -0.459       0.958\n",
      "topic_3                      -0.6482      0.378     -1.714      0.087      -1.390       0.093\n",
      "topic_4                      -1.8983      0.479     -3.963      0.000      -2.837      -0.959\n",
      "topic_6                      -0.6341      0.377     -1.682      0.093      -1.373       0.105\n",
      "topic_7                      -0.0198      0.363     -0.055      0.957      -0.732       0.692\n",
      "topic_8                      -0.9771      0.395     -2.476      0.013      -1.750      -0.204\n",
      "topic_10                      0.1215      0.361      0.336      0.737      -0.586       0.829\n",
      "topic_14                     -1.1615      0.407     -2.854      0.004      -1.959      -0.364\n",
      "topic_15                     -1.7328      0.460     -3.770      0.000      -2.634      -0.832\n",
      "topic_22                     -1.6107      0.446     -3.613      0.000      -2.485      -0.737\n",
      "topic_23                     -1.7357      0.460     -3.775      0.000      -2.637      -0.835\n",
      "topic_34                     -1.6001      0.444     -3.600      0.000      -2.471      -0.729\n",
      "topic_43                     -1.8908      0.479     -3.949      0.000      -2.829      -0.952\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.711601349300437\n",
      "Pr√§zision: 0.5316455696202531\n",
      "Recall: 0.16091954022988506\n",
      "F1-Score: 0.24705882352941178\n",
      "Brier-Score: 0.1792145933363979\n",
      "Confusion-Matrix:\n",
      "[[632  37]\n",
      " [219  42]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495553\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  930\n",
      "Model:                          Logit   Df Residuals:                      909\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.08784\n",
      "Time:                        10:58:40   Log-Likelihood:                -460.86\n",
      "converged:                       True   LL-Null:                       -505.24\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.221e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1038      0.507      0.205      0.838      -0.890       1.097\n",
      "issue attention Facebook     -1.5979      1.048     -1.525      0.127      -3.652       0.456\n",
      "issue attention Bundestag     0.2457      0.986      0.249      0.803      -1.688       2.179\n",
      "Social Media Nutzung         -0.0546      0.044     -1.233      0.217      -0.141       0.032\n",
      "Landtagswahlen               -0.1779      0.223     -0.799      0.424      -0.614       0.259\n",
      "Komplexit√§t Reden            -0.0107      0.084     -0.127      0.899      -0.176       0.154\n",
      "Komplexit√§t Posts             0.2311      0.174      1.331      0.183      -0.109       0.571\n",
      "topic_1                       1.2270      0.383      3.207      0.001       0.477       1.977\n",
      "topic_2                      -0.4794      0.389     -1.231      0.218      -1.243       0.284\n",
      "topic_3                      -1.4494      0.464     -3.123      0.002      -2.359      -0.540\n",
      "topic_4                      -1.5958      0.484     -3.299      0.001      -2.544      -0.648\n",
      "topic_6                      -0.0883      0.376     -0.235      0.814      -0.825       0.648\n",
      "topic_7                      -1.0619      0.427     -2.489      0.013      -1.898      -0.226\n",
      "topic_8                      -1.1908      0.438     -2.721      0.007      -2.049      -0.333\n",
      "topic_10                     -0.4724      0.389     -1.214      0.225      -1.235       0.290\n",
      "topic_14                     -1.3063      0.451     -2.899      0.004      -2.189      -0.423\n",
      "topic_15                     -0.7279      0.406     -1.792      0.073      -1.524       0.068\n",
      "topic_22                     -1.3086      0.451     -2.903      0.004      -2.192      -0.425\n",
      "topic_23                     -1.1550      0.438     -2.635      0.008      -2.014      -0.296\n",
      "topic_34                     -1.1581      0.438     -2.646      0.008      -2.016      -0.300\n",
      "topic_43                     -1.1640      0.439     -2.653      0.008      -2.024      -0.304\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.685627678207871\n",
      "Pr√§zision: 0.6557377049180327\n",
      "Recall: 0.18433179723502305\n",
      "F1-Score: 0.28776978417266186\n",
      "Brier-Score: 0.15973311846659516\n",
      "Confusion-Matrix:\n",
      "[[692  21]\n",
      " [177  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.521964\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  915\n",
      "Model:                          Logit   Df Residuals:                      894\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1194\n",
      "Time:                        10:58:40   Log-Likelihood:                -477.60\n",
      "converged:                       True   LL-Null:                       -542.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.771e-18\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1614      0.482      0.335      0.738      -0.783       1.106\n",
      "issue attention Facebook      0.0002      0.984      0.000      1.000      -1.929       1.929\n",
      "issue attention Bundestag    -0.8145      0.949     -0.859      0.391      -2.674       1.045\n",
      "Social Media Nutzung         -0.0336      0.041     -0.825      0.409      -0.114       0.046\n",
      "Landtagswahlen               -0.1369      0.210     -0.651      0.515      -0.549       0.275\n",
      "Komplexit√§t Reden            -0.3535      0.085     -4.158      0.000      -0.520      -0.187\n",
      "Komplexit√§t Posts             0.1778      0.166      1.073      0.283      -0.147       0.503\n",
      "topic_1                       0.0848      0.375      0.226      0.821      -0.650       0.820\n",
      "topic_2                       0.3444      0.370      0.930      0.353      -0.382       1.070\n",
      "topic_3                      -0.5930      0.387     -1.534      0.125      -1.351       0.165\n",
      "topic_4                      -1.8891      0.485     -3.891      0.000      -2.841      -0.938\n",
      "topic_6                      -0.6002      0.385     -1.559      0.119      -1.355       0.154\n",
      "topic_7                       0.0576      0.372      0.155      0.877      -0.672       0.787\n",
      "topic_8                      -0.9367      0.402     -2.327      0.020      -1.726      -0.148\n",
      "topic_10                      0.2038      0.370      0.551      0.582      -0.521       0.929\n",
      "topic_14                     -1.2441      0.422     -2.947      0.003      -2.072      -0.417\n",
      "topic_15                     -1.8980      0.485     -3.912      0.000      -2.849      -0.947\n",
      "topic_22                     -1.7353      0.467     -3.715      0.000      -2.651      -0.820\n",
      "topic_23                     -1.7428      0.467     -3.734      0.000      -2.657      -0.828\n",
      "topic_34                     -1.5980      0.451     -3.541      0.000      -2.482      -0.714\n",
      "topic_43                     -1.8939      0.485     -3.904      0.000      -2.845      -0.943\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7365148425644917\n",
      "Pr√§zision: 0.5939849624060151\n",
      "Recall: 0.30859375\n",
      "F1-Score: 0.40616966580976865\n",
      "Brier-Score: 0.17352198104699243\n",
      "Confusion-Matrix:\n",
      "[[605  54]\n",
      " [177  79]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.493633\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  915\n",
      "Model:                          Logit   Df Residuals:                      894\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.09246\n",
      "Time:                        10:58:41   Log-Likelihood:                -451.67\n",
      "converged:                       True   LL-Null:                       -497.69\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.268e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5277      0.492     -1.073      0.283      -1.492       0.436\n",
      "issue attention Facebook     -1.2140      1.048     -1.159      0.247      -3.268       0.840\n",
      "issue attention Bundestag     0.0458      1.000      0.046      0.963      -1.914       2.006\n",
      "Social Media Nutzung          0.0174      0.042      0.418      0.676      -0.064       0.099\n",
      "Landtagswahlen               -0.3459      0.226     -1.532      0.125      -0.788       0.097\n",
      "Komplexit√§t Reden            -0.0096      0.085     -0.113      0.910      -0.176       0.156\n",
      "Komplexit√§t Posts             0.1001      0.172      0.583      0.560      -0.236       0.437\n",
      "topic_1                       1.2315      0.386      3.188      0.001       0.474       1.989\n",
      "topic_2                      -0.5598      0.395     -1.416      0.157      -1.335       0.215\n",
      "topic_3                      -1.4473      0.466     -3.107      0.002      -2.360      -0.534\n",
      "topic_4                      -1.7736      0.509     -3.484      0.000      -2.771      -0.776\n",
      "topic_6                      -0.0905      0.378     -0.239      0.811      -0.832       0.651\n",
      "topic_7                      -1.0625      0.428     -2.480      0.013      -1.902      -0.223\n",
      "topic_8                      -1.1877      0.439     -2.703      0.007      -2.049      -0.327\n",
      "topic_10                     -0.5572      0.395     -1.409      0.159      -1.332       0.218\n",
      "topic_14                     -1.3129      0.453     -2.901      0.004      -2.200      -0.426\n",
      "topic_15                     -0.7359      0.408     -1.803      0.071      -1.536       0.064\n",
      "topic_22                     -1.3113      0.453     -2.897      0.004      -2.198      -0.424\n",
      "topic_23                     -1.1651      0.440     -2.646      0.008      -2.028      -0.302\n",
      "topic_34                     -1.1666      0.440     -2.654      0.008      -2.028      -0.305\n",
      "topic_43                     -1.1712      0.440     -2.659      0.008      -2.034      -0.308\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6858226565520552\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.18691588785046728\n",
      "F1-Score: 0.291970802919708\n",
      "Brier-Score: 0.15915997754696548\n",
      "Confusion-Matrix:\n",
      "[[681  20]\n",
      " [174  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.521304\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      879\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1161\n",
      "Time:                        10:58:41   Log-Likelihood:                -469.17\n",
      "converged:                       True   LL-Null:                       -530.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.103e-17\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1175      0.502      0.234      0.815      -0.866       1.100\n",
      "issue attention Facebook     -0.6763      1.000     -0.677      0.499      -2.636       1.283\n",
      "issue attention Bundestag    -0.0920      0.941     -0.098      0.922      -1.936       1.752\n",
      "Social Media Nutzung         -0.0352      0.044     -0.805      0.421      -0.121       0.050\n",
      "Landtagswahlen               -0.0563      0.215     -0.262      0.793      -0.477       0.364\n",
      "Komplexit√§t Reden             0.3286      0.082      4.020      0.000       0.168       0.489\n",
      "Komplexit√§t Posts             0.2219      0.172      1.293      0.196      -0.115       0.558\n",
      "topic_1                       0.1769      0.377      0.470      0.639      -0.561       0.915\n",
      "topic_2                       0.3321      0.373      0.891      0.373      -0.399       1.063\n",
      "topic_3                      -0.6242      0.391     -1.595      0.111      -1.391       0.143\n",
      "topic_4                      -2.0025      0.511     -3.919      0.000      -3.004      -1.001\n",
      "topic_6                      -0.6073      0.390     -1.558      0.119      -1.372       0.157\n",
      "topic_7                       0.1122      0.374      0.300      0.764      -0.621       0.846\n",
      "topic_8                      -0.9795      0.410     -2.390      0.017      -1.783      -0.176\n",
      "topic_10                      0.1972      0.372      0.530      0.596      -0.533       0.927\n",
      "topic_14                     -1.1796      0.424     -2.783      0.005      -2.010      -0.349\n",
      "topic_15                     -1.8105      0.486     -3.723      0.000      -2.764      -0.857\n",
      "topic_22                     -1.6746      0.469     -3.568      0.000      -2.594      -0.755\n",
      "topic_23                     -1.6624      0.469     -3.546      0.000      -2.581      -0.744\n",
      "topic_34                     -1.5256      0.454     -3.363      0.001      -2.415      -0.636\n",
      "topic_43                     -1.8174      0.487     -3.733      0.000      -2.772      -0.863\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7314974182444062\n",
      "Pr√§zision: 0.5980392156862745\n",
      "Recall: 0.24497991967871485\n",
      "F1-Score: 0.3475783475783476\n",
      "Brier-Score: 0.1729777528467521\n",
      "Confusion-Matrix:\n",
      "[[610  41]\n",
      " [188  61]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.494771\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      879\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.09366\n",
      "Time:                        10:58:41   Log-Likelihood:                -445.29\n",
      "converged:                       True   LL-Null:                       -491.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.257e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6201      0.498     -1.246      0.213      -1.596       0.355\n",
      "issue attention Facebook      0.9812      0.956      1.027      0.305      -0.892       2.854\n",
      "issue attention Bundestag    -1.0106      1.030     -0.981      0.326      -3.029       1.008\n",
      "Social Media Nutzung          0.0222      0.043      0.522      0.602      -0.061       0.106\n",
      "Landtagswahlen               -0.3017      0.228     -1.324      0.186      -0.748       0.145\n",
      "Komplexit√§t Reden            -0.0046      0.086     -0.054      0.957      -0.174       0.165\n",
      "Komplexit√§t Posts            -0.0039      0.175     -0.022      0.982      -0.346       0.338\n",
      "topic_1                       1.1457      0.386      2.966      0.003       0.389       1.903\n",
      "topic_2                      -0.5160      0.396     -1.302      0.193      -1.293       0.261\n",
      "topic_3                      -1.3747      0.466     -2.947      0.003      -2.289      -0.460\n",
      "topic_4                      -1.7252      0.510     -3.385      0.001      -2.724      -0.726\n",
      "topic_6                      -0.0789      0.380     -0.208      0.835      -0.823       0.665\n",
      "topic_7                      -1.0008      0.429     -2.332      0.020      -1.842      -0.160\n",
      "topic_8                      -1.2435      0.453     -2.747      0.006      -2.131      -0.356\n",
      "topic_10                     -0.5257      0.396     -1.327      0.185      -1.302       0.251\n",
      "topic_14                     -1.2603      0.453     -2.781      0.005      -2.149      -0.372\n",
      "topic_15                     -0.8440      0.415     -2.035      0.042      -1.657      -0.031\n",
      "topic_22                     -1.2611      0.454     -2.780      0.005      -2.150      -0.372\n",
      "topic_23                     -1.1653      0.441     -2.644      0.008      -2.029      -0.302\n",
      "topic_34                     -1.1563      0.440     -2.628      0.009      -2.019      -0.294\n",
      "topic_43                     -1.1584      0.441     -2.629      0.009      -2.022      -0.295\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6915519416410706\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.18867924528301888\n",
      "F1-Score: 0.29411764705882354\n",
      "Brier-Score: 0.1595508543977772\n",
      "Confusion-Matrix:\n",
      "[[668  20]\n",
      " [172  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.528141\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  885\n",
      "Model:                          Logit   Df Residuals:                      864\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1064\n",
      "Time:                        10:58:41   Log-Likelihood:                -467.40\n",
      "converged:                       True   LL-Null:                       -523.05\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.138e-14\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.0962      0.482     -2.272      0.023      -2.042      -0.151\n",
      "issue attention Facebook      1.2709      0.941      1.351      0.177      -0.573       3.115\n",
      "issue attention Bundestag    -1.4390      0.971     -1.482      0.138      -3.343       0.465\n",
      "Social Media Nutzung          0.0829      0.041      2.029      0.042       0.003       0.163\n",
      "Landtagswahlen                0.0715      0.211      0.339      0.734      -0.342       0.485\n",
      "Komplexit√§t Reden            -0.0706      0.083     -0.846      0.397      -0.234       0.093\n",
      "Komplexit√§t Posts            -0.3007      0.170     -1.771      0.077      -0.633       0.032\n",
      "topic_1                       0.1670      0.378      0.442      0.658      -0.573       0.907\n",
      "topic_2                       0.4500      0.374      1.202      0.229      -0.284       1.184\n",
      "topic_3                      -0.4841      0.392     -1.236      0.216      -1.251       0.283\n",
      "topic_4                      -1.8830      0.510     -3.693      0.000      -2.882      -0.884\n",
      "topic_6                      -0.6141      0.393     -1.561      0.118      -1.385       0.157\n",
      "topic_7                       0.2389      0.375      0.637      0.524      -0.496       0.974\n",
      "topic_8                      -0.8435      0.410     -2.059      0.039      -1.646      -0.041\n",
      "topic_10                      0.2309      0.373      0.618      0.536      -0.501       0.962\n",
      "topic_14                     -1.0662      0.423     -2.520      0.012      -1.896      -0.237\n",
      "topic_15                     -1.7578      0.486     -3.620      0.000      -2.710      -0.806\n",
      "topic_22                     -1.5535      0.469     -3.315      0.001      -2.472      -0.635\n",
      "topic_23                     -1.5930      0.468     -3.406      0.001      -2.510      -0.676\n",
      "topic_34                     -1.4465      0.452     -3.198      0.001      -2.333      -0.560\n",
      "topic_43                     -1.7387      0.486     -3.579      0.000      -2.691      -0.787\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7220377368092928\n",
      "Pr√§zision: 0.5268817204301075\n",
      "Recall: 0.1991869918699187\n",
      "F1-Score: 0.2890855457227139\n",
      "Brier-Score: 0.17572697959065012\n",
      "Confusion-Matrix:\n",
      "[[595  44]\n",
      " [197  49]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495094\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  885\n",
      "Model:                          Logit   Df Residuals:                      864\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.09860\n",
      "Time:                        10:58:41   Log-Likelihood:                -438.16\n",
      "converged:                       True   LL-Null:                       -486.09\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.898e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.8892      0.495     -1.795      0.073      -1.860       0.082\n",
      "issue attention Facebook      2.0949      0.927      2.260      0.024       0.278       3.912\n",
      "issue attention Bundestag    -0.7715      1.027     -0.751      0.453      -2.785       1.242\n",
      "Social Media Nutzung          0.0446      0.042      1.057      0.290      -0.038       0.127\n",
      "Landtagswahlen               -0.3113      0.229     -1.359      0.174      -0.760       0.138\n",
      "Komplexit√§t Reden            -0.0170      0.087     -0.195      0.846      -0.188       0.154\n",
      "Komplexit√§t Posts            -0.0855      0.176     -0.487      0.626      -0.429       0.258\n",
      "topic_1                       1.1195      0.391      2.860      0.004       0.352       1.887\n",
      "topic_2                      -0.4962      0.399     -1.243      0.214      -1.279       0.286\n",
      "topic_3                      -1.3300      0.469     -2.839      0.005      -2.248      -0.412\n",
      "topic_4                      -1.6746      0.512     -3.274      0.001      -2.677      -0.672\n",
      "topic_6                      -0.1264      0.385     -0.329      0.742      -0.880       0.627\n",
      "topic_7                      -0.9627      0.431     -2.232      0.026      -1.808      -0.117\n",
      "topic_8                      -1.1887      0.455     -2.614      0.009      -2.080      -0.297\n",
      "topic_10                     -0.5125      0.399     -1.284      0.199      -1.295       0.270\n",
      "topic_14                     -1.2045      0.455     -2.646      0.008      -2.097      -0.312\n",
      "topic_15                     -0.8221      0.418     -1.968      0.049      -1.641      -0.004\n",
      "topic_22                     -1.1995      0.456     -2.632      0.008      -2.093      -0.306\n",
      "topic_23                     -1.1343      0.444     -2.556      0.011      -2.004      -0.265\n",
      "topic_34                     -1.1297      0.443     -2.552      0.011      -1.997      -0.262\n",
      "topic_43                     -1.1253      0.444     -2.536      0.011      -1.995      -0.256\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6964644831029294\n",
      "Pr√§zision: 0.671875\n",
      "Recall: 0.2037914691943128\n",
      "F1-Score: 0.31272727272727274\n",
      "Brier-Score: 0.15996630794207758\n",
      "Confusion-Matrix:\n",
      "[[653  21]\n",
      " [168  43]]\n"
     ]
    }
   ],
   "source": [
    "from stargazer.stargazer import Stargazer\n",
    "\n",
    "# Initialisiere eine Liste f√ºr Stargazer-Tabellen\n",
    "stargazer_tables = []\n",
    "partei= \"spd\"\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    # Modell 1: Zielvariable basiert auf rede_common_fdp\n",
    "    model1, auc_roc1, f1_1 = log_reg_FE_control_test(\n",
    "        rede_reduced_{partei}, post_reduced_spd, rede_common_spd, lag, social_media_usage_spd, rede_komplex_spd, posts_komplex_spd\n",
    "    )\n",
    "    \n",
    "    # Modell 2: Zielvariable basiert auf post_common_fdp\n",
    "    model2, auc_roc2, f1_2 = log_reg_FE_control_test(\n",
    "        rede_reduced_spd, post_reduced_spd, post_common_spd, lag, social_media_usage_fdp, rede_komplex_fdp, posts_komplex_fdp\n",
    "    )\n",
    "    \n",
    "    # Stargazer-Tabelle f√ºr den Vergleich der beiden Modelle\n",
    "    stargazer = Stargazer([model1, model2])\n",
    "    stargazer.title(f\" FDP Vergleich f√ºr Lag {lag}\")\n",
    "    stargazer.custom_columns(\n",
    "        [f\"Bundestag \", \n",
    "         f\"Facebook\"], \n",
    "        [1, 1]\n",
    "    )\n",
    "    stargazer.significant_digits(3)\n",
    "    stargazer.dependent_variable_name(\"Themenerw√§hnung FDP\")\n",
    "    \n",
    "    # AUC-ROC und F1-Score f√ºr beide Modelle als individuelle Notizen\n",
    "    custom_notes = [\n",
    "        f\"Modell 1 (Reden als Zielvariable): AUC-ROC = {auc_roc1:.3f}, F1-Score = {f1_1:.3f}\",\n",
    "        f\"Modell 2 (Posts als Zielvariable): AUC-ROC = {auc_roc2:.3f}, F1-Score = {f1_2:.3f}\"\n",
    "    ]\n",
    "    stargazer.add_custom_notes(custom_notes)\n",
    "    \n",
    "    # Exportiere jede Tabelle separat\n",
    "    filename = f\"regression tables/regression_table_comparison_fdp_lag_{lag}.html\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(stargazer.render_html())\n",
    "    \n",
    "    # Speichere die Tabelle in der Liste\n",
    "    stargazer_tables.append((lag, stargazer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539528\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2234\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1434\n",
      "Time:                        11:45:54   Log-Likelihood:                -1227.4\n",
      "converged:                       True   LL-Null:                       -1432.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.902e-63\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0505      0.524     -0.096      0.923      -1.077       0.976\n",
      "issue attention Facebook      7.8255      1.712      4.571      0.000       4.470      11.181\n",
      "issue attention Bundestag    -1.6928      0.907     -1.866      0.062      -3.470       0.085\n",
      "Social Media Nutzung          0.0049      0.007      0.724      0.469      -0.008       0.018\n",
      "Landtagswahlen               -0.0094      0.093     -0.101      0.920      -0.192       0.174\n",
      "Komplexit√§t Reden            -0.0078      0.051     -0.153      0.878      -0.108       0.092\n",
      "Komplexit√§t Posts            -0.1001      0.104     -0.962      0.336      -0.304       0.104\n",
      "topic_1                       0.1340      0.383      0.349      0.727      -0.618       0.886\n",
      "topic_2                       0.7879      0.405      1.946      0.052      -0.006       1.581\n",
      "topic_3                      -0.7922      0.369     -2.148      0.032      -1.515      -0.069\n",
      "topic_4                      -0.6138      0.371     -1.653      0.098      -1.341       0.114\n",
      "topic_6                      -0.1682      0.372     -0.452      0.651      -0.898       0.561\n",
      "topic_7                       1.2605      0.433      2.914      0.004       0.413       2.108\n",
      "topic_8                      -0.8261      0.378     -2.187      0.029      -1.566      -0.086\n",
      "topic_10                      0.1016      0.378      0.269      0.788      -0.639       0.843\n",
      "topic_11                     -2.2494      0.458     -4.916      0.000      -3.146      -1.353\n",
      "topic_12                     -1.7589      0.407     -4.325      0.000      -2.556      -0.962\n",
      "topic_13                     -2.2451      0.456     -4.925      0.000      -3.139      -1.352\n",
      "topic_14                     -0.6471      0.379     -1.706      0.088      -1.390       0.096\n",
      "topic_15                     -1.6347      0.406     -4.024      0.000      -2.431      -0.839\n",
      "topic_16                     -1.4651      0.398     -3.679      0.000      -2.246      -0.685\n",
      "topic_17                     -2.3438      0.472     -4.969      0.000      -3.268      -1.419\n",
      "topic_18                     -1.4932      0.405     -3.691      0.000      -2.286      -0.700\n",
      "topic_19                     -1.1070      0.389     -2.848      0.004      -1.869      -0.345\n",
      "topic_20                     -1.6195      0.409     -3.963      0.000      -2.421      -0.819\n",
      "topic_21                     -1.6926      0.413     -4.099      0.000      -2.502      -0.883\n",
      "topic_22                     -1.5539      0.409     -3.803      0.000      -2.355      -0.753\n",
      "topic_23                     -1.8007      0.429     -4.199      0.000      -2.641      -0.960\n",
      "topic_24                     -1.5250      0.409     -3.724      0.000      -2.328      -0.722\n",
      "topic_25                     -0.9761      0.388     -2.516      0.012      -1.736      -0.216\n",
      "topic_29                     -1.0228      0.391     -2.617      0.009      -1.789      -0.257\n",
      "topic_30                     -1.8795      0.438     -4.289      0.000      -2.738      -1.021\n",
      "topic_34                     -1.4262      0.406     -3.510      0.000      -2.222      -0.630\n",
      "topic_36                     -1.7615      0.430     -4.094      0.000      -2.605      -0.918\n",
      "topic_37                     -1.4820      0.412     -3.597      0.000      -2.290      -0.675\n",
      "topic_40                     -1.7793      0.430     -4.133      0.000      -2.623      -0.936\n",
      "topic_41                     -1.8804      0.440     -4.278      0.000      -2.742      -1.019\n",
      "topic_43                     -1.6745      0.423     -3.960      0.000      -2.503      -0.846\n",
      "topic_54                     -2.1027      0.461     -4.560      0.000      -3.006      -1.199\n",
      "topic_68                     -2.2396      0.476     -4.708      0.000      -3.172      -1.307\n",
      "topic_75                     -1.2451      0.401     -3.108      0.002      -2.030      -0.460\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7451058926904666\n",
      "Pr√§zision: 0.6814159292035398\n",
      "Recall: 0.417910447761194\n",
      "F1-Score: 0.5180824222035324\n",
      "Brier-Score: 0.17919927966397808\n",
      "Confusion-Matrix:\n",
      "[[1394  144]\n",
      " [ 429  308]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531963\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2234\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.2321\n",
      "Time:                        11:45:55   Log-Likelihood:                -1210.2\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                5.544e-128\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.9640      0.853      3.474      0.001       1.292       4.636\n",
      "issue attention Facebook     17.8797      2.495      7.166      0.000      12.989      22.770\n",
      "issue attention Bundestag     0.2034      1.100      0.185      0.853      -1.954       2.360\n",
      "Social Media Nutzung         -0.0088      0.007     -1.317      0.188      -0.022       0.004\n",
      "Landtagswahlen                0.0251      0.093      0.269      0.788      -0.158       0.208\n",
      "Komplexit√§t Reden             0.0782      0.051      1.541      0.123      -0.021       0.178\n",
      "Komplexit√§t Posts             0.1017      0.103      0.986      0.324      -0.100       0.304\n",
      "topic_1                       0.5719      1.243      0.460      0.646      -1.865       3.009\n",
      "topic_2                      -1.3852      0.806     -1.718      0.086      -2.965       0.195\n",
      "topic_3                      -0.9264      0.866     -1.070      0.285      -2.624       0.771\n",
      "topic_4                       0.0550      1.024      0.054      0.957      -1.952       2.062\n",
      "topic_6                      -1.5485      0.791     -1.958      0.050      -3.099       0.002\n",
      "topic_7                      -2.5263      0.771     -3.276      0.001      -4.038      -1.015\n",
      "topic_8                      -2.1628      0.773     -2.798      0.005      -3.678      -0.648\n",
      "topic_10                     -2.3594      0.771     -3.061      0.002      -3.870      -0.849\n",
      "topic_11                     -2.5599      0.773     -3.314      0.001      -4.074      -1.046\n",
      "topic_12                     -2.5351      0.775     -3.273      0.001      -4.053      -1.017\n",
      "topic_13                     -2.1448      0.775     -2.768      0.006      -3.663      -0.626\n",
      "topic_14                     -2.9686      0.772     -3.845      0.000      -4.482      -1.455\n",
      "topic_15                     -2.1168      0.775     -2.730      0.006      -3.637      -0.597\n",
      "topic_16                     -2.6350      0.772     -3.415      0.001      -4.147      -1.123\n",
      "topic_17                     -2.8526      0.772     -3.697      0.000      -4.365      -1.340\n",
      "topic_18                     -2.4579      0.772     -3.184      0.001      -3.971      -0.945\n",
      "topic_19                     -2.6413      0.772     -3.422      0.001      -4.154      -1.129\n",
      "topic_20                     -3.6015      0.782     -4.608      0.000      -5.133      -2.070\n",
      "topic_21                     -2.6181      0.772     -3.393      0.001      -4.130      -1.106\n",
      "topic_22                     -2.6215      0.772     -3.397      0.001      -4.134      -1.109\n",
      "topic_23                     -3.0582      0.774     -3.950      0.000      -4.576      -1.541\n",
      "topic_24                     -3.0894      0.774     -3.994      0.000      -4.606      -1.573\n",
      "topic_25                     -3.0505      0.774     -3.942      0.000      -4.567      -1.534\n",
      "topic_29                     -3.4992      0.782     -4.475      0.000      -5.032      -1.967\n",
      "topic_30                     -3.4206      0.780     -4.383      0.000      -4.950      -1.891\n",
      "topic_34                     -3.3082      0.778     -4.254      0.000      -4.833      -1.784\n",
      "topic_36                     -3.9038      0.795     -4.912      0.000      -5.461      -2.346\n",
      "topic_37                     -3.8975      0.795     -4.905      0.000      -5.455      -2.340\n",
      "topic_40                     -3.4868      0.783     -4.456      0.000      -5.020      -1.953\n",
      "topic_41                     -3.9915      0.799     -4.995      0.000      -5.558      -2.425\n",
      "topic_43                     -4.2714      0.810     -5.275      0.000      -5.859      -2.684\n",
      "topic_54                     -4.4563      0.824     -5.410      0.000      -6.071      -2.842\n",
      "topic_68                     -4.4618      0.824     -5.414      0.000      -6.077      -2.846\n",
      "topic_75                     -4.1049      0.804     -5.105      0.000      -5.681      -2.529\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.802870277561223\n",
      "Pr√§zision: 0.7438271604938271\n",
      "Recall: 0.6531165311653117\n",
      "F1-Score: 0.6955266955266955\n",
      "Brier-Score: 0.1799498314035293\n",
      "Confusion-Matrix:\n",
      "[[919 249]\n",
      " [384 723]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535685\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2240\n",
      "Model:                          Logit   Df Residuals:                     2199\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1505\n",
      "Time:                        11:45:55   Log-Likelihood:                -1199.9\n",
      "converged:                       True   LL-Null:                       -1412.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.257e-66\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.9281      0.531      1.747      0.081      -0.113       1.969\n",
      "issue attention Facebook      3.1203      1.719      1.815      0.070      -0.249       6.490\n",
      "issue attention Bundestag     1.6628      0.973      1.709      0.087      -0.244       3.570\n",
      "Social Media Nutzung         -0.0088      0.007     -1.286      0.199      -0.022       0.005\n",
      "Landtagswahlen               -0.2727      0.106     -2.577      0.010      -0.480      -0.065\n",
      "Komplexit√§t Reden            -0.2898      0.054     -5.409      0.000      -0.395      -0.185\n",
      "Komplexit√§t Posts             0.0343      0.103      0.334      0.738      -0.167       0.236\n",
      "topic_1                       0.2320      0.385      0.602      0.547      -0.523       0.988\n",
      "topic_2                       0.6116      0.405      1.509      0.131      -0.183       1.406\n",
      "topic_3                      -0.6816      0.371     -1.837      0.066      -1.409       0.046\n",
      "topic_4                      -0.4377      0.373     -1.175      0.240      -1.168       0.293\n",
      "topic_6                      -0.2135      0.376     -0.568      0.570      -0.951       0.524\n",
      "topic_7                       1.2531      0.446      2.813      0.005       0.380       2.126\n",
      "topic_8                      -0.8928      0.383     -2.332      0.020      -1.643      -0.142\n",
      "topic_10                      0.0255      0.384      0.066      0.947      -0.727       0.778\n",
      "topic_11                     -2.2097      0.461     -4.798      0.000      -3.112      -1.307\n",
      "topic_12                     -1.6296      0.408     -3.996      0.000      -2.429      -0.830\n",
      "topic_13                     -2.2323      0.459     -4.864      0.000      -3.132      -1.333\n",
      "topic_14                     -0.6998      0.385     -1.819      0.069      -1.454       0.054\n",
      "topic_15                     -1.6077      0.410     -3.926      0.000      -2.410      -0.805\n",
      "topic_16                     -1.4297      0.402     -3.558      0.000      -2.217      -0.642\n",
      "topic_17                     -2.3538      0.475     -4.957      0.000      -3.285      -1.423\n",
      "topic_18                     -1.4815      0.409     -3.626      0.000      -2.282      -0.681\n",
      "topic_19                     -1.1645      0.396     -2.944      0.003      -1.940      -0.389\n",
      "topic_20                     -1.6006      0.411     -3.899      0.000      -2.405      -0.796\n",
      "topic_21                     -1.7120      0.416     -4.112      0.000      -2.528      -0.896\n",
      "topic_22                     -1.5883      0.412     -3.852      0.000      -2.396      -0.780\n",
      "topic_23                     -1.8485      0.433     -4.270      0.000      -2.697      -1.000\n",
      "topic_24                     -1.5689      0.414     -3.792      0.000      -2.380      -0.758\n",
      "topic_25                     -1.0154      0.393     -2.585      0.010      -1.785      -0.246\n",
      "topic_29                     -1.0809      0.396     -2.731      0.006      -1.857      -0.305\n",
      "topic_30                     -1.9459      0.442     -4.399      0.000      -2.813      -1.079\n",
      "topic_34                     -1.5551      0.415     -3.745      0.000      -2.369      -0.741\n",
      "topic_36                     -1.8329      0.435     -4.216      0.000      -2.685      -0.981\n",
      "topic_37                     -1.5407      0.417     -3.697      0.000      -2.358      -0.724\n",
      "topic_40                     -1.8266      0.435     -4.203      0.000      -2.678      -0.975\n",
      "topic_41                     -1.9230      0.444     -4.333      0.000      -2.793      -1.053\n",
      "topic_43                     -1.7350      0.427     -4.062      0.000      -2.572      -0.898\n",
      "topic_54                     -2.3063      0.479     -4.811      0.000      -3.246      -1.367\n",
      "topic_68                     -2.3038      0.480     -4.804      0.000      -3.244      -1.364\n",
      "topic_75                     -1.2823      0.405     -3.163      0.002      -2.077      -0.488\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7490033940926797\n",
      "Pr√§zision: 0.6898876404494382\n",
      "Recall: 0.4217032967032967\n",
      "F1-Score: 0.5234441602728048\n",
      "Brier-Score: 0.17786030568890937\n",
      "Confusion-Matrix:\n",
      "[[1374  138]\n",
      " [ 421  307]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.528308\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2240\n",
      "Model:                          Logit   Df Residuals:                     2199\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.2374\n",
      "Time:                        11:45:55   Log-Likelihood:                -1183.4\n",
      "converged:                       True   LL-Null:                       -1551.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.883e-129\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         3.0671      0.856      3.584      0.000       1.390       4.744\n",
      "issue attention Facebook     16.0066      2.490      6.430      0.000      11.127      20.886\n",
      "issue attention Bundestag     3.5034      1.319      2.656      0.008       0.918       6.089\n",
      "Social Media Nutzung         -0.0125      0.007     -1.842      0.065      -0.026       0.001\n",
      "Landtagswahlen               -0.0544      0.102     -0.533      0.594      -0.254       0.145\n",
      "Komplexit√§t Reden            -0.1018      0.052     -1.970      0.049      -0.203      -0.001\n",
      "Komplexit√§t Posts             0.2238      0.102      2.205      0.027       0.025       0.423\n",
      "topic_1                       0.6573      1.243      0.529      0.597      -1.780       3.094\n",
      "topic_2                      -1.4113      0.808     -1.747      0.081      -2.994       0.172\n",
      "topic_3                      -0.8044      0.867     -0.928      0.353      -2.503       0.894\n",
      "topic_4                       0.2076      1.023      0.203      0.839      -1.798       2.214\n",
      "topic_6                      -1.3819      0.795     -1.738      0.082      -2.941       0.177\n",
      "topic_7                      -2.4791      0.773     -3.205      0.001      -3.995      -0.963\n",
      "topic_8                      -2.1088      0.775     -2.722      0.006      -3.627      -0.590\n",
      "topic_10                     -2.2954      0.773     -2.971      0.003      -3.810      -0.781\n",
      "topic_11                     -2.3398      0.774     -3.025      0.002      -3.856      -0.824\n",
      "topic_12                     -2.3066      0.775     -2.976      0.003      -3.826      -0.787\n",
      "topic_13                     -1.9602      0.776     -2.525      0.012      -3.482      -0.439\n",
      "topic_14                     -2.8362      0.774     -3.666      0.000      -4.352      -1.320\n",
      "topic_15                     -1.9163      0.777     -2.465      0.014      -3.440      -0.393\n",
      "topic_16                     -2.4407      0.773     -3.159      0.002      -3.955      -0.926\n",
      "topic_17                     -2.7419      0.773     -3.549      0.000      -4.256      -1.227\n",
      "topic_18                     -2.3270      0.773     -3.012      0.003      -3.841      -0.813\n",
      "topic_19                     -2.4469      0.773     -3.167      0.002      -3.961      -0.933\n",
      "topic_20                     -3.5221      0.784     -4.492      0.000      -5.059      -1.985\n",
      "topic_21                     -2.4390      0.774     -3.153      0.002      -3.955      -0.923\n",
      "topic_22                     -2.4652      0.773     -3.189      0.001      -3.980      -0.950\n",
      "topic_23                     -2.9664      0.776     -3.822      0.000      -4.488      -1.445\n",
      "topic_24                     -3.0121      0.775     -3.885      0.000      -4.532      -1.493\n",
      "topic_25                     -2.9691      0.775     -3.829      0.000      -4.489      -1.449\n",
      "topic_29                     -3.4465      0.785     -4.392      0.000      -4.984      -1.909\n",
      "topic_30                     -3.3600      0.783     -4.289      0.000      -4.895      -1.825\n",
      "topic_34                     -3.2263      0.780     -4.137      0.000      -4.755      -1.698\n",
      "topic_36                     -3.7700      0.795     -4.739      0.000      -5.329      -2.211\n",
      "topic_37                     -3.7457      0.796     -4.708      0.000      -5.305      -2.186\n",
      "topic_40                     -3.3285      0.783     -4.248      0.000      -4.864      -1.793\n",
      "topic_41                     -3.9279      0.804     -4.884      0.000      -5.504      -2.352\n",
      "topic_43                     -4.1319      0.810     -5.102      0.000      -5.719      -2.545\n",
      "topic_54                     -4.4717      0.835     -5.354      0.000      -6.109      -2.835\n",
      "topic_68                     -4.3164      0.825     -5.231      0.000      -5.934      -2.699\n",
      "topic_75                     -3.9420      0.805     -4.898      0.000      -5.519      -2.365\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8069054646988434\n",
      "Pr√§zision: 0.7484662576687117\n",
      "Recall: 0.671559633027523\n",
      "F1-Score: 0.7079303675048356\n",
      "Brier-Score: 0.17773366324210213\n",
      "Confusion-Matrix:\n",
      "[[904 246]\n",
      " [358 732]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536279\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2205\n",
      "Model:                          Logit   Df Residuals:                     2164\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1470\n",
      "Time:                        11:45:55   Log-Likelihood:                -1182.5\n",
      "converged:                       True   LL-Null:                       -1386.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.120e-62\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.7219      0.533      1.354      0.176      -0.323       1.767\n",
      "issue attention Facebook      5.8355      1.737      3.359      0.001       2.430       9.241\n",
      "issue attention Bundestag    -0.2271      0.936     -0.243      0.808      -2.062       1.608\n",
      "Social Media Nutzung         -0.0072      0.007     -1.059      0.290      -0.021       0.006\n",
      "Landtagswahlen               -0.1501      0.118     -1.273      0.203      -0.381       0.081\n",
      "Komplexit√§t Reden             0.1603      0.052      3.061      0.002       0.058       0.263\n",
      "Komplexit√§t Posts             0.2556      0.104      2.468      0.014       0.053       0.459\n",
      "topic_1                       0.1959      0.387      0.506      0.613      -0.563       0.954\n",
      "topic_2                       0.7062      0.406      1.740      0.082      -0.089       1.502\n",
      "topic_3                      -0.7590      0.373     -2.033      0.042      -1.491      -0.027\n",
      "topic_4                      -0.5486      0.375     -1.463      0.143      -1.283       0.186\n",
      "topic_6                      -0.1796      0.377     -0.476      0.634      -0.918       0.559\n",
      "topic_7                       1.3437      0.446      3.012      0.003       0.469       2.218\n",
      "topic_8                      -0.7602      0.383     -1.986      0.047      -1.511      -0.010\n",
      "topic_10                      0.1127      0.384      0.293      0.769      -0.640       0.866\n",
      "topic_11                     -2.1525      0.461     -4.672      0.000      -3.056      -1.249\n",
      "topic_12                     -1.6251      0.409     -3.972      0.000      -2.427      -0.823\n",
      "topic_13                     -2.1700      0.460     -4.722      0.000      -3.071      -1.269\n",
      "topic_14                     -0.6425      0.386     -1.664      0.096      -1.399       0.114\n",
      "topic_15                     -1.6346      0.415     -3.937      0.000      -2.448      -0.821\n",
      "topic_16                     -1.3764      0.402     -3.423      0.001      -2.165      -0.588\n",
      "topic_17                     -2.4340      0.493     -4.935      0.000      -3.401      -1.467\n",
      "topic_18                     -1.4093      0.409     -3.446      0.001      -2.211      -0.608\n",
      "topic_19                     -1.0894      0.396     -2.750      0.006      -1.866      -0.313\n",
      "topic_20                     -1.6332      0.417     -3.916      0.000      -2.450      -0.816\n",
      "topic_21                     -1.7200      0.422     -4.075      0.000      -2.547      -0.893\n",
      "topic_22                     -1.5849      0.418     -3.793      0.000      -2.404      -0.766\n",
      "topic_23                     -1.7512      0.433     -4.045      0.000      -2.600      -0.903\n",
      "topic_24                     -1.4713      0.414     -3.556      0.000      -2.282      -0.660\n",
      "topic_25                     -0.9118      0.393     -2.320      0.020      -1.682      -0.142\n",
      "topic_29                     -1.0418      0.398     -2.616      0.009      -1.822      -0.261\n",
      "topic_30                     -1.8382      0.442     -4.157      0.000      -2.705      -0.971\n",
      "topic_34                     -1.5473      0.421     -3.679      0.000      -2.372      -0.723\n",
      "topic_36                     -1.7179      0.435     -3.950      0.000      -2.570      -0.866\n",
      "topic_37                     -1.4326      0.417     -3.437      0.001      -2.250      -0.616\n",
      "topic_40                     -1.8358      0.443     -4.144      0.000      -2.704      -0.968\n",
      "topic_41                     -1.8292      0.444     -4.121      0.000      -2.699      -0.959\n",
      "topic_43                     -1.6325      0.427     -3.821      0.000      -2.470      -0.795\n",
      "topic_54                     -2.2034      0.479     -4.596      0.000      -3.143      -1.264\n",
      "topic_68                     -2.2011      0.480     -4.589      0.000      -3.141      -1.261\n",
      "topic_75                     -1.1861      0.406     -2.924      0.003      -1.981      -0.391\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7440309762255773\n",
      "Pr√§zision: 0.6804597701149425\n",
      "Recall: 0.41631504922644164\n",
      "F1-Score: 0.5165794066317626\n",
      "Brier-Score: 0.17746076554348134\n",
      "Confusion-Matrix:\n",
      "[[1355  139]\n",
      " [ 415  296]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538058\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2205\n",
      "Model:                          Logit   Df Residuals:                     2164\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.2234\n",
      "Time:                        11:45:55   Log-Likelihood:                -1186.4\n",
      "converged:                       True   LL-Null:                       -1527.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.430e-118\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         3.1253      0.856      3.652      0.000       1.448       4.802\n",
      "issue attention Facebook      8.8853      2.230      3.985      0.000       4.515      13.256\n",
      "issue attention Bundestag     3.2918      1.272      2.588      0.010       0.799       5.784\n",
      "Social Media Nutzung         -0.0074      0.007     -1.084      0.278      -0.021       0.006\n",
      "Landtagswahlen               -0.0534      0.116     -0.462      0.644      -0.280       0.173\n",
      "Komplexit√§t Reden            -0.0007      0.052     -0.012      0.990      -0.103       0.102\n",
      "Komplexit√§t Posts             0.1177      0.103      1.144      0.253      -0.084       0.319\n",
      "topic_1                       0.7078      1.241      0.571      0.568      -1.724       3.140\n",
      "topic_2                      -1.5830      0.804     -1.968      0.049      -3.159      -0.007\n",
      "topic_3                      -0.8620      0.862     -1.000      0.317      -2.551       0.827\n",
      "topic_4                       0.1563      1.020      0.153      0.878      -1.843       2.156\n",
      "topic_6                      -1.5917      0.793     -2.008      0.045      -3.145      -0.038\n",
      "topic_7                      -2.6734      0.771     -3.467      0.001      -4.185      -1.162\n",
      "topic_8                      -2.3785      0.773     -3.077      0.002      -3.894      -0.863\n",
      "topic_10                     -2.5780      0.771     -3.342      0.001      -4.090      -1.066\n",
      "topic_11                     -2.6456      0.771     -3.431      0.001      -4.157      -1.134\n",
      "topic_12                     -2.4600      0.771     -3.189      0.001      -3.972      -0.948\n",
      "topic_13                     -2.1574      0.775     -2.783      0.005      -3.677      -0.638\n",
      "topic_14                     -3.1004      0.772     -4.015      0.000      -4.614      -1.587\n",
      "topic_15                     -2.1084      0.776     -2.717      0.007      -3.629      -0.587\n",
      "topic_16                     -2.6460      0.770     -3.436      0.001      -4.155      -1.137\n",
      "topic_17                     -2.9791      0.771     -3.866      0.000      -4.490      -1.469\n",
      "topic_18                     -2.6309      0.771     -3.412      0.001      -4.142      -1.120\n",
      "topic_19                     -2.6916      0.771     -3.490      0.000      -4.203      -1.180\n",
      "topic_20                     -3.8045      0.780     -4.879      0.000      -5.333      -2.276\n",
      "topic_21                     -2.7504      0.772     -3.565      0.000      -4.263      -1.238\n",
      "topic_22                     -2.7879      0.771     -3.615      0.000      -4.299      -1.277\n",
      "topic_23                     -3.2520      0.774     -4.199      0.000      -4.770      -1.734\n",
      "topic_24                     -3.2822      0.774     -4.242      0.000      -4.799      -1.766\n",
      "topic_25                     -3.3242      0.775     -4.290      0.000      -4.843      -1.805\n",
      "topic_29                     -3.8328      0.785     -4.881      0.000      -5.372      -2.294\n",
      "topic_30                     -3.6642      0.782     -4.687      0.000      -5.196      -2.132\n",
      "topic_34                     -3.5927      0.780     -4.608      0.000      -5.121      -2.065\n",
      "topic_36                     -4.0766      0.794     -5.132      0.000      -5.634      -2.520\n",
      "topic_37                     -4.0652      0.794     -5.118      0.000      -5.622      -2.508\n",
      "topic_40                     -3.6377      0.782     -4.652      0.000      -5.170      -2.105\n",
      "topic_41                     -4.2491      0.803     -5.292      0.000      -5.823      -2.675\n",
      "topic_43                     -4.4271      0.808     -5.481      0.000      -6.010      -2.844\n",
      "topic_54                     -4.7913      0.834     -5.747      0.000      -6.425      -3.157\n",
      "topic_68                     -4.6331      0.823     -5.627      0.000      -6.247      -3.019\n",
      "topic_75                     -4.2572      0.803     -5.302      0.000      -5.831      -2.684\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7986307662670599\n",
      "Pr√§zision: 0.7310344827586207\n",
      "Recall: 0.6908752327746741\n",
      "F1-Score: 0.7103877453326951\n",
      "Brier-Score: 0.18190751259058166\n",
      "Confusion-Matrix:\n",
      "[[858 273]\n",
      " [332 742]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539755\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2170\n",
      "Model:                          Logit   Df Residuals:                     2129\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1439\n",
      "Time:                        11:45:55   Log-Likelihood:                -1171.3\n",
      "converged:                       True   LL-Null:                       -1368.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.078e-59\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.1444      0.540     -2.121      0.034      -2.202      -0.087\n",
      "issue attention Facebook     -0.0738      1.721     -0.043      0.966      -3.447       3.299\n",
      "issue attention Bundestag     0.3321      0.958      0.346      0.729      -1.546       2.210\n",
      "Social Media Nutzung          0.0288      0.007      4.093      0.000       0.015       0.043\n",
      "Landtagswahlen                0.0096      0.130      0.074      0.941      -0.246       0.265\n",
      "Komplexit√§t Reden             0.1462      0.053      2.759      0.006       0.042       0.250\n",
      "Komplexit√§t Posts            -0.5149      0.106     -4.875      0.000      -0.722      -0.308\n",
      "topic_1                       0.1540      0.388      0.397      0.692      -0.607       0.915\n",
      "topic_2                       0.5642      0.412      1.369      0.171      -0.243       1.372\n",
      "topic_3                      -0.8035      0.374     -2.146      0.032      -1.537      -0.070\n",
      "topic_4                      -0.5987      0.376     -1.591      0.112      -1.336       0.139\n",
      "topic_6                      -0.4095      0.381     -1.075      0.283      -1.156       0.337\n",
      "topic_7                       0.9960      0.448      2.224      0.026       0.118       1.874\n",
      "topic_8                      -1.0738      0.387     -2.773      0.006      -1.833      -0.315\n",
      "topic_10                     -0.2080      0.390     -0.534      0.594      -0.972       0.556\n",
      "topic_11                     -2.4603      0.464     -5.304      0.000      -3.369      -1.551\n",
      "topic_12                     -1.8221      0.412     -4.426      0.000      -2.629      -1.015\n",
      "topic_13                     -2.4639      0.462     -5.330      0.000      -3.370      -1.558\n",
      "topic_14                     -1.0004      0.390     -2.562      0.010      -1.766      -0.235\n",
      "topic_15                     -1.9175      0.419     -4.580      0.000      -2.738      -1.097\n",
      "topic_16                     -1.6532      0.406     -4.074      0.000      -2.449      -0.858\n",
      "topic_17                     -2.7540      0.496     -5.554      0.000      -3.726      -1.782\n",
      "topic_18                     -1.7362      0.413     -4.208      0.000      -2.545      -0.927\n",
      "topic_19                     -1.4181      0.400     -3.546      0.000      -2.202      -0.634\n",
      "topic_20                     -1.9164      0.420     -4.563      0.000      -2.740      -1.093\n",
      "topic_21                     -2.0156      0.425     -4.738      0.000      -2.849      -1.182\n",
      "topic_22                     -1.9188      0.421     -4.553      0.000      -2.745      -1.093\n",
      "topic_23                     -2.1144      0.437     -4.842      0.000      -2.970      -1.258\n",
      "topic_24                     -1.8275      0.418     -4.376      0.000      -2.646      -1.009\n",
      "topic_25                     -1.3467      0.399     -3.375      0.001      -2.129      -0.565\n",
      "topic_29                     -1.4974      0.405     -3.699      0.000      -2.291      -0.704\n",
      "topic_30                     -2.2231      0.446     -4.985      0.000      -3.097      -1.349\n",
      "topic_34                     -1.9171      0.424     -4.518      0.000      -2.749      -1.085\n",
      "topic_36                     -2.1154      0.439     -4.822      0.000      -2.975      -1.256\n",
      "topic_37                     -1.8260      0.421     -4.340      0.000      -2.651      -1.001\n",
      "topic_40                     -2.2203      0.447     -4.970      0.000      -3.096      -1.345\n",
      "topic_41                     -2.2200      0.447     -4.964      0.000      -3.097      -1.344\n",
      "topic_43                     -2.0135      0.431     -4.675      0.000      -2.858      -1.169\n",
      "topic_54                     -2.6008      0.483     -5.388      0.000      -3.547      -1.655\n",
      "topic_68                     -2.6005      0.483     -5.383      0.000      -3.547      -1.654\n",
      "topic_75                     -1.5722      0.410     -3.838      0.000      -2.375      -0.769\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7417674823905309\n",
      "Pr√§zision: 0.68\n",
      "Recall: 0.4099290780141844\n",
      "F1-Score: 0.511504424778761\n",
      "Brier-Score: 0.17912349563472715\n",
      "Confusion-Matrix:\n",
      "[[1329  136]\n",
      " [ 416  289]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541906\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2170\n",
      "Model:                          Logit   Df Residuals:                     2129\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.2179\n",
      "Time:                        11:45:56   Log-Likelihood:                -1175.9\n",
      "converged:                       True   LL-Null:                       -1503.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.946e-112\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         3.4389      0.854      4.027      0.000       1.765       5.113\n",
      "issue attention Facebook      6.4705      2.137      3.028      0.002       2.282      10.659\n",
      "issue attention Bundestag     1.4471      1.157      1.250      0.211      -0.821       3.715\n",
      "Social Media Nutzung         -0.0091      0.007     -1.335      0.182      -0.022       0.004\n",
      "Landtagswahlen                0.0274      0.127      0.215      0.830      -0.222       0.277\n",
      "Komplexit√§t Reden             0.0322      0.052      0.617      0.537      -0.070       0.135\n",
      "Komplexit√§t Posts             0.1207      0.101      1.194      0.232      -0.077       0.319\n",
      "topic_1                       0.6974      1.240      0.562      0.574      -1.733       3.127\n",
      "topic_2                      -1.6145      0.802     -2.013      0.044      -3.186      -0.043\n",
      "topic_3                      -0.9270      0.860     -1.078      0.281      -2.613       0.759\n",
      "topic_4                       0.0813      1.019      0.080      0.936      -1.917       2.079\n",
      "topic_6                      -1.5951      0.796     -2.003      0.045      -3.156      -0.034\n",
      "topic_7                      -2.7138      0.770     -3.523      0.000      -4.224      -1.204\n",
      "topic_8                      -2.5260      0.772     -3.271      0.001      -4.040      -1.012\n",
      "topic_10                     -2.7171      0.771     -3.525      0.000      -4.228      -1.206\n",
      "topic_11                     -2.8619      0.771     -3.711      0.000      -4.373      -1.350\n",
      "topic_12                     -2.5588      0.772     -3.314      0.001      -4.072      -1.046\n",
      "topic_13                     -2.3467      0.775     -3.028      0.002      -3.866      -0.828\n",
      "topic_14                     -3.3009      0.773     -4.273      0.000      -4.815      -1.787\n",
      "topic_15                     -2.2914      0.776     -2.954      0.003      -3.812      -0.771\n",
      "topic_16                     -2.7727      0.770     -3.599      0.000      -4.283      -1.263\n",
      "topic_17                     -3.1235      0.771     -4.052      0.000      -4.634      -1.613\n",
      "topic_18                     -2.7786      0.772     -3.600      0.000      -4.291      -1.266\n",
      "topic_19                     -2.9066      0.772     -3.767      0.000      -4.419      -1.394\n",
      "topic_20                     -4.0138      0.780     -5.143      0.000      -5.543      -2.484\n",
      "topic_21                     -2.8878      0.771     -3.746      0.000      -4.399      -1.377\n",
      "topic_22                     -2.9224      0.771     -3.790      0.000      -4.434      -1.411\n",
      "topic_23                     -3.4123      0.774     -4.406      0.000      -4.930      -1.894\n",
      "topic_24                     -3.4987      0.774     -4.518      0.000      -5.017      -1.981\n",
      "topic_25                     -3.4811      0.775     -4.491      0.000      -5.000      -1.962\n",
      "topic_29                     -3.9956      0.785     -5.088      0.000      -5.535      -2.456\n",
      "topic_30                     -3.8301      0.782     -4.900      0.000      -5.362      -2.298\n",
      "topic_34                     -3.8369      0.781     -4.911      0.000      -5.368      -2.306\n",
      "topic_36                     -4.2470      0.795     -5.345      0.000      -5.804      -2.690\n",
      "topic_37                     -4.2424      0.795     -5.339      0.000      -5.800      -2.685\n",
      "topic_40                     -3.8116      0.782     -4.872      0.000      -5.345      -2.278\n",
      "topic_41                     -4.4435      0.803     -5.533      0.000      -6.018      -2.869\n",
      "topic_43                     -4.5906      0.807     -5.686      0.000      -6.173      -3.008\n",
      "topic_54                     -4.9734      0.834     -5.964      0.000      -6.608      -3.339\n",
      "topic_68                     -4.8207      0.823     -5.855      0.000      -6.435      -3.207\n",
      "topic_75                     -4.4472      0.803     -5.538      0.000      -6.021      -2.873\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7926053228552317\n",
      "Pr√§zision: 0.7098943323727186\n",
      "Recall: 0.6978281397544853\n",
      "F1-Score: 0.7038095238095238\n",
      "Brier-Score: 0.18387376644606188\n",
      "Confusion-Matrix:\n",
      "[[809 302]\n",
      " [320 739]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529822\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2135\n",
      "Model:                          Logit   Df Residuals:                     2094\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1557\n",
      "Time:                        11:45:56   Log-Likelihood:                -1131.2\n",
      "converged:                       True   LL-Null:                       -1339.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.812e-64\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.5679      0.544      2.882      0.004       0.501       2.634\n",
      "issue attention Facebook     -0.4014      1.750     -0.229      0.819      -3.831       3.029\n",
      "issue attention Bundestag    -0.9553      0.976     -0.979      0.328      -2.868       0.957\n",
      "Social Media Nutzung         -0.0119      0.007     -1.709      0.087      -0.025       0.002\n",
      "Landtagswahlen               -0.2338      0.132     -1.774      0.076      -0.492       0.024\n",
      "Komplexit√§t Reden            -0.3685      0.056     -6.544      0.000      -0.479      -0.258\n",
      "Komplexit√§t Posts             0.2168      0.105      2.060      0.039       0.011       0.423\n",
      "topic_1                       0.1408      0.393      0.358      0.720      -0.630       0.911\n",
      "topic_2                       0.5783      0.415      1.392      0.164      -0.236       1.392\n",
      "topic_3                      -0.8673      0.381     -2.278      0.023      -1.613      -0.121\n",
      "topic_4                      -0.6882      0.383     -1.797      0.072      -1.439       0.062\n",
      "topic_6                      -0.4133      0.387     -1.067      0.286      -1.172       0.346\n",
      "topic_7                       1.0924      0.463      2.358      0.018       0.185       2.000\n",
      "topic_8                      -1.1016      0.392     -2.808      0.005      -1.871      -0.333\n",
      "topic_10                     -0.2772      0.395     -0.701      0.483      -1.052       0.497\n",
      "topic_11                     -2.7006      0.483     -5.588      0.000      -3.648      -1.753\n",
      "topic_12                     -1.9083      0.418     -4.570      0.000      -2.727      -1.090\n",
      "topic_13                     -2.5532      0.468     -5.456      0.000      -3.470      -1.636\n",
      "topic_14                     -1.1248      0.398     -2.828      0.005      -1.904      -0.345\n",
      "topic_15                     -2.0951      0.431     -4.864      0.000      -2.939      -1.251\n",
      "topic_16                     -1.7350      0.411     -4.218      0.000      -2.541      -0.929\n",
      "topic_17                     -3.0241      0.524     -5.772      0.000      -4.051      -1.997\n",
      "topic_18                     -1.8274      0.419     -4.365      0.000      -2.648      -1.007\n",
      "topic_19                     -1.5022      0.406     -3.699      0.000      -2.298      -0.706\n",
      "topic_20                     -2.0970      0.431     -4.865      0.000      -2.942      -1.252\n",
      "topic_21                     -2.1902      0.437     -5.006      0.000      -3.048      -1.333\n",
      "topic_22                     -2.0940      0.433     -4.838      0.000      -2.942      -1.246\n",
      "topic_23                     -2.3152      0.450     -5.144      0.000      -3.197      -1.433\n",
      "topic_24                     -2.0014      0.428     -4.671      0.000      -2.841      -1.162\n",
      "topic_25                     -1.4965      0.407     -3.678      0.000      -2.294      -0.699\n",
      "topic_29                     -1.6537      0.413     -4.000      0.000      -2.464      -0.843\n",
      "topic_30                     -2.3139      0.451     -5.129      0.000      -3.198      -1.430\n",
      "topic_34                     -2.0065      0.430     -4.670      0.000      -2.849      -1.164\n",
      "topic_36                     -2.3150      0.452     -5.119      0.000      -3.201      -1.429\n",
      "topic_37                     -2.0095      0.432     -4.656      0.000      -2.855      -1.164\n",
      "topic_40                     -2.3224      0.452     -5.136      0.000      -3.209      -1.436\n",
      "topic_41                     -2.3238      0.453     -5.133      0.000      -3.211      -1.436\n",
      "topic_43                     -2.1027      0.437     -4.813      0.000      -2.959      -1.247\n",
      "topic_54                     -2.8559      0.505     -5.650      0.000      -3.847      -1.865\n",
      "topic_68                     -2.7036      0.488     -5.543      0.000      -3.659      -1.748\n",
      "topic_75                     -1.6652      0.416     -4.008      0.000      -2.480      -0.851\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.752359426126353\n",
      "Pr√§zision: 0.6833333333333333\n",
      "Recall: 0.41897810218978104\n",
      "F1-Score: 0.5194570135746607\n",
      "Brier-Score: 0.17489904554909216\n",
      "Confusion-Matrix:\n",
      "[[1317  133]\n",
      " [ 398  287]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543627\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2135\n",
      "Model:                          Logit   Df Residuals:                     2094\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.2154\n",
      "Time:                        11:45:56   Log-Likelihood:                -1160.6\n",
      "converged:                       True   LL-Null:                       -1479.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.237e-108\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.7061      0.853      3.171      0.002       1.034       4.379\n",
      "issue attention Facebook      5.7563      2.109      2.729      0.006       1.622       9.891\n",
      "issue attention Bundestag     0.2709      1.132      0.239      0.811      -1.948       2.489\n",
      "Social Media Nutzung          0.0043      0.007      0.626      0.531      -0.009       0.018\n",
      "Landtagswahlen                0.0045      0.128      0.035      0.972      -0.246       0.255\n",
      "Komplexit√§t Reden            -0.0239      0.053     -0.453      0.651      -0.127       0.079\n",
      "Komplexit√§t Posts            -0.0492      0.103     -0.479      0.632      -0.251       0.152\n",
      "topic_1                       0.6754      1.239      0.545      0.586      -1.754       3.105\n",
      "topic_2                      -1.6107      0.801     -2.011      0.044      -3.181      -0.041\n",
      "topic_3                      -0.9766      0.860     -1.136      0.256      -2.661       0.708\n",
      "topic_4                       0.0127      1.019      0.012      0.990      -1.985       2.011\n",
      "topic_6                      -1.6526      0.796     -2.075      0.038      -3.213      -0.092\n",
      "topic_7                      -2.6948      0.771     -3.497      0.000      -4.205      -1.185\n",
      "topic_8                      -2.5273      0.773     -3.269      0.001      -4.042      -1.012\n",
      "topic_10                     -2.7785      0.771     -3.603      0.000      -4.290      -1.267\n",
      "topic_11                     -2.9829      0.772     -3.863      0.000      -4.496      -1.469\n",
      "topic_12                     -2.5931      0.774     -3.352      0.001      -4.109      -1.077\n",
      "topic_13                     -2.4519      0.775     -3.162      0.002      -3.972      -0.932\n",
      "topic_14                     -3.3377      0.773     -4.317      0.000      -4.853      -1.822\n",
      "topic_15                     -2.3130      0.777     -2.975      0.003      -3.837      -0.789\n",
      "topic_16                     -2.8117      0.772     -3.644      0.000      -4.324      -1.299\n",
      "topic_17                     -3.2410      0.772     -4.199      0.000      -4.754      -1.728\n",
      "topic_18                     -2.8941      0.773     -3.745      0.000      -4.409      -1.379\n",
      "topic_19                     -3.0243      0.772     -3.915      0.000      -4.538      -1.510\n",
      "topic_20                     -4.1471      0.783     -5.298      0.000      -5.681      -2.613\n",
      "topic_21                     -2.9253      0.772     -3.791      0.000      -4.438      -1.413\n",
      "topic_22                     -2.9620      0.772     -3.837      0.000      -4.475      -1.449\n",
      "topic_23                     -3.4681      0.775     -4.474      0.000      -4.987      -1.949\n",
      "topic_24                     -3.5494      0.775     -4.580      0.000      -5.068      -2.030\n",
      "topic_25                     -3.5357      0.776     -4.558      0.000      -5.056      -2.015\n",
      "topic_29                     -4.1406      0.788     -5.254      0.000      -5.685      -2.596\n",
      "topic_30                     -3.8876      0.782     -4.969      0.000      -5.421      -2.354\n",
      "topic_34                     -3.8977      0.782     -4.984      0.000      -5.430      -2.365\n",
      "topic_36                     -4.3081      0.795     -5.419      0.000      -5.866      -2.750\n",
      "topic_37                     -4.3109      0.795     -5.422      0.000      -5.869      -2.752\n",
      "topic_40                     -3.8808      0.783     -4.955      0.000      -5.416      -2.346\n",
      "topic_41                     -4.5191      0.804     -5.623      0.000      -6.094      -2.944\n",
      "topic_43                     -4.6484      0.808     -5.755      0.000      -6.232      -3.065\n",
      "topic_54                     -5.0436      0.834     -6.045      0.000      -6.679      -3.408\n",
      "topic_68                     -4.8917      0.824     -5.937      0.000      -6.507      -3.277\n",
      "topic_75                     -4.6329      0.809     -5.726      0.000      -6.219      -3.047\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7911886174236438\n",
      "Pr√§zision: 0.7021883920076119\n",
      "Recall: 0.7068965517241379\n",
      "F1-Score: 0.7045346062052505\n",
      "Brier-Score: 0.18462824133573433\n",
      "Confusion-Matrix:\n",
      "[[778 313]\n",
      " [306 738]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536432\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2100\n",
      "Model:                          Logit   Df Residuals:                     2059\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1438\n",
      "Time:                        11:45:56   Log-Likelihood:                -1126.5\n",
      "converged:                       True   LL-Null:                       -1315.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.169e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.2823      0.549      0.515      0.607      -0.793       1.357\n",
      "issue attention Facebook      2.7837      1.732      1.608      0.108      -0.610       6.177\n",
      "issue attention Bundestag    -0.8594      0.975     -0.882      0.378      -2.769       1.051\n",
      "Social Media Nutzung          0.0032      0.007      0.453      0.651      -0.011       0.017\n",
      "Landtagswahlen                0.0349      0.131      0.267      0.790      -0.221       0.291\n",
      "Komplexit√§t Reden             0.1292      0.053      2.433      0.015       0.025       0.233\n",
      "Komplexit√§t Posts             0.0143      0.107      0.134      0.893      -0.195       0.224\n",
      "topic_1                       0.1994      0.393      0.508      0.612      -0.571       0.969\n",
      "topic_2                       0.6505      0.413      1.577      0.115      -0.158       1.459\n",
      "topic_3                      -0.8723      0.379     -2.302      0.021      -1.615      -0.130\n",
      "topic_4                      -0.6780      0.381     -1.782      0.075      -1.424       0.068\n",
      "topic_6                      -0.2741      0.384     -0.715      0.475      -1.026       0.478\n",
      "topic_7                       1.3737      0.475      2.893      0.004       0.443       2.304\n",
      "topic_8                      -0.9200      0.389     -2.364      0.018      -1.683      -0.157\n",
      "topic_10                     -0.0863      0.391     -0.221      0.825      -0.852       0.680\n",
      "topic_11                     -2.4221      0.479     -5.059      0.000      -3.361      -1.484\n",
      "topic_12                     -1.6934      0.413     -4.101      0.000      -2.503      -0.884\n",
      "topic_13                     -2.2849      0.463     -4.937      0.000      -3.192      -1.378\n",
      "topic_14                     -0.8386      0.393     -2.135      0.033      -1.608      -0.069\n",
      "topic_15                     -1.8358      0.425     -4.317      0.000      -2.669      -1.002\n",
      "topic_16                     -1.4823      0.407     -3.644      0.000      -2.279      -0.685\n",
      "topic_17                     -2.9394      0.550     -5.341      0.000      -4.018      -1.861\n",
      "topic_18                     -1.6330      0.418     -3.906      0.000      -2.453      -0.814\n",
      "topic_19                     -1.2228      0.401     -3.049      0.002      -2.009      -0.437\n",
      "topic_20                     -1.9378      0.433     -4.476      0.000      -2.786      -1.089\n",
      "topic_21                     -2.0340      0.441     -4.615      0.000      -2.898      -1.170\n",
      "topic_22                     -1.8094      0.428     -4.229      0.000      -2.648      -0.971\n",
      "topic_23                     -2.0095      0.445     -4.512      0.000      -2.882      -1.137\n",
      "topic_24                     -1.7060      0.423     -4.034      0.000      -2.535      -0.877\n",
      "topic_25                     -1.2796      0.405     -3.163      0.002      -2.073      -0.487\n",
      "topic_29                     -1.3504      0.408     -3.306      0.001      -2.151      -0.550\n",
      "topic_30                     -2.1143      0.456     -4.639      0.000      -3.008      -1.221\n",
      "topic_34                     -1.7019      0.425     -4.006      0.000      -2.535      -0.869\n",
      "topic_36                     -1.9920      0.447     -4.455      0.000      -2.868      -1.116\n",
      "topic_37                     -1.6911      0.426     -3.966      0.000      -2.527      -0.855\n",
      "topic_40                     -2.0050      0.447     -4.483      0.000      -2.882      -1.128\n",
      "topic_41                     -2.0032      0.448     -4.473      0.000      -2.881      -1.126\n",
      "topic_43                     -1.7903      0.431     -4.153      0.000      -2.635      -0.945\n",
      "topic_54                     -2.5280      0.501     -5.048      0.000      -3.509      -1.547\n",
      "topic_68                     -2.3759      0.483     -4.919      0.000      -3.323      -1.429\n",
      "topic_75                     -1.4327      0.414     -3.462      0.001      -2.244      -0.622\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7418379553198123\n",
      "Pr√§zision: 0.6819338422391857\n",
      "Recall: 0.39940387481371087\n",
      "F1-Score: 0.5037593984962406\n",
      "Brier-Score: 0.1779456262906332\n",
      "Confusion-Matrix:\n",
      "[[1304  125]\n",
      " [ 403  268]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541479\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2100\n",
      "Model:                          Logit   Df Residuals:                     2059\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.2186\n",
      "Time:                        11:45:56   Log-Likelihood:                -1137.1\n",
      "converged:                       True   LL-Null:                       -1455.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.318e-108\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         3.1439      0.860      3.655      0.000       1.458       4.830\n",
      "issue attention Facebook      6.6086      2.160      3.060      0.002       2.376      10.841\n",
      "issue attention Bundestag     0.9521      1.165      0.817      0.414      -1.331       3.236\n",
      "Social Media Nutzung         -0.0045      0.007     -0.646      0.518      -0.018       0.009\n",
      "Landtagswahlen                0.0157      0.129      0.122      0.903      -0.237       0.269\n",
      "Komplexit√§t Reden            -0.0741      0.053     -1.403      0.161      -0.178       0.029\n",
      "Komplexit√§t Posts             0.0552      0.105      0.524      0.600      -0.151       0.262\n",
      "topic_1                       0.6868      1.240      0.554      0.580      -1.744       3.117\n",
      "topic_2                      -1.5979      0.802     -1.992      0.046      -3.170      -0.025\n",
      "topic_3                      -0.9635      0.861     -1.119      0.263      -2.651       0.724\n",
      "topic_4                       0.0474      1.020      0.046      0.963      -1.952       2.047\n",
      "topic_6                      -1.5000      0.802     -1.870      0.062      -3.073       0.073\n",
      "topic_7                      -2.5902      0.773     -3.353      0.001      -4.104      -1.076\n",
      "topic_8                      -2.4836      0.774     -3.209      0.001      -4.000      -0.967\n",
      "topic_10                     -2.6708      0.773     -3.457      0.001      -4.185      -1.157\n",
      "topic_11                     -2.9172      0.773     -3.773      0.000      -4.433      -1.402\n",
      "topic_12                     -2.4603      0.776     -3.172      0.002      -3.980      -0.940\n",
      "topic_13                     -2.3143      0.777     -2.978      0.003      -3.838      -0.791\n",
      "topic_14                     -3.2212      0.774     -4.162      0.000      -4.738      -1.704\n",
      "topic_15                     -2.2513      0.778     -2.893      0.004      -3.777      -0.726\n",
      "topic_16                     -2.7508      0.773     -3.561      0.000      -4.265      -1.237\n",
      "topic_17                     -3.1860      0.773     -4.122      0.000      -4.701      -1.671\n",
      "topic_18                     -2.8284      0.774     -3.656      0.000      -4.345      -1.312\n",
      "topic_19                     -2.8948      0.773     -3.743      0.000      -4.411      -1.379\n",
      "topic_20                     -4.1346      0.786     -5.262      0.000      -5.675      -2.595\n",
      "topic_21                     -2.8685      0.773     -3.712      0.000      -4.383      -1.354\n",
      "topic_22                     -2.8366      0.773     -3.669      0.000      -4.352      -1.321\n",
      "topic_23                     -3.3398      0.776     -4.304      0.000      -4.861      -1.819\n",
      "topic_24                     -3.4323      0.776     -4.425      0.000      -4.952      -1.912\n",
      "topic_25                     -3.4151      0.776     -4.399      0.000      -4.937      -1.894\n",
      "topic_29                     -4.0236      0.789     -5.102      0.000      -5.569      -2.478\n",
      "topic_30                     -3.8469      0.785     -4.903      0.000      -5.385      -2.309\n",
      "topic_34                     -3.7769      0.782     -4.827      0.000      -5.311      -2.243\n",
      "topic_36                     -4.1879      0.795     -5.265      0.000      -5.747      -2.629\n",
      "topic_37                     -4.2896      0.799     -5.367      0.000      -5.856      -2.723\n",
      "topic_40                     -3.8341      0.785     -4.882      0.000      -5.373      -2.295\n",
      "topic_41                     -4.3918      0.804     -5.461      0.000      -5.968      -2.816\n",
      "topic_43                     -4.5315      0.808     -5.607      0.000      -6.115      -2.947\n",
      "topic_54                     -4.9217      0.835     -5.896      0.000      -6.558      -3.286\n",
      "topic_68                     -4.7709      0.824     -5.788      0.000      -6.386      -3.155\n",
      "topic_75                     -4.5080      0.809     -5.569      0.000      -6.095      -2.921\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7936999099831582\n",
      "Pr√§zision: 0.7091633466135459\n",
      "Recall: 0.6926070038910506\n",
      "F1-Score: 0.7007874015748031\n",
      "Brier-Score: 0.18348785503715886\n",
      "Confusion-Matrix:\n",
      "[[780 292]\n",
      " [316 712]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537148\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2065\n",
      "Model:                          Logit   Df Residuals:                     2024\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.1447\n",
      "Time:                        11:45:57   Log-Likelihood:                -1109.2\n",
      "converged:                       True   LL-Null:                       -1296.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.459e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.4026      0.559      0.721      0.471      -0.693       1.498\n",
      "issue attention Facebook     -0.0466      1.750     -0.027      0.979      -3.477       3.384\n",
      "issue attention Bundestag    -0.6062      0.986     -0.615      0.539      -2.538       1.326\n",
      "Social Media Nutzung          0.0038      0.007      0.518      0.604      -0.011       0.018\n",
      "Landtagswahlen                0.0418      0.131      0.319      0.749      -0.215       0.298\n",
      "Komplexit√§t Reden             0.1541      0.054      2.861      0.004       0.049       0.260\n",
      "Komplexit√§t Posts            -0.1345      0.109     -1.233      0.218      -0.348       0.079\n",
      "topic_1                       0.3039      0.397      0.765      0.445      -0.475       1.083\n",
      "topic_2                       0.6782      0.419      1.617      0.106      -0.144       1.500\n",
      "topic_3                      -0.7868      0.380     -2.069      0.039      -1.532      -0.041\n",
      "topic_4                      -0.5967      0.382     -1.562      0.118      -1.346       0.152\n",
      "topic_6                      -0.3802      0.386     -0.986      0.324      -1.136       0.375\n",
      "topic_7                       1.2505      0.476      2.627      0.009       0.317       2.184\n",
      "topic_8                      -1.0026      0.392     -2.559      0.011      -1.771      -0.235\n",
      "topic_10                     -0.2395      0.394     -0.609      0.543      -1.011       0.532\n",
      "topic_11                     -2.5101      0.481     -5.221      0.000      -3.452      -1.568\n",
      "topic_12                     -1.7280      0.415     -4.168      0.000      -2.541      -0.915\n",
      "topic_13                     -2.3654      0.464     -5.093      0.000      -3.276      -1.455\n",
      "topic_14                     -0.9443      0.396     -2.387      0.017      -1.720      -0.169\n",
      "topic_15                     -2.0126      0.434     -4.635      0.000      -2.864      -1.162\n",
      "topic_16                     -1.5537      0.409     -3.798      0.000      -2.355      -0.752\n",
      "topic_17                     -3.0340      0.552     -5.497      0.000      -4.116      -1.952\n",
      "topic_18                     -1.7291      0.420     -4.113      0.000      -2.553      -0.905\n",
      "topic_19                     -1.3177      0.404     -3.264      0.001      -2.109      -0.526\n",
      "topic_20                     -2.0154      0.435     -4.629      0.000      -2.869      -1.162\n",
      "topic_21                     -2.1208      0.444     -4.780      0.000      -2.990      -1.251\n",
      "topic_22                     -1.9101      0.430     -4.440      0.000      -2.753      -1.067\n",
      "topic_23                     -2.1253      0.448     -4.746      0.000      -3.003      -1.248\n",
      "topic_24                     -1.8141      0.425     -4.266      0.000      -2.648      -0.981\n",
      "topic_25                     -1.3901      0.407     -3.415      0.001      -2.188      -0.592\n",
      "topic_29                     -1.4689      0.411     -3.575      0.000      -2.274      -0.664\n",
      "topic_30                     -2.2404      0.458     -4.889      0.000      -3.139      -1.342\n",
      "topic_34                     -1.8181      0.427     -4.255      0.000      -2.655      -0.981\n",
      "topic_36                     -2.2418      0.459     -4.882      0.000      -3.142      -1.342\n",
      "topic_37                     -1.8185      0.429     -4.241      0.000      -2.659      -0.978\n",
      "topic_40                     -2.1291      0.449     -4.738      0.000      -3.010      -1.248\n",
      "topic_41                     -2.1301      0.450     -4.731      0.000      -3.013      -1.248\n",
      "topic_43                     -2.0151      0.440     -4.576      0.000      -2.878      -1.152\n",
      "topic_54                     -2.6613      0.503     -5.291      0.000      -3.647      -1.676\n",
      "topic_68                     -2.5080      0.485     -5.168      0.000      -3.459      -1.557\n",
      "topic_75                     -1.5573      0.417     -3.739      0.000      -2.374      -0.741\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7418206014636705\n",
      "Pr√§zision: 0.6810126582278481\n",
      "Recall: 0.40512048192771083\n",
      "F1-Score: 0.5080264400377715\n",
      "Brier-Score: 0.17821821209468913\n",
      "Confusion-Matrix:\n",
      "[[1275  126]\n",
      " [ 395  269]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538953\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2065\n",
      "Model:                          Logit   Df Residuals:                     2024\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                  0.2222\n",
      "Time:                        11:45:57   Log-Likelihood:                -1112.9\n",
      "converged:                       True   LL-Null:                       -1430.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.708e-108\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.1447      0.861      2.492      0.013       0.458       3.832\n",
      "issue attention Facebook      7.2295      2.203      3.282      0.001       2.912      11.547\n",
      "issue attention Bundestag     1.1690      1.182      0.989      0.323      -1.148       3.486\n",
      "Social Media Nutzung          0.0102      0.007      1.435      0.151      -0.004       0.024\n",
      "Landtagswahlen                0.1050      0.130      0.811      0.418      -0.149       0.359\n",
      "Komplexit√§t Reden             0.0698      0.053      1.309      0.191      -0.035       0.174\n",
      "Komplexit√§t Posts            -0.1532      0.108     -1.424      0.155      -0.364       0.058\n",
      "topic_1                       0.6761      1.241      0.545      0.586      -1.756       3.108\n",
      "topic_2                      -1.5858      0.804     -1.973      0.048      -3.161      -0.011\n",
      "topic_3                      -0.9900      0.861     -1.149      0.250      -2.678       0.698\n",
      "topic_4                       0.0400      1.021      0.039      0.969      -1.960       2.040\n",
      "topic_6                      -1.4908      0.803     -1.856      0.063      -3.065       0.083\n",
      "topic_7                      -2.5126      0.775     -3.243      0.001      -4.031      -0.994\n",
      "topic_8                      -2.4015      0.776     -3.096      0.002      -3.922      -0.881\n",
      "topic_10                     -2.5913      0.774     -3.347      0.001      -4.109      -1.074\n",
      "topic_11                     -2.9042      0.774     -3.752      0.000      -4.421      -1.387\n",
      "topic_12                     -2.3746      0.777     -3.055      0.002      -3.898      -0.851\n",
      "topic_13                     -2.2202      0.779     -2.849      0.004      -3.747      -0.693\n",
      "topic_14                     -3.2169      0.775     -4.149      0.000      -4.736      -1.697\n",
      "topic_15                     -2.2358      0.779     -2.871      0.004      -3.762      -0.709\n",
      "topic_16                     -2.6711      0.774     -3.453      0.001      -4.187      -1.155\n",
      "topic_17                     -3.1124      0.774     -4.023      0.000      -4.629      -1.596\n",
      "topic_18                     -2.8127      0.774     -3.632      0.000      -4.331      -1.295\n",
      "topic_19                     -2.8793      0.774     -3.718      0.000      -4.397      -1.362\n",
      "topic_20                     -4.1675      0.789     -5.282      0.000      -5.714      -2.621\n",
      "topic_21                     -2.8616      0.774     -3.698      0.000      -4.378      -1.345\n",
      "topic_22                     -2.8232      0.774     -3.647      0.000      -4.340      -1.306\n",
      "topic_23                     -3.2595      0.777     -4.196      0.000      -4.782      -1.737\n",
      "topic_24                     -3.3612      0.776     -4.329      0.000      -4.883      -1.840\n",
      "topic_25                     -3.4129      0.778     -4.389      0.000      -4.937      -1.889\n",
      "topic_29                     -4.0460      0.792     -5.110      0.000      -5.598      -2.494\n",
      "topic_30                     -3.7727      0.785     -4.805      0.000      -5.312      -2.234\n",
      "topic_34                     -3.7856      0.785     -4.824      0.000      -5.324      -2.248\n",
      "topic_36                     -4.1137      0.796     -5.167      0.000      -5.674      -2.553\n",
      "topic_37                     -4.2188      0.800     -5.275      0.000      -5.786      -2.651\n",
      "topic_40                     -3.8437      0.788     -4.879      0.000      -5.388      -2.299\n",
      "topic_41                     -4.3154      0.805     -5.362      0.000      -5.893      -2.738\n",
      "topic_43                     -4.4649      0.809     -5.521      0.000      -6.050      -2.880\n",
      "topic_54                     -4.8533      0.835     -5.812      0.000      -6.490      -3.217\n",
      "topic_68                     -4.8517      0.835     -5.809      0.000      -6.489      -3.215\n",
      "topic_75                     -4.4326      0.810     -5.473      0.000      -6.020      -2.845\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.797240554704628\n",
      "Pr√§zision: 0.7193717277486911\n",
      "Recall: 0.6808721506442021\n",
      "F1-Score: 0.6995926680244399\n",
      "Brier-Score: 0.18229132173994492\n",
      "Confusion-Matrix:\n",
      "[[788 268]\n",
      " [322 687]]\n"
     ]
    }
   ],
   "source": [
    "for lag in range(1,8):\n",
    "    model1,auc_roc1,f1_1=log_reg_FE_control_test(rede_relativ_reduced, post_relativ_reduced, rede_common,lag, social_media_usage,rede_komplex, posts_komplex)\n",
    "    model2,auc_roc2,f1_2=log_reg_FE_control_test(rede_relativ_reduced, post_relativ_reduced, post_common,lag, social_media_usage,rede_komplex, posts_komplex)\n",
    "     # Stargazer-Tabelle f√ºr den Vergleich der beiden Modelle\n",
    "    stargazer = Stargazer([model1, model2])\n",
    "    stargazer.title(f\" Aggregiert Vergleich f√ºr Lag {lag}\")\n",
    "    stargazer.custom_columns(\n",
    "        [f\"Bundestag \", \n",
    "         f\"Facebook\"], \n",
    "        [1, 1]\n",
    "    )\n",
    "    stargazer.significant_digits(3)\n",
    "    stargazer.dependent_variable_name(\"Themenerw√§hnung Aggregiert\")\n",
    "    \n",
    "    # AUC-ROC und F1-Score f√ºr beide Modelle als individuelle Notizen\n",
    "    custom_notes = [\n",
    "        f\"Modell 1 (Reden als Zielvariable): AUC-ROC = {auc_roc1:.3f}, F1-Score = {f1_1:.3f}\",\n",
    "        f\"Modell 2 (Posts als Zielvariable): AUC-ROC = {auc_roc2:.3f}, F1-Score = {f1_2:.3f}\"\n",
    "    ]\n",
    "    stargazer.add_custom_notes(custom_notes)\n",
    "    \n",
    "    # Exportiere jede Tabelle separat\n",
    "    filename = f\"regression tables/regression_table_comparison_agg_lag_{lag}.html\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(stargazer.render_html())\n",
    "    \n",
    "    # Speichere die Tabelle in der Liste\n",
    "    stargazer_tables.append((lag, stargazer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539528\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2234\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1434\n",
      "Time:                        11:10:00   Log-Likelihood:                -1227.4\n",
      "converged:                       True   LL-Null:                       -1432.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.902e-63\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0505      0.524     -0.096      0.923      -1.077       0.976\n",
      "issue attention Facebook      7.8255      1.712      4.571      0.000       4.470      11.181\n",
      "issue attention Bundestag    -1.6928      0.907     -1.866      0.062      -3.470       0.085\n",
      "Social Media Nutzung          0.0049      0.007      0.724      0.469      -0.008       0.018\n",
      "Landtagswahlen               -0.0094      0.093     -0.101      0.920      -0.192       0.174\n",
      "Komplexit√§t Reden            -0.0078      0.051     -0.153      0.878      -0.108       0.092\n",
      "Komplexit√§t Posts            -0.1001      0.104     -0.962      0.336      -0.304       0.104\n",
      "topic_1                       0.1340      0.383      0.349      0.727      -0.618       0.886\n",
      "topic_2                       0.7879      0.405      1.946      0.052      -0.006       1.581\n",
      "topic_3                      -0.7922      0.369     -2.148      0.032      -1.515      -0.069\n",
      "topic_4                      -0.6138      0.371     -1.653      0.098      -1.341       0.114\n",
      "topic_6                      -0.1682      0.372     -0.452      0.651      -0.898       0.561\n",
      "topic_7                       1.2605      0.433      2.914      0.004       0.413       2.108\n",
      "topic_8                      -0.8261      0.378     -2.187      0.029      -1.566      -0.086\n",
      "topic_10                      0.1016      0.378      0.269      0.788      -0.639       0.843\n",
      "topic_11                     -2.2494      0.458     -4.916      0.000      -3.146      -1.353\n",
      "topic_12                     -1.7589      0.407     -4.325      0.000      -2.556      -0.962\n",
      "topic_13                     -2.2451      0.456     -4.925      0.000      -3.139      -1.352\n",
      "topic_14                     -0.6471      0.379     -1.706      0.088      -1.390       0.096\n",
      "topic_15                     -1.6347      0.406     -4.024      0.000      -2.431      -0.839\n",
      "topic_16                     -1.4651      0.398     -3.679      0.000      -2.246      -0.685\n",
      "topic_17                     -2.3438      0.472     -4.969      0.000      -3.268      -1.419\n",
      "topic_18                     -1.4932      0.405     -3.691      0.000      -2.286      -0.700\n",
      "topic_19                     -1.1070      0.389     -2.848      0.004      -1.869      -0.345\n",
      "topic_20                     -1.6195      0.409     -3.963      0.000      -2.421      -0.819\n",
      "topic_21                     -1.6926      0.413     -4.099      0.000      -2.502      -0.883\n",
      "topic_22                     -1.5539      0.409     -3.803      0.000      -2.355      -0.753\n",
      "topic_23                     -1.8007      0.429     -4.199      0.000      -2.641      -0.960\n",
      "topic_24                     -1.5250      0.409     -3.724      0.000      -2.328      -0.722\n",
      "topic_25                     -0.9761      0.388     -2.516      0.012      -1.736      -0.216\n",
      "topic_29                     -1.0228      0.391     -2.617      0.009      -1.789      -0.257\n",
      "topic_30                     -1.8795      0.438     -4.289      0.000      -2.738      -1.021\n",
      "topic_34                     -1.4262      0.406     -3.510      0.000      -2.222      -0.630\n",
      "topic_36                     -1.7615      0.430     -4.094      0.000      -2.605      -0.918\n",
      "topic_37                     -1.4820      0.412     -3.597      0.000      -2.290      -0.675\n",
      "topic_40                     -1.7793      0.430     -4.133      0.000      -2.623      -0.936\n",
      "topic_41                     -1.8804      0.440     -4.278      0.000      -2.742      -1.019\n",
      "topic_43                     -1.6745      0.423     -3.960      0.000      -2.503      -0.846\n",
      "topic_54                     -2.1027      0.461     -4.560      0.000      -3.006      -1.199\n",
      "topic_68                     -2.2396      0.476     -4.708      0.000      -3.172      -1.307\n",
      "topic_75                     -1.2451      0.401     -3.108      0.002      -2.030      -0.460\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7451058926904666\n",
      "Pr√§zision: 0.6814159292035398\n",
      "Recall: 0.417910447761194\n",
      "F1-Score: 0.5180824222035324\n",
      "Brier-Score: 0.17919927966397808\n",
      "Confusion-Matrix:\n",
      "[[1394  144]\n",
      " [ 429  308]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531963\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2234\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2321\n",
      "Time:                        11:10:00   Log-Likelihood:                -1210.2\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                5.544e-128\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.9640      0.853      3.474      0.001       1.292       4.636\n",
      "issue attention Facebook     17.8797      2.495      7.166      0.000      12.989      22.770\n",
      "issue attention Bundestag     0.2034      1.100      0.185      0.853      -1.954       2.360\n",
      "Social Media Nutzung         -0.0088      0.007     -1.317      0.188      -0.022       0.004\n",
      "Landtagswahlen                0.0251      0.093      0.269      0.788      -0.158       0.208\n",
      "Komplexit√§t Reden             0.0782      0.051      1.541      0.123      -0.021       0.178\n",
      "Komplexit√§t Posts             0.1017      0.103      0.986      0.324      -0.100       0.304\n",
      "topic_1                       0.5719      1.243      0.460      0.646      -1.865       3.009\n",
      "topic_2                      -1.3852      0.806     -1.718      0.086      -2.965       0.195\n",
      "topic_3                      -0.9264      0.866     -1.070      0.285      -2.624       0.771\n",
      "topic_4                       0.0550      1.024      0.054      0.957      -1.952       2.062\n",
      "topic_6                      -1.5485      0.791     -1.958      0.050      -3.099       0.002\n",
      "topic_7                      -2.5263      0.771     -3.276      0.001      -4.038      -1.015\n",
      "topic_8                      -2.1628      0.773     -2.798      0.005      -3.678      -0.648\n",
      "topic_10                     -2.3594      0.771     -3.061      0.002      -3.870      -0.849\n",
      "topic_11                     -2.5599      0.773     -3.314      0.001      -4.074      -1.046\n",
      "topic_12                     -2.5351      0.775     -3.273      0.001      -4.053      -1.017\n",
      "topic_13                     -2.1448      0.775     -2.768      0.006      -3.663      -0.626\n",
      "topic_14                     -2.9686      0.772     -3.845      0.000      -4.482      -1.455\n",
      "topic_15                     -2.1168      0.775     -2.730      0.006      -3.637      -0.597\n",
      "topic_16                     -2.6350      0.772     -3.415      0.001      -4.147      -1.123\n",
      "topic_17                     -2.8526      0.772     -3.697      0.000      -4.365      -1.340\n",
      "topic_18                     -2.4579      0.772     -3.184      0.001      -3.971      -0.945\n",
      "topic_19                     -2.6413      0.772     -3.422      0.001      -4.154      -1.129\n",
      "topic_20                     -3.6015      0.782     -4.608      0.000      -5.133      -2.070\n",
      "topic_21                     -2.6181      0.772     -3.393      0.001      -4.130      -1.106\n",
      "topic_22                     -2.6215      0.772     -3.397      0.001      -4.134      -1.109\n",
      "topic_23                     -3.0582      0.774     -3.950      0.000      -4.576      -1.541\n",
      "topic_24                     -3.0894      0.774     -3.994      0.000      -4.606      -1.573\n",
      "topic_25                     -3.0505      0.774     -3.942      0.000      -4.567      -1.534\n",
      "topic_29                     -3.4992      0.782     -4.475      0.000      -5.032      -1.967\n",
      "topic_30                     -3.4206      0.780     -4.383      0.000      -4.950      -1.891\n",
      "topic_34                     -3.3082      0.778     -4.254      0.000      -4.833      -1.784\n",
      "topic_36                     -3.9038      0.795     -4.912      0.000      -5.461      -2.346\n",
      "topic_37                     -3.8975      0.795     -4.905      0.000      -5.455      -2.340\n",
      "topic_40                     -3.4868      0.783     -4.456      0.000      -5.020      -1.953\n",
      "topic_41                     -3.9915      0.799     -4.995      0.000      -5.558      -2.425\n",
      "topic_43                     -4.2714      0.810     -5.275      0.000      -5.859      -2.684\n",
      "topic_54                     -4.4563      0.824     -5.410      0.000      -6.071      -2.842\n",
      "topic_68                     -4.4618      0.824     -5.414      0.000      -6.077      -2.846\n",
      "topic_75                     -4.1049      0.804     -5.105      0.000      -5.681      -2.529\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.802870277561223\n",
      "Pr√§zision: 0.7438271604938271\n",
      "Recall: 0.6531165311653117\n",
      "F1-Score: 0.6955266955266955\n",
      "Brier-Score: 0.1799498314035293\n",
      "Confusion-Matrix:\n",
      "[[919 249]\n",
      " [384 723]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535685\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2240\n",
      "Model:                          Logit   Df Residuals:                     2199\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1505\n",
      "Time:                        11:10:00   Log-Likelihood:                -1199.9\n",
      "converged:                       True   LL-Null:                       -1412.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.257e-66\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.9281      0.531      1.747      0.081      -0.113       1.969\n",
      "issue attention Facebook      3.1203      1.719      1.815      0.070      -0.249       6.490\n",
      "issue attention Bundestag     1.6628      0.973      1.709      0.087      -0.244       3.570\n",
      "Social Media Nutzung         -0.0088      0.007     -1.286      0.199      -0.022       0.005\n",
      "Landtagswahlen               -0.2727      0.106     -2.577      0.010      -0.480      -0.065\n",
      "Komplexit√§t Reden            -0.2898      0.054     -5.409      0.000      -0.395      -0.185\n",
      "Komplexit√§t Posts             0.0343      0.103      0.334      0.738      -0.167       0.236\n",
      "topic_1                       0.2320      0.385      0.602      0.547      -0.523       0.988\n",
      "topic_2                       0.6116      0.405      1.509      0.131      -0.183       1.406\n",
      "topic_3                      -0.6816      0.371     -1.837      0.066      -1.409       0.046\n",
      "topic_4                      -0.4377      0.373     -1.175      0.240      -1.168       0.293\n",
      "topic_6                      -0.2135      0.376     -0.568      0.570      -0.951       0.524\n",
      "topic_7                       1.2531      0.446      2.813      0.005       0.380       2.126\n",
      "topic_8                      -0.8928      0.383     -2.332      0.020      -1.643      -0.142\n",
      "topic_10                      0.0255      0.384      0.066      0.947      -0.727       0.778\n",
      "topic_11                     -2.2097      0.461     -4.798      0.000      -3.112      -1.307\n",
      "topic_12                     -1.6296      0.408     -3.996      0.000      -2.429      -0.830\n",
      "topic_13                     -2.2323      0.459     -4.864      0.000      -3.132      -1.333\n",
      "topic_14                     -0.6998      0.385     -1.819      0.069      -1.454       0.054\n",
      "topic_15                     -1.6077      0.410     -3.926      0.000      -2.410      -0.805\n",
      "topic_16                     -1.4297      0.402     -3.558      0.000      -2.217      -0.642\n",
      "topic_17                     -2.3538      0.475     -4.957      0.000      -3.285      -1.423\n",
      "topic_18                     -1.4815      0.409     -3.626      0.000      -2.282      -0.681\n",
      "topic_19                     -1.1645      0.396     -2.944      0.003      -1.940      -0.389\n",
      "topic_20                     -1.6006      0.411     -3.899      0.000      -2.405      -0.796\n",
      "topic_21                     -1.7120      0.416     -4.112      0.000      -2.528      -0.896\n",
      "topic_22                     -1.5883      0.412     -3.852      0.000      -2.396      -0.780\n",
      "topic_23                     -1.8485      0.433     -4.270      0.000      -2.697      -1.000\n",
      "topic_24                     -1.5689      0.414     -3.792      0.000      -2.380      -0.758\n",
      "topic_25                     -1.0154      0.393     -2.585      0.010      -1.785      -0.246\n",
      "topic_29                     -1.0809      0.396     -2.731      0.006      -1.857      -0.305\n",
      "topic_30                     -1.9459      0.442     -4.399      0.000      -2.813      -1.079\n",
      "topic_34                     -1.5551      0.415     -3.745      0.000      -2.369      -0.741\n",
      "topic_36                     -1.8329      0.435     -4.216      0.000      -2.685      -0.981\n",
      "topic_37                     -1.5407      0.417     -3.697      0.000      -2.358      -0.724\n",
      "topic_40                     -1.8266      0.435     -4.203      0.000      -2.678      -0.975\n",
      "topic_41                     -1.9230      0.444     -4.333      0.000      -2.793      -1.053\n",
      "topic_43                     -1.7350      0.427     -4.062      0.000      -2.572      -0.898\n",
      "topic_54                     -2.3063      0.479     -4.811      0.000      -3.246      -1.367\n",
      "topic_68                     -2.3038      0.480     -4.804      0.000      -3.244      -1.364\n",
      "topic_75                     -1.2823      0.405     -3.163      0.002      -2.077      -0.488\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7490033940926797\n",
      "Pr√§zision: 0.6898876404494382\n",
      "Recall: 0.4217032967032967\n",
      "F1-Score: 0.5234441602728048\n",
      "Brier-Score: 0.17786030568890937\n",
      "Confusion-Matrix:\n",
      "[[1374  138]\n",
      " [ 421  307]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.528308\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2240\n",
      "Model:                          Logit   Df Residuals:                     2199\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2374\n",
      "Time:                        11:10:00   Log-Likelihood:                -1183.4\n",
      "converged:                       True   LL-Null:                       -1551.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.883e-129\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         3.0671      0.856      3.584      0.000       1.390       4.744\n",
      "issue attention Facebook     16.0066      2.490      6.430      0.000      11.127      20.886\n",
      "issue attention Bundestag     3.5034      1.319      2.656      0.008       0.918       6.089\n",
      "Social Media Nutzung         -0.0125      0.007     -1.842      0.065      -0.026       0.001\n",
      "Landtagswahlen               -0.0544      0.102     -0.533      0.594      -0.254       0.145\n",
      "Komplexit√§t Reden            -0.1018      0.052     -1.970      0.049      -0.203      -0.001\n",
      "Komplexit√§t Posts             0.2238      0.102      2.205      0.027       0.025       0.423\n",
      "topic_1                       0.6573      1.243      0.529      0.597      -1.780       3.094\n",
      "topic_2                      -1.4113      0.808     -1.747      0.081      -2.994       0.172\n",
      "topic_3                      -0.8044      0.867     -0.928      0.353      -2.503       0.894\n",
      "topic_4                       0.2076      1.023      0.203      0.839      -1.798       2.214\n",
      "topic_6                      -1.3819      0.795     -1.738      0.082      -2.941       0.177\n",
      "topic_7                      -2.4791      0.773     -3.205      0.001      -3.995      -0.963\n",
      "topic_8                      -2.1088      0.775     -2.722      0.006      -3.627      -0.590\n",
      "topic_10                     -2.2954      0.773     -2.971      0.003      -3.810      -0.781\n",
      "topic_11                     -2.3398      0.774     -3.025      0.002      -3.856      -0.824\n",
      "topic_12                     -2.3066      0.775     -2.976      0.003      -3.826      -0.787\n",
      "topic_13                     -1.9602      0.776     -2.525      0.012      -3.482      -0.439\n",
      "topic_14                     -2.8362      0.774     -3.666      0.000      -4.352      -1.320\n",
      "topic_15                     -1.9163      0.777     -2.465      0.014      -3.440      -0.393\n",
      "topic_16                     -2.4407      0.773     -3.159      0.002      -3.955      -0.926\n",
      "topic_17                     -2.7419      0.773     -3.549      0.000      -4.256      -1.227\n",
      "topic_18                     -2.3270      0.773     -3.012      0.003      -3.841      -0.813\n",
      "topic_19                     -2.4469      0.773     -3.167      0.002      -3.961      -0.933\n",
      "topic_20                     -3.5221      0.784     -4.492      0.000      -5.059      -1.985\n",
      "topic_21                     -2.4390      0.774     -3.153      0.002      -3.955      -0.923\n",
      "topic_22                     -2.4652      0.773     -3.189      0.001      -3.980      -0.950\n",
      "topic_23                     -2.9664      0.776     -3.822      0.000      -4.488      -1.445\n",
      "topic_24                     -3.0121      0.775     -3.885      0.000      -4.532      -1.493\n",
      "topic_25                     -2.9691      0.775     -3.829      0.000      -4.489      -1.449\n",
      "topic_29                     -3.4465      0.785     -4.392      0.000      -4.984      -1.909\n",
      "topic_30                     -3.3600      0.783     -4.289      0.000      -4.895      -1.825\n",
      "topic_34                     -3.2263      0.780     -4.137      0.000      -4.755      -1.698\n",
      "topic_36                     -3.7700      0.795     -4.739      0.000      -5.329      -2.211\n",
      "topic_37                     -3.7457      0.796     -4.708      0.000      -5.305      -2.186\n",
      "topic_40                     -3.3285      0.783     -4.248      0.000      -4.864      -1.793\n",
      "topic_41                     -3.9279      0.804     -4.884      0.000      -5.504      -2.352\n",
      "topic_43                     -4.1319      0.810     -5.102      0.000      -5.719      -2.545\n",
      "topic_54                     -4.4717      0.835     -5.354      0.000      -6.109      -2.835\n",
      "topic_68                     -4.3164      0.825     -5.231      0.000      -5.934      -2.699\n",
      "topic_75                     -3.9420      0.805     -4.898      0.000      -5.519      -2.365\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.8069054646988434\n",
      "Pr√§zision: 0.7484662576687117\n",
      "Recall: 0.671559633027523\n",
      "F1-Score: 0.7079303675048356\n",
      "Brier-Score: 0.17773366324210213\n",
      "Confusion-Matrix:\n",
      "[[904 246]\n",
      " [358 732]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536279\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2205\n",
      "Model:                          Logit   Df Residuals:                     2164\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1470\n",
      "Time:                        11:10:00   Log-Likelihood:                -1182.5\n",
      "converged:                       True   LL-Null:                       -1386.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.120e-62\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.7219      0.533      1.354      0.176      -0.323       1.767\n",
      "issue attention Facebook      5.8355      1.737      3.359      0.001       2.430       9.241\n",
      "issue attention Bundestag    -0.2271      0.936     -0.243      0.808      -2.062       1.608\n",
      "Social Media Nutzung         -0.0072      0.007     -1.059      0.290      -0.021       0.006\n",
      "Landtagswahlen               -0.1501      0.118     -1.273      0.203      -0.381       0.081\n",
      "Komplexit√§t Reden             0.1603      0.052      3.061      0.002       0.058       0.263\n",
      "Komplexit√§t Posts             0.2556      0.104      2.468      0.014       0.053       0.459\n",
      "topic_1                       0.1959      0.387      0.506      0.613      -0.563       0.954\n",
      "topic_2                       0.7062      0.406      1.740      0.082      -0.089       1.502\n",
      "topic_3                      -0.7590      0.373     -2.033      0.042      -1.491      -0.027\n",
      "topic_4                      -0.5486      0.375     -1.463      0.143      -1.283       0.186\n",
      "topic_6                      -0.1796      0.377     -0.476      0.634      -0.918       0.559\n",
      "topic_7                       1.3437      0.446      3.012      0.003       0.469       2.218\n",
      "topic_8                      -0.7602      0.383     -1.986      0.047      -1.511      -0.010\n",
      "topic_10                      0.1127      0.384      0.293      0.769      -0.640       0.866\n",
      "topic_11                     -2.1525      0.461     -4.672      0.000      -3.056      -1.249\n",
      "topic_12                     -1.6251      0.409     -3.972      0.000      -2.427      -0.823\n",
      "topic_13                     -2.1700      0.460     -4.722      0.000      -3.071      -1.269\n",
      "topic_14                     -0.6425      0.386     -1.664      0.096      -1.399       0.114\n",
      "topic_15                     -1.6346      0.415     -3.937      0.000      -2.448      -0.821\n",
      "topic_16                     -1.3764      0.402     -3.423      0.001      -2.165      -0.588\n",
      "topic_17                     -2.4340      0.493     -4.935      0.000      -3.401      -1.467\n",
      "topic_18                     -1.4093      0.409     -3.446      0.001      -2.211      -0.608\n",
      "topic_19                     -1.0894      0.396     -2.750      0.006      -1.866      -0.313\n",
      "topic_20                     -1.6332      0.417     -3.916      0.000      -2.450      -0.816\n",
      "topic_21                     -1.7200      0.422     -4.075      0.000      -2.547      -0.893\n",
      "topic_22                     -1.5849      0.418     -3.793      0.000      -2.404      -0.766\n",
      "topic_23                     -1.7512      0.433     -4.045      0.000      -2.600      -0.903\n",
      "topic_24                     -1.4713      0.414     -3.556      0.000      -2.282      -0.660\n",
      "topic_25                     -0.9118      0.393     -2.320      0.020      -1.682      -0.142\n",
      "topic_29                     -1.0418      0.398     -2.616      0.009      -1.822      -0.261\n",
      "topic_30                     -1.8382      0.442     -4.157      0.000      -2.705      -0.971\n",
      "topic_34                     -1.5473      0.421     -3.679      0.000      -2.372      -0.723\n",
      "topic_36                     -1.7179      0.435     -3.950      0.000      -2.570      -0.866\n",
      "topic_37                     -1.4326      0.417     -3.437      0.001      -2.250      -0.616\n",
      "topic_40                     -1.8358      0.443     -4.144      0.000      -2.704      -0.968\n",
      "topic_41                     -1.8292      0.444     -4.121      0.000      -2.699      -0.959\n",
      "topic_43                     -1.6325      0.427     -3.821      0.000      -2.470      -0.795\n",
      "topic_54                     -2.2034      0.479     -4.596      0.000      -3.143      -1.264\n",
      "topic_68                     -2.2011      0.480     -4.589      0.000      -3.141      -1.261\n",
      "topic_75                     -1.1861      0.406     -2.924      0.003      -1.981      -0.391\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7440309762255773\n",
      "Pr√§zision: 0.6804597701149425\n",
      "Recall: 0.41631504922644164\n",
      "F1-Score: 0.5165794066317626\n",
      "Brier-Score: 0.17746076554348134\n",
      "Confusion-Matrix:\n",
      "[[1355  139]\n",
      " [ 415  296]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538058\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2205\n",
      "Model:                          Logit   Df Residuals:                     2164\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2234\n",
      "Time:                        11:10:00   Log-Likelihood:                -1186.4\n",
      "converged:                       True   LL-Null:                       -1527.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.430e-118\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         3.1253      0.856      3.652      0.000       1.448       4.802\n",
      "issue attention Facebook      8.8853      2.230      3.985      0.000       4.515      13.256\n",
      "issue attention Bundestag     3.2918      1.272      2.588      0.010       0.799       5.784\n",
      "Social Media Nutzung         -0.0074      0.007     -1.084      0.278      -0.021       0.006\n",
      "Landtagswahlen               -0.0534      0.116     -0.462      0.644      -0.280       0.173\n",
      "Komplexit√§t Reden            -0.0007      0.052     -0.012      0.990      -0.103       0.102\n",
      "Komplexit√§t Posts             0.1177      0.103      1.144      0.253      -0.084       0.319\n",
      "topic_1                       0.7078      1.241      0.571      0.568      -1.724       3.140\n",
      "topic_2                      -1.5830      0.804     -1.968      0.049      -3.159      -0.007\n",
      "topic_3                      -0.8620      0.862     -1.000      0.317      -2.551       0.827\n",
      "topic_4                       0.1563      1.020      0.153      0.878      -1.843       2.156\n",
      "topic_6                      -1.5917      0.793     -2.008      0.045      -3.145      -0.038\n",
      "topic_7                      -2.6734      0.771     -3.467      0.001      -4.185      -1.162\n",
      "topic_8                      -2.3785      0.773     -3.077      0.002      -3.894      -0.863\n",
      "topic_10                     -2.5780      0.771     -3.342      0.001      -4.090      -1.066\n",
      "topic_11                     -2.6456      0.771     -3.431      0.001      -4.157      -1.134\n",
      "topic_12                     -2.4600      0.771     -3.189      0.001      -3.972      -0.948\n",
      "topic_13                     -2.1574      0.775     -2.783      0.005      -3.677      -0.638\n",
      "topic_14                     -3.1004      0.772     -4.015      0.000      -4.614      -1.587\n",
      "topic_15                     -2.1084      0.776     -2.717      0.007      -3.629      -0.587\n",
      "topic_16                     -2.6460      0.770     -3.436      0.001      -4.155      -1.137\n",
      "topic_17                     -2.9791      0.771     -3.866      0.000      -4.490      -1.469\n",
      "topic_18                     -2.6309      0.771     -3.412      0.001      -4.142      -1.120\n",
      "topic_19                     -2.6916      0.771     -3.490      0.000      -4.203      -1.180\n",
      "topic_20                     -3.8045      0.780     -4.879      0.000      -5.333      -2.276\n",
      "topic_21                     -2.7504      0.772     -3.565      0.000      -4.263      -1.238\n",
      "topic_22                     -2.7879      0.771     -3.615      0.000      -4.299      -1.277\n",
      "topic_23                     -3.2520      0.774     -4.199      0.000      -4.770      -1.734\n",
      "topic_24                     -3.2822      0.774     -4.242      0.000      -4.799      -1.766\n",
      "topic_25                     -3.3242      0.775     -4.290      0.000      -4.843      -1.805\n",
      "topic_29                     -3.8328      0.785     -4.881      0.000      -5.372      -2.294\n",
      "topic_30                     -3.6642      0.782     -4.687      0.000      -5.196      -2.132\n",
      "topic_34                     -3.5927      0.780     -4.608      0.000      -5.121      -2.065\n",
      "topic_36                     -4.0766      0.794     -5.132      0.000      -5.634      -2.520\n",
      "topic_37                     -4.0652      0.794     -5.118      0.000      -5.622      -2.508\n",
      "topic_40                     -3.6377      0.782     -4.652      0.000      -5.170      -2.105\n",
      "topic_41                     -4.2491      0.803     -5.292      0.000      -5.823      -2.675\n",
      "topic_43                     -4.4271      0.808     -5.481      0.000      -6.010      -2.844\n",
      "topic_54                     -4.7913      0.834     -5.747      0.000      -6.425      -3.157\n",
      "topic_68                     -4.6331      0.823     -5.627      0.000      -6.247      -3.019\n",
      "topic_75                     -4.2572      0.803     -5.302      0.000      -5.831      -2.684\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7986307662670599\n",
      "Pr√§zision: 0.7310344827586207\n",
      "Recall: 0.6908752327746741\n",
      "F1-Score: 0.7103877453326951\n",
      "Brier-Score: 0.18190751259058166\n",
      "Confusion-Matrix:\n",
      "[[858 273]\n",
      " [332 742]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539755\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2170\n",
      "Model:                          Logit   Df Residuals:                     2129\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1439\n",
      "Time:                        11:10:00   Log-Likelihood:                -1171.3\n",
      "converged:                       True   LL-Null:                       -1368.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.078e-59\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.1444      0.540     -2.121      0.034      -2.202      -0.087\n",
      "issue attention Facebook     -0.0738      1.721     -0.043      0.966      -3.447       3.299\n",
      "issue attention Bundestag     0.3321      0.958      0.346      0.729      -1.546       2.210\n",
      "Social Media Nutzung          0.0288      0.007      4.093      0.000       0.015       0.043\n",
      "Landtagswahlen                0.0096      0.130      0.074      0.941      -0.246       0.265\n",
      "Komplexit√§t Reden             0.1462      0.053      2.759      0.006       0.042       0.250\n",
      "Komplexit√§t Posts            -0.5149      0.106     -4.875      0.000      -0.722      -0.308\n",
      "topic_1                       0.1540      0.388      0.397      0.692      -0.607       0.915\n",
      "topic_2                       0.5642      0.412      1.369      0.171      -0.243       1.372\n",
      "topic_3                      -0.8035      0.374     -2.146      0.032      -1.537      -0.070\n",
      "topic_4                      -0.5987      0.376     -1.591      0.112      -1.336       0.139\n",
      "topic_6                      -0.4095      0.381     -1.075      0.283      -1.156       0.337\n",
      "topic_7                       0.9960      0.448      2.224      0.026       0.118       1.874\n",
      "topic_8                      -1.0738      0.387     -2.773      0.006      -1.833      -0.315\n",
      "topic_10                     -0.2080      0.390     -0.534      0.594      -0.972       0.556\n",
      "topic_11                     -2.4603      0.464     -5.304      0.000      -3.369      -1.551\n",
      "topic_12                     -1.8221      0.412     -4.426      0.000      -2.629      -1.015\n",
      "topic_13                     -2.4639      0.462     -5.330      0.000      -3.370      -1.558\n",
      "topic_14                     -1.0004      0.390     -2.562      0.010      -1.766      -0.235\n",
      "topic_15                     -1.9175      0.419     -4.580      0.000      -2.738      -1.097\n",
      "topic_16                     -1.6532      0.406     -4.074      0.000      -2.449      -0.858\n",
      "topic_17                     -2.7540      0.496     -5.554      0.000      -3.726      -1.782\n",
      "topic_18                     -1.7362      0.413     -4.208      0.000      -2.545      -0.927\n",
      "topic_19                     -1.4181      0.400     -3.546      0.000      -2.202      -0.634\n",
      "topic_20                     -1.9164      0.420     -4.563      0.000      -2.740      -1.093\n",
      "topic_21                     -2.0156      0.425     -4.738      0.000      -2.849      -1.182\n",
      "topic_22                     -1.9188      0.421     -4.553      0.000      -2.745      -1.093\n",
      "topic_23                     -2.1144      0.437     -4.842      0.000      -2.970      -1.258\n",
      "topic_24                     -1.8275      0.418     -4.376      0.000      -2.646      -1.009\n",
      "topic_25                     -1.3467      0.399     -3.375      0.001      -2.129      -0.565\n",
      "topic_29                     -1.4974      0.405     -3.699      0.000      -2.291      -0.704\n",
      "topic_30                     -2.2231      0.446     -4.985      0.000      -3.097      -1.349\n",
      "topic_34                     -1.9171      0.424     -4.518      0.000      -2.749      -1.085\n",
      "topic_36                     -2.1154      0.439     -4.822      0.000      -2.975      -1.256\n",
      "topic_37                     -1.8260      0.421     -4.340      0.000      -2.651      -1.001\n",
      "topic_40                     -2.2203      0.447     -4.970      0.000      -3.096      -1.345\n",
      "topic_41                     -2.2200      0.447     -4.964      0.000      -3.097      -1.344\n",
      "topic_43                     -2.0135      0.431     -4.675      0.000      -2.858      -1.169\n",
      "topic_54                     -2.6008      0.483     -5.388      0.000      -3.547      -1.655\n",
      "topic_68                     -2.6005      0.483     -5.383      0.000      -3.547      -1.654\n",
      "topic_75                     -1.5722      0.410     -3.838      0.000      -2.375      -0.769\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7417674823905309\n",
      "Pr√§zision: 0.68\n",
      "Recall: 0.4099290780141844\n",
      "F1-Score: 0.511504424778761\n",
      "Brier-Score: 0.17912349563472715\n",
      "Confusion-Matrix:\n",
      "[[1329  136]\n",
      " [ 416  289]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541906\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2170\n",
      "Model:                          Logit   Df Residuals:                     2129\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2179\n",
      "Time:                        11:10:00   Log-Likelihood:                -1175.9\n",
      "converged:                       True   LL-Null:                       -1503.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.946e-112\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         3.4389      0.854      4.027      0.000       1.765       5.113\n",
      "issue attention Facebook      6.4705      2.137      3.028      0.002       2.282      10.659\n",
      "issue attention Bundestag     1.4471      1.157      1.250      0.211      -0.821       3.715\n",
      "Social Media Nutzung         -0.0091      0.007     -1.335      0.182      -0.022       0.004\n",
      "Landtagswahlen                0.0274      0.127      0.215      0.830      -0.222       0.277\n",
      "Komplexit√§t Reden             0.0322      0.052      0.617      0.537      -0.070       0.135\n",
      "Komplexit√§t Posts             0.1207      0.101      1.194      0.232      -0.077       0.319\n",
      "topic_1                       0.6974      1.240      0.562      0.574      -1.733       3.127\n",
      "topic_2                      -1.6145      0.802     -2.013      0.044      -3.186      -0.043\n",
      "topic_3                      -0.9270      0.860     -1.078      0.281      -2.613       0.759\n",
      "topic_4                       0.0813      1.019      0.080      0.936      -1.917       2.079\n",
      "topic_6                      -1.5951      0.796     -2.003      0.045      -3.156      -0.034\n",
      "topic_7                      -2.7138      0.770     -3.523      0.000      -4.224      -1.204\n",
      "topic_8                      -2.5260      0.772     -3.271      0.001      -4.040      -1.012\n",
      "topic_10                     -2.7171      0.771     -3.525      0.000      -4.228      -1.206\n",
      "topic_11                     -2.8619      0.771     -3.711      0.000      -4.373      -1.350\n",
      "topic_12                     -2.5588      0.772     -3.314      0.001      -4.072      -1.046\n",
      "topic_13                     -2.3467      0.775     -3.028      0.002      -3.866      -0.828\n",
      "topic_14                     -3.3009      0.773     -4.273      0.000      -4.815      -1.787\n",
      "topic_15                     -2.2914      0.776     -2.954      0.003      -3.812      -0.771\n",
      "topic_16                     -2.7727      0.770     -3.599      0.000      -4.283      -1.263\n",
      "topic_17                     -3.1235      0.771     -4.052      0.000      -4.634      -1.613\n",
      "topic_18                     -2.7786      0.772     -3.600      0.000      -4.291      -1.266\n",
      "topic_19                     -2.9066      0.772     -3.767      0.000      -4.419      -1.394\n",
      "topic_20                     -4.0138      0.780     -5.143      0.000      -5.543      -2.484\n",
      "topic_21                     -2.8878      0.771     -3.746      0.000      -4.399      -1.377\n",
      "topic_22                     -2.9224      0.771     -3.790      0.000      -4.434      -1.411\n",
      "topic_23                     -3.4123      0.774     -4.406      0.000      -4.930      -1.894\n",
      "topic_24                     -3.4987      0.774     -4.518      0.000      -5.017      -1.981\n",
      "topic_25                     -3.4811      0.775     -4.491      0.000      -5.000      -1.962\n",
      "topic_29                     -3.9956      0.785     -5.088      0.000      -5.535      -2.456\n",
      "topic_30                     -3.8301      0.782     -4.900      0.000      -5.362      -2.298\n",
      "topic_34                     -3.8369      0.781     -4.911      0.000      -5.368      -2.306\n",
      "topic_36                     -4.2470      0.795     -5.345      0.000      -5.804      -2.690\n",
      "topic_37                     -4.2424      0.795     -5.339      0.000      -5.800      -2.685\n",
      "topic_40                     -3.8116      0.782     -4.872      0.000      -5.345      -2.278\n",
      "topic_41                     -4.4435      0.803     -5.533      0.000      -6.018      -2.869\n",
      "topic_43                     -4.5906      0.807     -5.686      0.000      -6.173      -3.008\n",
      "topic_54                     -4.9734      0.834     -5.964      0.000      -6.608      -3.339\n",
      "topic_68                     -4.8207      0.823     -5.855      0.000      -6.435      -3.207\n",
      "topic_75                     -4.4472      0.803     -5.538      0.000      -6.021      -2.873\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7926053228552317\n",
      "Pr√§zision: 0.7098943323727186\n",
      "Recall: 0.6978281397544853\n",
      "F1-Score: 0.7038095238095238\n",
      "Brier-Score: 0.18387376644606188\n",
      "Confusion-Matrix:\n",
      "[[809 302]\n",
      " [320 739]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529822\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2135\n",
      "Model:                          Logit   Df Residuals:                     2094\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1557\n",
      "Time:                        11:10:00   Log-Likelihood:                -1131.2\n",
      "converged:                       True   LL-Null:                       -1339.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.812e-64\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.5679      0.544      2.882      0.004       0.501       2.634\n",
      "issue attention Facebook     -0.4014      1.750     -0.229      0.819      -3.831       3.029\n",
      "issue attention Bundestag    -0.9553      0.976     -0.979      0.328      -2.868       0.957\n",
      "Social Media Nutzung         -0.0119      0.007     -1.709      0.087      -0.025       0.002\n",
      "Landtagswahlen               -0.2338      0.132     -1.774      0.076      -0.492       0.024\n",
      "Komplexit√§t Reden            -0.3685      0.056     -6.544      0.000      -0.479      -0.258\n",
      "Komplexit√§t Posts             0.2168      0.105      2.060      0.039       0.011       0.423\n",
      "topic_1                       0.1408      0.393      0.358      0.720      -0.630       0.911\n",
      "topic_2                       0.5783      0.415      1.392      0.164      -0.236       1.392\n",
      "topic_3                      -0.8673      0.381     -2.278      0.023      -1.613      -0.121\n",
      "topic_4                      -0.6882      0.383     -1.797      0.072      -1.439       0.062\n",
      "topic_6                      -0.4133      0.387     -1.067      0.286      -1.172       0.346\n",
      "topic_7                       1.0924      0.463      2.358      0.018       0.185       2.000\n",
      "topic_8                      -1.1016      0.392     -2.808      0.005      -1.871      -0.333\n",
      "topic_10                     -0.2772      0.395     -0.701      0.483      -1.052       0.497\n",
      "topic_11                     -2.7006      0.483     -5.588      0.000      -3.648      -1.753\n",
      "topic_12                     -1.9083      0.418     -4.570      0.000      -2.727      -1.090\n",
      "topic_13                     -2.5532      0.468     -5.456      0.000      -3.470      -1.636\n",
      "topic_14                     -1.1248      0.398     -2.828      0.005      -1.904      -0.345\n",
      "topic_15                     -2.0951      0.431     -4.864      0.000      -2.939      -1.251\n",
      "topic_16                     -1.7350      0.411     -4.218      0.000      -2.541      -0.929\n",
      "topic_17                     -3.0241      0.524     -5.772      0.000      -4.051      -1.997\n",
      "topic_18                     -1.8274      0.419     -4.365      0.000      -2.648      -1.007\n",
      "topic_19                     -1.5022      0.406     -3.699      0.000      -2.298      -0.706\n",
      "topic_20                     -2.0970      0.431     -4.865      0.000      -2.942      -1.252\n",
      "topic_21                     -2.1902      0.437     -5.006      0.000      -3.048      -1.333\n",
      "topic_22                     -2.0940      0.433     -4.838      0.000      -2.942      -1.246\n",
      "topic_23                     -2.3152      0.450     -5.144      0.000      -3.197      -1.433\n",
      "topic_24                     -2.0014      0.428     -4.671      0.000      -2.841      -1.162\n",
      "topic_25                     -1.4965      0.407     -3.678      0.000      -2.294      -0.699\n",
      "topic_29                     -1.6537      0.413     -4.000      0.000      -2.464      -0.843\n",
      "topic_30                     -2.3139      0.451     -5.129      0.000      -3.198      -1.430\n",
      "topic_34                     -2.0065      0.430     -4.670      0.000      -2.849      -1.164\n",
      "topic_36                     -2.3150      0.452     -5.119      0.000      -3.201      -1.429\n",
      "topic_37                     -2.0095      0.432     -4.656      0.000      -2.855      -1.164\n",
      "topic_40                     -2.3224      0.452     -5.136      0.000      -3.209      -1.436\n",
      "topic_41                     -2.3238      0.453     -5.133      0.000      -3.211      -1.436\n",
      "topic_43                     -2.1027      0.437     -4.813      0.000      -2.959      -1.247\n",
      "topic_54                     -2.8559      0.505     -5.650      0.000      -3.847      -1.865\n",
      "topic_68                     -2.7036      0.488     -5.543      0.000      -3.659      -1.748\n",
      "topic_75                     -1.6652      0.416     -4.008      0.000      -2.480      -0.851\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.752359426126353\n",
      "Pr√§zision: 0.6833333333333333\n",
      "Recall: 0.41897810218978104\n",
      "F1-Score: 0.5194570135746607\n",
      "Brier-Score: 0.17489904554909216\n",
      "Confusion-Matrix:\n",
      "[[1317  133]\n",
      " [ 398  287]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543627\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2135\n",
      "Model:                          Logit   Df Residuals:                     2094\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2154\n",
      "Time:                        11:10:01   Log-Likelihood:                -1160.6\n",
      "converged:                       True   LL-Null:                       -1479.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.237e-108\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.7061      0.853      3.171      0.002       1.034       4.379\n",
      "issue attention Facebook      5.7563      2.109      2.729      0.006       1.622       9.891\n",
      "issue attention Bundestag     0.2709      1.132      0.239      0.811      -1.948       2.489\n",
      "Social Media Nutzung          0.0043      0.007      0.626      0.531      -0.009       0.018\n",
      "Landtagswahlen                0.0045      0.128      0.035      0.972      -0.246       0.255\n",
      "Komplexit√§t Reden            -0.0239      0.053     -0.453      0.651      -0.127       0.079\n",
      "Komplexit√§t Posts            -0.0492      0.103     -0.479      0.632      -0.251       0.152\n",
      "topic_1                       0.6754      1.239      0.545      0.586      -1.754       3.105\n",
      "topic_2                      -1.6107      0.801     -2.011      0.044      -3.181      -0.041\n",
      "topic_3                      -0.9766      0.860     -1.136      0.256      -2.661       0.708\n",
      "topic_4                       0.0127      1.019      0.012      0.990      -1.985       2.011\n",
      "topic_6                      -1.6526      0.796     -2.075      0.038      -3.213      -0.092\n",
      "topic_7                      -2.6948      0.771     -3.497      0.000      -4.205      -1.185\n",
      "topic_8                      -2.5273      0.773     -3.269      0.001      -4.042      -1.012\n",
      "topic_10                     -2.7785      0.771     -3.603      0.000      -4.290      -1.267\n",
      "topic_11                     -2.9829      0.772     -3.863      0.000      -4.496      -1.469\n",
      "topic_12                     -2.5931      0.774     -3.352      0.001      -4.109      -1.077\n",
      "topic_13                     -2.4519      0.775     -3.162      0.002      -3.972      -0.932\n",
      "topic_14                     -3.3377      0.773     -4.317      0.000      -4.853      -1.822\n",
      "topic_15                     -2.3130      0.777     -2.975      0.003      -3.837      -0.789\n",
      "topic_16                     -2.8117      0.772     -3.644      0.000      -4.324      -1.299\n",
      "topic_17                     -3.2410      0.772     -4.199      0.000      -4.754      -1.728\n",
      "topic_18                     -2.8941      0.773     -3.745      0.000      -4.409      -1.379\n",
      "topic_19                     -3.0243      0.772     -3.915      0.000      -4.538      -1.510\n",
      "topic_20                     -4.1471      0.783     -5.298      0.000      -5.681      -2.613\n",
      "topic_21                     -2.9253      0.772     -3.791      0.000      -4.438      -1.413\n",
      "topic_22                     -2.9620      0.772     -3.837      0.000      -4.475      -1.449\n",
      "topic_23                     -3.4681      0.775     -4.474      0.000      -4.987      -1.949\n",
      "topic_24                     -3.5494      0.775     -4.580      0.000      -5.068      -2.030\n",
      "topic_25                     -3.5357      0.776     -4.558      0.000      -5.056      -2.015\n",
      "topic_29                     -4.1406      0.788     -5.254      0.000      -5.685      -2.596\n",
      "topic_30                     -3.8876      0.782     -4.969      0.000      -5.421      -2.354\n",
      "topic_34                     -3.8977      0.782     -4.984      0.000      -5.430      -2.365\n",
      "topic_36                     -4.3081      0.795     -5.419      0.000      -5.866      -2.750\n",
      "topic_37                     -4.3109      0.795     -5.422      0.000      -5.869      -2.752\n",
      "topic_40                     -3.8808      0.783     -4.955      0.000      -5.416      -2.346\n",
      "topic_41                     -4.5191      0.804     -5.623      0.000      -6.094      -2.944\n",
      "topic_43                     -4.6484      0.808     -5.755      0.000      -6.232      -3.065\n",
      "topic_54                     -5.0436      0.834     -6.045      0.000      -6.679      -3.408\n",
      "topic_68                     -4.8917      0.824     -5.937      0.000      -6.507      -3.277\n",
      "topic_75                     -4.6329      0.809     -5.726      0.000      -6.219      -3.047\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7911886174236438\n",
      "Pr√§zision: 0.7021883920076119\n",
      "Recall: 0.7068965517241379\n",
      "F1-Score: 0.7045346062052505\n",
      "Brier-Score: 0.18462824133573433\n",
      "Confusion-Matrix:\n",
      "[[778 313]\n",
      " [306 738]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536432\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2100\n",
      "Model:                          Logit   Df Residuals:                     2059\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1438\n",
      "Time:                        11:10:01   Log-Likelihood:                -1126.5\n",
      "converged:                       True   LL-Null:                       -1315.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.169e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.2823      0.549      0.515      0.607      -0.793       1.357\n",
      "issue attention Facebook      2.7837      1.732      1.608      0.108      -0.610       6.177\n",
      "issue attention Bundestag    -0.8594      0.975     -0.882      0.378      -2.769       1.051\n",
      "Social Media Nutzung          0.0032      0.007      0.453      0.651      -0.011       0.017\n",
      "Landtagswahlen                0.0349      0.131      0.267      0.790      -0.221       0.291\n",
      "Komplexit√§t Reden             0.1292      0.053      2.433      0.015       0.025       0.233\n",
      "Komplexit√§t Posts             0.0143      0.107      0.134      0.893      -0.195       0.224\n",
      "topic_1                       0.1994      0.393      0.508      0.612      -0.571       0.969\n",
      "topic_2                       0.6505      0.413      1.577      0.115      -0.158       1.459\n",
      "topic_3                      -0.8723      0.379     -2.302      0.021      -1.615      -0.130\n",
      "topic_4                      -0.6780      0.381     -1.782      0.075      -1.424       0.068\n",
      "topic_6                      -0.2741      0.384     -0.715      0.475      -1.026       0.478\n",
      "topic_7                       1.3737      0.475      2.893      0.004       0.443       2.304\n",
      "topic_8                      -0.9200      0.389     -2.364      0.018      -1.683      -0.157\n",
      "topic_10                     -0.0863      0.391     -0.221      0.825      -0.852       0.680\n",
      "topic_11                     -2.4221      0.479     -5.059      0.000      -3.361      -1.484\n",
      "topic_12                     -1.6934      0.413     -4.101      0.000      -2.503      -0.884\n",
      "topic_13                     -2.2849      0.463     -4.937      0.000      -3.192      -1.378\n",
      "topic_14                     -0.8386      0.393     -2.135      0.033      -1.608      -0.069\n",
      "topic_15                     -1.8358      0.425     -4.317      0.000      -2.669      -1.002\n",
      "topic_16                     -1.4823      0.407     -3.644      0.000      -2.279      -0.685\n",
      "topic_17                     -2.9394      0.550     -5.341      0.000      -4.018      -1.861\n",
      "topic_18                     -1.6330      0.418     -3.906      0.000      -2.453      -0.814\n",
      "topic_19                     -1.2228      0.401     -3.049      0.002      -2.009      -0.437\n",
      "topic_20                     -1.9378      0.433     -4.476      0.000      -2.786      -1.089\n",
      "topic_21                     -2.0340      0.441     -4.615      0.000      -2.898      -1.170\n",
      "topic_22                     -1.8094      0.428     -4.229      0.000      -2.648      -0.971\n",
      "topic_23                     -2.0095      0.445     -4.512      0.000      -2.882      -1.137\n",
      "topic_24                     -1.7060      0.423     -4.034      0.000      -2.535      -0.877\n",
      "topic_25                     -1.2796      0.405     -3.163      0.002      -2.073      -0.487\n",
      "topic_29                     -1.3504      0.408     -3.306      0.001      -2.151      -0.550\n",
      "topic_30                     -2.1143      0.456     -4.639      0.000      -3.008      -1.221\n",
      "topic_34                     -1.7019      0.425     -4.006      0.000      -2.535      -0.869\n",
      "topic_36                     -1.9920      0.447     -4.455      0.000      -2.868      -1.116\n",
      "topic_37                     -1.6911      0.426     -3.966      0.000      -2.527      -0.855\n",
      "topic_40                     -2.0050      0.447     -4.483      0.000      -2.882      -1.128\n",
      "topic_41                     -2.0032      0.448     -4.473      0.000      -2.881      -1.126\n",
      "topic_43                     -1.7903      0.431     -4.153      0.000      -2.635      -0.945\n",
      "topic_54                     -2.5280      0.501     -5.048      0.000      -3.509      -1.547\n",
      "topic_68                     -2.3759      0.483     -4.919      0.000      -3.323      -1.429\n",
      "topic_75                     -1.4327      0.414     -3.462      0.001      -2.244      -0.622\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7418379553198123\n",
      "Pr√§zision: 0.6819338422391857\n",
      "Recall: 0.39940387481371087\n",
      "F1-Score: 0.5037593984962406\n",
      "Brier-Score: 0.1779456262906332\n",
      "Confusion-Matrix:\n",
      "[[1304  125]\n",
      " [ 403  268]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541479\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2100\n",
      "Model:                          Logit   Df Residuals:                     2059\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2186\n",
      "Time:                        11:10:01   Log-Likelihood:                -1137.1\n",
      "converged:                       True   LL-Null:                       -1455.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.318e-108\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         3.1439      0.860      3.655      0.000       1.458       4.830\n",
      "issue attention Facebook      6.6086      2.160      3.060      0.002       2.376      10.841\n",
      "issue attention Bundestag     0.9521      1.165      0.817      0.414      -1.331       3.236\n",
      "Social Media Nutzung         -0.0045      0.007     -0.646      0.518      -0.018       0.009\n",
      "Landtagswahlen                0.0157      0.129      0.122      0.903      -0.237       0.269\n",
      "Komplexit√§t Reden            -0.0741      0.053     -1.403      0.161      -0.178       0.029\n",
      "Komplexit√§t Posts             0.0552      0.105      0.524      0.600      -0.151       0.262\n",
      "topic_1                       0.6868      1.240      0.554      0.580      -1.744       3.117\n",
      "topic_2                      -1.5979      0.802     -1.992      0.046      -3.170      -0.025\n",
      "topic_3                      -0.9635      0.861     -1.119      0.263      -2.651       0.724\n",
      "topic_4                       0.0474      1.020      0.046      0.963      -1.952       2.047\n",
      "topic_6                      -1.5000      0.802     -1.870      0.062      -3.073       0.073\n",
      "topic_7                      -2.5902      0.773     -3.353      0.001      -4.104      -1.076\n",
      "topic_8                      -2.4836      0.774     -3.209      0.001      -4.000      -0.967\n",
      "topic_10                     -2.6708      0.773     -3.457      0.001      -4.185      -1.157\n",
      "topic_11                     -2.9172      0.773     -3.773      0.000      -4.433      -1.402\n",
      "topic_12                     -2.4603      0.776     -3.172      0.002      -3.980      -0.940\n",
      "topic_13                     -2.3143      0.777     -2.978      0.003      -3.838      -0.791\n",
      "topic_14                     -3.2212      0.774     -4.162      0.000      -4.738      -1.704\n",
      "topic_15                     -2.2513      0.778     -2.893      0.004      -3.777      -0.726\n",
      "topic_16                     -2.7508      0.773     -3.561      0.000      -4.265      -1.237\n",
      "topic_17                     -3.1860      0.773     -4.122      0.000      -4.701      -1.671\n",
      "topic_18                     -2.8284      0.774     -3.656      0.000      -4.345      -1.312\n",
      "topic_19                     -2.8948      0.773     -3.743      0.000      -4.411      -1.379\n",
      "topic_20                     -4.1346      0.786     -5.262      0.000      -5.675      -2.595\n",
      "topic_21                     -2.8685      0.773     -3.712      0.000      -4.383      -1.354\n",
      "topic_22                     -2.8366      0.773     -3.669      0.000      -4.352      -1.321\n",
      "topic_23                     -3.3398      0.776     -4.304      0.000      -4.861      -1.819\n",
      "topic_24                     -3.4323      0.776     -4.425      0.000      -4.952      -1.912\n",
      "topic_25                     -3.4151      0.776     -4.399      0.000      -4.937      -1.894\n",
      "topic_29                     -4.0236      0.789     -5.102      0.000      -5.569      -2.478\n",
      "topic_30                     -3.8469      0.785     -4.903      0.000      -5.385      -2.309\n",
      "topic_34                     -3.7769      0.782     -4.827      0.000      -5.311      -2.243\n",
      "topic_36                     -4.1879      0.795     -5.265      0.000      -5.747      -2.629\n",
      "topic_37                     -4.2896      0.799     -5.367      0.000      -5.856      -2.723\n",
      "topic_40                     -3.8341      0.785     -4.882      0.000      -5.373      -2.295\n",
      "topic_41                     -4.3918      0.804     -5.461      0.000      -5.968      -2.816\n",
      "topic_43                     -4.5315      0.808     -5.607      0.000      -6.115      -2.947\n",
      "topic_54                     -4.9217      0.835     -5.896      0.000      -6.558      -3.286\n",
      "topic_68                     -4.7709      0.824     -5.788      0.000      -6.386      -3.155\n",
      "topic_75                     -4.5080      0.809     -5.569      0.000      -6.095      -2.921\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7936999099831582\n",
      "Pr√§zision: 0.7091633466135459\n",
      "Recall: 0.6926070038910506\n",
      "F1-Score: 0.7007874015748031\n",
      "Brier-Score: 0.18348785503715886\n",
      "Confusion-Matrix:\n",
      "[[780 292]\n",
      " [316 712]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537148\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2065\n",
      "Model:                          Logit   Df Residuals:                     2024\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1447\n",
      "Time:                        11:10:01   Log-Likelihood:                -1109.2\n",
      "converged:                       True   LL-Null:                       -1296.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.459e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.4026      0.559      0.721      0.471      -0.693       1.498\n",
      "issue attention Facebook     -0.0466      1.750     -0.027      0.979      -3.477       3.384\n",
      "issue attention Bundestag    -0.6062      0.986     -0.615      0.539      -2.538       1.326\n",
      "Social Media Nutzung          0.0038      0.007      0.518      0.604      -0.011       0.018\n",
      "Landtagswahlen                0.0418      0.131      0.319      0.749      -0.215       0.298\n",
      "Komplexit√§t Reden             0.1541      0.054      2.861      0.004       0.049       0.260\n",
      "Komplexit√§t Posts            -0.1345      0.109     -1.233      0.218      -0.348       0.079\n",
      "topic_1                       0.3039      0.397      0.765      0.445      -0.475       1.083\n",
      "topic_2                       0.6782      0.419      1.617      0.106      -0.144       1.500\n",
      "topic_3                      -0.7868      0.380     -2.069      0.039      -1.532      -0.041\n",
      "topic_4                      -0.5967      0.382     -1.562      0.118      -1.346       0.152\n",
      "topic_6                      -0.3802      0.386     -0.986      0.324      -1.136       0.375\n",
      "topic_7                       1.2505      0.476      2.627      0.009       0.317       2.184\n",
      "topic_8                      -1.0026      0.392     -2.559      0.011      -1.771      -0.235\n",
      "topic_10                     -0.2395      0.394     -0.609      0.543      -1.011       0.532\n",
      "topic_11                     -2.5101      0.481     -5.221      0.000      -3.452      -1.568\n",
      "topic_12                     -1.7280      0.415     -4.168      0.000      -2.541      -0.915\n",
      "topic_13                     -2.3654      0.464     -5.093      0.000      -3.276      -1.455\n",
      "topic_14                     -0.9443      0.396     -2.387      0.017      -1.720      -0.169\n",
      "topic_15                     -2.0126      0.434     -4.635      0.000      -2.864      -1.162\n",
      "topic_16                     -1.5537      0.409     -3.798      0.000      -2.355      -0.752\n",
      "topic_17                     -3.0340      0.552     -5.497      0.000      -4.116      -1.952\n",
      "topic_18                     -1.7291      0.420     -4.113      0.000      -2.553      -0.905\n",
      "topic_19                     -1.3177      0.404     -3.264      0.001      -2.109      -0.526\n",
      "topic_20                     -2.0154      0.435     -4.629      0.000      -2.869      -1.162\n",
      "topic_21                     -2.1208      0.444     -4.780      0.000      -2.990      -1.251\n",
      "topic_22                     -1.9101      0.430     -4.440      0.000      -2.753      -1.067\n",
      "topic_23                     -2.1253      0.448     -4.746      0.000      -3.003      -1.248\n",
      "topic_24                     -1.8141      0.425     -4.266      0.000      -2.648      -0.981\n",
      "topic_25                     -1.3901      0.407     -3.415      0.001      -2.188      -0.592\n",
      "topic_29                     -1.4689      0.411     -3.575      0.000      -2.274      -0.664\n",
      "topic_30                     -2.2404      0.458     -4.889      0.000      -3.139      -1.342\n",
      "topic_34                     -1.8181      0.427     -4.255      0.000      -2.655      -0.981\n",
      "topic_36                     -2.2418      0.459     -4.882      0.000      -3.142      -1.342\n",
      "topic_37                     -1.8185      0.429     -4.241      0.000      -2.659      -0.978\n",
      "topic_40                     -2.1291      0.449     -4.738      0.000      -3.010      -1.248\n",
      "topic_41                     -2.1301      0.450     -4.731      0.000      -3.013      -1.248\n",
      "topic_43                     -2.0151      0.440     -4.576      0.000      -2.878      -1.152\n",
      "topic_54                     -2.6613      0.503     -5.291      0.000      -3.647      -1.676\n",
      "topic_68                     -2.5080      0.485     -5.168      0.000      -3.459      -1.557\n",
      "topic_75                     -1.5573      0.417     -3.739      0.000      -2.374      -0.741\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7418206014636705\n",
      "Pr√§zision: 0.6810126582278481\n",
      "Recall: 0.40512048192771083\n",
      "F1-Score: 0.5080264400377715\n",
      "Brier-Score: 0.17821821209468913\n",
      "Confusion-Matrix:\n",
      "[[1275  126]\n",
      " [ 395  269]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538953\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2065\n",
      "Model:                          Logit   Df Residuals:                     2024\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2222\n",
      "Time:                        11:10:01   Log-Likelihood:                -1112.9\n",
      "converged:                       True   LL-Null:                       -1430.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.708e-108\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.1447      0.861      2.492      0.013       0.458       3.832\n",
      "issue attention Facebook      7.2295      2.203      3.282      0.001       2.912      11.547\n",
      "issue attention Bundestag     1.1690      1.182      0.989      0.323      -1.148       3.486\n",
      "Social Media Nutzung          0.0102      0.007      1.435      0.151      -0.004       0.024\n",
      "Landtagswahlen                0.1050      0.130      0.811      0.418      -0.149       0.359\n",
      "Komplexit√§t Reden             0.0698      0.053      1.309      0.191      -0.035       0.174\n",
      "Komplexit√§t Posts            -0.1532      0.108     -1.424      0.155      -0.364       0.058\n",
      "topic_1                       0.6761      1.241      0.545      0.586      -1.756       3.108\n",
      "topic_2                      -1.5858      0.804     -1.973      0.048      -3.161      -0.011\n",
      "topic_3                      -0.9900      0.861     -1.149      0.250      -2.678       0.698\n",
      "topic_4                       0.0400      1.021      0.039      0.969      -1.960       2.040\n",
      "topic_6                      -1.4908      0.803     -1.856      0.063      -3.065       0.083\n",
      "topic_7                      -2.5126      0.775     -3.243      0.001      -4.031      -0.994\n",
      "topic_8                      -2.4015      0.776     -3.096      0.002      -3.922      -0.881\n",
      "topic_10                     -2.5913      0.774     -3.347      0.001      -4.109      -1.074\n",
      "topic_11                     -2.9042      0.774     -3.752      0.000      -4.421      -1.387\n",
      "topic_12                     -2.3746      0.777     -3.055      0.002      -3.898      -0.851\n",
      "topic_13                     -2.2202      0.779     -2.849      0.004      -3.747      -0.693\n",
      "topic_14                     -3.2169      0.775     -4.149      0.000      -4.736      -1.697\n",
      "topic_15                     -2.2358      0.779     -2.871      0.004      -3.762      -0.709\n",
      "topic_16                     -2.6711      0.774     -3.453      0.001      -4.187      -1.155\n",
      "topic_17                     -3.1124      0.774     -4.023      0.000      -4.629      -1.596\n",
      "topic_18                     -2.8127      0.774     -3.632      0.000      -4.331      -1.295\n",
      "topic_19                     -2.8793      0.774     -3.718      0.000      -4.397      -1.362\n",
      "topic_20                     -4.1675      0.789     -5.282      0.000      -5.714      -2.621\n",
      "topic_21                     -2.8616      0.774     -3.698      0.000      -4.378      -1.345\n",
      "topic_22                     -2.8232      0.774     -3.647      0.000      -4.340      -1.306\n",
      "topic_23                     -3.2595      0.777     -4.196      0.000      -4.782      -1.737\n",
      "topic_24                     -3.3612      0.776     -4.329      0.000      -4.883      -1.840\n",
      "topic_25                     -3.4129      0.778     -4.389      0.000      -4.937      -1.889\n",
      "topic_29                     -4.0460      0.792     -5.110      0.000      -5.598      -2.494\n",
      "topic_30                     -3.7727      0.785     -4.805      0.000      -5.312      -2.234\n",
      "topic_34                     -3.7856      0.785     -4.824      0.000      -5.324      -2.248\n",
      "topic_36                     -4.1137      0.796     -5.167      0.000      -5.674      -2.553\n",
      "topic_37                     -4.2188      0.800     -5.275      0.000      -5.786      -2.651\n",
      "topic_40                     -3.8437      0.788     -4.879      0.000      -5.388      -2.299\n",
      "topic_41                     -4.3154      0.805     -5.362      0.000      -5.893      -2.738\n",
      "topic_43                     -4.4649      0.809     -5.521      0.000      -6.050      -2.880\n",
      "topic_54                     -4.8533      0.835     -5.812      0.000      -6.490      -3.217\n",
      "topic_68                     -4.8517      0.835     -5.809      0.000      -6.489      -3.215\n",
      "topic_75                     -4.4326      0.810     -5.473      0.000      -6.020      -2.845\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.797240554704628\n",
      "Pr√§zision: 0.7193717277486911\n",
      "Recall: 0.6808721506442021\n",
      "F1-Score: 0.6995926680244399\n",
      "Brier-Score: 0.18229132173994492\n",
      "Confusion-Matrix:\n",
      "[[788 268]\n",
      " [322 687]]\n"
     ]
    }
   ],
   "source": [
    "# Mastertabelle aggregierte Daten\n",
    "# Liste zur Speicherung der Modelle und der zugeh√∂rigen Lag-Beschriftungen\n",
    "models = []\n",
    "lag_labels = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):\n",
    "    model1, auc_roc1, f1_1 = log_reg_FE_control_test(\n",
    "        rede_relativ_reduced, post_relativ_reduced, rede_common, lag, \n",
    "        social_media_usage, rede_komplex, posts_komplex\n",
    "    )\n",
    "    \n",
    "    model2, auc_roc2, f1_2 = log_reg_FE_control_test(\n",
    "        rede_relativ_reduced, post_relativ_reduced, post_common, lag, \n",
    "        social_media_usage, rede_komplex, posts_komplex\n",
    "    )\n",
    "\n",
    "    # Modelle und Lag-Beschriftung speichern\n",
    "    models.extend([model1, model2])\n",
    "    lag_labels.extend([f\"Lag {lag} - Bundestag\", f\"Lag {lag} - Facebook\"])\n",
    "\n",
    "# Eine einzige Stargazer-Tabelle mit allen Lags erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Aggregierter Vergleich f√ºr alle Lags\")\n",
    "stargazer.custom_columns(lag_labels, [1] * len(lag_labels))\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung Aggregiert\")\n",
    "\n",
    "# AUC-ROC und F1-Score f√ºr jedes Lag als Notizen hinzuf√ºgen\n",
    "custom_notes = [\n",
    "    f\"Lag {lag}: Modell 1 (Bundestag) - AUC-ROC = {auc_roc1:.3f}, F1-Score = {f1_1:.3f}; \"\n",
    "    f\"Modell 2 (Facebook) - AUC-ROC = {auc_roc2:.3f}, F1-Score = {f1_2:.3f}\"\n",
    "    for lag in range(1, 8)\n",
    "]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# HTML-Datei speichern\n",
    "filename = \"regression tables/regression_table_comparison_agg_all_lags.html\"\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608104\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  295\n",
      "Model:                          Logit   Df Residuals:                      286\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.03229\n",
      "Time:                        11:37:50   Log-Likelihood:                -179.39\n",
      "converged:                       True   LL-Null:                       -185.38\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1525\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4501      0.392     -1.148      0.251      -1.219       0.319\n",
      "issue attention Facebook      0.0563      0.585      0.096      0.923      -1.090       1.203\n",
      "issue attention Bundestag    -2.1475      1.053     -2.039      0.041      -4.212      -0.083\n",
      "Social Media Nutzung          0.1148      0.113      1.016      0.310      -0.107       0.336\n",
      "Landtagswahlen                0.1167      0.236      0.494      0.621      -0.346       0.580\n",
      "topic_1                      -0.3385      0.384     -0.882      0.378      -1.091       0.414\n",
      "topic_2                      -0.6198      0.396     -1.564      0.118      -1.397       0.157\n",
      "topic_6                      -0.5805      0.393     -1.479      0.139      -1.350       0.189\n",
      "topic_8                      -0.9244      0.410     -2.253      0.024      -1.729      -0.120\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6239473684210526\n",
      "Pr√§zision: 0.5555555555555556\n",
      "Recall: 0.05263157894736842\n",
      "F1-Score: 0.09615384615384616\n",
      "Brier-Score: 0.20933688466662081\n",
      "Confusion-Matrix:\n",
      "[[196   4]\n",
      " [ 90   5]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.379926\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  295\n",
      "Model:                          Logit   Df Residuals:                      286\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.04272\n",
      "Time:                        11:37:50   Log-Likelihood:                -112.08\n",
      "converged:                       True   LL-Null:                       -117.08\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2647\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.7960      0.581     -4.817      0.000      -3.934      -1.658\n",
      "issue attention Facebook     -1.2538      1.001     -1.253      0.210      -3.215       0.708\n",
      "issue attention Bundestag     1.1382      0.948      1.200      0.230      -0.720       2.997\n",
      "Social Media Nutzung          0.2526      0.148      1.712      0.087      -0.037       0.542\n",
      "Landtagswahlen                0.2246      0.292      0.769      0.442      -0.348       0.797\n",
      "topic_1                       0.0210      0.576      0.037      0.971      -1.108       1.150\n",
      "topic_2                       0.7175      0.526      1.363      0.173      -0.314       1.749\n",
      "topic_6                       0.1816      0.561      0.324      0.746      -0.917       1.280\n",
      "topic_8                      -0.1870      0.596     -0.314      0.754      -1.355       0.981\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6389705882352942\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.11303858082276579\n",
      "Confusion-Matrix:\n",
      "[[255   0]\n",
      " [ 40   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.609307\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  290\n",
      "Model:                          Logit   Df Residuals:                      281\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.02475\n",
      "Time:                        11:37:50   Log-Likelihood:                -176.70\n",
      "converged:                       True   LL-Null:                       -181.18\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3448\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4120      0.393     -1.049      0.294      -1.182       0.358\n",
      "issue attention Facebook      0.2795      0.545      0.513      0.608      -0.789       1.348\n",
      "issue attention Bundestag     1.3536      0.774      1.750      0.080      -0.162       2.870\n",
      "Social Media Nutzung         -0.0400      0.113     -0.354      0.724      -0.262       0.182\n",
      "Landtagswahlen                0.0563      0.261      0.216      0.829      -0.455       0.568\n",
      "topic_1                      -0.2587      0.386     -0.670      0.503      -1.015       0.498\n",
      "topic_2                      -0.4710      0.395     -1.193      0.233      -1.245       0.303\n",
      "topic_6                      -0.5063      0.396     -1.280      0.201      -1.282       0.269\n",
      "topic_8                      -0.8764      0.416     -2.107      0.035      -1.692      -0.061\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6057037768994291\n",
      "Pr√§zision: 0.5\n",
      "Recall: 0.043478260869565216\n",
      "F1-Score: 0.08\n",
      "Brier-Score: 0.20994536534377195\n",
      "Confusion-Matrix:\n",
      "[[194   4]\n",
      " [ 88   4]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.375681\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  290\n",
      "Model:                          Logit   Df Residuals:                      281\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.04848\n",
      "Time:                        11:37:50   Log-Likelihood:                -108.95\n",
      "converged:                       True   LL-Null:                       -114.50\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1960\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.9032      0.605     -4.800      0.000      -4.089      -1.718\n",
      "issue attention Facebook      1.3562      0.608      2.231      0.026       0.165       2.548\n",
      "issue attention Bundestag     0.8634      1.004      0.860      0.390      -1.104       2.831\n",
      "Social Media Nutzung          0.1947      0.147      1.321      0.187      -0.094       0.484\n",
      "Landtagswahlen               -0.0485      0.344     -0.141      0.888      -0.723       0.626\n",
      "topic_1                       0.2444      0.599      0.408      0.683      -0.929       1.417\n",
      "topic_2                       0.7180      0.553      1.298      0.194      -0.366       1.802\n",
      "topic_6                       0.3889      0.584      0.666      0.505      -0.755       1.533\n",
      "topic_8                       0.0927      0.619      0.150      0.881      -1.120       1.305\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6457247931351517\n",
      "Pr√§zision: 1.0\n",
      "Recall: 0.02564102564102564\n",
      "F1-Score: 0.05\n",
      "Brier-Score: 0.11107569056199423\n",
      "Confusion-Matrix:\n",
      "[[251   0]\n",
      " [ 38   1]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.616955\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  285\n",
      "Model:                          Logit   Df Residuals:                      276\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.02309\n",
      "Time:                        11:37:50   Log-Likelihood:                -175.83\n",
      "converged:                       True   LL-Null:                       -179.99\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4035\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1745      0.394     -0.442      0.658      -0.947       0.598\n",
      "issue attention Facebook      0.1293      0.555      0.233      0.816      -0.959       1.218\n",
      "issue attention Bundestag     1.2997      0.777      1.672      0.095      -0.224       2.823\n",
      "Social Media Nutzung         -0.1085      0.114     -0.952      0.341      -0.332       0.115\n",
      "Landtagswahlen               -0.0163      0.295     -0.055      0.956      -0.594       0.561\n",
      "topic_1                      -0.2712      0.389     -0.698      0.485      -1.033       0.490\n",
      "topic_2                      -0.5508      0.399     -1.379      0.168      -1.333       0.232\n",
      "topic_6                      -0.4389      0.394     -1.113      0.266      -1.212       0.334\n",
      "topic_8                      -0.7983      0.412     -1.938      0.053      -1.606       0.009\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5910338261648745\n",
      "Pr√§zision: 0.7777777777777778\n",
      "Recall: 0.07526881720430108\n",
      "F1-Score: 0.13725490196078433\n",
      "Brier-Score: 0.2129343839271174\n",
      "Confusion-Matrix:\n",
      "[[190   2]\n",
      " [ 86   7]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.381776\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  285\n",
      "Model:                          Logit   Df Residuals:                      276\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.02775\n",
      "Time:                        11:37:50   Log-Likelihood:                -108.81\n",
      "converged:                       True   LL-Null:                       -111.91\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6235\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.2343      0.589     -3.796      0.000      -3.388      -1.081\n",
      "issue attention Facebook     -0.0765      0.736     -0.104      0.917      -1.518       1.365\n",
      "issue attention Bundestag     0.5916      1.042      0.568      0.570      -1.451       2.634\n",
      "Social Media Nutzung          0.0572      0.152      0.375      0.708      -0.242       0.356\n",
      "Landtagswahlen               -0.5862      0.479     -1.225      0.221      -1.524       0.352\n",
      "topic_1                       0.1879      0.593      0.317      0.752      -0.975       1.351\n",
      "topic_2                       0.8306      0.544      1.527      0.127      -0.236       1.897\n",
      "topic_6                       0.3437      0.578      0.595      0.552      -0.789       1.477\n",
      "topic_8                      -0.2030      0.640     -0.317      0.751      -1.456       1.050\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.625506072874494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.11344598916471275\n",
      "Confusion-Matrix:\n",
      "[[247   0]\n",
      " [ 38   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.613708\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  280\n",
      "Model:                          Logit   Df Residuals:                      271\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        11:37:50   Log-Likelihood:                -171.84\n",
      "converged:                       True   LL-Null:                       -176.56\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3059\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1153      0.411      0.280      0.779      -0.691       0.922\n",
      "issue attention Facebook     -0.1309      0.599     -0.219      0.827      -1.304       1.042\n",
      "issue attention Bundestag    -1.7406      1.017     -1.712      0.087      -3.734       0.252\n",
      "Social Media Nutzung         -0.1293      0.120     -1.080      0.280      -0.364       0.105\n",
      "Landtagswahlen                0.0001      0.342      0.000      1.000      -0.670       0.670\n",
      "topic_1                      -0.2652      0.393     -0.675      0.500      -1.036       0.505\n",
      "topic_2                      -0.4967      0.404     -1.230      0.219      -1.288       0.294\n",
      "topic_6                      -0.4268      0.399     -1.070      0.285      -1.209       0.355\n",
      "topic_8                      -0.8858      0.423     -2.095      0.036      -1.714      -0.057\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5920983778126635\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.21307131289439435\n",
      "Confusion-Matrix:\n",
      "[[189   0]\n",
      " [ 91   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.381740\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  280\n",
      "Model:                          Logit   Df Residuals:                      271\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.03870\n",
      "Time:                        11:37:50   Log-Likelihood:                -106.89\n",
      "converged:                       True   LL-Null:                       -111.19\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3767\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.8428      0.593     -3.106      0.002      -3.006      -0.680\n",
      "issue attention Facebook      0.3617      0.665      0.544      0.587      -0.942       1.666\n",
      "issue attention Bundestag     0.3932      1.081      0.364      0.716      -1.725       2.511\n",
      "Social Media Nutzung         -0.0915      0.162     -0.565      0.572      -0.409       0.226\n",
      "Landtagswahlen               -1.0237      0.629     -1.628      0.104      -2.256       0.209\n",
      "topic_1                       0.1963      0.596      0.329      0.742      -0.972       1.364\n",
      "topic_2                       0.8125      0.547      1.485      0.138      -0.260       1.885\n",
      "topic_6                       0.3496      0.581      0.602      0.547      -0.789       1.488\n",
      "topic_8                      -0.1792      0.642     -0.279      0.780      -1.437       1.079\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6440300130491519\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.11370889701446807\n",
      "Confusion-Matrix:\n",
      "[[242   0]\n",
      " [ 38   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.627850\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  275\n",
      "Model:                          Logit   Df Residuals:                      266\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.01491\n",
      "Time:                        11:37:50   Log-Likelihood:                -172.66\n",
      "converged:                       True   LL-Null:                       -175.27\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7332\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3287      0.407     -0.808      0.419      -1.126       0.469\n",
      "issue attention Facebook      0.1943      0.574      0.339      0.735      -0.930       1.319\n",
      "issue attention Bundestag    -1.2299      0.973     -1.264      0.206      -3.137       0.677\n",
      "Social Media Nutzung          0.0336      0.115      0.293      0.770      -0.192       0.259\n",
      "Landtagswahlen                0.0567      0.336      0.169      0.866      -0.601       0.714\n",
      "topic_1                      -0.3292      0.396     -0.832      0.406      -1.105       0.447\n",
      "topic_2                      -0.4333      0.400     -1.083      0.279      -1.218       0.351\n",
      "topic_6                      -0.4125      0.399     -1.034      0.301      -1.194       0.369\n",
      "topic_8                      -0.7596      0.416     -1.827      0.068      -1.575       0.055\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6003504395343312\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.21801311025363104\n",
      "Confusion-Matrix:\n",
      "[[183   0]\n",
      " [ 92   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.378094\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  275\n",
      "Model:                          Logit   Df Residuals:                      266\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.04265\n",
      "Time:                        11:37:50   Log-Likelihood:                -103.98\n",
      "converged:                       True   LL-Null:                       -108.61\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3206\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.0544      0.622     -3.302      0.001      -3.274      -0.835\n",
      "issue attention Facebook     -1.2369      1.046     -1.183      0.237      -3.287       0.813\n",
      "issue attention Bundestag    -0.8405      1.418     -0.593      0.553      -3.620       1.939\n",
      "Social Media Nutzung          0.0048      0.160      0.030      0.976      -0.309       0.318\n",
      "Landtagswahlen               -0.7343      0.561     -1.308      0.191      -1.834       0.366\n",
      "topic_1                       0.3264      0.624      0.523      0.601      -0.896       1.549\n",
      "topic_2                       1.0601      0.578      1.833      0.067      -0.073       2.194\n",
      "topic_6                       0.4942      0.610      0.810      0.418      -0.702       1.690\n",
      "topic_8                      -0.0632      0.667     -0.095      0.925      -1.371       1.245\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6440495116965705\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.1124761159226722\n",
      "Confusion-Matrix:\n",
      "[[238   0]\n",
      " [ 37   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623877\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  270\n",
      "Model:                          Logit   Df Residuals:                      261\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.01584\n",
      "Time:                        11:37:50   Log-Likelihood:                -168.45\n",
      "converged:                       True   LL-Null:                       -171.16\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7118\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3449      0.412     -0.837      0.403      -1.153       0.463\n",
      "issue attention Facebook     -0.0663      0.595     -0.112      0.911      -1.232       1.099\n",
      "issue attention Bundestag     0.8065      0.824      0.978      0.328      -0.809       2.422\n",
      "Social Media Nutzung         -0.0135      0.117     -0.115      0.908      -0.242       0.216\n",
      "Landtagswahlen                0.0396      0.337      0.117      0.906      -0.620       0.700\n",
      "topic_1                      -0.2940      0.397     -0.740      0.459      -1.072       0.484\n",
      "topic_2                      -0.4540      0.406     -1.119      0.263      -1.249       0.341\n",
      "topic_6                      -0.4678      0.403     -1.161      0.246      -1.258       0.322\n",
      "topic_8                      -0.8465      0.422     -2.006      0.045      -1.673      -0.020\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5857595133155379\n",
      "Pr√§zision: 0.5\n",
      "Recall: 0.02247191011235955\n",
      "F1-Score: 0.043010752688172046\n",
      "Brier-Score: 0.21658773651392627\n",
      "Confusion-Matrix:\n",
      "[[179   2]\n",
      " [ 87   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.374665\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  270\n",
      "Model:                          Logit   Df Residuals:                      261\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.04586\n",
      "Time:                        11:37:50   Log-Likelihood:                -101.16\n",
      "converged:                       True   LL-Null:                       -106.02\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2848\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.9317      0.654     -4.482      0.000      -4.214      -1.650\n",
      "issue attention Facebook      0.6713      0.686      0.978      0.328      -0.673       2.016\n",
      "issue attention Bundestag     0.9972      1.084      0.920      0.358      -1.128       3.122\n",
      "Social Media Nutzung          0.1952      0.155      1.263      0.206      -0.108       0.498\n",
      "Landtagswahlen               -0.1242      0.490     -0.254      0.800      -1.084       0.835\n",
      "topic_1                       0.4306      0.625      0.689      0.491      -0.794       1.656\n",
      "topic_2                       1.0210      0.581      1.756      0.079      -0.118       2.160\n",
      "topic_6                       0.5653      0.611      0.926      0.355      -0.631       1.762\n",
      "topic_8                      -0.2166      0.705     -0.307      0.759      -1.599       1.166\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6486229819563153\n",
      "Pr√§zision: 1.0\n",
      "Recall: 0.027777777777777776\n",
      "F1-Score: 0.05405405405405406\n",
      "Brier-Score: 0.11061302232010631\n",
      "Confusion-Matrix:\n",
      "[[234   0]\n",
      " [ 35   1]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605682\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  265\n",
      "Model:                          Logit   Df Residuals:                      256\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.04311\n",
      "Time:                        11:37:50   Log-Likelihood:                -160.51\n",
      "converged:                       True   LL-Null:                       -167.74\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.07048\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5463      0.425     -1.284      0.199      -1.380       0.288\n",
      "issue attention Facebook      1.1355      0.614      1.850      0.064      -0.067       2.338\n",
      "issue attention Bundestag    -3.3451      1.296     -2.581      0.010      -5.885      -0.805\n",
      "Social Media Nutzung          0.1384      0.120      1.155      0.248      -0.097       0.373\n",
      "Landtagswahlen                0.2600      0.340      0.764      0.445      -0.407       0.927\n",
      "topic_1                      -0.3632      0.412     -0.882      0.378      -1.170       0.444\n",
      "topic_2                      -0.5683      0.419     -1.355      0.176      -1.391       0.254\n",
      "topic_6                      -0.5696      0.420     -1.357      0.175      -1.393       0.253\n",
      "topic_8                      -0.7343      0.429     -1.712      0.087      -1.575       0.106\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6299883765982177\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.11494252873563218\n",
      "F1-Score: 0.19607843137254902\n",
      "Brier-Score: 0.20944085446641977\n",
      "Confusion-Matrix:\n",
      "[[173   5]\n",
      " [ 77  10]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.368542\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  265\n",
      "Model:                          Logit   Df Residuals:                      256\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 29 Jan 2025   Pseudo R-squ.:                 0.05578\n",
      "Time:                        11:37:50   Log-Likelihood:                -97.664\n",
      "converged:                       True   LL-Null:                       -103.43\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1730\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.4058      0.678     -3.549      0.000      -3.734      -1.077\n",
      "issue attention Facebook      0.6230      0.791      0.787      0.431      -0.928       2.174\n",
      "issue attention Bundestag    -3.6805      2.141     -1.719      0.086      -7.876       0.515\n",
      "Social Media Nutzung          0.0467      0.165      0.284      0.776      -0.276       0.369\n",
      "Landtagswahlen               -0.0812      0.492     -0.165      0.869      -1.046       0.883\n",
      "topic_1                       0.5940      0.664      0.895      0.371      -0.707       1.895\n",
      "topic_2                       1.1820      0.622      1.901      0.057      -0.036       2.401\n",
      "topic_6                       0.7243      0.651      1.113      0.266      -0.552       2.000\n",
      "topic_8                      -0.0522      0.741     -0.070      0.944      -1.504       1.400\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6850931677018633\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.10899739568285839\n",
      "Confusion-Matrix:\n",
      "[[230   0]\n",
      " [ 35   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Partei einmal definieren\n",
    "partei = \"gruen\"\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    # Dynamische Referenzierung der Variablen basierend auf dem Parteinamen\n",
    "    model1, auc_roc1, f1_1 = log_reg_FE_control_test(\n",
    "        globals()[f\"rede_reduced_{partei}\"], \n",
    "        globals()[f\"post_reduced_{partei}\"], \n",
    "        globals()[f\"rede_common_{partei}\"], \n",
    "        lag, \n",
    "        globals()[f\"social_media_usage_{partei}\"], \n",
    "        globals()[f\"rede_komplex_{partei}\"], \n",
    "        globals()[f\"posts_komplex_{partei}\"]\n",
    "    )\n",
    "\n",
    "    model2, auc_roc2, f1_2 = log_reg_FE_control_test(\n",
    "        globals()[f\"rede_reduced_{partei}\"], \n",
    "        globals()[f\"post_reduced_{partei}\"], \n",
    "        globals()[f\"post_common_{partei}\"], \n",
    "        lag, \n",
    "        globals()[f\"social_media_usage_{partei}\"], \n",
    "        globals()[f\"rede_komplex_{partei}\"], \n",
    "        globals()[f\"posts_komplex_{partei}\"]\n",
    "    )\n",
    "\n",
    "    # Stargazer-Tabelle f√ºr den Vergleich der beiden Modelle\n",
    "    stargazer = Stargazer([model1, model2])\n",
    "    stargazer.title(f\"Gr√ºne Vergleich f√ºr Lag {lag} - {partei.upper()}\")\n",
    "    stargazer.custom_columns(\n",
    "        [f\"Bundestag\", \n",
    "         f\"Facebook\"], \n",
    "        [1, 1]\n",
    "    )\n",
    "    stargazer.significant_digits(3)\n",
    "    stargazer.dependent_variable_name(\"Themenerw√§hnung Gr√ºne\")\n",
    "\n",
    "    # AUC-ROC und F1-Score als Notizen\n",
    "    custom_notes = [\n",
    "        f\"Modell 1 (Reden als Zielvariable): AUC-ROC = {auc_roc1:.3f}, F1-Score = {f1_1:.3f}\",\n",
    "        f\"Modell 2 (Posts als Zielvariable): AUC-ROC = {auc_roc2:.3f}, F1-Score = {f1_2:.3f}\"\n",
    "    ]\n",
    "    stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "    # HTML-Datei mit gr√∂√üerem Spaltenabstand speichern\n",
    "    filename = f\"regression tables/regression_table_comparison_{partei}_lag_{lag}.html\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 300 elements, new values have 295 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Schleife √ºber Lags\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m):  \u001b[38;5;66;03m# F√ºr Lags 1 bis 7\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Dynamische Referenzierung der Variablen basierend auf dem Parteinamen\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     model1, auc_roc1, f1_1 \u001b[38;5;241m=\u001b[39m \u001b[43mlog_reg_FE_control_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrede_reduced_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpartei\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost_reduced_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpartei\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrede_common_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpartei\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msocial_media_usage_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpartei\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrede_komplex_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpartei\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposts_komplex_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpartei\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     model2, auc_roc2, f1_2 \u001b[38;5;241m=\u001b[39m log_reg_FE_control_test(\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrede_reduced_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpartei\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_reduced_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpartei\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposts_komplex_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpartei\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Modelle und Lag-Beschriftung speichern\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 64\u001b[0m, in \u001b[0;36mlog_reg_FE_control_test\u001b[1;34m(relativ_rede, relativ_posts, post_to_shift, shifts, social_media_usage, complexity_rede, complexity_post)\u001b[0m\n\u001b[0;32m     62\u001b[0m complexity_post_stacked \u001b[38;5;241m=\u001b[39m complexity_post_z\u001b[38;5;241m.\u001b[39mreindex(relativ_posts\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     63\u001b[0m complexity_post_stacked \u001b[38;5;241m=\u001b[39m complexity_post_stacked\u001b[38;5;241m.\u001b[39mrepeat(relativ_posts\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 64\u001b[0m \u001b[43mcomplexity_post_stacked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m \u001b[38;5;241m=\u001b[39m relative_posts\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Zielvariable und unabh√§ngige Variablen zusammenf√ºhren\u001b[39;00m\n\u001b[0;32m     67\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue attention Facebook\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_posts,\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue attention Bundestag\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_reden,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKomplexit√§t Posts\u001b[39m\u001b[38;5;124m'\u001b[39m: complexity_post_stacked\n\u001b[0;32m     74\u001b[0m })\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 300 elements, new values have 295 elements"
     ]
    }
   ],
   "source": [
    "## Mastertabelle mit allen Lags in einer Tabelle (um Interpretation leichter zu machen)\n",
    "# Partei einmal definieren\n",
    "partei = \"linke\"\n",
    "\n",
    "# Liste zur Speicherung der Modelle\n",
    "models = []\n",
    "lag_labels = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    # Dynamische Referenzierung der Variablen basierend auf dem Parteinamen\n",
    "    model1, auc_roc1, f1_1 = log_reg_FE_control_test(\n",
    "        globals()[f\"rede_reduced_{partei}\"], \n",
    "        globals()[f\"post_reduced_{partei}\"], \n",
    "        globals()[f\"rede_common_{partei}\"], \n",
    "        lag, \n",
    "        globals()[f\"social_media_usage_{partei}\"], \n",
    "        globals()[f\"rede_komplex_{partei}\"], \n",
    "        globals()[f\"posts_komplex_{partei}\"]\n",
    "    )\n",
    "\n",
    "    model2, auc_roc2, f1_2 = log_reg_FE_control_test(\n",
    "        globals()[f\"rede_reduced_{partei}\"], \n",
    "        globals()[f\"post_reduced_{partei}\"], \n",
    "        globals()[f\"post_common_{partei}\"], \n",
    "        lag, \n",
    "        globals()[f\"social_media_usage_{partei}\"], \n",
    "        globals()[f\"rede_komplex_{partei}\"], \n",
    "        globals()[f\"posts_komplex_{partei}\"]\n",
    "    )\n",
    "\n",
    "    # Modelle und Lag-Beschriftung speichern\n",
    "    models.extend([model1, model2])\n",
    "    lag_labels.extend([f\"Lag {lag} - Bundestag\", f\"Lag {lag} - Facebook\"])\n",
    "\n",
    "# Eine einzige Stargazer-Tabelle mit allen Lags erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(f\"Vergleich aller Lags f√ºr {partei.upper()}\")\n",
    "stargazer.custom_columns(lag_labels, [1] * len(lag_labels))\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung Gr√ºne\")\n",
    "\n",
    "# AUC-ROC und F1-Score f√ºr jedes Lag als Notizen hinzuf√ºgen\n",
    "custom_notes = [\n",
    "    f\"Lag {lag}: Modell 1 (Bundestag) - AUC-ROC = {auc_roc1:.3f}, F1-Score = {f1_1:.3f}; \"\n",
    "    f\"Modell 2 (Facebook) - AUC-ROC = {auc_roc2:.3f}, F1-Score = {f1_2:.3f}\"\n",
    "    for lag in range(1, 8)\n",
    "]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# HTML-Datei speichern\n",
    "filename = f\"regression tables/regression_table_comparison_{partei}_all_lags.html\"\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(stargazer.render_html())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
