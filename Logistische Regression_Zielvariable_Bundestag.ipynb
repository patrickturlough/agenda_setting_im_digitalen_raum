{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Notebook zur logistischen Regression; Zielvariable: Themenerw√§hnung im Bundestag\n",
    "Zielvariable ist hier, ob ein Thema im Bundestag erw√§hnt wurde. Dementsprechend werden Bundestagsreden zum Zeitpunkt t+1 als Zielvariable hinzugezogen. Was es dabei unbedingt zu beachten gilt, ist dass, da meine Zeitreihe nicht kontinuierlich ist, bei den Bundestagsreden zum Zeitpunkt t die vorangegangene Bundestagssitzung gemeint ist und *nicht* eine Sitzung am Tag zuvor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "subset_reden = pd.read_csv(\"subset_reden.csv\")\n",
    "subset_posts = pd.read_csv(\"subset_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_reden[\"date\"] = pd.to_datetime(subset_reden[\"date\"])\n",
    "#Zusammenz√§hlen von CDU & CSU\n",
    "#subset_reden[\"partei\"] = subset_reden[\"partei\"].replace({\"CDU\" : \"CDU/CSU\", \"CSU\":\"CDU/CSU\"})\n",
    "subset_posts[\"date\"] = pd.to_datetime(subset_posts[\"date\"])\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich = subset_reden.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich = subset_posts.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "# Berechnung der t√§glichen Summen der Wortanzahlen\n",
    "reden_komplexit√§t_t√§glich = subset_reden.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich = subset_posts.groupby('date')['komplexit√§t'].sum()\n",
    "\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates = redethemen_t√§glich.index.intersection(postthemen_t√§glich.index)\n",
    "redethemen_t√§glich_aligned = redethemen_t√§glich.loc[common_dates]\n",
    "postthemen_t√§glich_aligned = postthemen_t√§glich.loc[common_dates]\n",
    "# posts_shifted enth√§lt die Facebookposts mit lag t+1, Die Daten hier sind zwar die gleichen wie in den anderen Dataframes,\n",
    " # die Werte jedoch die vom Vortag, weshalb die Analyse zul√§ssig ist\n",
    "reden_shifted=redethemen_t√§glich_aligned.shift().dropna()\n",
    "# # # Erneute Anpassung des Datums\n",
    "common_dates2 = redethemen_t√§glich.index.intersection(reden_shifted.index)\n",
    "rede_komplex = reden_komplexit√§t_t√§glich.loc[common_dates]\n",
    "posts_komplex = posts_komplexit√§t_t√§glich.loc[common_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Topic</th>\n",
       "      <th>CustomName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Russland-Ukraine-Konflikt und Zuwanderungskrim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>Gegenerziehung: Gendersprache im √∂ffentlichen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Bundesregierung plant Verbot von Gasheizungen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>Wahlrechtsform zur Verkleinerung des Bundestags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Corona-Pandemie und Pflegenotstand in Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2515</td>\n",
       "      <td>93</td>\n",
       "      <td>Bayerisches Wochenendziel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2690</td>\n",
       "      <td>62</td>\n",
       "      <td>Polit-Podcasts aus Hessen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3335</td>\n",
       "      <td>72</td>\n",
       "      <td>Deutsche Parlamentarische Verfahren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3384</td>\n",
       "      <td>64</td>\n",
       "      <td>Mitbestimmung in Unternehmen - Richtlinien und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>11669</td>\n",
       "      <td>85</td>\n",
       "      <td>Operation Irini zur Durchsetzung des Waffenemb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Topic                                         CustomName\n",
       "0       0      4  Russland-Ukraine-Konflikt und Zuwanderungskrim...\n",
       "1       1     35  Gegenerziehung: Gendersprache im √∂ffentlichen ...\n",
       "2       2     20  Bundesregierung plant Verbot von Gasheizungen ...\n",
       "3       4     21    Wahlrechtsform zur Verkleinerung des Bundestags\n",
       "4       5      0  Corona-Pandemie und Pflegenotstand in Deutschland\n",
       "..    ...    ...                                                ...\n",
       "89   2515     93                          Bayerisches Wochenendziel\n",
       "90   2690     62                          Polit-Podcasts aus Hessen\n",
       "91   3335     72                Deutsche Parlamentarische Verfahren\n",
       "92   3384     64  Mitbestimmung in Unternehmen - Richtlinien und...\n",
       "93  11669     85  Operation Irini zur Durchsetzung des Waffenemb...\n",
       "\n",
       "[94 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_topics = subset_posts.drop_duplicates(subset=[\"Topic\"])\n",
    "unique_topics= unique_topics[[\"Topic\", \"CustomName\"]]\n",
    "unique_topics.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>CustomName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6</td>\n",
       "      <td>Fr√ºhkindliche Bildung und Betreuung in Kitas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic                                    CustomName\n",
       "145      6  Fr√ºhkindliche Bildung und Betreuung in Kitas"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_topics[unique_topics[\"Topic\"] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Russland-Ukraine-Konflikt und Zuwanderungskriminalit√§t in Deutschland',\n",
       "       'Gegenerziehung: Gendersprache im √∂ffentlichen Leben in Deutschland[/INST]',\n",
       "       'Bundesregierung plant Verbot von Gasheizungen - F√∂rderung von W√§rmepumpen',\n",
       "       'Wahlrechtsform zur Verkleinerung des Bundestags',\n",
       "       'Corona-Pandemie und Pflegenotstand in Deutschland',\n",
       "       'Bildungspolitik in Deutschland',\n",
       "       'Sicherheit in deutschen Freib√§dern',\n",
       "       'Migration und Asyl in Deutschland',\n",
       "       'Russischer Angriffskrieg in der Ukraine und Europas Reaktion[/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST',\n",
       "       'Russische Energiekrise und ihre Auswirkungen auf Europa',\n",
       "       'Kritik an Deutschlands Klimaschutzpolitik',\n",
       "       'Klimaextremisten und ihre Straftaten',\n",
       "       'Plenarsitzung des Bundestages', 'Bezahlbarer Wohnraum in Bayern',\n",
       "       'Reform des √∂ffentlich-rechtlichen Rundfunks in Deutschland',\n",
       "       'B√ºrgergeld-Reform im Sozialstaat',\n",
       "       'Bayerische Staatsregierung kritisiert wegen Kostenexplosion bei M√ºnchner Stammstrecke',\n",
       "       'Infrastruktur f√ºr Schiffsfahrt in Hamburg', 'Berlin-Wahlen 2023',\n",
       "       'Entlastungspaket zur Energiekrise',\n",
       "       'Windenergie und Photovoltaik im Kontext der Energiewende',\n",
       "       'Deutschlands Grundsatzprogramm',\n",
       "       'Russlands Nord Stream-Pipeline-Anschlag und seine Auswirkungen auf Europa und Deutschland[/INST]',\n",
       "       'Flutkatastrophe im Rheinland-Pfalz',\n",
       "       'Gleichbezahltag - Frauen verdienen immer noch weniger als M√§nner[/INST]',\n",
       "       'Deutschlands Atomkraftwerks-Frage: Weiterbetrieb oder Ausstieg?',\n",
       "       'Internationale Queer-Rechte und -Sichtbarkeit im Kampf gegen Hass und Diskriminierung',\n",
       "       '#UnserLandZuerst - Kundgebung gegen Preissteigerung und Regierungspolitik',\n",
       "       'Deutschlandticket - Attraktives √ñPNV-Angebot f√ºr eine klimafreundliche Mobilit√§t',\n",
       "       'Kunst und Kultur im Zeitalter der Krise',\n",
       "       'Lindners Entlastungspolitik im Kontext der Inflationsbek√§mpfung',\n",
       "       'B√ºrgermobiler Marktbesuch in Th√ºringen',\n",
       "       'Russisches √ñl-Embargo und seine Auswirkungen auf Ostdeutschland',\n",
       "       'Landwirtschaftspolitik in Deutschland',\n",
       "       'S√§chsische Haushaltsprobleme und Steuerpolitik',\n",
       "       'Klimaneutrale Mobilit√§t durch synthetische Kraftstoffe',\n",
       "       'Kannabiskonsum in Deutschland - Legalisierung und Kontrolle',\n",
       "       'Bundestagswahl in Deutschland',\n",
       "       'Erdbeben in der T√ºrkei und Syrien - Internationale Hilfe erforderlich',\n",
       "       'Rentenpaket und Nachholfaktor im deutschen Rentensystem',\n",
       "       'Fr√ºhkindliche Bildung und Betreuung in Kitas',\n",
       "       'Beseitigung von Gewalt gegen Frauen',\n",
       "       'F√∂rderung des Radverkehrs in Deutschland',\n",
       "       'Bek√§mpfung sexuellem Missbrauch im Internet',\n",
       "       'Iranische Frauen k√§mpfen f√ºr Freiheit und Menschenrechte im Angesicht brutaler Repressionen des Regimes',\n",
       "       'Russischer Angriffskrieg in der Ukraine - Auswirkungen auf Sport und Gesellschaft',\n",
       "       'Olaf Scholz Rolle in der Cum-Ex Aff√§re',\n",
       "       'China-Strategie: Abh√§ngigkeiten reduzieren, Souver√§nit√§t st√§rken',\n",
       "       'Wolfsmanagement in Deutschland',\n",
       "       'Europ√§ische Digitalisierungspolitik - Datenutzung und Datenschutz im Zeitalter der Digitalisierung[/INST]',\n",
       "       'Flughafen-Chaos in Deutschland',\n",
       "       'Russland-Ukraine-Konflikt und Energiesicherheit Europas[/INST]',\n",
       "       'CDU-MV Mecklenburg-Vorpommern',\n",
       "       'Bau der Berliner Mauer und ihr Fall',\n",
       "       'Bewerbung und Personalwesen bei der Gr√ºnen Landesgesch√§ftstelle Bayern',\n",
       "       'Gl√ºckw√ºnsche an Politiker in Deutschland',\n",
       "       'Deutschlands Verkehrsinfrastruktur soll beschleunigt werden',\n",
       "       'Deutsche Politiker w√§hlen neue Positionen ein',\n",
       "       'Europatag - Ein Fest f√ºr Frieden, Einheit und Freiheit in Europa',\n",
       "       'Frohes Weihnachtsfest',\n",
       "       'Franziska Giffey als Spitzenkandidatin f√ºr Berlin',\n",
       "       'Mindestlohn steigt im Oktober', 'Blutspende und -versorgung',\n",
       "       'Russland-China-Aktion im Sahel-Region Afrika',\n",
       "       'Landesparteitag der [Partei]',\n",
       "       'Deutsch-israelische Freundschaft und Gegenwart des Holocausts',\n",
       "       'Russischer Angriffskrieg in der Ukraine und NATO-Bindung Finnlands und Schwedens',\n",
       "       'Bundesverfassungsgericht entscheidet √ºber Zinssatz bei Steuererstattungen und -nachzahlungen',\n",
       "       'Saarl√§ndisches Politikthema', 'B√ºrgerschaftswahl in Bremen',\n",
       "       'Inflation und Finanzpolitik im Kontext der Corona-Krise und der Energiekrise',\n",
       "       'Sommerferien im Saarland',\n",
       "       'Holocaust-Gedenken und Erinnerung an Opfer des Nationalsozialismus',\n",
       "       'Peter Tschentscher Live - Hamburgs B√ºrgermeister im Gespr√§ch mit B√ºrgern',\n",
       "       'Schwangerschaftsabbr√ºche und Frauenrechte',\n",
       "       'R√ºckkehr der Bundeswehr nach Bosnien Herzegowina',\n",
       "       'Froher Ostern', 'Nat√ºrlicher Wasser- und Klimaschutz',\n",
       "       'Katastrophenschutz und Waldbr√§nde im Harz',\n",
       "       'Deutsch-Franz√∂sische Freundschaft',\n",
       "       'CETA-Ratifizierung und Freihandelsabkommen mit Kanada und anderen Staaten Europas und Lateinamerikas[/INST]',\n",
       "       'Ehrenamtliches Engagement', 'Sch√∂ner Besinnlicher Advent',\n",
       "       'Bayerische Politik im Fernsehen',\n",
       "       'Festtagsfeiern im Islam und Judentum[/INST]', 'Frohes Neues Jahr',\n",
       "       'Krise um Kernenergie unter Markus S√∂der',\n",
       "       'W√ºrttembergs Doppelhaushalt',\n",
       "       'Aufarbeitung des Afghanistan-Einsatzes nach Macht√ºbernahme der Taliban',\n",
       "       'Bayerisches Wochenendziel', 'Polit-Podcasts aus Hessen',\n",
       "       'Deutsche Parlamentarische Verfahren',\n",
       "       'Mitbestimmung in Unternehmen - Richtlinien und Rechte',\n",
       "       'Operation Irini zur Durchsetzung des Waffenembargos gegen Libyen'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_topics[\"CustomName\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_topics.to_csv(\"unique_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>CustomName</th>\n",
       "      <th>Representation</th>\n",
       "      <th>KeyBERT</th>\n",
       "      <th>Llama3.1</th>\n",
       "      <th>MMR</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>date</th>\n",
       "      <th>partei</th>\n",
       "      <th>art</th>\n",
       "      <th>komplexit√§t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>1095</td>\n",
       "      <td>1095</td>\n",
       "      <td>beratungen einzelplans   bundesministerium woh...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>0.986716</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>1107</td>\n",
       "      <td>1107</td>\n",
       "      <td>f√∂st zahlen    vorschl√§ge haushalt wiederfinde...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1117</td>\n",
       "      <td>1117</td>\n",
       "      <td>verehrte    froh   bisschen schwung ganze  zah...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>1119</td>\n",
       "      <td>1119</td>\n",
       "      <td>daldrup zwischenfrage  ersten  dauer    lange ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>mache    gelegenheit  zeitenwende gemeinsame k...</td>\n",
       "      <td>77</td>\n",
       "      <td>77_zinssatz_zinsen_abgabenordnung_zinssatzes</td>\n",
       "      <td>Bundesverfassungsgericht entscheidet √ºber Zins...</td>\n",
       "      <td>['zinssatz', 'zinsen', 'abgabenordnung', 'zins...</td>\n",
       "      <td>['nachzahlungszinsen', 'vollverzinsung', 'steu...</td>\n",
       "      <td>['Bundesverfassungsgericht entscheidet √ºber Zi...</td>\n",
       "      <td>['abgabenordnung', 'erstattungszinsen', 'vollv...</td>\n",
       "      <td>['bundesverfassungsgericht  verpflichtet zinss...</td>\n",
       "      <td>zinssatz - zinsen - abgabenordnung - zinssatze...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>11678</td>\n",
       "      <td>11678</td>\n",
       "      <td>ferlemann  dramatische abrutschen dargestellt ...</td>\n",
       "      <td>78</td>\n",
       "      <td>78_frankreich_atomkraft_atomkraftwerke_kernkra...</td>\n",
       "      <td>Russland-Ukraine-Konflikt und Energiesicherhei...</td>\n",
       "      <td>['frankreich', 'atomkraft', 'atomkraftwerke', ...</td>\n",
       "      <td>['kernkraftwerke', 'energiepolitik', 'kernkraf...</td>\n",
       "      <td>['Russland-Ukraine-Konflikt und Energiesicherh...</td>\n",
       "      <td>['frankreich', 'kernkraftwerke', 'strom', 'ern...</td>\n",
       "      <td>['drau√üen hei√üer junitag sommerferien  bevor  ...</td>\n",
       "      <td>frankreich - atomkraft - atomkraftwerke - kern...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>11695</td>\n",
       "      <td>11695</td>\n",
       "      <td>anrede ‚Äûdon‚Äú   wahrscheinlich robert habeck ve...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>0.979697</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>11697</td>\n",
       "      <td>11697</td>\n",
       "      <td>bereit akzeptieren  v√∂llig unterschiedliche sa...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>0.897986</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>11699</td>\n",
       "      <td>11699</td>\n",
       "      <td>gleich abstimmungsverhalten  gespannt    rede ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>0.935367</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>11707</td>\n",
       "      <td>11707</td>\n",
       "      <td>wohnungsnot  wichtiges wohnungsfrage besch√§fti...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>0.953011</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102 rows √ó 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  \\\n",
       "735           1095        1095   \n",
       "745           1107        1107   \n",
       "751           1117        1117   \n",
       "752           1119        1119   \n",
       "753           1120        1120   \n",
       "...            ...         ...   \n",
       "7491         11678       11678   \n",
       "7496         11695       11695   \n",
       "7497         11697       11697   \n",
       "7499         11699       11699   \n",
       "7506         11707       11707   \n",
       "\n",
       "                                               Document  Topic  \\\n",
       "735   beratungen einzelplans   bundesministerium woh...      8   \n",
       "745   f√∂st zahlen    vorschl√§ge haushalt wiederfinde...      8   \n",
       "751   verehrte    froh   bisschen schwung ganze  zah...      8   \n",
       "752   daldrup zwischenfrage  ersten  dauer    lange ...      8   \n",
       "753   mache    gelegenheit  zeitenwende gemeinsame k...     77   \n",
       "...                                                 ...    ...   \n",
       "7491  ferlemann  dramatische abrutschen dargestellt ...     78   \n",
       "7496  anrede ‚Äûdon‚Äú   wahrscheinlich robert habeck ve...      8   \n",
       "7497  bereit akzeptieren  v√∂llig unterschiedliche sa...      8   \n",
       "7499  gleich abstimmungsverhalten  gespannt    rede ...      8   \n",
       "7506  wohnungsnot  wichtiges wohnungsfrage besch√§fti...      8   \n",
       "\n",
       "                                                   Name  \\\n",
       "735                   8_wohnungen_bauen_wohnen_wohnraum   \n",
       "745                   8_wohnungen_bauen_wohnen_wohnraum   \n",
       "751                   8_wohnungen_bauen_wohnen_wohnraum   \n",
       "752                   8_wohnungen_bauen_wohnen_wohnraum   \n",
       "753        77_zinssatz_zinsen_abgabenordnung_zinssatzes   \n",
       "...                                                 ...   \n",
       "7491  78_frankreich_atomkraft_atomkraftwerke_kernkra...   \n",
       "7496                  8_wohnungen_bauen_wohnen_wohnraum   \n",
       "7497                  8_wohnungen_bauen_wohnen_wohnraum   \n",
       "7499                  8_wohnungen_bauen_wohnen_wohnraum   \n",
       "7506                  8_wohnungen_bauen_wohnen_wohnraum   \n",
       "\n",
       "                                             CustomName  \\\n",
       "735                      Bezahlbarer Wohnraum in Bayern   \n",
       "745                      Bezahlbarer Wohnraum in Bayern   \n",
       "751                      Bezahlbarer Wohnraum in Bayern   \n",
       "752                      Bezahlbarer Wohnraum in Bayern   \n",
       "753   Bundesverfassungsgericht entscheidet √ºber Zins...   \n",
       "...                                                 ...   \n",
       "7491  Russland-Ukraine-Konflikt und Energiesicherhei...   \n",
       "7496                     Bezahlbarer Wohnraum in Bayern   \n",
       "7497                     Bezahlbarer Wohnraum in Bayern   \n",
       "7499                     Bezahlbarer Wohnraum in Bayern   \n",
       "7506                     Bezahlbarer Wohnraum in Bayern   \n",
       "\n",
       "                                         Representation  \\\n",
       "735   ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "745   ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "751   ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "752   ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "753   ['zinssatz', 'zinsen', 'abgabenordnung', 'zins...   \n",
       "...                                                 ...   \n",
       "7491  ['frankreich', 'atomkraft', 'atomkraftwerke', ...   \n",
       "7496  ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "7497  ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "7499  ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "7506  ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "\n",
       "                                                KeyBERT  \\\n",
       "735   ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "745   ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "751   ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "752   ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "753   ['nachzahlungszinsen', 'vollverzinsung', 'steu...   \n",
       "...                                                 ...   \n",
       "7491  ['kernkraftwerke', 'energiepolitik', 'kernkraf...   \n",
       "7496  ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "7497  ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "7499  ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "7506  ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "\n",
       "                                               Llama3.1  \\\n",
       "735   ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "745   ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "751   ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "752   ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "753   ['Bundesverfassungsgericht entscheidet √ºber Zi...   \n",
       "...                                                 ...   \n",
       "7491  ['Russland-Ukraine-Konflikt und Energiesicherh...   \n",
       "7496  ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "7497  ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "7499  ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "7506  ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "\n",
       "                                                    MMR  \\\n",
       "735   ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "745   ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "751   ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "752   ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "753   ['abgabenordnung', 'erstattungszinsen', 'vollv...   \n",
       "...                                                 ...   \n",
       "7491  ['frankreich', 'kernkraftwerke', 'strom', 'ern...   \n",
       "7496  ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "7497  ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "7499  ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "7506  ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "\n",
       "                                    Representative_Docs  \\\n",
       "735   ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "745   ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "751   ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "752   ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "753   ['bundesverfassungsgericht  verpflichtet zinss...   \n",
       "...                                                 ...   \n",
       "7491  ['drau√üen hei√üer junitag sommerferien  bevor  ...   \n",
       "7496  ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "7497  ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "7499  ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "7506  ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "\n",
       "                                            Top_n_words  Probability  \\\n",
       "735   wohnungen - bauen - wohnen - wohnraum - wohnun...     0.986716   \n",
       "745   wohnungen - bauen - wohnen - wohnraum - wohnun...     1.000000   \n",
       "751   wohnungen - bauen - wohnen - wohnraum - wohnun...     1.000000   \n",
       "752   wohnungen - bauen - wohnen - wohnraum - wohnun...     1.000000   \n",
       "753   zinssatz - zinsen - abgabenordnung - zinssatze...     1.000000   \n",
       "...                                                 ...          ...   \n",
       "7491  frankreich - atomkraft - atomkraftwerke - kern...     1.000000   \n",
       "7496  wohnungen - bauen - wohnen - wohnraum - wohnun...     0.979697   \n",
       "7497  wohnungen - bauen - wohnen - wohnraum - wohnun...     0.897986   \n",
       "7499  wohnungen - bauen - wohnen - wohnraum - wohnun...     0.935367   \n",
       "7506  wohnungen - bauen - wohnen - wohnraum - wohnun...     0.953011   \n",
       "\n",
       "      Representative_document       date partei          art  komplexit√§t  \n",
       "735                     False 2022-05-31    CDU  redebeitrag          260  \n",
       "745                     False 2022-05-31    CDU  redebeitrag          236  \n",
       "751                     False 2022-05-31    CDU  redebeitrag          193  \n",
       "752                     False 2022-05-31    CDU  redebeitrag          152  \n",
       "753                     False 2022-05-31    CDU  redebeitrag           13  \n",
       "...                       ...        ...    ...          ...          ...  \n",
       "7491                    False 2023-05-12    CDU  redebeitrag          141  \n",
       "7496                    False 2023-05-12    CDU  redebeitrag          112  \n",
       "7497                    False 2023-05-12    CDU  redebeitrag           84  \n",
       "7499                    False 2023-05-12    CDU  redebeitrag          169  \n",
       "7506                    False 2023-05-12    CDU  redebeitrag          211  \n",
       "\n",
       "[1102 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = subset_reden[(subset_reden[\"date\"] >= '2022-05-31') & (subset_reden[\"date\"] <= '2023-05-12')]\n",
    "r[r[\"partei\"] == \"CDU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Russischer Angriffskrieg in der Ukraine und Eu...\n",
       "1             Bek√§mpfung sexuellem Missbrauch im Internet\n",
       "2             Bek√§mpfung sexuellem Missbrauch im Internet\n",
       "3             Bek√§mpfung sexuellem Missbrauch im Internet\n",
       "4             Bek√§mpfung sexuellem Missbrauch im Internet\n",
       "                              ...                        \n",
       "7862    Deutschlands Verkehrsinfrastruktur soll beschl...\n",
       "7863    Deutschlands Verkehrsinfrastruktur soll beschl...\n",
       "7864    Deutschlands Verkehrsinfrastruktur soll beschl...\n",
       "7865    Russischer Angriffskrieg in der Ukraine - Ausw...\n",
       "7866                        Plenarsitzung des Bundestages\n",
       "Name: CustomName, Length: 7867, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_reden[\"CustomName\"].replace('Russischer Angriffskrieg in der Ukraine und Europas Reaktion                                                                                                                                                                 [/INST', \"Russischer Angriffskrieg in der Ukraine und Europas Reaktion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Russischer Angriffskrieg in der Ukraine und Europas Reaktion[/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_reden[\"CustomName\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing whitespace before performing the replacement\n",
    "subset_reden[\"CustomName\"] = subset_reden[\"CustomName\"].str.strip()\n",
    "subset_reden[\"CustomName\"] = subset_reden[\"CustomName\"].replace(\n",
    "    'Russischer Angriffskrieg in der Ukraine und Europas Reaktion                                                                                                                                                                 [/INST',\n",
    "    \"Russischer Angriffskrieg in der Ukraine und Europas Reaktion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>CustomName</th>\n",
       "      <th>Representation</th>\n",
       "      <th>KeyBERT</th>\n",
       "      <th>Llama3.1</th>\n",
       "      <th>MMR</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>date</th>\n",
       "      <th>partei</th>\n",
       "      <th>art</th>\n",
       "      <th>komplexit√§t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>bundeshaushalt  umfasst  milliarden   milliard...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_corona_pflege_lauterbach_maskenpflicht</td>\n",
       "      <td>Corona-Pandemie und Pflegenotstand in Deutschland</td>\n",
       "      <td>['corona', 'pflege', 'lauterbach', 'maskenpfli...</td>\n",
       "      <td>['gesundheitspolitischer', 'impfpflicht', 'imp...</td>\n",
       "      <td>['Corona-Pandemie und Pflegenotstand in Deutsc...</td>\n",
       "      <td>['lauterbach', 'maskenpflicht', 'versorgung', ...</td>\n",
       "      <td>['mangel pflegepersonal lie√ü wohl  landesminis...</td>\n",
       "      <td>corona - pflege - lauterbach - maskenpflicht -...</td>\n",
       "      <td>0.972841</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>AfD</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1074</td>\n",
       "      <td>1074</td>\n",
       "      <td>bevor   aufrufe  kurzen hinweis mitglieder  re...</td>\n",
       "      <td>5</td>\n",
       "      <td>5_redezeit_b√ºndnis_zwischenfrage_kurzintervention</td>\n",
       "      <td>Plenarsitzung des Bundestages</td>\n",
       "      <td>['redezeit', 'b√ºndnis', 'zwischenfrage', 'kurz...</td>\n",
       "      <td>['abstimmung', 'redezeiten', 'redezeit', 'zwis...</td>\n",
       "      <td>['Plenarsitzung des Bundestages\\n\\n[INST]\\nIch...</td>\n",
       "      <td>['redezeit', 'kurzintervention', 'protokoll', ...</td>\n",
       "      <td>['bevor weiterreden einrei√üen redezeit k√ºnstli...</td>\n",
       "      <td>redezeit - b√ºndnis - zwischenfrage - kurzinter...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>SPD</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>1075</td>\n",
       "      <td>1075</td>\n",
       "      <td>gesch√§tzte      beraten woche abschlie√üend bun...</td>\n",
       "      <td>2</td>\n",
       "      <td>2_ukraine_bundeswehr_krieg_russland</td>\n",
       "      <td>Russischer Angriffskrieg in der Ukraine und Eu...</td>\n",
       "      <td>['ukraine', 'bundeswehr', 'krieg', 'russland',...</td>\n",
       "      <td>['milit√§risch', 'waffenlieferungen', 'milit√§ri...</td>\n",
       "      <td>['Russischer Angriffskrieg in der Ukraine und ...</td>\n",
       "      <td>['ukraine', 'bundeswehr', 'nato', 'sonderverm√∂...</td>\n",
       "      <td>['vergangenen sonntagabend konnten koalitionsf...</td>\n",
       "      <td>ukraine - bundeswehr - krieg - russland - frie...</td>\n",
       "      <td>0.482274</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>SPD</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>1079</td>\n",
       "      <td>1079</td>\n",
       "      <td>liebes finanzpolitikgeplagtes publikum all√ºber...</td>\n",
       "      <td>52</td>\n",
       "      <td>52_inflation_milliarden_ezb_schuldenbremse</td>\n",
       "      <td>Inflation und Finanzpolitik im Kontext der Cor...</td>\n",
       "      <td>['inflation', 'milliarden', 'ezb', 'schuldenbr...</td>\n",
       "      <td>['verm√∂gensabgabe', 'inflationsausgleichsgeset...</td>\n",
       "      <td>['Inflation und Finanzpolitik im Kontext der C...</td>\n",
       "      <td>['inflation', 'milliarden', 'schuldenbremse', ...</td>\n",
       "      <td>['middelberg verlaub ton rede teilen  hause er...</td>\n",
       "      <td>inflation - milliarden - ezb - schuldenbremse ...</td>\n",
       "      <td>0.961712</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>AfD</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>1081</td>\n",
       "      <td>1081</td>\n",
       "      <td>haushalt  einzige fingerhakelei unehrlich  mil...</td>\n",
       "      <td>52</td>\n",
       "      <td>52_inflation_milliarden_ezb_schuldenbremse</td>\n",
       "      <td>Inflation und Finanzpolitik im Kontext der Cor...</td>\n",
       "      <td>['inflation', 'milliarden', 'ezb', 'schuldenbr...</td>\n",
       "      <td>['verm√∂gensabgabe', 'inflationsausgleichsgeset...</td>\n",
       "      <td>['Inflation und Finanzpolitik im Kontext der C...</td>\n",
       "      <td>['inflation', 'milliarden', 'schuldenbremse', ...</td>\n",
       "      <td>['middelberg verlaub ton rede teilen  hause er...</td>\n",
       "      <td>inflation - milliarden - ezb - schuldenbremse ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>DIE LINKE.</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>11705</td>\n",
       "      <td>11705</td>\n",
       "      <td>zwischenfrage  vergessen  formuliert vorschlag...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>FDP</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>11706</td>\n",
       "      <td>11706</td>\n",
       "      <td>demokratischen parteien statistisch belegt  √§l...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>SPD</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>11707</td>\n",
       "      <td>11707</td>\n",
       "      <td>wohnungsnot  wichtiges wohnungsfrage besch√§fti...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>0.953011</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>CDU</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>11708</td>\n",
       "      <td>11708</td>\n",
       "      <td>werte   jemand abgeordnetenzeit beruflich wohn...</td>\n",
       "      <td>8</td>\n",
       "      <td>8_wohnungen_bauen_wohnen_wohnraum</td>\n",
       "      <td>Bezahlbarer Wohnraum in Bayern</td>\n",
       "      <td>['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...</td>\n",
       "      <td>['wohnungspolitik', 'wohngeldreform', 'wohnung...</td>\n",
       "      <td>['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...</td>\n",
       "      <td>['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...</td>\n",
       "      <td>['los  herbstklausur n√ºrnberg startet dringend...</td>\n",
       "      <td>wohnungen - bauen - wohnen - wohnraum - wohnun...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>SPD</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7508</th>\n",
       "      <td>11713</td>\n",
       "      <td>11713</td>\n",
       "      <td>aktuellen stunde  f√ºnf minuten    √ºberzogen la...</td>\n",
       "      <td>5</td>\n",
       "      <td>5_redezeit_b√ºndnis_zwischenfrage_kurzintervention</td>\n",
       "      <td>Plenarsitzung des Bundestages</td>\n",
       "      <td>['redezeit', 'b√ºndnis', 'zwischenfrage', 'kurz...</td>\n",
       "      <td>['abstimmung', 'redezeiten', 'redezeit', 'zwis...</td>\n",
       "      <td>['Plenarsitzung des Bundestages\\n\\n[INST]\\nIch...</td>\n",
       "      <td>['redezeit', 'kurzintervention', 'protokoll', ...</td>\n",
       "      <td>['bevor weiterreden einrei√üen redezeit k√ºnstli...</td>\n",
       "      <td>redezeit - b√ºndnis - zwischenfrage - kurzinter...</td>\n",
       "      <td>0.436683</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>SPD</td>\n",
       "      <td>redebeitrag</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6784 rows √ó 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  \\\n",
       "725           1073        1073   \n",
       "726           1074        1074   \n",
       "727           1075        1075   \n",
       "728           1079        1079   \n",
       "729           1081        1081   \n",
       "...            ...         ...   \n",
       "7504         11705       11705   \n",
       "7505         11706       11706   \n",
       "7506         11707       11707   \n",
       "7507         11708       11708   \n",
       "7508         11713       11713   \n",
       "\n",
       "                                               Document  Topic  \\\n",
       "725   bundeshaushalt  umfasst  milliarden   milliard...      0   \n",
       "726   bevor   aufrufe  kurzen hinweis mitglieder  re...      5   \n",
       "727   gesch√§tzte      beraten woche abschlie√üend bun...      2   \n",
       "728   liebes finanzpolitikgeplagtes publikum all√ºber...     52   \n",
       "729   haushalt  einzige fingerhakelei unehrlich  mil...     52   \n",
       "...                                                 ...    ...   \n",
       "7504  zwischenfrage  vergessen  formuliert vorschlag...      8   \n",
       "7505  demokratischen parteien statistisch belegt  √§l...      8   \n",
       "7506  wohnungsnot  wichtiges wohnungsfrage besch√§fti...      8   \n",
       "7507  werte   jemand abgeordnetenzeit beruflich wohn...      8   \n",
       "7508  aktuellen stunde  f√ºnf minuten    √ºberzogen la...      5   \n",
       "\n",
       "                                                   Name  \\\n",
       "725            0_corona_pflege_lauterbach_maskenpflicht   \n",
       "726   5_redezeit_b√ºndnis_zwischenfrage_kurzintervention   \n",
       "727                 2_ukraine_bundeswehr_krieg_russland   \n",
       "728          52_inflation_milliarden_ezb_schuldenbremse   \n",
       "729          52_inflation_milliarden_ezb_schuldenbremse   \n",
       "...                                                 ...   \n",
       "7504                  8_wohnungen_bauen_wohnen_wohnraum   \n",
       "7505                  8_wohnungen_bauen_wohnen_wohnraum   \n",
       "7506                  8_wohnungen_bauen_wohnen_wohnraum   \n",
       "7507                  8_wohnungen_bauen_wohnen_wohnraum   \n",
       "7508  5_redezeit_b√ºndnis_zwischenfrage_kurzintervention   \n",
       "\n",
       "                                             CustomName  \\\n",
       "725   Corona-Pandemie und Pflegenotstand in Deutschland   \n",
       "726                       Plenarsitzung des Bundestages   \n",
       "727   Russischer Angriffskrieg in der Ukraine und Eu...   \n",
       "728   Inflation und Finanzpolitik im Kontext der Cor...   \n",
       "729   Inflation und Finanzpolitik im Kontext der Cor...   \n",
       "...                                                 ...   \n",
       "7504                     Bezahlbarer Wohnraum in Bayern   \n",
       "7505                     Bezahlbarer Wohnraum in Bayern   \n",
       "7506                     Bezahlbarer Wohnraum in Bayern   \n",
       "7507                     Bezahlbarer Wohnraum in Bayern   \n",
       "7508                      Plenarsitzung des Bundestages   \n",
       "\n",
       "                                         Representation  \\\n",
       "725   ['corona', 'pflege', 'lauterbach', 'maskenpfli...   \n",
       "726   ['redezeit', 'b√ºndnis', 'zwischenfrage', 'kurz...   \n",
       "727   ['ukraine', 'bundeswehr', 'krieg', 'russland',...   \n",
       "728   ['inflation', 'milliarden', 'ezb', 'schuldenbr...   \n",
       "729   ['inflation', 'milliarden', 'ezb', 'schuldenbr...   \n",
       "...                                                 ...   \n",
       "7504  ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "7505  ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "7506  ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "7507  ['wohnungen', 'bauen', 'wohnen', 'wohnraum', '...   \n",
       "7508  ['redezeit', 'b√ºndnis', 'zwischenfrage', 'kurz...   \n",
       "\n",
       "                                                KeyBERT  \\\n",
       "725   ['gesundheitspolitischer', 'impfpflicht', 'imp...   \n",
       "726   ['abstimmung', 'redezeiten', 'redezeit', 'zwis...   \n",
       "727   ['milit√§risch', 'waffenlieferungen', 'milit√§ri...   \n",
       "728   ['verm√∂gensabgabe', 'inflationsausgleichsgeset...   \n",
       "729   ['verm√∂gensabgabe', 'inflationsausgleichsgeset...   \n",
       "...                                                 ...   \n",
       "7504  ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "7505  ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "7506  ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "7507  ['wohnungspolitik', 'wohngeldreform', 'wohnung...   \n",
       "7508  ['abstimmung', 'redezeiten', 'redezeit', 'zwis...   \n",
       "\n",
       "                                               Llama3.1  \\\n",
       "725   ['Corona-Pandemie und Pflegenotstand in Deutsc...   \n",
       "726   ['Plenarsitzung des Bundestages\\n\\n[INST]\\nIch...   \n",
       "727   ['Russischer Angriffskrieg in der Ukraine und ...   \n",
       "728   ['Inflation und Finanzpolitik im Kontext der C...   \n",
       "729   ['Inflation und Finanzpolitik im Kontext der C...   \n",
       "...                                                 ...   \n",
       "7504  ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "7505  ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "7506  ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "7507  ['Bezahlbarer Wohnraum in Bayern\\n\\n[INST]\\nIc...   \n",
       "7508  ['Plenarsitzung des Bundestages\\n\\n[INST]\\nIch...   \n",
       "\n",
       "                                                    MMR  \\\n",
       "725   ['lauterbach', 'maskenpflicht', 'versorgung', ...   \n",
       "726   ['redezeit', 'kurzintervention', 'protokoll', ...   \n",
       "727   ['ukraine', 'bundeswehr', 'nato', 'sonderverm√∂...   \n",
       "728   ['inflation', 'milliarden', 'schuldenbremse', ...   \n",
       "729   ['inflation', 'milliarden', 'schuldenbremse', ...   \n",
       "...                                                 ...   \n",
       "7504  ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "7505  ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "7506  ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "7507  ['bauen', 'mieter', 'wohnungsmarkt', 'sozialwo...   \n",
       "7508  ['redezeit', 'kurzintervention', 'protokoll', ...   \n",
       "\n",
       "                                    Representative_Docs  \\\n",
       "725   ['mangel pflegepersonal lie√ü wohl  landesminis...   \n",
       "726   ['bevor weiterreden einrei√üen redezeit k√ºnstli...   \n",
       "727   ['vergangenen sonntagabend konnten koalitionsf...   \n",
       "728   ['middelberg verlaub ton rede teilen  hause er...   \n",
       "729   ['middelberg verlaub ton rede teilen  hause er...   \n",
       "...                                                 ...   \n",
       "7504  ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "7505  ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "7506  ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "7507  ['los  herbstklausur n√ºrnberg startet dringend...   \n",
       "7508  ['bevor weiterreden einrei√üen redezeit k√ºnstli...   \n",
       "\n",
       "                                            Top_n_words  Probability  \\\n",
       "725   corona - pflege - lauterbach - maskenpflicht -...     0.972841   \n",
       "726   redezeit - b√ºndnis - zwischenfrage - kurzinter...     1.000000   \n",
       "727   ukraine - bundeswehr - krieg - russland - frie...     0.482274   \n",
       "728   inflation - milliarden - ezb - schuldenbremse ...     0.961712   \n",
       "729   inflation - milliarden - ezb - schuldenbremse ...     1.000000   \n",
       "...                                                 ...          ...   \n",
       "7504  wohnungen - bauen - wohnen - wohnraum - wohnun...     1.000000   \n",
       "7505  wohnungen - bauen - wohnen - wohnraum - wohnun...     1.000000   \n",
       "7506  wohnungen - bauen - wohnen - wohnraum - wohnun...     0.953011   \n",
       "7507  wohnungen - bauen - wohnen - wohnraum - wohnun...     1.000000   \n",
       "7508  redezeit - b√ºndnis - zwischenfrage - kurzinter...     0.436683   \n",
       "\n",
       "      Representative_document       date      partei          art  komplexit√§t  \n",
       "725                     False 2022-05-31         AfD  redebeitrag          380  \n",
       "726                     False 2022-05-31         SPD  redebeitrag           14  \n",
       "727                     False 2022-05-31         SPD  redebeitrag          326  \n",
       "728                     False 2022-05-31         AfD  redebeitrag          210  \n",
       "729                     False 2022-05-31  DIE LINKE.  redebeitrag          122  \n",
       "...                       ...        ...         ...          ...          ...  \n",
       "7504                    False 2023-05-12         FDP  redebeitrag          238  \n",
       "7505                    False 2023-05-12         SPD  redebeitrag          255  \n",
       "7506                    False 2023-05-12         CDU  redebeitrag          211  \n",
       "7507                    False 2023-05-12         SPD  redebeitrag          145  \n",
       "7508                    False 2023-05-12         SPD  redebeitrag           11  \n",
       "\n",
       "[6784 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>CustomName</th>\n",
       "      <th>Representation</th>\n",
       "      <th>KeyBERT</th>\n",
       "      <th>Llama3.1</th>\n",
       "      <th>MMR</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>date</th>\n",
       "      <th>partei</th>\n",
       "      <th>art</th>\n",
       "      <th>komplexit√§t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>14564</td>\n",
       "      <td>14564</td>\n",
       "      <td>cent pro kilowattstunde hoch gasumlage n√∂tig r...</td>\n",
       "      <td>7</td>\n",
       "      <td>7_gas_russland_unternehmen_winter</td>\n",
       "      <td>Russische Energiekrise und ihre Auswirkungen a...</td>\n",
       "      <td>['gas', 'russland', 'unternehmen', 'winter', '...</td>\n",
       "      <td>['energiepolitik', 'kernkraftwerke', 'energiev...</td>\n",
       "      <td>['Russische Energiekrise und ihre Auswirkungen...</td>\n",
       "      <td>['winter', 'putin', 'krise', 'ukraine', 'gassp...</td>\n",
       "      <td>['verehrte   sonntag gelegenheit ukrainischen ...</td>\n",
       "      <td>gas - russland - unternehmen - winter - putin ...</td>\n",
       "      <td>0.909051</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>15251</td>\n",
       "      <td>15251</td>\n",
       "      <td>b√ºrgerinnen  allein  fr√ºhzeitig bundesregierun...</td>\n",
       "      <td>12</td>\n",
       "      <td>12_gasumlage_entlastungspaket_entlastungen_gas</td>\n",
       "      <td>Entlastungspaket zur Energiekrise</td>\n",
       "      <td>['gasumlage', 'entlastungspaket', 'entlastunge...</td>\n",
       "      <td>['energiepreispauschale', 'gaspreisbremse', 'e...</td>\n",
       "      <td>['Entlastungspaket zur Energiekrise\\n\\n[INST]\\...</td>\n",
       "      <td>['entlastungspaket', 'cent', 'bundesregierung'...</td>\n",
       "      <td>['versprochen  steigenden #energiepreisen alle...</td>\n",
       "      <td>gasumlage - entlastungspaket - entlastungen - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>15585</td>\n",
       "      <td>15585</td>\n",
       "      <td>happy pride bundeskanzleramt ministerien beken...</td>\n",
       "      <td>46</td>\n",
       "      <td>46_inter_csd_trans_diskriminierung</td>\n",
       "      <td>Internationale Queer-Rechte und -Sichtbarkeit ...</td>\n",
       "      <td>['inter', 'csd', 'trans', 'diskriminierung', '...</td>\n",
       "      <td>['lgbtq', 'lgbtqi', 'bisexuellen', 'transsexue...</td>\n",
       "      <td>['Internationale Queer-Rechte und -Sichtbarkei...</td>\n",
       "      <td>['csd', 'diskriminierung', 'pride', 'bi', 'lsb...</td>\n",
       "      <td>['internationalen  homo bi inter transphobie k...</td>\n",
       "      <td>inter - csd - trans - diskriminierung - pride ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>15729</td>\n",
       "      <td>15729</td>\n",
       "      <td>ukraine kampfpanzer typ leopard  verf√ºgung  bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>2_ukraine_bundeswehr_krieg_russland</td>\n",
       "      <td>Russischer Angriffskrieg in der Ukraine und Eu...</td>\n",
       "      <td>['ukraine', 'bundeswehr', 'krieg', 'russland',...</td>\n",
       "      <td>['milit√§risch', 'waffenlieferungen', 'milit√§ri...</td>\n",
       "      <td>['Russischer Angriffskrieg in der Ukraine und ...</td>\n",
       "      <td>['ukraine', 'bundeswehr', 'nato', 'sonderverm√∂...</td>\n",
       "      <td>['vergangenen sonntagabend konnten koalitionsf...</td>\n",
       "      <td>ukraine - bundeswehr - krieg - russland - frie...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>16235</td>\n",
       "      <td>16235</td>\n",
       "      <td>august  ukraine unabh√§ngig  genau   bundeskanz...</td>\n",
       "      <td>2</td>\n",
       "      <td>2_ukraine_bundeswehr_krieg_russland</td>\n",
       "      <td>Russischer Angriffskrieg in der Ukraine und Eu...</td>\n",
       "      <td>['ukraine', 'bundeswehr', 'krieg', 'russland',...</td>\n",
       "      <td>['milit√§risch', 'waffenlieferungen', 'milit√§ri...</td>\n",
       "      <td>['Russischer Angriffskrieg in der Ukraine und ...</td>\n",
       "      <td>['ukraine', 'bundeswehr', 'nato', 'sonderverm√∂...</td>\n",
       "      <td>['vergangenen sonntagabend konnten koalitionsf...</td>\n",
       "      <td>ukraine - bundeswehr - krieg - russland - frie...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15927</th>\n",
       "      <td>40256</td>\n",
       "      <td>40256</td>\n",
       "      <td>kindertag   gleich doppelt wann feiern  juni  ...</td>\n",
       "      <td>6</td>\n",
       "      <td>6_kita_kitas_familien_kindern</td>\n",
       "      <td>Fr√ºhkindliche Bildung und Betreuung in Kitas</td>\n",
       "      <td>['kita', 'kitas', 'familien', 'kindern', 'spra...</td>\n",
       "      <td>['sprachf√∂rderung', 'sprachkitas', 'f√∂rderung'...</td>\n",
       "      <td>['Fr√ºhkindliche Bildung und Betreuung in Kitas...</td>\n",
       "      <td>['kitas', 'kindern', 'kindergrundsicherung', '...</td>\n",
       "      <td>['werte    b√ºrgerinnen   kita  meilenstein ers...</td>\n",
       "      <td>kita - kitas - familien - kindern - sprach - e...</td>\n",
       "      <td>0.653165</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971</th>\n",
       "      <td>40346</td>\n",
       "      <td>40346</td>\n",
       "      <td>wir berufsfeuerwehr ausw√§rtigen amtes   buck m...</td>\n",
       "      <td>2</td>\n",
       "      <td>2_ukraine_bundeswehr_krieg_russland</td>\n",
       "      <td>Russischer Angriffskrieg in der Ukraine und Eu...</td>\n",
       "      <td>['ukraine', 'bundeswehr', 'krieg', 'russland',...</td>\n",
       "      <td>['milit√§risch', 'waffenlieferungen', 'milit√§ri...</td>\n",
       "      <td>['Russischer Angriffskrieg in der Ukraine und ...</td>\n",
       "      <td>['ukraine', 'bundeswehr', 'nato', 'sonderverm√∂...</td>\n",
       "      <td>['vergangenen sonntagabend konnten koalitionsf...</td>\n",
       "      <td>ukraine - bundeswehr - krieg - russland - frie...</td>\n",
       "      <td>0.904667</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15983</th>\n",
       "      <td>40374</td>\n",
       "      <td>40374</td>\n",
       "      <td>fotos erinnerung   entstehen oft zuf√§llig  g g...</td>\n",
       "      <td>68</td>\n",
       "      <td>68_cum_warburg_ex_bank</td>\n",
       "      <td>Olaf Scholz Rolle in der Cum-Ex Aff√§re</td>\n",
       "      <td>['cum', 'warburg', 'ex', 'bank', 'scholz', 'ol...</td>\n",
       "      <td>['steuerbetrug', 'ged√§chtnisl√ºcken', 'steueraf...</td>\n",
       "      <td>['Russischer Angriffskrieg in der Ukraine\\n\\n[...</td>\n",
       "      <td>['hamburger', 'bundeskanzler', 'staatsanwaltsc...</td>\n",
       "      <td>['verehrten   v√∂lkerrechtswidrige angriffskrie...</td>\n",
       "      <td>cum - warburg - ex - bank - scholz - olaf - ha...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16068</th>\n",
       "      <td>40534</td>\n",
       "      <td>40534</td>\n",
       "      <td>happy birthday erasmus   studieren lernen euro...</td>\n",
       "      <td>41</td>\n",
       "      <td>41_europa_europ√§ischen_europatag_eu</td>\n",
       "      <td>Europatag - Ein Fest f√ºr Frieden, Einheit und ...</td>\n",
       "      <td>['europa', 'europ√§ischen', 'europatag', 'eu', ...</td>\n",
       "      <td>['europeday', 'europatag', 'europaparlament', ...</td>\n",
       "      <td>['Europatag - Ein Fest f√ºr Frieden, Einheit un...</td>\n",
       "      <td>['europatag', 'eu', 'europas', 'frieden', 'sch...</td>\n",
       "      <td>['europatag  mai  legte robert schuman innovat...</td>\n",
       "      <td>europa - europ√§ischen - europatag - eu - europ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-10-13</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16069</th>\n",
       "      <td>40536</td>\n",
       "      <td>40536</td>\n",
       "      <td>bestnoten badegew√§sser  europa meisten seen fl...</td>\n",
       "      <td>25</td>\n",
       "      <td>25_wasser_w√§lder_wasserstrategie_klimaschutz</td>\n",
       "      <td>Nat√ºrlicher Wasser- und Klimaschutz</td>\n",
       "      <td>['wasser', 'w√§lder', 'wasserstrategie', 'klima...</td>\n",
       "      <td>['wasserhaushalt', 'renaturierung', 'wasserstr...</td>\n",
       "      <td>['Nat√ºrlicher Wasser- und Klimaschutz\\n\\n[INST...</td>\n",
       "      <td>['w√§lder', 'wasserstrategie', 'klimaschutz', '...</td>\n",
       "      <td>['pr√§sident      beraten  haushalt ministerium...</td>\n",
       "      <td>wasser - w√§lder - wasserstrategie - klimaschut...</td>\n",
       "      <td>0.706584</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-07-12</td>\n",
       "      <td>Bundesregierung</td>\n",
       "      <td>post</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows √ó 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  \\\n",
       "1291          14564       14564   \n",
       "1702          15251       15251   \n",
       "1891          15585       15585   \n",
       "1978          15729       15729   \n",
       "2277          16235       16235   \n",
       "...             ...         ...   \n",
       "15927         40256       40256   \n",
       "15971         40346       40346   \n",
       "15983         40374       40374   \n",
       "16068         40534       40534   \n",
       "16069         40536       40536   \n",
       "\n",
       "                                                Document  Topic  \\\n",
       "1291   cent pro kilowattstunde hoch gasumlage n√∂tig r...      7   \n",
       "1702   b√ºrgerinnen  allein  fr√ºhzeitig bundesregierun...     12   \n",
       "1891   happy pride bundeskanzleramt ministerien beken...     46   \n",
       "1978   ukraine kampfpanzer typ leopard  verf√ºgung  bi...      2   \n",
       "2277   august  ukraine unabh√§ngig  genau   bundeskanz...      2   \n",
       "...                                                  ...    ...   \n",
       "15927  kindertag   gleich doppelt wann feiern  juni  ...      6   \n",
       "15971  wir berufsfeuerwehr ausw√§rtigen amtes   buck m...      2   \n",
       "15983  fotos erinnerung   entstehen oft zuf√§llig  g g...     68   \n",
       "16068  happy birthday erasmus   studieren lernen euro...     41   \n",
       "16069  bestnoten badegew√§sser  europa meisten seen fl...     25   \n",
       "\n",
       "                                                 Name  \\\n",
       "1291                7_gas_russland_unternehmen_winter   \n",
       "1702   12_gasumlage_entlastungspaket_entlastungen_gas   \n",
       "1891               46_inter_csd_trans_diskriminierung   \n",
       "1978              2_ukraine_bundeswehr_krieg_russland   \n",
       "2277              2_ukraine_bundeswehr_krieg_russland   \n",
       "...                                               ...   \n",
       "15927                   6_kita_kitas_familien_kindern   \n",
       "15971             2_ukraine_bundeswehr_krieg_russland   \n",
       "15983                          68_cum_warburg_ex_bank   \n",
       "16068             41_europa_europ√§ischen_europatag_eu   \n",
       "16069    25_wasser_w√§lder_wasserstrategie_klimaschutz   \n",
       "\n",
       "                                              CustomName  \\\n",
       "1291   Russische Energiekrise und ihre Auswirkungen a...   \n",
       "1702                   Entlastungspaket zur Energiekrise   \n",
       "1891   Internationale Queer-Rechte und -Sichtbarkeit ...   \n",
       "1978   Russischer Angriffskrieg in der Ukraine und Eu...   \n",
       "2277   Russischer Angriffskrieg in der Ukraine und Eu...   \n",
       "...                                                  ...   \n",
       "15927       Fr√ºhkindliche Bildung und Betreuung in Kitas   \n",
       "15971  Russischer Angriffskrieg in der Ukraine und Eu...   \n",
       "15983             Olaf Scholz Rolle in der Cum-Ex Aff√§re   \n",
       "16068  Europatag - Ein Fest f√ºr Frieden, Einheit und ...   \n",
       "16069                Nat√ºrlicher Wasser- und Klimaschutz   \n",
       "\n",
       "                                          Representation  \\\n",
       "1291   ['gas', 'russland', 'unternehmen', 'winter', '...   \n",
       "1702   ['gasumlage', 'entlastungspaket', 'entlastunge...   \n",
       "1891   ['inter', 'csd', 'trans', 'diskriminierung', '...   \n",
       "1978   ['ukraine', 'bundeswehr', 'krieg', 'russland',...   \n",
       "2277   ['ukraine', 'bundeswehr', 'krieg', 'russland',...   \n",
       "...                                                  ...   \n",
       "15927  ['kita', 'kitas', 'familien', 'kindern', 'spra...   \n",
       "15971  ['ukraine', 'bundeswehr', 'krieg', 'russland',...   \n",
       "15983  ['cum', 'warburg', 'ex', 'bank', 'scholz', 'ol...   \n",
       "16068  ['europa', 'europ√§ischen', 'europatag', 'eu', ...   \n",
       "16069  ['wasser', 'w√§lder', 'wasserstrategie', 'klima...   \n",
       "\n",
       "                                                 KeyBERT  \\\n",
       "1291   ['energiepolitik', 'kernkraftwerke', 'energiev...   \n",
       "1702   ['energiepreispauschale', 'gaspreisbremse', 'e...   \n",
       "1891   ['lgbtq', 'lgbtqi', 'bisexuellen', 'transsexue...   \n",
       "1978   ['milit√§risch', 'waffenlieferungen', 'milit√§ri...   \n",
       "2277   ['milit√§risch', 'waffenlieferungen', 'milit√§ri...   \n",
       "...                                                  ...   \n",
       "15927  ['sprachf√∂rderung', 'sprachkitas', 'f√∂rderung'...   \n",
       "15971  ['milit√§risch', 'waffenlieferungen', 'milit√§ri...   \n",
       "15983  ['steuerbetrug', 'ged√§chtnisl√ºcken', 'steueraf...   \n",
       "16068  ['europeday', 'europatag', 'europaparlament', ...   \n",
       "16069  ['wasserhaushalt', 'renaturierung', 'wasserstr...   \n",
       "\n",
       "                                                Llama3.1  \\\n",
       "1291   ['Russische Energiekrise und ihre Auswirkungen...   \n",
       "1702   ['Entlastungspaket zur Energiekrise\\n\\n[INST]\\...   \n",
       "1891   ['Internationale Queer-Rechte und -Sichtbarkei...   \n",
       "1978   ['Russischer Angriffskrieg in der Ukraine und ...   \n",
       "2277   ['Russischer Angriffskrieg in der Ukraine und ...   \n",
       "...                                                  ...   \n",
       "15927  ['Fr√ºhkindliche Bildung und Betreuung in Kitas...   \n",
       "15971  ['Russischer Angriffskrieg in der Ukraine und ...   \n",
       "15983  ['Russischer Angriffskrieg in der Ukraine\\n\\n[...   \n",
       "16068  ['Europatag - Ein Fest f√ºr Frieden, Einheit un...   \n",
       "16069  ['Nat√ºrlicher Wasser- und Klimaschutz\\n\\n[INST...   \n",
       "\n",
       "                                                     MMR  \\\n",
       "1291   ['winter', 'putin', 'krise', 'ukraine', 'gassp...   \n",
       "1702   ['entlastungspaket', 'cent', 'bundesregierung'...   \n",
       "1891   ['csd', 'diskriminierung', 'pride', 'bi', 'lsb...   \n",
       "1978   ['ukraine', 'bundeswehr', 'nato', 'sonderverm√∂...   \n",
       "2277   ['ukraine', 'bundeswehr', 'nato', 'sonderverm√∂...   \n",
       "...                                                  ...   \n",
       "15927  ['kitas', 'kindern', 'kindergrundsicherung', '...   \n",
       "15971  ['ukraine', 'bundeswehr', 'nato', 'sonderverm√∂...   \n",
       "15983  ['hamburger', 'bundeskanzler', 'staatsanwaltsc...   \n",
       "16068  ['europatag', 'eu', 'europas', 'frieden', 'sch...   \n",
       "16069  ['w√§lder', 'wasserstrategie', 'klimaschutz', '...   \n",
       "\n",
       "                                     Representative_Docs  \\\n",
       "1291   ['verehrte   sonntag gelegenheit ukrainischen ...   \n",
       "1702   ['versprochen  steigenden #energiepreisen alle...   \n",
       "1891   ['internationalen  homo bi inter transphobie k...   \n",
       "1978   ['vergangenen sonntagabend konnten koalitionsf...   \n",
       "2277   ['vergangenen sonntagabend konnten koalitionsf...   \n",
       "...                                                  ...   \n",
       "15927  ['werte    b√ºrgerinnen   kita  meilenstein ers...   \n",
       "15971  ['vergangenen sonntagabend konnten koalitionsf...   \n",
       "15983  ['verehrten   v√∂lkerrechtswidrige angriffskrie...   \n",
       "16068  ['europatag  mai  legte robert schuman innovat...   \n",
       "16069  ['pr√§sident      beraten  haushalt ministerium...   \n",
       "\n",
       "                                             Top_n_words  Probability  \\\n",
       "1291   gas - russland - unternehmen - winter - putin ...     0.909051   \n",
       "1702   gasumlage - entlastungspaket - entlastungen - ...     1.000000   \n",
       "1891   inter - csd - trans - diskriminierung - pride ...     1.000000   \n",
       "1978   ukraine - bundeswehr - krieg - russland - frie...     1.000000   \n",
       "2277   ukraine - bundeswehr - krieg - russland - frie...     1.000000   \n",
       "...                                                  ...          ...   \n",
       "15927  kita - kitas - familien - kindern - sprach - e...     0.653165   \n",
       "15971  ukraine - bundeswehr - krieg - russland - frie...     0.904667   \n",
       "15983  cum - warburg - ex - bank - scholz - olaf - ha...     1.000000   \n",
       "16068  europa - europ√§ischen - europatag - eu - europ...     1.000000   \n",
       "16069  wasser - w√§lder - wasserstrategie - klimaschut...     0.706584   \n",
       "\n",
       "       Representative_document       date           partei   art  komplexit√§t  \n",
       "1291                     False 2022-08-15  Bundesregierung  post           41  \n",
       "1702                     False 2022-09-07  Bundesregierung  post           22  \n",
       "1891                     False 2022-07-23  Bundesregierung  post           17  \n",
       "1978                     False 2023-01-25  Bundesregierung  post           22  \n",
       "2277                     False 2022-08-24  Bundesregierung  post           59  \n",
       "...                        ...        ...              ...   ...          ...  \n",
       "15927                    False 2022-06-01  Bundesregierung  post           38  \n",
       "15971                    False 2022-06-01  Bundesregierung  post           46  \n",
       "15983                    False 2022-06-20  Bundesregierung  post           28  \n",
       "16068                    False 2022-10-13  Bundesregierung  post           36  \n",
       "16069                    False 2022-07-12  Bundesregierung  post           24  \n",
       "\n",
       "[270 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = subset_posts [(subset_posts[\"date\"] >= '2022-05-31') & (subset_posts[\"date\"] <= '2023-05-12')]\n",
    "p[p[\"partei\"]==\"Bundesregierung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2022-05-31    2712\n",
       "2022-06-01    4939\n",
       "2022-06-02    2277\n",
       "2022-06-03    4780\n",
       "2022-06-22    3475\n",
       "              ... \n",
       "2023-04-27    2553\n",
       "2023-04-28    2364\n",
       "2023-05-10    2350\n",
       "2023-05-11    3783\n",
       "2023-05-12    4190\n",
       "Name: komplexit√§t, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_komplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([p, r], ignore_index=True)\n",
    "len(df[\"Topic\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nur Topics ber√ºcksichtigen, die in beiden Datens√§tzen vorkommen\n",
    "# Filterfunktion\n",
    "def filter_common_topics(df1, df2):\n",
    "    \"\"\"\n",
    "    Filtert gemeinsame Topics aus zwei DataFrames und gibt neue DataFrames zur√ºck,\n",
    "    die nur die gemeinsamen Topics enthalten.\n",
    "    \n",
    "    Args:\n",
    "    - df1: Erster DataFrame\n",
    "    - df2: Zweiter DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_df1: DataFrame mit den gemeinsamen Topics aus df1\n",
    "    - filtered_df2: DataFrame mit den gemeinsamen Topics aus df2\n",
    "    \"\"\"\n",
    "    # Extrahiere die Spaltennamen, die Topics darstellen\n",
    "    topics_df1 = set(df1.columns)\n",
    "    topics_df2 = set(df2.columns)\n",
    "    \n",
    "    # Finde gemeinsame Topics\n",
    "    common_topics = topics_df1.intersection(topics_df2)\n",
    "    \n",
    "    print(f\"Gemeinsame Topics: {common_topics}\")\n",
    "    \n",
    "    # Filtere DataFrames auf die gemeinsamen Topics\n",
    "    filtered_df1 = df1[list(common_topics)]\n",
    "    filtered_df2 = df2[list(common_topics)]\n",
    "    \n",
    "    return filtered_df1, filtered_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 88, 90, 91, 92, 93}\n"
     ]
    }
   ],
   "source": [
    "rede_common, post_common = filter_common_topics(redethemen_t√§glich_aligned, postthemen_t√§glich_aligned)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ =  rede_common.div(rede_common.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ = post_common.div(post_common.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 30, 34, 36, 37, 40, 41, 43, 54, 68, 75}\n"
     ]
    }
   ],
   "source": [
    "def remove_near_constant(df):\n",
    "    \"\"\"\n",
    "    Entfernt Topics, wo mehr als 90% der Werte 0 sind, da diese als Konstant interpretiert werden\n",
    "    \"\"\"\n",
    "    percent_zeros_reden = (df == 0).mean() * 100\n",
    "    df = df.loc[:, percent_zeros_reden <= 90]\n",
    "    return df\n",
    "reden_relativ = remove_near_constant(reden_relativ)\n",
    "post_relativ = remove_near_constant(post_relativ)\n",
    "reden_relativ_reduced, post_relativ_reduced = filter_common_topics(reden_relativ, post_relativ)\n",
    "social_media_usage = subset_posts.groupby('date').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Topic</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>69</th>\n",
       "      <th>72</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>80</th>\n",
       "      <th>85</th>\n",
       "      <th>90</th>\n",
       "      <th>92</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>0.189873</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.240506</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-22</th>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.014184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-10</th>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.149123</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12</th>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows √ó 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Topic             0         1         2         3         4         5   \\\n",
       "date                                                                     \n",
       "2022-05-31  0.012658  0.012658  0.025316  0.000000  0.000000  0.101266   \n",
       "2022-06-01  0.000000  0.000000  0.632353  0.014706  0.000000  0.132353   \n",
       "2022-06-02  0.209677  0.177419  0.064516  0.008065  0.040323  0.064516   \n",
       "2022-06-03  0.000000  0.020000  0.520000  0.000000  0.000000  0.060000   \n",
       "2022-06-22  0.007092  0.007092  0.595745  0.000000  0.000000  0.070922   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2023-04-27  0.134454  0.100840  0.058824  0.025210  0.008403  0.067227   \n",
       "2023-04-28  0.000000  0.246575  0.000000  0.315068  0.013699  0.109589   \n",
       "2023-05-10  0.008772  0.096491  0.008772  0.035088  0.035088  0.149123   \n",
       "2023-05-11  0.058333  0.166667  0.091667  0.258333  0.075000  0.058333   \n",
       "2023-05-12  0.141026  0.000000  0.000000  0.000000  0.000000  0.064103   \n",
       "\n",
       "Topic             6         7         8         10  ...        69        72  \\\n",
       "date                                                ...                       \n",
       "2022-05-31  0.189873  0.075949  0.240506  0.101266  ...  0.012658  0.000000   \n",
       "2022-06-01  0.000000  0.044118  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "2022-06-02  0.008065  0.024194  0.000000  0.048387  ...  0.000000  0.016129   \n",
       "2022-06-03  0.000000  0.020000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "2022-06-22  0.000000  0.007092  0.000000  0.000000  ...  0.000000  0.007092   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2023-04-27  0.000000  0.000000  0.000000  0.016807  ...  0.000000  0.008403   \n",
       "2023-04-28  0.000000  0.027397  0.000000  0.000000  ...  0.000000  0.027397   \n",
       "2023-05-10  0.061404  0.008772  0.000000  0.087719  ...  0.000000  0.017544   \n",
       "2023-05-11  0.016667  0.000000  0.000000  0.000000  ...  0.000000  0.008333   \n",
       "2023-05-12  0.000000  0.000000  0.205128  0.000000  ...  0.141026  0.012821   \n",
       "\n",
       "Topic             74   75        77        78        80   85        90  \\\n",
       "date                                                                     \n",
       "2022-05-31  0.000000  0.0  0.025316  0.012658  0.000000  0.0  0.000000   \n",
       "2022-06-01  0.014706  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "2022-06-02  0.000000  0.0  0.016129  0.000000  0.000000  0.0  0.000000   \n",
       "2022-06-03  0.000000  0.0  0.040000  0.000000  0.000000  0.0  0.000000   \n",
       "2022-06-22  0.000000  0.0  0.000000  0.000000  0.007092  0.0  0.007092   \n",
       "...              ...  ...       ...       ...       ...  ...       ...   \n",
       "2023-04-27  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "2023-04-28  0.000000  0.0  0.000000  0.041096  0.000000  0.0  0.000000   \n",
       "2023-05-10  0.000000  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "2023-05-11  0.000000  0.0  0.000000  0.008333  0.008333  0.0  0.000000   \n",
       "2023-05-12  0.000000  0.0  0.000000  0.012821  0.000000  0.0  0.000000   \n",
       "\n",
       "Topic             92  \n",
       "date                  \n",
       "2022-05-31  0.000000  \n",
       "2022-06-01  0.000000  \n",
       "2022-06-02  0.000000  \n",
       "2022-06-03  0.000000  \n",
       "2022-06-22  0.014184  \n",
       "...              ...  \n",
       "2023-04-27  0.000000  \n",
       "2023-04-28  0.000000  \n",
       "2023-05-10  0.000000  \n",
       "2023-05-11  0.000000  \n",
       "2023-05-12  0.000000  \n",
       "\n",
       "[66 rows x 49 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reden_relativ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Liste der Landtagswahltermine\n",
    "# landtagswahltermine = [\n",
    "#     \"2022-05-08\",  # Schleswig-Holstein\n",
    "#     \"2022-05-15\",  # Nordrhein-Westfalen\n",
    "#     \"2022-10-09\"   # Niedersachsen\n",
    "# ]\n",
    "\n",
    "# # Konvertiere die Termine zu Datetime\n",
    "# landtagswahltermine = pd.to_datetime(landtagswahltermine)\n",
    "\n",
    "# # Zeitfenster: 30 Tage nach der Wahl\n",
    "# zeitfenster = 30\n",
    "\n",
    "# # Erstelle eine vollst√§ndige Datumsreihe im Beobachtungszeitraum\n",
    "# beobachtungszeitraum = pd.date_range(start=\"2022-05-01\", end=\"2023-05-31\", freq=\"D\")\n",
    "\n",
    "# # Initialisiere die Series mit Nullen\n",
    "# landtagswahlen_series = pd.Series(0, index=beobachtungszeitraum)\n",
    "\n",
    "# # Markiere die Zeitfenster nach den Landtagswahlen\n",
    "# for wahltermin in landtagswahltermine:\n",
    "#     landtagswahlen_series.loc[wahltermin:wahltermin + pd.Timedelta(days=zeitfenster)] = 1\n",
    "\n",
    "# # Kontrolliere die Series\n",
    "# landtagswahlen_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-05-01    2\n",
       "2022-05-02    2\n",
       "2022-05-03    2\n",
       "2022-05-04    2\n",
       "2022-05-05    2\n",
       "             ..\n",
       "2023-05-27    0\n",
       "2023-05-28    0\n",
       "2023-05-29    0\n",
       "2023-05-30    0\n",
       "2023-05-31    0\n",
       "Freq: D, Length: 396, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Liste der Landtagswahltermine\n",
    "landtagswahltermine = [\n",
    "    \"2022-05-08\",  # Schleswig-Holstein\n",
    "    \"2022-05-15\",  # Nordrhein-Westfalen\n",
    "    \"2022-10-09\"   # Niedersachsen\n",
    "]\n",
    "\n",
    "# Konvertiere die Termine zu Datetime\n",
    "landtagswahltermine = pd.to_datetime(landtagswahltermine)\n",
    "\n",
    "# Zeitfenster: 30 Tage vor und nach der Wahl\n",
    "zeitfenster = 30\n",
    "\n",
    "# Erstelle eine vollst√§ndige Datumsreihe im Beobachtungszeitraum\n",
    "beobachtungszeitraum = pd.date_range(start=\"2022-05-01\", end=\"2023-05-31\", freq=\"D\")\n",
    "\n",
    "# Initialisiere die Series mit Nullen\n",
    "landtagswahlen_series = pd.Series(0, index=beobachtungszeitraum)\n",
    "\n",
    "# Inkrementiere die Werte f√ºr sich √ºberlappende Zeitfenster\n",
    "for wahltermin in landtagswahltermine:\n",
    "    startdatum = wahltermin - pd.Timedelta(days=zeitfenster)\n",
    "    enddatum = wahltermin + pd.Timedelta(days=zeitfenster)\n",
    "    landtagswahlen_series.loc[startdatum:enddatum] += 1\n",
    "\n",
    "# Kontrolliere die Series\n",
    "landtagswahlen_series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_with_lags_SM(relativ_rede, relativ_posts, reden_to_shift):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit zeitversetzten unabh√§ngigen Variablen durch.\n",
    "    \n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit Erw√§hnungen im Parlament; relative Anteile.\n",
    "    - relativ_posts: DataFrame mit Erw√§hnungen auf Social Media; relative Anteile.\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    # # Erneute Anpassung des Datums\n",
    "    # common_dates2 = redethemen_t√§glich.index.intersection(posts_shifted.index)\n",
    "    # redethemen_t√§glich_aligned = redethemen_t√§glich.loc[common_dates2]\n",
    "    # postthemen_t√§glich_aligned = postthemen_t√§glich.loc[common_dates2]\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    reden_shifted_common = reden_to_shift.shift().dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(reden_shifted_common.index)\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts=relativ_posts.loc[common_dates2]\n",
    "    y = (reden_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen (t-1): Erw√§hnungen im Parlament mit Zeitversatz\n",
    "    #absolute = rede_common.shift(lag_days).stack()\n",
    "    \n",
    "    relative_reden = relativ_rede.stack()\n",
    "\n",
    "    relative_posts = relativ_posts.stack()\n",
    "\n",
    "    # DataFrame f√ºr die logistische Regression\n",
    "    X = pd.DataFrame({ 'posts_relative': relative_posts, 'reden_relativ': relative_reden}).dropna()\n",
    "\n",
    "    # Zielvariable und unabh√§ngige Variablen ausrichten\n",
    "    y = y[X.index]\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y, X).fit()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistische Regression mit der Kontrollvariable 'social_media_usage'\n",
    "def logistic_regression_with_control(relativ_rede, relativ_posts, reden_to_shift, social_media_usage):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit der Kontrollvariable 'social_media_usage' durch.\n",
    "    \n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit relativen Anteilen der Themen im Bundestag.\n",
    "    - relativ_posts: DataFrame mit relativen Anteilen der Themen auf Social Media.\n",
    "    - post_to_shift: DataFrame mit Themen auf Social Media (Zielvariable, t+1).\n",
    "    - social_media_usage: Series mit t√§glicher Social-Media-Aktivit√§t.\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    reden_shifted_common = reden_to_shift.shift().dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(reden_shifted_common.index)\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts = relativ_posts.loc[common_dates2]\n",
    "    social_media_usage = social_media_usage.loc[common_dates2]\n",
    "    landtagswahlen = landtagswahlen_series.loc[common_dates2]\n",
    "\n",
    "    y = (reden_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen\n",
    "    relative_reden = relativ_rede.stack()\n",
    "    relative_posts = relativ_posts.stack()\n",
    "\n",
    "    # Kontrollvariablen hinzuf√ºgen\n",
    "    social_media_usage_stacked = social_media_usage.reindex(relativ_rede.index)\n",
    "    social_media_usage_stacked = social_media_usage_stacked.repeat(relativ_rede.shape[1])\n",
    "    social_media_usage_stacked.index = relative_reden.index\n",
    "\n",
    "   # Dummy-Variable f√ºr Landtagswahlen\n",
    "    landtagswahlen_stacked = landtagswahlen.reindex(relativ_rede.index)\n",
    "    landtagswahlen_stacked = landtagswahlen_stacked.repeat(relativ_rede.shape[1])\n",
    "    landtagswahlen_stacked.index = relative_reden.index\n",
    "\n",
    "   \n",
    "    \n",
    "    # DataFrame f√ºr die logistische Regression\n",
    "    X = pd.DataFrame({\n",
    "        'posts_relative': relative_posts, \n",
    "        'reden_relativ': relative_reden,\n",
    "        'social_media_usage': social_media_usage_stacked,\n",
    "        'Landtagswahlen': landtagswahlen_stacked\n",
    "    }).dropna()\n",
    "\n",
    "    # Zielvariable und X ausrichten\n",
    "    y = y.reindex(X.index).dropna()\n",
    "    X = X.loc[y.index]\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y, X).fit()\n",
    "    print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, brier_score_loss, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "# Mit fixed_effects\n",
    "\n",
    "def log_reg_FE_control(relativ_rede, relativ_posts, post_to_shift,shifts, social_media_usage):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit Fixed Effects f√ºr Themen durch.\n",
    "    \n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit Erw√§hnungen im Parlament; relative Anteile.\n",
    "    - relativ_posts: DataFrame mit Erw√§hnungen auf Social Media; relative Anteile.\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    posts_shifted_common = post_to_shift.shift(shifts).dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(posts_shifted_common.index)\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts=relativ_posts.loc[common_dates2]\n",
    "    social_media_usage = social_media_usage.loc[common_dates2]\n",
    "    landtagswahlen = landtagswahlen_series.loc[common_dates2]\n",
    "    y = (posts_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen: relative Anteile im Parlament und auf Social Media\n",
    "    relative_reden = relativ_rede.stack()\n",
    "    relative_posts = relativ_posts.stack()\n",
    "    # Kontrollvariable Social Media hinzuf√ºgen\n",
    "    social_media_usage_stacked = social_media_usage.reindex(relativ_rede.index)\n",
    "    social_media_usage_stacked = social_media_usage_stacked.repeat(relativ_rede.shape[1])\n",
    "    social_media_usage_stacked.index = relative_reden.index\n",
    "\n",
    "    # Kontrollvariable Landtagswahlen hinzuf√ºgen\n",
    "    # Dummy-Variable f√ºr Landtagswahlen\n",
    "    landtagswahlen_stacked = landtagswahlen.reindex(relativ_rede.index)\n",
    "    landtagswahlen_stacked = landtagswahlen_stacked.repeat(relativ_rede.shape[1])\n",
    "    landtagswahlen_stacked.index = relative_reden.index\n",
    "    # Zielvariable und unabh√§ngige Variablen als DataFrame zusammenf√ºhren\n",
    "    X = pd.DataFrame({'issue attention Facebook': relative_posts, \n",
    "                      'issue attention Bundestag': relative_reden,\n",
    "                      'Social Media Nutzung': social_media_usage_stacked,\n",
    "                       'Landtagswahlen': landtagswahlen_stacked }).dropna()\n",
    "    y = y.reindex(X.index).dropna()\n",
    "\n",
    "    # Konvertiere MultiIndex zu flachem Index, um die Kompatibilit√§t sicherzustellen\n",
    "    X.index = X.index.to_flat_index()\n",
    "    y.index = y.index.to_flat_index()\n",
    "\n",
    "    # Dummy-Variablen f√ºr Themen (Fixed Effects)\n",
    "    topics = [idx[1] for idx in X.index]  # Der zweite Wert im Tupel repr√§sentiert das Topic\n",
    "    topic_dummies = pd.get_dummies(topics, prefix='topic',drop_first=True).astype(int) # ohne.astype(int) kommen hier Fehlermeldungen\n",
    "    # Versuch aus den Topics Topic 0 zu l√∂schen und somit bessere Daten zu erlangen\n",
    "\n",
    "    # F√ºge Dummy-Variablen hinzu\n",
    "    X = pd.concat([X.reset_index(drop=True), topic_dummies.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y.values, X).fit(maxiter=100)\n",
    "    print(model.summary())\n",
    "    # Modellg√ºte-Kennzahlen berechnen\n",
    "    y_pred_prob = model.predict(X)  # Vorhergesagte Wahrscheinlichkeiten\n",
    "    y_pred = (y_pred_prob >= 0.5).astype(int)  # Bin√§re Vorhersagen\n",
    "\n",
    "    # AUC-ROC\n",
    "    auc_roc = roc_auc_score(y, y_pred_prob)\n",
    "    print(f\"AUC-ROC: {auc_roc}\")\n",
    "\n",
    "    # Pr√§zision, Recall und F1-Score\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(f\"Pr√§zision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "\n",
    "    # Brier-Score\n",
    "    brier_score = brier_score_loss(y, y_pred_prob)\n",
    "    print(f\"Brier-Score: {brier_score}\")\n",
    "\n",
    "    # Confusion-Matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    print(\"Confusion-Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    return model, auc_roc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, brier_score_loss, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "def log_reg_FE_control_test(relativ_rede, relativ_posts, post_to_shift, shifts, social_media_usage, complexity_rede, complexity_post):\n",
    "    \"\"\"\n",
    "    F√ºhrt eine logistische Regression mit Fixed Effects f√ºr Themen durch, inklusive Kontrolle f√ºr Komplexit√§t.\n",
    "\n",
    "    Args:\n",
    "    - relativ_rede: DataFrame mit Erw√§hnungen im Parlament; relative Anteile.\n",
    "    - relativ_posts: DataFrame mit Erw√§hnungen auf Social Media; relative Anteile.\n",
    "    - post_to_shift: DataFrame der Social-Media-Posts zur Erstellung der Zielvariablen (verschoben um t+1).\n",
    "    - shifts: Anzahl der Tage, um die Zielvariable zu verschieben.\n",
    "    - social_media_usage: DataFrame mit der Anzahl der t√§glichen Social-Media-Beitr√§ge.\n",
    "    - landtagswahlen_series: Series mit Dummy-Variablen f√ºr Landtagswahlen.\n",
    "    - complexity_rede: DataFrame mit der Komplexit√§t (z. B. Wortanzahl) pro Tag f√ºr Reden.\n",
    "    - complexity_post: DataFrame mit der Komplexit√§t (z. B. Wortanzahl) pro Tag f√ºr Social-Media-Posts.\n",
    "\n",
    "    Returns:\n",
    "    - model: Das trainierte logistische Regressionsmodell.\n",
    "    - auc_roc: Der AUC-ROC-Wert des Modells.\n",
    "    - f1: Der F1-Score des Modells.\n",
    "    \"\"\"\n",
    "    # Zielvariable (t+1): Thema auf Social Media erw√§hnt, einen Tag nach Besprechung im Parlament\n",
    "    posts_shifted_common = post_to_shift.shift(shifts).dropna()\n",
    "    common_dates2 = relativ_rede.index.intersection(posts_shifted_common.index)\n",
    "\n",
    "    # Synchronisiere alle relevanten Daten mit den gemeinsamen Datenpunkten\n",
    "    relativ_rede = relativ_rede.loc[common_dates2]\n",
    "    relativ_posts = relativ_posts.loc[common_dates2]\n",
    "    social_media_usage = social_media_usage.loc[common_dates2]\n",
    "    landtagswahlen = landtagswahlen_series.loc[common_dates2]\n",
    "    complexity_rede = complexity_rede.loc[common_dates2]\n",
    "    complexity_post = complexity_post.loc[common_dates2]\n",
    "    landtagswahlen = landtagswahlen_series.loc[common_dates2]\n",
    "\n",
    "    # Zielvariable erstellen\n",
    "    y = (posts_shifted_common > 0).astype(int).stack()\n",
    "\n",
    "    # Unabh√§ngige Variablen erstellen\n",
    "    relative_reden = relativ_rede.stack()\n",
    "    relative_posts = relativ_posts.stack()\n",
    "\n",
    "    # Kontrollvariable: Social Media Nutzung\n",
    "    social_media_usage_stacked = social_media_usage.reindex(relativ_rede.index)\n",
    "    social_media_usage_stacked = social_media_usage_stacked.repeat(relativ_rede.shape[1])\n",
    "    social_media_usage_stacked.index = relative_reden.index\n",
    "\n",
    "    # Kontrollvariable: Landtagswahlen\n",
    "    landtagswahlen_stacked = landtagswahlen.reindex(relativ_rede.index)\n",
    "    landtagswahlen_stacked = landtagswahlen_stacked.repeat(relativ_rede.shape[1])\n",
    "    landtagswahlen_stacked.index = relative_reden.index\n",
    "\n",
    "    # Kontrollvariable: Komplexit√§t der Reden (Z-Scores)\n",
    "    complexity_rede_z = (complexity_rede - complexity_rede.mean()) / complexity_rede.std()\n",
    "    complexity_rede_stacked = complexity_rede_z.reindex(relativ_rede.index)\n",
    "    complexity_rede_stacked = complexity_rede_stacked.repeat(relativ_rede.shape[1])\n",
    "    complexity_rede_stacked.index = relative_reden.index\n",
    "\n",
    "    # Kontrollvariable: Komplexit√§t der Posts (Z-Scores)\n",
    "    complexity_post_z = (complexity_post - complexity_post.mean()) / complexity_post.std()\n",
    "    complexity_post_stacked = complexity_post_z.reindex(relativ_posts.index)\n",
    "    complexity_post_stacked = complexity_post_stacked.repeat(relativ_posts.shape[1])\n",
    "    complexity_post_stacked.index = relative_posts.index\n",
    "\n",
    "    # Zielvariable und unabh√§ngige Variablen zusammenf√ºhren\n",
    "    X = pd.DataFrame({\n",
    "        'issue attention Facebook': relative_posts,\n",
    "        'issue attention Bundestag': relative_reden,\n",
    "        'Social Media Nutzung': social_media_usage_stacked,\n",
    "        'Landtagswahlen': landtagswahlen_stacked,\n",
    "        'Komplexit√§t Reden': complexity_rede_stacked,\n",
    "        'Komplexit√§t Posts': complexity_post_stacked\n",
    "    }).dropna()\n",
    "\n",
    "    y = y.reindex(X.index).dropna()\n",
    "\n",
    "    # Konvertiere MultiIndex zu flachem Index, um die Kompatibilit√§t sicherzustellen\n",
    "    X.index = X.index.to_flat_index()\n",
    "    y.index = y.index.to_flat_index()\n",
    "\n",
    "    # Dummy-Variablen f√ºr Themen (Fixed Effects)\n",
    "    topics = [idx[1] for idx in X.index]  # Der zweite Wert im Tupel repr√§sentiert das Topic\n",
    "    topic_dummies = pd.get_dummies(topics, prefix='topic', drop_first=True).astype(int)\n",
    "\n",
    "    # F√ºge Dummy-Variablen hinzu\n",
    "    X = pd.concat([X.reset_index(drop=True), topic_dummies.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Logistische Regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y.values, X).fit(maxiter=100)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # Modellg√ºte-Kennzahlen berechnen\n",
    "    y_pred_prob = model.predict(X)  # Vorhergesagte Wahrscheinlichkeiten\n",
    "    y_pred = (y_pred_prob >= 0.5).astype(int)  # Bin√§re Vorhersagen\n",
    "\n",
    "    # AUC-ROC\n",
    "    auc_roc = roc_auc_score(y, y_pred_prob)\n",
    "    print(f\"AUC-ROC: {auc_roc}\")\n",
    "\n",
    "    # Pr√§zision, Recall und F1-Score\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(f\"Pr√§zision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "\n",
    "    # Brier-Score\n",
    "    brier_score = brier_score_loss(y, y_pred_prob)\n",
    "    print(f\"Brier-Score: {brier_score}\")\n",
    "\n",
    "    # Confusion-Matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    print(\"Confusion-Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    return model, auc_roc, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.600862\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2272\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.04597\n",
      "Time:                        11:17:09   Log-Likelihood:                -1367.0\n",
      "converged:                       True   LL-Null:                       -1432.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.471e-29\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -1.0841      0.057    -19.151      0.000      -1.195      -0.973\n",
      "posts_relative    12.8815      1.421      9.068      0.000      10.097      15.666\n",
      "reden_relativ      2.2160      0.828      2.677      0.007       0.594       3.838\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM(reden_relativ_reduced, post_relativ_reduced, rede_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.600862\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2272\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.04597\n",
      "Time:                        11:17:09   Log-Likelihood:                -1367.0\n",
      "converged:                       True   LL-Null:                       -1432.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.471e-29\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -1.0841      0.057    -19.151      0.000      -1.195      -0.973\n",
      "posts_relative    12.8815      1.421      9.068      0.000      10.097      15.666\n",
      "reden_relativ      2.2160      0.828      2.677      0.007       0.594       3.838\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_with_lags_SM(reden_relativ_reduced, post_relativ_reduced, rede_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.600813\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2270\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.04605\n",
      "Time:                        11:17:09   Log-Likelihood:                -1366.8\n",
      "converged:                       True   LL-Null:                       -1432.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.481e-27\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 -1.0739      0.203     -5.302      0.000      -1.471      -0.677\n",
      "posts_relative        12.9019      1.424      9.060      0.000      10.111      15.693\n",
      "reden_relativ          2.2163      0.827      2.678      0.007       0.594       3.838\n",
      "social_media_usage  1.663e-05      0.003      0.005      0.996      -0.006       0.006\n",
      "Landtagswahlen        -0.0401      0.085     -0.469      0.639      -0.208       0.127\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Beispielaufruf\n",
    "logistic_regression_with_control(reden_relativ, post_relativ, rede_common, social_media_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531963\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2234\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.2321\n",
      "Time:                        11:17:10   Log-Likelihood:                -1210.2\n",
      "converged:                       True   LL-Null:                       -1576.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                5.544e-128\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.9640      0.853      3.474      0.001       1.292       4.636\n",
      "issue attention Facebook     17.8797      2.495      7.166      0.000      12.989      22.770\n",
      "issue attention Bundestag     0.2034      1.100      0.185      0.853      -1.954       2.360\n",
      "Social Media Nutzung         -0.0088      0.007     -1.317      0.188      -0.022       0.004\n",
      "Landtagswahlen                0.0251      0.093      0.269      0.788      -0.158       0.208\n",
      "Komplexit√§t Reden             0.0782      0.051      1.541      0.123      -0.021       0.178\n",
      "Komplexit√§t Posts             0.1017      0.103      0.986      0.324      -0.100       0.304\n",
      "topic_1                       0.5719      1.243      0.460      0.646      -1.865       3.009\n",
      "topic_2                      -1.3852      0.806     -1.718      0.086      -2.965       0.195\n",
      "topic_3                      -0.9264      0.866     -1.070      0.285      -2.624       0.771\n",
      "topic_4                       0.0550      1.024      0.054      0.957      -1.952       2.062\n",
      "topic_6                      -1.5485      0.791     -1.958      0.050      -3.099       0.002\n",
      "topic_7                      -2.5263      0.771     -3.276      0.001      -4.038      -1.015\n",
      "topic_8                      -2.1628      0.773     -2.798      0.005      -3.678      -0.648\n",
      "topic_10                     -2.3594      0.771     -3.061      0.002      -3.870      -0.849\n",
      "topic_11                     -2.5599      0.773     -3.314      0.001      -4.074      -1.046\n",
      "topic_12                     -2.5351      0.775     -3.273      0.001      -4.053      -1.017\n",
      "topic_13                     -2.1448      0.775     -2.768      0.006      -3.663      -0.626\n",
      "topic_14                     -2.9686      0.772     -3.845      0.000      -4.482      -1.455\n",
      "topic_15                     -2.1168      0.775     -2.730      0.006      -3.637      -0.597\n",
      "topic_16                     -2.6350      0.772     -3.415      0.001      -4.147      -1.123\n",
      "topic_17                     -2.8526      0.772     -3.697      0.000      -4.365      -1.340\n",
      "topic_18                     -2.4579      0.772     -3.184      0.001      -3.971      -0.945\n",
      "topic_19                     -2.6413      0.772     -3.422      0.001      -4.154      -1.129\n",
      "topic_20                     -3.6015      0.782     -4.608      0.000      -5.133      -2.070\n",
      "topic_21                     -2.6181      0.772     -3.393      0.001      -4.130      -1.106\n",
      "topic_22                     -2.6215      0.772     -3.397      0.001      -4.134      -1.109\n",
      "topic_23                     -3.0582      0.774     -3.950      0.000      -4.576      -1.541\n",
      "topic_24                     -3.0894      0.774     -3.994      0.000      -4.606      -1.573\n",
      "topic_25                     -3.0505      0.774     -3.942      0.000      -4.567      -1.534\n",
      "topic_29                     -3.4992      0.782     -4.475      0.000      -5.032      -1.967\n",
      "topic_30                     -3.4206      0.780     -4.383      0.000      -4.950      -1.891\n",
      "topic_34                     -3.3082      0.778     -4.254      0.000      -4.833      -1.784\n",
      "topic_36                     -3.9038      0.795     -4.912      0.000      -5.461      -2.346\n",
      "topic_37                     -3.8975      0.795     -4.905      0.000      -5.455      -2.340\n",
      "topic_40                     -3.4868      0.783     -4.456      0.000      -5.020      -1.953\n",
      "topic_41                     -3.9915      0.799     -4.995      0.000      -5.558      -2.425\n",
      "topic_43                     -4.2714      0.810     -5.275      0.000      -5.859      -2.684\n",
      "topic_54                     -4.4563      0.824     -5.410      0.000      -6.071      -2.842\n",
      "topic_68                     -4.4618      0.824     -5.414      0.000      -6.077      -2.846\n",
      "topic_75                     -4.1049      0.804     -5.105      0.000      -5.681      -2.529\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.802870277561223\n",
      "Pr√§zision: 0.7438271604938271\n",
      "Recall: 0.6531165311653117\n",
      "F1-Score: 0.6955266955266955\n",
      "Brier-Score: 0.1799498314035293\n",
      "Confusion-Matrix:\n",
      "[[919 249]\n",
      " [384 723]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x22402817fb0>,\n",
       " 0.802870277561223,\n",
       " 0.6955266955266955)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_FE_control_test(reden_relativ_reduced, post_relativ_reduced, post_common,1, social_media_usage,rede_komplex, posts_komplex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression f√ºr Lag 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539753\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2236\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1430\n",
      "Time:                        11:17:10   Log-Likelihood:                -1227.9\n",
      "converged:                       True   LL-Null:                       -1432.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.198e-64\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.3091      0.363      0.851      0.395      -0.403       1.021\n",
      "issue attention Facebook      7.7768      1.712      4.543      0.000       4.421      11.132\n",
      "issue attention Bundestag    -1.6714      0.907     -1.843      0.065      -3.449       0.106\n",
      "Social Media Nutzung         -0.0007      0.003     -0.211      0.833      -0.007       0.006\n",
      "Landtagswahlen               -0.0251      0.091     -0.275      0.784      -0.204       0.154\n",
      "topic_1                       0.1336      0.383      0.348      0.728      -0.618       0.885\n",
      "topic_2                       0.7828      0.405      1.935      0.053      -0.010       1.576\n",
      "topic_3                      -0.7913      0.369     -2.145      0.032      -1.514      -0.068\n",
      "topic_4                      -0.6126      0.371     -1.650      0.099      -1.340       0.115\n",
      "topic_6                      -0.1699      0.372     -0.456      0.648      -0.899       0.560\n",
      "topic_7                       1.2594      0.433      2.911      0.004       0.411       2.107\n",
      "topic_8                      -0.8275      0.378     -2.191      0.028      -1.568      -0.087\n",
      "topic_10                      0.0989      0.378      0.262      0.794      -0.642       0.840\n",
      "topic_11                     -2.2481      0.457     -4.914      0.000      -3.145      -1.351\n",
      "topic_12                     -1.7586      0.407     -4.325      0.000      -2.556      -0.962\n",
      "topic_13                     -2.2458      0.456     -4.926      0.000      -3.139      -1.352\n",
      "topic_14                     -0.6490      0.379     -1.711      0.087      -1.392       0.094\n",
      "topic_15                     -1.6348      0.406     -4.025      0.000      -2.431      -0.839\n",
      "topic_16                     -1.4665      0.398     -3.682      0.000      -2.247      -0.686\n",
      "topic_17                     -2.3439      0.472     -4.969      0.000      -3.268      -1.419\n",
      "topic_18                     -1.4935      0.404     -3.692      0.000      -2.286      -0.701\n",
      "topic_19                     -1.1083      0.389     -2.851      0.004      -1.870      -0.346\n",
      "topic_20                     -1.6209      0.409     -3.966      0.000      -2.422      -0.820\n",
      "topic_21                     -1.6943      0.413     -4.103      0.000      -2.504      -0.885\n",
      "topic_22                     -1.5550      0.409     -3.806      0.000      -2.356      -0.754\n",
      "topic_23                     -1.8022      0.429     -4.203      0.000      -2.643      -0.962\n",
      "topic_24                     -1.5263      0.409     -3.727      0.000      -2.329      -0.724\n",
      "topic_25                     -0.9778      0.388     -2.520      0.012      -1.738      -0.217\n",
      "topic_29                     -1.0246      0.391     -2.622      0.009      -1.791      -0.259\n",
      "topic_30                     -1.8808      0.438     -4.292      0.000      -2.740      -1.022\n",
      "topic_34                     -1.4278      0.406     -3.514      0.000      -2.224      -0.631\n",
      "topic_36                     -1.7627      0.430     -4.096      0.000      -2.606      -0.919\n",
      "topic_37                     -1.4833      0.412     -3.600      0.000      -2.291      -0.676\n",
      "topic_40                     -1.7804      0.430     -4.136      0.000      -2.624      -0.937\n",
      "topic_41                     -1.8814      0.440     -4.281      0.000      -2.743      -1.020\n",
      "topic_43                     -1.6756      0.423     -3.963      0.000      -2.504      -0.847\n",
      "topic_54                     -2.1039      0.461     -4.563      0.000      -3.008      -1.200\n",
      "topic_68                     -2.2412      0.476     -4.711      0.000      -3.174      -1.309\n",
      "topic_75                     -1.2471      0.401     -3.112      0.002      -2.032      -0.462\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7439947384486717\n",
      "Pr√§zision: 0.6844444444444444\n",
      "Recall: 0.417910447761194\n",
      "F1-Score: 0.518955349620893\n",
      "Brier-Score: 0.17924679702060345\n",
      "Confusion-Matrix:\n",
      "[[1396  142]\n",
      " [ 429  308]]\n",
      "\n",
      "Regression f√ºr Lag 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542504\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2240\n",
      "Model:                          Logit   Df Residuals:                     2201\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1397\n",
      "Time:                        11:17:10   Log-Likelihood:                -1215.2\n",
      "converged:                       True   LL-Null:                       -1412.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.303e-61\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.6949      0.371      1.874      0.061      -0.032       1.422\n",
      "issue attention Facebook      2.8123      1.699      1.655      0.098      -0.518       6.143\n",
      "issue attention Bundestag     1.6378      0.960      1.706      0.088      -0.244       3.520\n",
      "Social Media Nutzung         -0.0051      0.003     -1.481      0.139      -0.012       0.002\n",
      "Landtagswahlen               -0.2044      0.101     -2.019      0.044      -0.403      -0.006\n",
      "topic_1                       0.2289      0.383      0.598      0.550      -0.522       0.979\n",
      "topic_2                       0.5873      0.402      1.462      0.144      -0.200       1.375\n",
      "topic_3                      -0.6704      0.368     -1.824      0.068      -1.391       0.050\n",
      "topic_4                      -0.4337      0.369     -1.175      0.240      -1.157       0.290\n",
      "topic_6                      -0.2234      0.373     -0.599      0.549      -0.954       0.508\n",
      "topic_7                       1.2197      0.443      2.753      0.006       0.351       2.088\n",
      "topic_8                      -0.8918      0.379     -2.351      0.019      -1.635      -0.148\n",
      "topic_10                      0.0069      0.380      0.018      0.986      -0.739       0.752\n",
      "topic_11                     -2.1908      0.458     -4.786      0.000      -3.088      -1.294\n",
      "topic_12                     -1.6139      0.404     -3.990      0.000      -2.407      -0.821\n",
      "topic_13                     -2.2169      0.456     -4.862      0.000      -3.111      -1.323\n",
      "topic_14                     -0.7061      0.381     -1.852      0.064      -1.453       0.041\n",
      "topic_15                     -1.5980      0.406     -3.932      0.000      -2.395      -0.801\n",
      "topic_16                     -1.4182      0.398     -3.559      0.000      -2.199      -0.637\n",
      "topic_17                     -2.3360      0.472     -4.948      0.000      -3.261      -1.411\n",
      "topic_18                     -1.4727      0.405     -3.634      0.000      -2.267      -0.679\n",
      "topic_19                     -1.1621      0.392     -2.964      0.003      -1.931      -0.394\n",
      "topic_20                     -1.5880      0.407     -3.899      0.000      -2.386      -0.790\n",
      "topic_21                     -1.6943      0.413     -4.106      0.000      -2.503      -0.886\n",
      "topic_22                     -1.5778      0.409     -3.857      0.000      -2.380      -0.776\n",
      "topic_23                     -1.8376      0.430     -4.276      0.000      -2.680      -0.995\n",
      "topic_24                     -1.5624      0.410     -3.806      0.000      -2.367      -0.758\n",
      "topic_25                     -1.0152      0.389     -2.608      0.009      -1.778      -0.252\n",
      "topic_29                     -1.0804      0.392     -2.754      0.006      -1.849      -0.311\n",
      "topic_30                     -1.9348      0.439     -4.406      0.000      -2.796      -1.074\n",
      "topic_34                     -1.5467      0.412     -3.754      0.000      -2.354      -0.739\n",
      "topic_36                     -1.8247      0.431     -4.229      0.000      -2.670      -0.979\n",
      "topic_37                     -1.5348      0.414     -3.711      0.000      -2.345      -0.724\n",
      "topic_40                     -1.8162      0.431     -4.209      0.000      -2.662      -0.970\n",
      "topic_41                     -1.9130      0.441     -4.341      0.000      -2.777      -1.049\n",
      "topic_43                     -1.7298      0.424     -4.082      0.000      -2.560      -0.899\n",
      "topic_54                     -2.2933      0.477     -4.812      0.000      -3.227      -1.359\n",
      "topic_68                     -2.2905      0.477     -4.804      0.000      -3.225      -1.356\n",
      "topic_75                     -1.2798      0.402     -3.184      0.001      -2.068      -0.492\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.738036186696901\n",
      "Pr√§zision: 0.6784140969162996\n",
      "Recall: 0.4230769230769231\n",
      "F1-Score: 0.5211505922165821\n",
      "Brier-Score: 0.18028125549459456\n",
      "Confusion-Matrix:\n",
      "[[1366  146]\n",
      " [ 420  308]]\n",
      "\n",
      "Regression f√ºr Lag 3:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540756\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2205\n",
      "Model:                          Logit   Df Residuals:                     2166\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1399\n",
      "Time:                        11:17:10   Log-Likelihood:                -1192.4\n",
      "converged:                       True   LL-Null:                       -1386.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.566e-59\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1737      0.367     -0.474      0.636      -0.892       0.545\n",
      "issue attention Facebook      6.0754      1.723      3.525      0.000       2.698       9.453\n",
      "issue attention Bundestag    -0.3037      0.931     -0.326      0.744      -2.129       1.522\n",
      "Social Media Nutzung          0.0066      0.003      1.957      0.050   -1.11e-05       0.013\n",
      "Landtagswahlen               -0.1274      0.110     -1.155      0.248      -0.343       0.089\n",
      "topic_1                       0.1914      0.385      0.497      0.619      -0.563       0.946\n",
      "topic_2                       0.7161      0.404      1.771      0.077      -0.076       1.509\n",
      "topic_3                      -0.7525      0.371     -2.028      0.043      -1.480      -0.025\n",
      "topic_4                      -0.5448      0.373     -1.462      0.144      -1.275       0.186\n",
      "topic_6                      -0.1671      0.375     -0.446      0.656      -0.901       0.567\n",
      "topic_7                       1.3394      0.444      3.017      0.003       0.469       2.209\n",
      "topic_8                      -0.7365      0.381     -1.934      0.053      -1.483       0.010\n",
      "topic_10                      0.1276      0.382      0.334      0.738      -0.621       0.876\n",
      "topic_11                     -2.1231      0.459     -4.627      0.000      -3.022      -1.224\n",
      "topic_12                     -1.6017      0.407     -3.937      0.000      -2.399      -0.804\n",
      "topic_13                     -2.1333      0.457     -4.665      0.000      -3.030      -1.237\n",
      "topic_14                     -0.6184      0.384     -1.611      0.107      -1.371       0.134\n",
      "topic_15                     -1.6057      0.413     -3.887      0.000      -2.415      -0.796\n",
      "topic_16                     -1.3494      0.400     -3.374      0.001      -2.133      -0.566\n",
      "topic_17                     -2.3995      0.491     -4.884      0.000      -3.362      -1.437\n",
      "topic_18                     -1.3808      0.407     -3.394      0.001      -2.178      -0.584\n",
      "topic_19                     -1.0615      0.394     -2.695      0.007      -1.834      -0.290\n",
      "topic_20                     -1.6029      0.415     -3.863      0.000      -2.416      -0.790\n",
      "topic_21                     -1.6883      0.420     -4.019      0.000      -2.512      -0.865\n",
      "topic_22                     -1.5529      0.416     -3.735      0.000      -2.368      -0.738\n",
      "topic_23                     -1.7153      0.431     -3.981      0.000      -2.560      -0.871\n",
      "topic_24                     -1.4391      0.412     -3.496      0.000      -2.246      -0.632\n",
      "topic_25                     -0.8843      0.391     -2.263      0.024      -1.650      -0.119\n",
      "topic_29                     -1.0121      0.396     -2.556      0.011      -1.788      -0.236\n",
      "topic_30                     -1.8019      0.440     -4.094      0.000      -2.665      -0.939\n",
      "topic_34                     -1.5143      0.418     -3.619      0.000      -2.334      -0.694\n",
      "topic_36                     -1.6818      0.433     -3.886      0.000      -2.530      -0.834\n",
      "topic_37                     -1.4005      0.415     -3.377      0.001      -2.213      -0.588\n",
      "topic_40                     -1.8000      0.441     -4.083      0.000      -2.664      -0.936\n",
      "topic_41                     -1.7931      0.442     -4.060      0.000      -2.659      -0.927\n",
      "topic_43                     -1.5952      0.425     -3.754      0.000      -2.428      -0.762\n",
      "topic_54                     -2.1643      0.477     -4.533      0.000      -3.100      -1.229\n",
      "topic_68                     -2.1619      0.478     -4.526      0.000      -3.098      -1.226\n",
      "topic_75                     -1.1544      0.403     -2.862      0.004      -1.945      -0.364\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7391601097310009\n",
      "Pr√§zision: 0.6812933025404158\n",
      "Recall: 0.4149085794655415\n",
      "F1-Score: 0.5157342657342657\n",
      "Brier-Score: 0.1793857891219391\n",
      "Confusion-Matrix:\n",
      "[[1356  138]\n",
      " [ 416  295]]\n",
      "\n",
      "Regression f√ºr Lag 4:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546070\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2170\n",
      "Model:                          Logit   Df Residuals:                     2131\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1339\n",
      "Time:                        11:17:10   Log-Likelihood:                -1185.0\n",
      "converged:                       True   LL-Null:                       -1368.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.546e-55\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.7766      0.374      2.076      0.038       0.043       1.510\n",
      "issue attention Facebook     -0.2155      1.710     -0.126      0.900      -3.566       3.135\n",
      "issue attention Bundestag     0.4206      0.953      0.441      0.659      -1.447       2.288\n",
      "Social Media Nutzung         -0.0015      0.003     -0.424      0.672      -0.008       0.005\n",
      "Landtagswahlen               -0.1525      0.126     -1.215      0.224      -0.399       0.094\n",
      "topic_1                       0.1546      0.385      0.401      0.688      -0.600       0.909\n",
      "topic_2                       0.5521      0.409      1.352      0.177      -0.249       1.353\n",
      "topic_3                      -0.7854      0.371     -2.115      0.034      -1.513      -0.058\n",
      "topic_4                      -0.5823      0.373     -1.560      0.119      -1.314       0.149\n",
      "topic_6                      -0.4041      0.378     -1.069      0.285      -1.145       0.337\n",
      "topic_7                       0.9785      0.445      2.199      0.028       0.106       1.851\n",
      "topic_8                      -1.0588      0.384     -2.757      0.006      -1.812      -0.306\n",
      "topic_10                     -0.2087      0.387     -0.540      0.589      -0.966       0.549\n",
      "topic_11                     -2.4242      0.462     -5.252      0.000      -3.329      -1.520\n",
      "topic_12                     -1.7906      0.409     -4.377      0.000      -2.592      -0.989\n",
      "topic_13                     -2.4279      0.460     -5.278      0.000      -3.329      -1.526\n",
      "topic_14                     -0.9861      0.387     -2.545      0.011      -1.746      -0.227\n",
      "topic_15                     -1.8872      0.416     -4.536      0.000      -2.703      -1.072\n",
      "topic_16                     -1.6257      0.403     -4.036      0.000      -2.415      -0.836\n",
      "topic_17                     -2.7160      0.494     -5.501      0.000      -3.684      -1.748\n",
      "topic_18                     -1.7086      0.410     -4.168      0.000      -2.512      -0.905\n",
      "topic_19                     -1.3951      0.397     -3.514      0.000      -2.173      -0.617\n",
      "topic_20                     -1.8862      0.417     -4.524      0.000      -2.703      -1.069\n",
      "topic_21                     -1.9849      0.422     -4.700      0.000      -2.813      -1.157\n",
      "topic_22                     -1.8900      0.419     -4.514      0.000      -2.710      -1.069\n",
      "topic_23                     -2.0838      0.434     -4.804      0.000      -2.934      -1.234\n",
      "topic_24                     -1.7999      0.415     -4.339      0.000      -2.613      -0.987\n",
      "topic_25                     -1.3262      0.396     -3.349      0.001      -2.102      -0.550\n",
      "topic_29                     -1.4751      0.402     -3.670      0.000      -2.263      -0.687\n",
      "topic_30                     -2.1918      0.443     -4.946      0.000      -3.060      -1.323\n",
      "topic_34                     -1.8883      0.421     -4.481      0.000      -2.714      -1.062\n",
      "topic_36                     -2.0856      0.436     -4.784      0.000      -2.940      -1.231\n",
      "topic_37                     -1.7988      0.418     -4.303      0.000      -2.618      -0.979\n",
      "topic_40                     -2.1882      0.444     -4.928      0.000      -3.059      -1.318\n",
      "topic_41                     -2.1881      0.445     -4.921      0.000      -3.060      -1.317\n",
      "topic_43                     -1.9847      0.428     -4.636      0.000      -2.824      -1.146\n",
      "topic_54                     -2.5661      0.480     -5.344      0.000      -3.507      -1.625\n",
      "topic_68                     -2.5656      0.480     -5.340      0.000      -3.507      -1.624\n",
      "topic_75                     -1.5481      0.407     -3.807      0.000      -2.345      -0.751\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7320567375886525\n",
      "Pr√§zision: 0.6745843230403801\n",
      "Recall: 0.40283687943262414\n",
      "F1-Score: 0.5044404973357016\n",
      "Brier-Score: 0.1817864385532324\n",
      "Confusion-Matrix:\n",
      "[[1328  137]\n",
      " [ 421  284]]\n",
      "\n",
      "Regression f√ºr Lag 5:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540400\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2135\n",
      "Model:                          Logit   Df Residuals:                     2096\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1388\n",
      "Time:                        11:17:10   Log-Likelihood:                -1153.8\n",
      "converged:                       True   LL-Null:                       -1339.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.105e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.6493      0.376      1.729      0.084      -0.087       1.385\n",
      "issue attention Facebook     -0.6524      1.732     -0.377      0.706      -4.047       2.742\n",
      "issue attention Bundestag    -0.9311      0.968     -0.962      0.336      -2.829       0.967\n",
      "Social Media Nutzung          0.0021      0.003      0.616      0.538      -0.005       0.009\n",
      "Landtagswahlen               -0.0598      0.126     -0.477      0.634      -0.306       0.186\n",
      "topic_1                       0.1393      0.387      0.360      0.719      -0.620       0.898\n",
      "topic_2                       0.5592      0.410      1.364      0.173      -0.244       1.363\n",
      "topic_3                      -0.8391      0.375     -2.239      0.025      -1.574      -0.104\n",
      "topic_4                      -0.6659      0.377     -1.767      0.077      -1.404       0.073\n",
      "topic_6                      -0.4100      0.381     -1.075      0.282      -1.157       0.337\n",
      "topic_7                       1.0574      0.458      2.307      0.021       0.159       1.956\n",
      "topic_8                      -1.0823      0.387     -2.800      0.005      -1.840      -0.325\n",
      "topic_10                     -0.2824      0.389     -0.726      0.468      -1.045       0.480\n",
      "topic_11                     -2.6474      0.478     -5.537      0.000      -3.585      -1.710\n",
      "topic_12                     -1.8640      0.412     -4.529      0.000      -2.671      -1.057\n",
      "topic_13                     -2.5002      0.462     -5.410      0.000      -3.406      -1.594\n",
      "topic_14                     -1.1062      0.391     -2.825      0.005      -1.873      -0.339\n",
      "topic_15                     -2.0485      0.425     -4.825      0.000      -2.881      -1.216\n",
      "topic_16                     -1.6982      0.406     -4.187      0.000      -2.493      -0.903\n",
      "topic_17                     -2.9668      0.519     -5.717      0.000      -3.984      -1.950\n",
      "topic_18                     -1.7906      0.413     -4.339      0.000      -2.599      -0.982\n",
      "topic_19                     -1.4727      0.400     -3.683      0.000      -2.256      -0.689\n",
      "topic_20                     -2.0529      0.426     -4.824      0.000      -2.887      -1.219\n",
      "topic_21                     -2.1474      0.433     -4.964      0.000      -2.995      -1.300\n",
      "topic_22                     -2.0521      0.427     -4.804      0.000      -2.889      -1.215\n",
      "topic_23                     -2.2696      0.444     -5.106      0.000      -3.141      -1.399\n",
      "topic_24                     -1.9598      0.422     -4.641      0.000      -2.788      -1.132\n",
      "topic_25                     -1.4691      0.401     -3.665      0.000      -2.255      -0.683\n",
      "topic_29                     -1.6231      0.407     -3.984      0.000      -2.422      -0.825\n",
      "topic_30                     -2.2691      0.445     -5.094      0.000      -3.142      -1.396\n",
      "topic_34                     -1.9672      0.424     -4.640      0.000      -2.798      -1.136\n",
      "topic_36                     -2.2706      0.446     -5.086      0.000      -3.146      -1.396\n",
      "topic_37                     -1.9703      0.426     -4.630      0.000      -2.804      -1.136\n",
      "topic_40                     -2.2776      0.446     -5.101      0.000      -3.153      -1.403\n",
      "topic_41                     -2.2792      0.447     -5.100      0.000      -3.155      -1.403\n",
      "topic_43                     -2.0612      0.431     -4.788      0.000      -2.905      -1.217\n",
      "topic_54                     -2.8043      0.500     -5.606      0.000      -3.785      -1.824\n",
      "topic_68                     -2.6533      0.482     -5.499      0.000      -3.599      -1.708\n",
      "topic_75                     -1.6344      0.409     -3.992      0.000      -2.437      -0.832\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7360261766926756\n",
      "Pr√§zision: 0.6714975845410628\n",
      "Recall: 0.4058394160583942\n",
      "F1-Score: 0.5059144676979072\n",
      "Brier-Score: 0.17943534106570924\n",
      "Confusion-Matrix:\n",
      "[[1314  136]\n",
      " [ 407  278]]\n",
      "\n",
      "Regression f√ºr Lag 6:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537921\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2100\n",
      "Model:                          Logit   Df Residuals:                     2061\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1414\n",
      "Time:                        11:17:10   Log-Likelihood:                -1129.6\n",
      "converged:                       True   LL-Null:                       -1315.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.977e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.2640      0.376      0.703      0.482      -0.472       1.000\n",
      "issue attention Facebook      2.9316      1.728      1.697      0.090      -0.455       6.318\n",
      "issue attention Bundestag    -0.8719      0.973     -0.896      0.370      -2.778       1.035\n",
      "Social Media Nutzung          0.0034      0.003      0.995      0.320      -0.003       0.010\n",
      "Landtagswahlen                0.0040      0.125      0.032      0.974      -0.241       0.249\n",
      "topic_1                       0.1976      0.392      0.504      0.615      -0.571       0.966\n",
      "topic_2                       0.6535      0.412      1.586      0.113      -0.154       1.461\n",
      "topic_3                      -0.8705      0.378     -2.302      0.021      -1.612      -0.129\n",
      "topic_4                      -0.6766      0.380     -1.781      0.075      -1.421       0.068\n",
      "topic_6                      -0.2682      0.383     -0.701      0.483      -1.018       0.482\n",
      "topic_7                       1.3746      0.474      2.900      0.004       0.445       2.304\n",
      "topic_8                      -0.9090      0.388     -2.340      0.019      -1.670      -0.148\n",
      "topic_10                     -0.0778      0.390     -0.200      0.842      -0.842       0.687\n",
      "topic_11                     -2.4078      0.478     -5.035      0.000      -3.345      -1.471\n",
      "topic_12                     -1.6827      0.412     -4.081      0.000      -2.491      -0.875\n",
      "topic_13                     -2.2692      0.462     -4.910      0.000      -3.175      -1.363\n",
      "topic_14                     -0.8267      0.392     -2.108      0.035      -1.595      -0.058\n",
      "topic_15                     -1.8231      0.425     -4.292      0.000      -2.655      -0.991\n",
      "topic_16                     -1.4704      0.406     -3.621      0.000      -2.266      -0.675\n",
      "topic_17                     -2.9232      0.550     -5.317      0.000      -4.001      -1.846\n",
      "topic_18                     -1.6189      0.417     -3.878      0.000      -2.437      -0.801\n",
      "topic_19                     -1.2099      0.400     -3.022      0.003      -1.995      -0.425\n",
      "topic_20                     -1.9246      0.432     -4.453      0.000      -2.772      -1.077\n",
      "topic_21                     -2.0197      0.440     -4.591      0.000      -2.882      -1.158\n",
      "topic_22                     -1.7945      0.427     -4.201      0.000      -2.632      -0.957\n",
      "topic_23                     -1.9939      0.445     -4.483      0.000      -2.866      -1.122\n",
      "topic_24                     -1.6915      0.422     -4.005      0.000      -2.519      -0.864\n",
      "topic_25                     -1.2657      0.404     -3.134      0.002      -2.057      -0.474\n",
      "topic_29                     -1.3355      0.408     -3.276      0.001      -2.135      -0.536\n",
      "topic_30                     -2.0980      0.455     -4.609      0.000      -2.990      -1.206\n",
      "topic_34                     -1.6869      0.424     -3.977      0.000      -2.518      -0.855\n",
      "topic_36                     -1.9752      0.446     -4.424      0.000      -2.850      -1.100\n",
      "topic_37                     -1.6757      0.426     -3.936      0.000      -2.510      -0.841\n",
      "topic_40                     -1.9887      0.447     -4.453      0.000      -2.864      -1.113\n",
      "topic_41                     -1.9866      0.447     -4.442      0.000      -2.863      -1.110\n",
      "topic_43                     -1.7736      0.431     -4.120      0.000      -2.617      -0.930\n",
      "topic_54                     -2.5099      0.500     -5.018      0.000      -3.490      -1.530\n",
      "topic_68                     -2.3588      0.482     -4.889      0.000      -3.304      -1.413\n",
      "topic_75                     -1.4176      0.413     -3.431      0.001      -2.227      -0.608\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7392291254501444\n",
      "Pr√§zision: 0.6804123711340206\n",
      "Recall: 0.39344262295081966\n",
      "F1-Score: 0.4985835694050991\n",
      "Brier-Score: 0.1785696508966536\n",
      "Confusion-Matrix:\n",
      "[[1305  124]\n",
      " [ 407  264]]\n",
      "\n",
      "Regression f√ºr Lag 7:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539254\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2065\n",
      "Model:                          Logit   Df Residuals:                     2026\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1414\n",
      "Time:                        11:17:10   Log-Likelihood:                -1113.6\n",
      "converged:                       True   LL-Null:                       -1296.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.282e-55\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.9293      0.383      2.426      0.015       0.178       1.680\n",
      "issue attention Facebook      0.0682      1.745      0.039      0.969      -3.352       3.488\n",
      "issue attention Bundestag    -0.5940      0.983     -0.605      0.546      -2.520       1.332\n",
      "Social Media Nutzung         -0.0045      0.004     -1.269      0.205      -0.012       0.002\n",
      "Landtagswahlen               -0.0382      0.126     -0.303      0.762      -0.285       0.209\n",
      "topic_1                       0.3015      0.397      0.760      0.447      -0.476       1.079\n",
      "topic_2                       0.6772      0.418      1.618      0.106      -0.143       1.497\n",
      "topic_3                      -0.7834      0.379     -2.065      0.039      -1.527      -0.040\n",
      "topic_4                      -0.5937      0.381     -1.557      0.119      -1.341       0.153\n",
      "topic_6                      -0.3739      0.385     -0.972      0.331      -1.128       0.380\n",
      "topic_7                       1.2501      0.475      2.631      0.009       0.319       2.181\n",
      "topic_8                      -0.9911      0.391     -2.536      0.011      -1.757      -0.225\n",
      "topic_10                     -0.2319      0.393     -0.591      0.555      -1.002       0.538\n",
      "topic_11                     -2.4915      0.480     -5.191      0.000      -3.432      -1.551\n",
      "topic_12                     -1.7142      0.414     -4.142      0.000      -2.525      -0.903\n",
      "topic_13                     -2.3480      0.464     -5.062      0.000      -3.257      -1.439\n",
      "topic_14                     -0.9319      0.395     -2.361      0.018      -1.706      -0.158\n",
      "topic_15                     -1.9968      0.434     -4.606      0.000      -2.846      -1.147\n",
      "topic_16                     -1.5392      0.408     -3.771      0.000      -2.339      -0.739\n",
      "topic_17                     -3.0144      0.551     -5.468      0.000      -4.095      -1.934\n",
      "topic_18                     -1.7128      0.420     -4.082      0.000      -2.535      -0.890\n",
      "topic_19                     -1.3034      0.403     -3.235      0.001      -2.093      -0.514\n",
      "topic_20                     -1.9989      0.434     -4.602      0.000      -2.850      -1.147\n",
      "topic_21                     -2.1032      0.443     -4.752      0.000      -2.971      -1.236\n",
      "topic_22                     -1.8931      0.429     -4.409      0.000      -2.735      -1.052\n",
      "topic_23                     -2.1069      0.447     -4.715      0.000      -2.983      -1.231\n",
      "topic_24                     -1.7977      0.425     -4.234      0.000      -2.630      -0.966\n",
      "topic_25                     -1.3750      0.406     -3.385      0.001      -2.171      -0.579\n",
      "topic_29                     -1.4531      0.410     -3.544      0.000      -2.257      -0.649\n",
      "topic_30                     -2.2214      0.457     -4.856      0.000      -3.118      -1.325\n",
      "topic_34                     -1.8009      0.426     -4.224      0.000      -2.636      -0.965\n",
      "topic_36                     -2.2224      0.458     -4.848      0.000      -3.121      -1.324\n",
      "topic_37                     -1.8011      0.428     -4.208      0.000      -2.640      -0.962\n",
      "topic_40                     -2.1104      0.449     -4.704      0.000      -2.990      -1.231\n",
      "topic_41                     -2.1111      0.449     -4.697      0.000      -2.992      -1.230\n",
      "topic_43                     -1.9969      0.440     -4.541      0.000      -2.859      -1.135\n",
      "topic_54                     -2.6406      0.502     -5.258      0.000      -3.625      -1.656\n",
      "topic_68                     -2.4880      0.484     -5.136      0.000      -3.437      -1.538\n",
      "topic_75                     -1.5407      0.416     -3.707      0.000      -2.355      -0.726\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.737528809026255\n",
      "Pr√§zision: 0.6810126582278481\n",
      "Recall: 0.40512048192771083\n",
      "F1-Score: 0.5080264400377715\n",
      "Brier-Score: 0.17900796007180078\n",
      "Confusion-Matrix:\n",
      "[[1275  126]\n",
      " [ 395  269]]\n"
     ]
    }
   ],
   "source": [
    "# Schleife f√ºr logistische Regression mit Lags von -7 bis 7\n",
    "for n in range(1, 8):  # Einschlie√ülich 1 bis 7\n",
    "    try:\n",
    "        print(f\"\\nRegression f√ºr Lag {n}:\")\n",
    "        log_reg_FE_control(reden_relativ_reduced, post_relativ_reduced, rede_common,n, social_media_usage)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Lag {n}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539753\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2236\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1430\n",
      "Time:                        11:17:11   Log-Likelihood:                -1227.9\n",
      "converged:                       True   LL-Null:                       -1432.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.198e-64\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.3091      0.363      0.851      0.395      -0.403       1.021\n",
      "issue attention Facebook      7.7768      1.712      4.543      0.000       4.421      11.132\n",
      "issue attention Bundestag    -1.6714      0.907     -1.843      0.065      -3.449       0.106\n",
      "Social Media Nutzung         -0.0007      0.003     -0.211      0.833      -0.007       0.006\n",
      "Landtagswahlen               -0.0251      0.091     -0.275      0.784      -0.204       0.154\n",
      "topic_1                       0.1336      0.383      0.348      0.728      -0.618       0.885\n",
      "topic_2                       0.7828      0.405      1.935      0.053      -0.010       1.576\n",
      "topic_3                      -0.7913      0.369     -2.145      0.032      -1.514      -0.068\n",
      "topic_4                      -0.6126      0.371     -1.650      0.099      -1.340       0.115\n",
      "topic_6                      -0.1699      0.372     -0.456      0.648      -0.899       0.560\n",
      "topic_7                       1.2594      0.433      2.911      0.004       0.411       2.107\n",
      "topic_8                      -0.8275      0.378     -2.191      0.028      -1.568      -0.087\n",
      "topic_10                      0.0989      0.378      0.262      0.794      -0.642       0.840\n",
      "topic_11                     -2.2481      0.457     -4.914      0.000      -3.145      -1.351\n",
      "topic_12                     -1.7586      0.407     -4.325      0.000      -2.556      -0.962\n",
      "topic_13                     -2.2458      0.456     -4.926      0.000      -3.139      -1.352\n",
      "topic_14                     -0.6490      0.379     -1.711      0.087      -1.392       0.094\n",
      "topic_15                     -1.6348      0.406     -4.025      0.000      -2.431      -0.839\n",
      "topic_16                     -1.4665      0.398     -3.682      0.000      -2.247      -0.686\n",
      "topic_17                     -2.3439      0.472     -4.969      0.000      -3.268      -1.419\n",
      "topic_18                     -1.4935      0.404     -3.692      0.000      -2.286      -0.701\n",
      "topic_19                     -1.1083      0.389     -2.851      0.004      -1.870      -0.346\n",
      "topic_20                     -1.6209      0.409     -3.966      0.000      -2.422      -0.820\n",
      "topic_21                     -1.6943      0.413     -4.103      0.000      -2.504      -0.885\n",
      "topic_22                     -1.5550      0.409     -3.806      0.000      -2.356      -0.754\n",
      "topic_23                     -1.8022      0.429     -4.203      0.000      -2.643      -0.962\n",
      "topic_24                     -1.5263      0.409     -3.727      0.000      -2.329      -0.724\n",
      "topic_25                     -0.9778      0.388     -2.520      0.012      -1.738      -0.217\n",
      "topic_29                     -1.0246      0.391     -2.622      0.009      -1.791      -0.259\n",
      "topic_30                     -1.8808      0.438     -4.292      0.000      -2.740      -1.022\n",
      "topic_34                     -1.4278      0.406     -3.514      0.000      -2.224      -0.631\n",
      "topic_36                     -1.7627      0.430     -4.096      0.000      -2.606      -0.919\n",
      "topic_37                     -1.4833      0.412     -3.600      0.000      -2.291      -0.676\n",
      "topic_40                     -1.7804      0.430     -4.136      0.000      -2.624      -0.937\n",
      "topic_41                     -1.8814      0.440     -4.281      0.000      -2.743      -1.020\n",
      "topic_43                     -1.6756      0.423     -3.963      0.000      -2.504      -0.847\n",
      "topic_54                     -2.1039      0.461     -4.563      0.000      -3.008      -1.200\n",
      "topic_68                     -2.2412      0.476     -4.711      0.000      -3.174      -1.309\n",
      "topic_75                     -1.2471      0.401     -3.112      0.002      -2.032      -0.462\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7439947384486717\n",
      "Pr√§zision: 0.6844444444444444\n",
      "Recall: 0.417910447761194\n",
      "F1-Score: 0.518955349620893\n",
      "Brier-Score: 0.17924679702060345\n",
      "Confusion-Matrix:\n",
      "[[1396  142]\n",
      " [ 429  308]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542504\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2240\n",
      "Model:                          Logit   Df Residuals:                     2201\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1397\n",
      "Time:                        11:17:11   Log-Likelihood:                -1215.2\n",
      "converged:                       True   LL-Null:                       -1412.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.303e-61\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.6949      0.371      1.874      0.061      -0.032       1.422\n",
      "issue attention Facebook      2.8123      1.699      1.655      0.098      -0.518       6.143\n",
      "issue attention Bundestag     1.6378      0.960      1.706      0.088      -0.244       3.520\n",
      "Social Media Nutzung         -0.0051      0.003     -1.481      0.139      -0.012       0.002\n",
      "Landtagswahlen               -0.2044      0.101     -2.019      0.044      -0.403      -0.006\n",
      "topic_1                       0.2289      0.383      0.598      0.550      -0.522       0.979\n",
      "topic_2                       0.5873      0.402      1.462      0.144      -0.200       1.375\n",
      "topic_3                      -0.6704      0.368     -1.824      0.068      -1.391       0.050\n",
      "topic_4                      -0.4337      0.369     -1.175      0.240      -1.157       0.290\n",
      "topic_6                      -0.2234      0.373     -0.599      0.549      -0.954       0.508\n",
      "topic_7                       1.2197      0.443      2.753      0.006       0.351       2.088\n",
      "topic_8                      -0.8918      0.379     -2.351      0.019      -1.635      -0.148\n",
      "topic_10                      0.0069      0.380      0.018      0.986      -0.739       0.752\n",
      "topic_11                     -2.1908      0.458     -4.786      0.000      -3.088      -1.294\n",
      "topic_12                     -1.6139      0.404     -3.990      0.000      -2.407      -0.821\n",
      "topic_13                     -2.2169      0.456     -4.862      0.000      -3.111      -1.323\n",
      "topic_14                     -0.7061      0.381     -1.852      0.064      -1.453       0.041\n",
      "topic_15                     -1.5980      0.406     -3.932      0.000      -2.395      -0.801\n",
      "topic_16                     -1.4182      0.398     -3.559      0.000      -2.199      -0.637\n",
      "topic_17                     -2.3360      0.472     -4.948      0.000      -3.261      -1.411\n",
      "topic_18                     -1.4727      0.405     -3.634      0.000      -2.267      -0.679\n",
      "topic_19                     -1.1621      0.392     -2.964      0.003      -1.931      -0.394\n",
      "topic_20                     -1.5880      0.407     -3.899      0.000      -2.386      -0.790\n",
      "topic_21                     -1.6943      0.413     -4.106      0.000      -2.503      -0.886\n",
      "topic_22                     -1.5778      0.409     -3.857      0.000      -2.380      -0.776\n",
      "topic_23                     -1.8376      0.430     -4.276      0.000      -2.680      -0.995\n",
      "topic_24                     -1.5624      0.410     -3.806      0.000      -2.367      -0.758\n",
      "topic_25                     -1.0152      0.389     -2.608      0.009      -1.778      -0.252\n",
      "topic_29                     -1.0804      0.392     -2.754      0.006      -1.849      -0.311\n",
      "topic_30                     -1.9348      0.439     -4.406      0.000      -2.796      -1.074\n",
      "topic_34                     -1.5467      0.412     -3.754      0.000      -2.354      -0.739\n",
      "topic_36                     -1.8247      0.431     -4.229      0.000      -2.670      -0.979\n",
      "topic_37                     -1.5348      0.414     -3.711      0.000      -2.345      -0.724\n",
      "topic_40                     -1.8162      0.431     -4.209      0.000      -2.662      -0.970\n",
      "topic_41                     -1.9130      0.441     -4.341      0.000      -2.777      -1.049\n",
      "topic_43                     -1.7298      0.424     -4.082      0.000      -2.560      -0.899\n",
      "topic_54                     -2.2933      0.477     -4.812      0.000      -3.227      -1.359\n",
      "topic_68                     -2.2905      0.477     -4.804      0.000      -3.225      -1.356\n",
      "topic_75                     -1.2798      0.402     -3.184      0.001      -2.068      -0.492\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.738036186696901\n",
      "Pr√§zision: 0.6784140969162996\n",
      "Recall: 0.4230769230769231\n",
      "F1-Score: 0.5211505922165821\n",
      "Brier-Score: 0.18028125549459456\n",
      "Confusion-Matrix:\n",
      "[[1366  146]\n",
      " [ 420  308]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540756\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2205\n",
      "Model:                          Logit   Df Residuals:                     2166\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1399\n",
      "Time:                        11:17:11   Log-Likelihood:                -1192.4\n",
      "converged:                       True   LL-Null:                       -1386.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.566e-59\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1737      0.367     -0.474      0.636      -0.892       0.545\n",
      "issue attention Facebook      6.0754      1.723      3.525      0.000       2.698       9.453\n",
      "issue attention Bundestag    -0.3037      0.931     -0.326      0.744      -2.129       1.522\n",
      "Social Media Nutzung          0.0066      0.003      1.957      0.050   -1.11e-05       0.013\n",
      "Landtagswahlen               -0.1274      0.110     -1.155      0.248      -0.343       0.089\n",
      "topic_1                       0.1914      0.385      0.497      0.619      -0.563       0.946\n",
      "topic_2                       0.7161      0.404      1.771      0.077      -0.076       1.509\n",
      "topic_3                      -0.7525      0.371     -2.028      0.043      -1.480      -0.025\n",
      "topic_4                      -0.5448      0.373     -1.462      0.144      -1.275       0.186\n",
      "topic_6                      -0.1671      0.375     -0.446      0.656      -0.901       0.567\n",
      "topic_7                       1.3394      0.444      3.017      0.003       0.469       2.209\n",
      "topic_8                      -0.7365      0.381     -1.934      0.053      -1.483       0.010\n",
      "topic_10                      0.1276      0.382      0.334      0.738      -0.621       0.876\n",
      "topic_11                     -2.1231      0.459     -4.627      0.000      -3.022      -1.224\n",
      "topic_12                     -1.6017      0.407     -3.937      0.000      -2.399      -0.804\n",
      "topic_13                     -2.1333      0.457     -4.665      0.000      -3.030      -1.237\n",
      "topic_14                     -0.6184      0.384     -1.611      0.107      -1.371       0.134\n",
      "topic_15                     -1.6057      0.413     -3.887      0.000      -2.415      -0.796\n",
      "topic_16                     -1.3494      0.400     -3.374      0.001      -2.133      -0.566\n",
      "topic_17                     -2.3995      0.491     -4.884      0.000      -3.362      -1.437\n",
      "topic_18                     -1.3808      0.407     -3.394      0.001      -2.178      -0.584\n",
      "topic_19                     -1.0615      0.394     -2.695      0.007      -1.834      -0.290\n",
      "topic_20                     -1.6029      0.415     -3.863      0.000      -2.416      -0.790\n",
      "topic_21                     -1.6883      0.420     -4.019      0.000      -2.512      -0.865\n",
      "topic_22                     -1.5529      0.416     -3.735      0.000      -2.368      -0.738\n",
      "topic_23                     -1.7153      0.431     -3.981      0.000      -2.560      -0.871\n",
      "topic_24                     -1.4391      0.412     -3.496      0.000      -2.246      -0.632\n",
      "topic_25                     -0.8843      0.391     -2.263      0.024      -1.650      -0.119\n",
      "topic_29                     -1.0121      0.396     -2.556      0.011      -1.788      -0.236\n",
      "topic_30                     -1.8019      0.440     -4.094      0.000      -2.665      -0.939\n",
      "topic_34                     -1.5143      0.418     -3.619      0.000      -2.334      -0.694\n",
      "topic_36                     -1.6818      0.433     -3.886      0.000      -2.530      -0.834\n",
      "topic_37                     -1.4005      0.415     -3.377      0.001      -2.213      -0.588\n",
      "topic_40                     -1.8000      0.441     -4.083      0.000      -2.664      -0.936\n",
      "topic_41                     -1.7931      0.442     -4.060      0.000      -2.659      -0.927\n",
      "topic_43                     -1.5952      0.425     -3.754      0.000      -2.428      -0.762\n",
      "topic_54                     -2.1643      0.477     -4.533      0.000      -3.100      -1.229\n",
      "topic_68                     -2.1619      0.478     -4.526      0.000      -3.098      -1.226\n",
      "topic_75                     -1.1544      0.403     -2.862      0.004      -1.945      -0.364\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7391601097310009\n",
      "Pr√§zision: 0.6812933025404158\n",
      "Recall: 0.4149085794655415\n",
      "F1-Score: 0.5157342657342657\n",
      "Brier-Score: 0.1793857891219391\n",
      "Confusion-Matrix:\n",
      "[[1356  138]\n",
      " [ 416  295]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546070\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2170\n",
      "Model:                          Logit   Df Residuals:                     2131\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1339\n",
      "Time:                        11:17:11   Log-Likelihood:                -1185.0\n",
      "converged:                       True   LL-Null:                       -1368.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.546e-55\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.7766      0.374      2.076      0.038       0.043       1.510\n",
      "issue attention Facebook     -0.2155      1.710     -0.126      0.900      -3.566       3.135\n",
      "issue attention Bundestag     0.4206      0.953      0.441      0.659      -1.447       2.288\n",
      "Social Media Nutzung         -0.0015      0.003     -0.424      0.672      -0.008       0.005\n",
      "Landtagswahlen               -0.1525      0.126     -1.215      0.224      -0.399       0.094\n",
      "topic_1                       0.1546      0.385      0.401      0.688      -0.600       0.909\n",
      "topic_2                       0.5521      0.409      1.352      0.177      -0.249       1.353\n",
      "topic_3                      -0.7854      0.371     -2.115      0.034      -1.513      -0.058\n",
      "topic_4                      -0.5823      0.373     -1.560      0.119      -1.314       0.149\n",
      "topic_6                      -0.4041      0.378     -1.069      0.285      -1.145       0.337\n",
      "topic_7                       0.9785      0.445      2.199      0.028       0.106       1.851\n",
      "topic_8                      -1.0588      0.384     -2.757      0.006      -1.812      -0.306\n",
      "topic_10                     -0.2087      0.387     -0.540      0.589      -0.966       0.549\n",
      "topic_11                     -2.4242      0.462     -5.252      0.000      -3.329      -1.520\n",
      "topic_12                     -1.7906      0.409     -4.377      0.000      -2.592      -0.989\n",
      "topic_13                     -2.4279      0.460     -5.278      0.000      -3.329      -1.526\n",
      "topic_14                     -0.9861      0.387     -2.545      0.011      -1.746      -0.227\n",
      "topic_15                     -1.8872      0.416     -4.536      0.000      -2.703      -1.072\n",
      "topic_16                     -1.6257      0.403     -4.036      0.000      -2.415      -0.836\n",
      "topic_17                     -2.7160      0.494     -5.501      0.000      -3.684      -1.748\n",
      "topic_18                     -1.7086      0.410     -4.168      0.000      -2.512      -0.905\n",
      "topic_19                     -1.3951      0.397     -3.514      0.000      -2.173      -0.617\n",
      "topic_20                     -1.8862      0.417     -4.524      0.000      -2.703      -1.069\n",
      "topic_21                     -1.9849      0.422     -4.700      0.000      -2.813      -1.157\n",
      "topic_22                     -1.8900      0.419     -4.514      0.000      -2.710      -1.069\n",
      "topic_23                     -2.0838      0.434     -4.804      0.000      -2.934      -1.234\n",
      "topic_24                     -1.7999      0.415     -4.339      0.000      -2.613      -0.987\n",
      "topic_25                     -1.3262      0.396     -3.349      0.001      -2.102      -0.550\n",
      "topic_29                     -1.4751      0.402     -3.670      0.000      -2.263      -0.687\n",
      "topic_30                     -2.1918      0.443     -4.946      0.000      -3.060      -1.323\n",
      "topic_34                     -1.8883      0.421     -4.481      0.000      -2.714      -1.062\n",
      "topic_36                     -2.0856      0.436     -4.784      0.000      -2.940      -1.231\n",
      "topic_37                     -1.7988      0.418     -4.303      0.000      -2.618      -0.979\n",
      "topic_40                     -2.1882      0.444     -4.928      0.000      -3.059      -1.318\n",
      "topic_41                     -2.1881      0.445     -4.921      0.000      -3.060      -1.317\n",
      "topic_43                     -1.9847      0.428     -4.636      0.000      -2.824      -1.146\n",
      "topic_54                     -2.5661      0.480     -5.344      0.000      -3.507      -1.625\n",
      "topic_68                     -2.5656      0.480     -5.340      0.000      -3.507      -1.624\n",
      "topic_75                     -1.5481      0.407     -3.807      0.000      -2.345      -0.751\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7320567375886525\n",
      "Pr√§zision: 0.6745843230403801\n",
      "Recall: 0.40283687943262414\n",
      "F1-Score: 0.5044404973357016\n",
      "Brier-Score: 0.1817864385532324\n",
      "Confusion-Matrix:\n",
      "[[1328  137]\n",
      " [ 421  284]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540400\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2135\n",
      "Model:                          Logit   Df Residuals:                     2096\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1388\n",
      "Time:                        11:17:11   Log-Likelihood:                -1153.8\n",
      "converged:                       True   LL-Null:                       -1339.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.105e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.6493      0.376      1.729      0.084      -0.087       1.385\n",
      "issue attention Facebook     -0.6524      1.732     -0.377      0.706      -4.047       2.742\n",
      "issue attention Bundestag    -0.9311      0.968     -0.962      0.336      -2.829       0.967\n",
      "Social Media Nutzung          0.0021      0.003      0.616      0.538      -0.005       0.009\n",
      "Landtagswahlen               -0.0598      0.126     -0.477      0.634      -0.306       0.186\n",
      "topic_1                       0.1393      0.387      0.360      0.719      -0.620       0.898\n",
      "topic_2                       0.5592      0.410      1.364      0.173      -0.244       1.363\n",
      "topic_3                      -0.8391      0.375     -2.239      0.025      -1.574      -0.104\n",
      "topic_4                      -0.6659      0.377     -1.767      0.077      -1.404       0.073\n",
      "topic_6                      -0.4100      0.381     -1.075      0.282      -1.157       0.337\n",
      "topic_7                       1.0574      0.458      2.307      0.021       0.159       1.956\n",
      "topic_8                      -1.0823      0.387     -2.800      0.005      -1.840      -0.325\n",
      "topic_10                     -0.2824      0.389     -0.726      0.468      -1.045       0.480\n",
      "topic_11                     -2.6474      0.478     -5.537      0.000      -3.585      -1.710\n",
      "topic_12                     -1.8640      0.412     -4.529      0.000      -2.671      -1.057\n",
      "topic_13                     -2.5002      0.462     -5.410      0.000      -3.406      -1.594\n",
      "topic_14                     -1.1062      0.391     -2.825      0.005      -1.873      -0.339\n",
      "topic_15                     -2.0485      0.425     -4.825      0.000      -2.881      -1.216\n",
      "topic_16                     -1.6982      0.406     -4.187      0.000      -2.493      -0.903\n",
      "topic_17                     -2.9668      0.519     -5.717      0.000      -3.984      -1.950\n",
      "topic_18                     -1.7906      0.413     -4.339      0.000      -2.599      -0.982\n",
      "topic_19                     -1.4727      0.400     -3.683      0.000      -2.256      -0.689\n",
      "topic_20                     -2.0529      0.426     -4.824      0.000      -2.887      -1.219\n",
      "topic_21                     -2.1474      0.433     -4.964      0.000      -2.995      -1.300\n",
      "topic_22                     -2.0521      0.427     -4.804      0.000      -2.889      -1.215\n",
      "topic_23                     -2.2696      0.444     -5.106      0.000      -3.141      -1.399\n",
      "topic_24                     -1.9598      0.422     -4.641      0.000      -2.788      -1.132\n",
      "topic_25                     -1.4691      0.401     -3.665      0.000      -2.255      -0.683\n",
      "topic_29                     -1.6231      0.407     -3.984      0.000      -2.422      -0.825\n",
      "topic_30                     -2.2691      0.445     -5.094      0.000      -3.142      -1.396\n",
      "topic_34                     -1.9672      0.424     -4.640      0.000      -2.798      -1.136\n",
      "topic_36                     -2.2706      0.446     -5.086      0.000      -3.146      -1.396\n",
      "topic_37                     -1.9703      0.426     -4.630      0.000      -2.804      -1.136\n",
      "topic_40                     -2.2776      0.446     -5.101      0.000      -3.153      -1.403\n",
      "topic_41                     -2.2792      0.447     -5.100      0.000      -3.155      -1.403\n",
      "topic_43                     -2.0612      0.431     -4.788      0.000      -2.905      -1.217\n",
      "topic_54                     -2.8043      0.500     -5.606      0.000      -3.785      -1.824\n",
      "topic_68                     -2.6533      0.482     -5.499      0.000      -3.599      -1.708\n",
      "topic_75                     -1.6344      0.409     -3.992      0.000      -2.437      -0.832\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7360261766926756\n",
      "Pr√§zision: 0.6714975845410628\n",
      "Recall: 0.4058394160583942\n",
      "F1-Score: 0.5059144676979072\n",
      "Brier-Score: 0.17943534106570924\n",
      "Confusion-Matrix:\n",
      "[[1314  136]\n",
      " [ 407  278]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537921\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2100\n",
      "Model:                          Logit   Df Residuals:                     2061\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1414\n",
      "Time:                        11:17:11   Log-Likelihood:                -1129.6\n",
      "converged:                       True   LL-Null:                       -1315.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.977e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.2640      0.376      0.703      0.482      -0.472       1.000\n",
      "issue attention Facebook      2.9316      1.728      1.697      0.090      -0.455       6.318\n",
      "issue attention Bundestag    -0.8719      0.973     -0.896      0.370      -2.778       1.035\n",
      "Social Media Nutzung          0.0034      0.003      0.995      0.320      -0.003       0.010\n",
      "Landtagswahlen                0.0040      0.125      0.032      0.974      -0.241       0.249\n",
      "topic_1                       0.1976      0.392      0.504      0.615      -0.571       0.966\n",
      "topic_2                       0.6535      0.412      1.586      0.113      -0.154       1.461\n",
      "topic_3                      -0.8705      0.378     -2.302      0.021      -1.612      -0.129\n",
      "topic_4                      -0.6766      0.380     -1.781      0.075      -1.421       0.068\n",
      "topic_6                      -0.2682      0.383     -0.701      0.483      -1.018       0.482\n",
      "topic_7                       1.3746      0.474      2.900      0.004       0.445       2.304\n",
      "topic_8                      -0.9090      0.388     -2.340      0.019      -1.670      -0.148\n",
      "topic_10                     -0.0778      0.390     -0.200      0.842      -0.842       0.687\n",
      "topic_11                     -2.4078      0.478     -5.035      0.000      -3.345      -1.471\n",
      "topic_12                     -1.6827      0.412     -4.081      0.000      -2.491      -0.875\n",
      "topic_13                     -2.2692      0.462     -4.910      0.000      -3.175      -1.363\n",
      "topic_14                     -0.8267      0.392     -2.108      0.035      -1.595      -0.058\n",
      "topic_15                     -1.8231      0.425     -4.292      0.000      -2.655      -0.991\n",
      "topic_16                     -1.4704      0.406     -3.621      0.000      -2.266      -0.675\n",
      "topic_17                     -2.9232      0.550     -5.317      0.000      -4.001      -1.846\n",
      "topic_18                     -1.6189      0.417     -3.878      0.000      -2.437      -0.801\n",
      "topic_19                     -1.2099      0.400     -3.022      0.003      -1.995      -0.425\n",
      "topic_20                     -1.9246      0.432     -4.453      0.000      -2.772      -1.077\n",
      "topic_21                     -2.0197      0.440     -4.591      0.000      -2.882      -1.158\n",
      "topic_22                     -1.7945      0.427     -4.201      0.000      -2.632      -0.957\n",
      "topic_23                     -1.9939      0.445     -4.483      0.000      -2.866      -1.122\n",
      "topic_24                     -1.6915      0.422     -4.005      0.000      -2.519      -0.864\n",
      "topic_25                     -1.2657      0.404     -3.134      0.002      -2.057      -0.474\n",
      "topic_29                     -1.3355      0.408     -3.276      0.001      -2.135      -0.536\n",
      "topic_30                     -2.0980      0.455     -4.609      0.000      -2.990      -1.206\n",
      "topic_34                     -1.6869      0.424     -3.977      0.000      -2.518      -0.855\n",
      "topic_36                     -1.9752      0.446     -4.424      0.000      -2.850      -1.100\n",
      "topic_37                     -1.6757      0.426     -3.936      0.000      -2.510      -0.841\n",
      "topic_40                     -1.9887      0.447     -4.453      0.000      -2.864      -1.113\n",
      "topic_41                     -1.9866      0.447     -4.442      0.000      -2.863      -1.110\n",
      "topic_43                     -1.7736      0.431     -4.120      0.000      -2.617      -0.930\n",
      "topic_54                     -2.5099      0.500     -5.018      0.000      -3.490      -1.530\n",
      "topic_68                     -2.3588      0.482     -4.889      0.000      -3.304      -1.413\n",
      "topic_75                     -1.4176      0.413     -3.431      0.001      -2.227      -0.608\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7392291254501444\n",
      "Pr√§zision: 0.6804123711340206\n",
      "Recall: 0.39344262295081966\n",
      "F1-Score: 0.4985835694050991\n",
      "Brier-Score: 0.1785696508966536\n",
      "Confusion-Matrix:\n",
      "[[1305  124]\n",
      " [ 407  264]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539254\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2065\n",
      "Model:                          Logit   Df Residuals:                     2026\n",
      "Method:                           MLE   Df Model:                           38\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1414\n",
      "Time:                        11:17:11   Log-Likelihood:                -1113.6\n",
      "converged:                       True   LL-Null:                       -1296.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.282e-55\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.9293      0.383      2.426      0.015       0.178       1.680\n",
      "issue attention Facebook      0.0682      1.745      0.039      0.969      -3.352       3.488\n",
      "issue attention Bundestag    -0.5940      0.983     -0.605      0.546      -2.520       1.332\n",
      "Social Media Nutzung         -0.0045      0.004     -1.269      0.205      -0.012       0.002\n",
      "Landtagswahlen               -0.0382      0.126     -0.303      0.762      -0.285       0.209\n",
      "topic_1                       0.3015      0.397      0.760      0.447      -0.476       1.079\n",
      "topic_2                       0.6772      0.418      1.618      0.106      -0.143       1.497\n",
      "topic_3                      -0.7834      0.379     -2.065      0.039      -1.527      -0.040\n",
      "topic_4                      -0.5937      0.381     -1.557      0.119      -1.341       0.153\n",
      "topic_6                      -0.3739      0.385     -0.972      0.331      -1.128       0.380\n",
      "topic_7                       1.2501      0.475      2.631      0.009       0.319       2.181\n",
      "topic_8                      -0.9911      0.391     -2.536      0.011      -1.757      -0.225\n",
      "topic_10                     -0.2319      0.393     -0.591      0.555      -1.002       0.538\n",
      "topic_11                     -2.4915      0.480     -5.191      0.000      -3.432      -1.551\n",
      "topic_12                     -1.7142      0.414     -4.142      0.000      -2.525      -0.903\n",
      "topic_13                     -2.3480      0.464     -5.062      0.000      -3.257      -1.439\n",
      "topic_14                     -0.9319      0.395     -2.361      0.018      -1.706      -0.158\n",
      "topic_15                     -1.9968      0.434     -4.606      0.000      -2.846      -1.147\n",
      "topic_16                     -1.5392      0.408     -3.771      0.000      -2.339      -0.739\n",
      "topic_17                     -3.0144      0.551     -5.468      0.000      -4.095      -1.934\n",
      "topic_18                     -1.7128      0.420     -4.082      0.000      -2.535      -0.890\n",
      "topic_19                     -1.3034      0.403     -3.235      0.001      -2.093      -0.514\n",
      "topic_20                     -1.9989      0.434     -4.602      0.000      -2.850      -1.147\n",
      "topic_21                     -2.1032      0.443     -4.752      0.000      -2.971      -1.236\n",
      "topic_22                     -1.8931      0.429     -4.409      0.000      -2.735      -1.052\n",
      "topic_23                     -2.1069      0.447     -4.715      0.000      -2.983      -1.231\n",
      "topic_24                     -1.7977      0.425     -4.234      0.000      -2.630      -0.966\n",
      "topic_25                     -1.3750      0.406     -3.385      0.001      -2.171      -0.579\n",
      "topic_29                     -1.4531      0.410     -3.544      0.000      -2.257      -0.649\n",
      "topic_30                     -2.2214      0.457     -4.856      0.000      -3.118      -1.325\n",
      "topic_34                     -1.8009      0.426     -4.224      0.000      -2.636      -0.965\n",
      "topic_36                     -2.2224      0.458     -4.848      0.000      -3.121      -1.324\n",
      "topic_37                     -1.8011      0.428     -4.208      0.000      -2.640      -0.962\n",
      "topic_40                     -2.1104      0.449     -4.704      0.000      -2.990      -1.231\n",
      "topic_41                     -2.1111      0.449     -4.697      0.000      -2.992      -1.230\n",
      "topic_43                     -1.9969      0.440     -4.541      0.000      -2.859      -1.135\n",
      "topic_54                     -2.6406      0.502     -5.258      0.000      -3.625      -1.656\n",
      "topic_68                     -2.4880      0.484     -5.136      0.000      -3.437      -1.538\n",
      "topic_75                     -1.5407      0.416     -3.707      0.000      -2.355      -0.726\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.737528809026255\n",
      "Pr√§zision: 0.6810126582278481\n",
      "Recall: 0.40512048192771083\n",
      "F1-Score: 0.5080264400377715\n",
      "Brier-Score: 0.17900796007180078\n",
      "Confusion-Matrix:\n",
      "[[1275  126]\n",
      " [ 395  269]]\n"
     ]
    }
   ],
   "source": [
    "from stargazer.stargazer import Stargazer\n",
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(reden_relativ_reduced, post_relativ_reduced, rede_common,lag, social_media_usage)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung im Bundestag\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539528\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2275\n",
      "Model:                          Logit   Df Residuals:                     2234\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1434\n",
      "Time:                        11:17:12   Log-Likelihood:                -1227.4\n",
      "converged:                       True   LL-Null:                       -1432.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.902e-63\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0505      0.524     -0.096      0.923      -1.077       0.976\n",
      "issue attention Facebook      7.8255      1.712      4.571      0.000       4.470      11.181\n",
      "issue attention Bundestag    -1.6928      0.907     -1.866      0.062      -3.470       0.085\n",
      "Social Media Nutzung          0.0049      0.007      0.724      0.469      -0.008       0.018\n",
      "Landtagswahlen               -0.0094      0.093     -0.101      0.920      -0.192       0.174\n",
      "Komplexit√§t Reden            -0.0078      0.051     -0.153      0.878      -0.108       0.092\n",
      "Komplexit√§t Posts            -0.1001      0.104     -0.962      0.336      -0.304       0.104\n",
      "topic_1                       0.1340      0.383      0.349      0.727      -0.618       0.886\n",
      "topic_2                       0.7879      0.405      1.946      0.052      -0.006       1.581\n",
      "topic_3                      -0.7922      0.369     -2.148      0.032      -1.515      -0.069\n",
      "topic_4                      -0.6138      0.371     -1.653      0.098      -1.341       0.114\n",
      "topic_6                      -0.1682      0.372     -0.452      0.651      -0.898       0.561\n",
      "topic_7                       1.2605      0.433      2.914      0.004       0.413       2.108\n",
      "topic_8                      -0.8261      0.378     -2.187      0.029      -1.566      -0.086\n",
      "topic_10                      0.1016      0.378      0.269      0.788      -0.639       0.843\n",
      "topic_11                     -2.2494      0.458     -4.916      0.000      -3.146      -1.353\n",
      "topic_12                     -1.7589      0.407     -4.325      0.000      -2.556      -0.962\n",
      "topic_13                     -2.2451      0.456     -4.925      0.000      -3.139      -1.352\n",
      "topic_14                     -0.6471      0.379     -1.706      0.088      -1.390       0.096\n",
      "topic_15                     -1.6347      0.406     -4.024      0.000      -2.431      -0.839\n",
      "topic_16                     -1.4651      0.398     -3.679      0.000      -2.246      -0.685\n",
      "topic_17                     -2.3438      0.472     -4.969      0.000      -3.268      -1.419\n",
      "topic_18                     -1.4932      0.405     -3.691      0.000      -2.286      -0.700\n",
      "topic_19                     -1.1070      0.389     -2.848      0.004      -1.869      -0.345\n",
      "topic_20                     -1.6195      0.409     -3.963      0.000      -2.421      -0.819\n",
      "topic_21                     -1.6926      0.413     -4.099      0.000      -2.502      -0.883\n",
      "topic_22                     -1.5539      0.409     -3.803      0.000      -2.355      -0.753\n",
      "topic_23                     -1.8007      0.429     -4.199      0.000      -2.641      -0.960\n",
      "topic_24                     -1.5250      0.409     -3.724      0.000      -2.328      -0.722\n",
      "topic_25                     -0.9761      0.388     -2.516      0.012      -1.736      -0.216\n",
      "topic_29                     -1.0228      0.391     -2.617      0.009      -1.789      -0.257\n",
      "topic_30                     -1.8795      0.438     -4.289      0.000      -2.738      -1.021\n",
      "topic_34                     -1.4262      0.406     -3.510      0.000      -2.222      -0.630\n",
      "topic_36                     -1.7615      0.430     -4.094      0.000      -2.605      -0.918\n",
      "topic_37                     -1.4820      0.412     -3.597      0.000      -2.290      -0.675\n",
      "topic_40                     -1.7793      0.430     -4.133      0.000      -2.623      -0.936\n",
      "topic_41                     -1.8804      0.440     -4.278      0.000      -2.742      -1.019\n",
      "topic_43                     -1.6745      0.423     -3.960      0.000      -2.503      -0.846\n",
      "topic_54                     -2.1027      0.461     -4.560      0.000      -3.006      -1.199\n",
      "topic_68                     -2.2396      0.476     -4.708      0.000      -3.172      -1.307\n",
      "topic_75                     -1.2451      0.401     -3.108      0.002      -2.030      -0.460\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7451058926904666\n",
      "Pr√§zision: 0.6814159292035398\n",
      "Recall: 0.417910447761194\n",
      "F1-Score: 0.5180824222035324\n",
      "Brier-Score: 0.17919927966397808\n",
      "Confusion-Matrix:\n",
      "[[1394  144]\n",
      " [ 429  308]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535685\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2240\n",
      "Model:                          Logit   Df Residuals:                     2199\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1505\n",
      "Time:                        11:17:12   Log-Likelihood:                -1199.9\n",
      "converged:                       True   LL-Null:                       -1412.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.257e-66\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.9281      0.531      1.747      0.081      -0.113       1.969\n",
      "issue attention Facebook      3.1203      1.719      1.815      0.070      -0.249       6.490\n",
      "issue attention Bundestag     1.6628      0.973      1.709      0.087      -0.244       3.570\n",
      "Social Media Nutzung         -0.0088      0.007     -1.286      0.199      -0.022       0.005\n",
      "Landtagswahlen               -0.2727      0.106     -2.577      0.010      -0.480      -0.065\n",
      "Komplexit√§t Reden            -0.2898      0.054     -5.409      0.000      -0.395      -0.185\n",
      "Komplexit√§t Posts             0.0343      0.103      0.334      0.738      -0.167       0.236\n",
      "topic_1                       0.2320      0.385      0.602      0.547      -0.523       0.988\n",
      "topic_2                       0.6116      0.405      1.509      0.131      -0.183       1.406\n",
      "topic_3                      -0.6816      0.371     -1.837      0.066      -1.409       0.046\n",
      "topic_4                      -0.4377      0.373     -1.175      0.240      -1.168       0.293\n",
      "topic_6                      -0.2135      0.376     -0.568      0.570      -0.951       0.524\n",
      "topic_7                       1.2531      0.446      2.813      0.005       0.380       2.126\n",
      "topic_8                      -0.8928      0.383     -2.332      0.020      -1.643      -0.142\n",
      "topic_10                      0.0255      0.384      0.066      0.947      -0.727       0.778\n",
      "topic_11                     -2.2097      0.461     -4.798      0.000      -3.112      -1.307\n",
      "topic_12                     -1.6296      0.408     -3.996      0.000      -2.429      -0.830\n",
      "topic_13                     -2.2323      0.459     -4.864      0.000      -3.132      -1.333\n",
      "topic_14                     -0.6998      0.385     -1.819      0.069      -1.454       0.054\n",
      "topic_15                     -1.6077      0.410     -3.926      0.000      -2.410      -0.805\n",
      "topic_16                     -1.4297      0.402     -3.558      0.000      -2.217      -0.642\n",
      "topic_17                     -2.3538      0.475     -4.957      0.000      -3.285      -1.423\n",
      "topic_18                     -1.4815      0.409     -3.626      0.000      -2.282      -0.681\n",
      "topic_19                     -1.1645      0.396     -2.944      0.003      -1.940      -0.389\n",
      "topic_20                     -1.6006      0.411     -3.899      0.000      -2.405      -0.796\n",
      "topic_21                     -1.7120      0.416     -4.112      0.000      -2.528      -0.896\n",
      "topic_22                     -1.5883      0.412     -3.852      0.000      -2.396      -0.780\n",
      "topic_23                     -1.8485      0.433     -4.270      0.000      -2.697      -1.000\n",
      "topic_24                     -1.5689      0.414     -3.792      0.000      -2.380      -0.758\n",
      "topic_25                     -1.0154      0.393     -2.585      0.010      -1.785      -0.246\n",
      "topic_29                     -1.0809      0.396     -2.731      0.006      -1.857      -0.305\n",
      "topic_30                     -1.9459      0.442     -4.399      0.000      -2.813      -1.079\n",
      "topic_34                     -1.5551      0.415     -3.745      0.000      -2.369      -0.741\n",
      "topic_36                     -1.8329      0.435     -4.216      0.000      -2.685      -0.981\n",
      "topic_37                     -1.5407      0.417     -3.697      0.000      -2.358      -0.724\n",
      "topic_40                     -1.8266      0.435     -4.203      0.000      -2.678      -0.975\n",
      "topic_41                     -1.9230      0.444     -4.333      0.000      -2.793      -1.053\n",
      "topic_43                     -1.7350      0.427     -4.062      0.000      -2.572      -0.898\n",
      "topic_54                     -2.3063      0.479     -4.811      0.000      -3.246      -1.367\n",
      "topic_68                     -2.3038      0.480     -4.804      0.000      -3.244      -1.364\n",
      "topic_75                     -1.2823      0.405     -3.163      0.002      -2.077      -0.488\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7490033940926797\n",
      "Pr√§zision: 0.6898876404494382\n",
      "Recall: 0.4217032967032967\n",
      "F1-Score: 0.5234441602728048\n",
      "Brier-Score: 0.17786030568890937\n",
      "Confusion-Matrix:\n",
      "[[1374  138]\n",
      " [ 421  307]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536279\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2205\n",
      "Model:                          Logit   Df Residuals:                     2164\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1470\n",
      "Time:                        11:17:12   Log-Likelihood:                -1182.5\n",
      "converged:                       True   LL-Null:                       -1386.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.120e-62\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.7219      0.533      1.354      0.176      -0.323       1.767\n",
      "issue attention Facebook      5.8355      1.737      3.359      0.001       2.430       9.241\n",
      "issue attention Bundestag    -0.2271      0.936     -0.243      0.808      -2.062       1.608\n",
      "Social Media Nutzung         -0.0072      0.007     -1.059      0.290      -0.021       0.006\n",
      "Landtagswahlen               -0.1501      0.118     -1.273      0.203      -0.381       0.081\n",
      "Komplexit√§t Reden             0.1603      0.052      3.061      0.002       0.058       0.263\n",
      "Komplexit√§t Posts             0.2556      0.104      2.468      0.014       0.053       0.459\n",
      "topic_1                       0.1959      0.387      0.506      0.613      -0.563       0.954\n",
      "topic_2                       0.7062      0.406      1.740      0.082      -0.089       1.502\n",
      "topic_3                      -0.7590      0.373     -2.033      0.042      -1.491      -0.027\n",
      "topic_4                      -0.5486      0.375     -1.463      0.143      -1.283       0.186\n",
      "topic_6                      -0.1796      0.377     -0.476      0.634      -0.918       0.559\n",
      "topic_7                       1.3437      0.446      3.012      0.003       0.469       2.218\n",
      "topic_8                      -0.7602      0.383     -1.986      0.047      -1.511      -0.010\n",
      "topic_10                      0.1127      0.384      0.293      0.769      -0.640       0.866\n",
      "topic_11                     -2.1525      0.461     -4.672      0.000      -3.056      -1.249\n",
      "topic_12                     -1.6251      0.409     -3.972      0.000      -2.427      -0.823\n",
      "topic_13                     -2.1700      0.460     -4.722      0.000      -3.071      -1.269\n",
      "topic_14                     -0.6425      0.386     -1.664      0.096      -1.399       0.114\n",
      "topic_15                     -1.6346      0.415     -3.937      0.000      -2.448      -0.821\n",
      "topic_16                     -1.3764      0.402     -3.423      0.001      -2.165      -0.588\n",
      "topic_17                     -2.4340      0.493     -4.935      0.000      -3.401      -1.467\n",
      "topic_18                     -1.4093      0.409     -3.446      0.001      -2.211      -0.608\n",
      "topic_19                     -1.0894      0.396     -2.750      0.006      -1.866      -0.313\n",
      "topic_20                     -1.6332      0.417     -3.916      0.000      -2.450      -0.816\n",
      "topic_21                     -1.7200      0.422     -4.075      0.000      -2.547      -0.893\n",
      "topic_22                     -1.5849      0.418     -3.793      0.000      -2.404      -0.766\n",
      "topic_23                     -1.7512      0.433     -4.045      0.000      -2.600      -0.903\n",
      "topic_24                     -1.4713      0.414     -3.556      0.000      -2.282      -0.660\n",
      "topic_25                     -0.9118      0.393     -2.320      0.020      -1.682      -0.142\n",
      "topic_29                     -1.0418      0.398     -2.616      0.009      -1.822      -0.261\n",
      "topic_30                     -1.8382      0.442     -4.157      0.000      -2.705      -0.971\n",
      "topic_34                     -1.5473      0.421     -3.679      0.000      -2.372      -0.723\n",
      "topic_36                     -1.7179      0.435     -3.950      0.000      -2.570      -0.866\n",
      "topic_37                     -1.4326      0.417     -3.437      0.001      -2.250      -0.616\n",
      "topic_40                     -1.8358      0.443     -4.144      0.000      -2.704      -0.968\n",
      "topic_41                     -1.8292      0.444     -4.121      0.000      -2.699      -0.959\n",
      "topic_43                     -1.6325      0.427     -3.821      0.000      -2.470      -0.795\n",
      "topic_54                     -2.2034      0.479     -4.596      0.000      -3.143      -1.264\n",
      "topic_68                     -2.2011      0.480     -4.589      0.000      -3.141      -1.261\n",
      "topic_75                     -1.1861      0.406     -2.924      0.003      -1.981      -0.391\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7440309762255773\n",
      "Pr√§zision: 0.6804597701149425\n",
      "Recall: 0.41631504922644164\n",
      "F1-Score: 0.5165794066317626\n",
      "Brier-Score: 0.17746076554348134\n",
      "Confusion-Matrix:\n",
      "[[1355  139]\n",
      " [ 415  296]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539755\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2170\n",
      "Model:                          Logit   Df Residuals:                     2129\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1439\n",
      "Time:                        11:17:12   Log-Likelihood:                -1171.3\n",
      "converged:                       True   LL-Null:                       -1368.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.078e-59\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.1444      0.540     -2.121      0.034      -2.202      -0.087\n",
      "issue attention Facebook     -0.0738      1.721     -0.043      0.966      -3.447       3.299\n",
      "issue attention Bundestag     0.3321      0.958      0.346      0.729      -1.546       2.210\n",
      "Social Media Nutzung          0.0288      0.007      4.093      0.000       0.015       0.043\n",
      "Landtagswahlen                0.0096      0.130      0.074      0.941      -0.246       0.265\n",
      "Komplexit√§t Reden             0.1462      0.053      2.759      0.006       0.042       0.250\n",
      "Komplexit√§t Posts            -0.5149      0.106     -4.875      0.000      -0.722      -0.308\n",
      "topic_1                       0.1540      0.388      0.397      0.692      -0.607       0.915\n",
      "topic_2                       0.5642      0.412      1.369      0.171      -0.243       1.372\n",
      "topic_3                      -0.8035      0.374     -2.146      0.032      -1.537      -0.070\n",
      "topic_4                      -0.5987      0.376     -1.591      0.112      -1.336       0.139\n",
      "topic_6                      -0.4095      0.381     -1.075      0.283      -1.156       0.337\n",
      "topic_7                       0.9960      0.448      2.224      0.026       0.118       1.874\n",
      "topic_8                      -1.0738      0.387     -2.773      0.006      -1.833      -0.315\n",
      "topic_10                     -0.2080      0.390     -0.534      0.594      -0.972       0.556\n",
      "topic_11                     -2.4603      0.464     -5.304      0.000      -3.369      -1.551\n",
      "topic_12                     -1.8221      0.412     -4.426      0.000      -2.629      -1.015\n",
      "topic_13                     -2.4639      0.462     -5.330      0.000      -3.370      -1.558\n",
      "topic_14                     -1.0004      0.390     -2.562      0.010      -1.766      -0.235\n",
      "topic_15                     -1.9175      0.419     -4.580      0.000      -2.738      -1.097\n",
      "topic_16                     -1.6532      0.406     -4.074      0.000      -2.449      -0.858\n",
      "topic_17                     -2.7540      0.496     -5.554      0.000      -3.726      -1.782\n",
      "topic_18                     -1.7362      0.413     -4.208      0.000      -2.545      -0.927\n",
      "topic_19                     -1.4181      0.400     -3.546      0.000      -2.202      -0.634\n",
      "topic_20                     -1.9164      0.420     -4.563      0.000      -2.740      -1.093\n",
      "topic_21                     -2.0156      0.425     -4.738      0.000      -2.849      -1.182\n",
      "topic_22                     -1.9188      0.421     -4.553      0.000      -2.745      -1.093\n",
      "topic_23                     -2.1144      0.437     -4.842      0.000      -2.970      -1.258\n",
      "topic_24                     -1.8275      0.418     -4.376      0.000      -2.646      -1.009\n",
      "topic_25                     -1.3467      0.399     -3.375      0.001      -2.129      -0.565\n",
      "topic_29                     -1.4974      0.405     -3.699      0.000      -2.291      -0.704\n",
      "topic_30                     -2.2231      0.446     -4.985      0.000      -3.097      -1.349\n",
      "topic_34                     -1.9171      0.424     -4.518      0.000      -2.749      -1.085\n",
      "topic_36                     -2.1154      0.439     -4.822      0.000      -2.975      -1.256\n",
      "topic_37                     -1.8260      0.421     -4.340      0.000      -2.651      -1.001\n",
      "topic_40                     -2.2203      0.447     -4.970      0.000      -3.096      -1.345\n",
      "topic_41                     -2.2200      0.447     -4.964      0.000      -3.097      -1.344\n",
      "topic_43                     -2.0135      0.431     -4.675      0.000      -2.858      -1.169\n",
      "topic_54                     -2.6008      0.483     -5.388      0.000      -3.547      -1.655\n",
      "topic_68                     -2.6005      0.483     -5.383      0.000      -3.547      -1.654\n",
      "topic_75                     -1.5722      0.410     -3.838      0.000      -2.375      -0.769\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7417674823905309\n",
      "Pr√§zision: 0.68\n",
      "Recall: 0.4099290780141844\n",
      "F1-Score: 0.511504424778761\n",
      "Brier-Score: 0.17912349563472715\n",
      "Confusion-Matrix:\n",
      "[[1329  136]\n",
      " [ 416  289]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529822\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2135\n",
      "Model:                          Logit   Df Residuals:                     2094\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1557\n",
      "Time:                        11:17:12   Log-Likelihood:                -1131.2\n",
      "converged:                       True   LL-Null:                       -1339.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.812e-64\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.5679      0.544      2.882      0.004       0.501       2.634\n",
      "issue attention Facebook     -0.4014      1.750     -0.229      0.819      -3.831       3.029\n",
      "issue attention Bundestag    -0.9553      0.976     -0.979      0.328      -2.868       0.957\n",
      "Social Media Nutzung         -0.0119      0.007     -1.709      0.087      -0.025       0.002\n",
      "Landtagswahlen               -0.2338      0.132     -1.774      0.076      -0.492       0.024\n",
      "Komplexit√§t Reden            -0.3685      0.056     -6.544      0.000      -0.479      -0.258\n",
      "Komplexit√§t Posts             0.2168      0.105      2.060      0.039       0.011       0.423\n",
      "topic_1                       0.1408      0.393      0.358      0.720      -0.630       0.911\n",
      "topic_2                       0.5783      0.415      1.392      0.164      -0.236       1.392\n",
      "topic_3                      -0.8673      0.381     -2.278      0.023      -1.613      -0.121\n",
      "topic_4                      -0.6882      0.383     -1.797      0.072      -1.439       0.062\n",
      "topic_6                      -0.4133      0.387     -1.067      0.286      -1.172       0.346\n",
      "topic_7                       1.0924      0.463      2.358      0.018       0.185       2.000\n",
      "topic_8                      -1.1016      0.392     -2.808      0.005      -1.871      -0.333\n",
      "topic_10                     -0.2772      0.395     -0.701      0.483      -1.052       0.497\n",
      "topic_11                     -2.7006      0.483     -5.588      0.000      -3.648      -1.753\n",
      "topic_12                     -1.9083      0.418     -4.570      0.000      -2.727      -1.090\n",
      "topic_13                     -2.5532      0.468     -5.456      0.000      -3.470      -1.636\n",
      "topic_14                     -1.1248      0.398     -2.828      0.005      -1.904      -0.345\n",
      "topic_15                     -2.0951      0.431     -4.864      0.000      -2.939      -1.251\n",
      "topic_16                     -1.7350      0.411     -4.218      0.000      -2.541      -0.929\n",
      "topic_17                     -3.0241      0.524     -5.772      0.000      -4.051      -1.997\n",
      "topic_18                     -1.8274      0.419     -4.365      0.000      -2.648      -1.007\n",
      "topic_19                     -1.5022      0.406     -3.699      0.000      -2.298      -0.706\n",
      "topic_20                     -2.0970      0.431     -4.865      0.000      -2.942      -1.252\n",
      "topic_21                     -2.1902      0.437     -5.006      0.000      -3.048      -1.333\n",
      "topic_22                     -2.0940      0.433     -4.838      0.000      -2.942      -1.246\n",
      "topic_23                     -2.3152      0.450     -5.144      0.000      -3.197      -1.433\n",
      "topic_24                     -2.0014      0.428     -4.671      0.000      -2.841      -1.162\n",
      "topic_25                     -1.4965      0.407     -3.678      0.000      -2.294      -0.699\n",
      "topic_29                     -1.6537      0.413     -4.000      0.000      -2.464      -0.843\n",
      "topic_30                     -2.3139      0.451     -5.129      0.000      -3.198      -1.430\n",
      "topic_34                     -2.0065      0.430     -4.670      0.000      -2.849      -1.164\n",
      "topic_36                     -2.3150      0.452     -5.119      0.000      -3.201      -1.429\n",
      "topic_37                     -2.0095      0.432     -4.656      0.000      -2.855      -1.164\n",
      "topic_40                     -2.3224      0.452     -5.136      0.000      -3.209      -1.436\n",
      "topic_41                     -2.3238      0.453     -5.133      0.000      -3.211      -1.436\n",
      "topic_43                     -2.1027      0.437     -4.813      0.000      -2.959      -1.247\n",
      "topic_54                     -2.8559      0.505     -5.650      0.000      -3.847      -1.865\n",
      "topic_68                     -2.7036      0.488     -5.543      0.000      -3.659      -1.748\n",
      "topic_75                     -1.6652      0.416     -4.008      0.000      -2.480      -0.851\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.752359426126353\n",
      "Pr√§zision: 0.6833333333333333\n",
      "Recall: 0.41897810218978104\n",
      "F1-Score: 0.5194570135746607\n",
      "Brier-Score: 0.17489904554909216\n",
      "Confusion-Matrix:\n",
      "[[1317  133]\n",
      " [ 398  287]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536432\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2100\n",
      "Model:                          Logit   Df Residuals:                     2059\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1438\n",
      "Time:                        11:17:12   Log-Likelihood:                -1126.5\n",
      "converged:                       True   LL-Null:                       -1315.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.169e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.2823      0.549      0.515      0.607      -0.793       1.357\n",
      "issue attention Facebook      2.7837      1.732      1.608      0.108      -0.610       6.177\n",
      "issue attention Bundestag    -0.8594      0.975     -0.882      0.378      -2.769       1.051\n",
      "Social Media Nutzung          0.0032      0.007      0.453      0.651      -0.011       0.017\n",
      "Landtagswahlen                0.0349      0.131      0.267      0.790      -0.221       0.291\n",
      "Komplexit√§t Reden             0.1292      0.053      2.433      0.015       0.025       0.233\n",
      "Komplexit√§t Posts             0.0143      0.107      0.134      0.893      -0.195       0.224\n",
      "topic_1                       0.1994      0.393      0.508      0.612      -0.571       0.969\n",
      "topic_2                       0.6505      0.413      1.577      0.115      -0.158       1.459\n",
      "topic_3                      -0.8723      0.379     -2.302      0.021      -1.615      -0.130\n",
      "topic_4                      -0.6780      0.381     -1.782      0.075      -1.424       0.068\n",
      "topic_6                      -0.2741      0.384     -0.715      0.475      -1.026       0.478\n",
      "topic_7                       1.3737      0.475      2.893      0.004       0.443       2.304\n",
      "topic_8                      -0.9200      0.389     -2.364      0.018      -1.683      -0.157\n",
      "topic_10                     -0.0863      0.391     -0.221      0.825      -0.852       0.680\n",
      "topic_11                     -2.4221      0.479     -5.059      0.000      -3.361      -1.484\n",
      "topic_12                     -1.6934      0.413     -4.101      0.000      -2.503      -0.884\n",
      "topic_13                     -2.2849      0.463     -4.937      0.000      -3.192      -1.378\n",
      "topic_14                     -0.8386      0.393     -2.135      0.033      -1.608      -0.069\n",
      "topic_15                     -1.8358      0.425     -4.317      0.000      -2.669      -1.002\n",
      "topic_16                     -1.4823      0.407     -3.644      0.000      -2.279      -0.685\n",
      "topic_17                     -2.9394      0.550     -5.341      0.000      -4.018      -1.861\n",
      "topic_18                     -1.6330      0.418     -3.906      0.000      -2.453      -0.814\n",
      "topic_19                     -1.2228      0.401     -3.049      0.002      -2.009      -0.437\n",
      "topic_20                     -1.9378      0.433     -4.476      0.000      -2.786      -1.089\n",
      "topic_21                     -2.0340      0.441     -4.615      0.000      -2.898      -1.170\n",
      "topic_22                     -1.8094      0.428     -4.229      0.000      -2.648      -0.971\n",
      "topic_23                     -2.0095      0.445     -4.512      0.000      -2.882      -1.137\n",
      "topic_24                     -1.7060      0.423     -4.034      0.000      -2.535      -0.877\n",
      "topic_25                     -1.2796      0.405     -3.163      0.002      -2.073      -0.487\n",
      "topic_29                     -1.3504      0.408     -3.306      0.001      -2.151      -0.550\n",
      "topic_30                     -2.1143      0.456     -4.639      0.000      -3.008      -1.221\n",
      "topic_34                     -1.7019      0.425     -4.006      0.000      -2.535      -0.869\n",
      "topic_36                     -1.9920      0.447     -4.455      0.000      -2.868      -1.116\n",
      "topic_37                     -1.6911      0.426     -3.966      0.000      -2.527      -0.855\n",
      "topic_40                     -2.0050      0.447     -4.483      0.000      -2.882      -1.128\n",
      "topic_41                     -2.0032      0.448     -4.473      0.000      -2.881      -1.126\n",
      "topic_43                     -1.7903      0.431     -4.153      0.000      -2.635      -0.945\n",
      "topic_54                     -2.5280      0.501     -5.048      0.000      -3.509      -1.547\n",
      "topic_68                     -2.3759      0.483     -4.919      0.000      -3.323      -1.429\n",
      "topic_75                     -1.4327      0.414     -3.462      0.001      -2.244      -0.622\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7418379553198123\n",
      "Pr√§zision: 0.6819338422391857\n",
      "Recall: 0.39940387481371087\n",
      "F1-Score: 0.5037593984962406\n",
      "Brier-Score: 0.1779456262906332\n",
      "Confusion-Matrix:\n",
      "[[1304  125]\n",
      " [ 403  268]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537148\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2065\n",
      "Model:                          Logit   Df Residuals:                     2024\n",
      "Method:                           MLE   Df Model:                           40\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1447\n",
      "Time:                        11:17:12   Log-Likelihood:                -1109.2\n",
      "converged:                       True   LL-Null:                       -1296.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.459e-56\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.4026      0.559      0.721      0.471      -0.693       1.498\n",
      "issue attention Facebook     -0.0466      1.750     -0.027      0.979      -3.477       3.384\n",
      "issue attention Bundestag    -0.6062      0.986     -0.615      0.539      -2.538       1.326\n",
      "Social Media Nutzung          0.0038      0.007      0.518      0.604      -0.011       0.018\n",
      "Landtagswahlen                0.0418      0.131      0.319      0.749      -0.215       0.298\n",
      "Komplexit√§t Reden             0.1541      0.054      2.861      0.004       0.049       0.260\n",
      "Komplexit√§t Posts            -0.1345      0.109     -1.233      0.218      -0.348       0.079\n",
      "topic_1                       0.3039      0.397      0.765      0.445      -0.475       1.083\n",
      "topic_2                       0.6782      0.419      1.617      0.106      -0.144       1.500\n",
      "topic_3                      -0.7868      0.380     -2.069      0.039      -1.532      -0.041\n",
      "topic_4                      -0.5967      0.382     -1.562      0.118      -1.346       0.152\n",
      "topic_6                      -0.3802      0.386     -0.986      0.324      -1.136       0.375\n",
      "topic_7                       1.2505      0.476      2.627      0.009       0.317       2.184\n",
      "topic_8                      -1.0026      0.392     -2.559      0.011      -1.771      -0.235\n",
      "topic_10                     -0.2395      0.394     -0.609      0.543      -1.011       0.532\n",
      "topic_11                     -2.5101      0.481     -5.221      0.000      -3.452      -1.568\n",
      "topic_12                     -1.7280      0.415     -4.168      0.000      -2.541      -0.915\n",
      "topic_13                     -2.3654      0.464     -5.093      0.000      -3.276      -1.455\n",
      "topic_14                     -0.9443      0.396     -2.387      0.017      -1.720      -0.169\n",
      "topic_15                     -2.0126      0.434     -4.635      0.000      -2.864      -1.162\n",
      "topic_16                     -1.5537      0.409     -3.798      0.000      -2.355      -0.752\n",
      "topic_17                     -3.0340      0.552     -5.497      0.000      -4.116      -1.952\n",
      "topic_18                     -1.7291      0.420     -4.113      0.000      -2.553      -0.905\n",
      "topic_19                     -1.3177      0.404     -3.264      0.001      -2.109      -0.526\n",
      "topic_20                     -2.0154      0.435     -4.629      0.000      -2.869      -1.162\n",
      "topic_21                     -2.1208      0.444     -4.780      0.000      -2.990      -1.251\n",
      "topic_22                     -1.9101      0.430     -4.440      0.000      -2.753      -1.067\n",
      "topic_23                     -2.1253      0.448     -4.746      0.000      -3.003      -1.248\n",
      "topic_24                     -1.8141      0.425     -4.266      0.000      -2.648      -0.981\n",
      "topic_25                     -1.3901      0.407     -3.415      0.001      -2.188      -0.592\n",
      "topic_29                     -1.4689      0.411     -3.575      0.000      -2.274      -0.664\n",
      "topic_30                     -2.2404      0.458     -4.889      0.000      -3.139      -1.342\n",
      "topic_34                     -1.8181      0.427     -4.255      0.000      -2.655      -0.981\n",
      "topic_36                     -2.2418      0.459     -4.882      0.000      -3.142      -1.342\n",
      "topic_37                     -1.8185      0.429     -4.241      0.000      -2.659      -0.978\n",
      "topic_40                     -2.1291      0.449     -4.738      0.000      -3.010      -1.248\n",
      "topic_41                     -2.1301      0.450     -4.731      0.000      -3.013      -1.248\n",
      "topic_43                     -2.0151      0.440     -4.576      0.000      -2.878      -1.152\n",
      "topic_54                     -2.6613      0.503     -5.291      0.000      -3.647      -1.676\n",
      "topic_68                     -2.5080      0.485     -5.168      0.000      -3.459      -1.557\n",
      "topic_75                     -1.5573      0.417     -3.739      0.000      -2.374      -0.741\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7418206014636705\n",
      "Pr√§zision: 0.6810126582278481\n",
      "Recall: 0.40512048192771083\n",
      "F1-Score: 0.5080264400377715\n",
      "Brier-Score: 0.17821821209468913\n",
      "Confusion-Matrix:\n",
      "[[1275  126]\n",
      " [ 395  269]]\n"
     ]
    }
   ],
   "source": [
    "from stargazer.stargazer import Stargazer\n",
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(reden_relativ_reduced, post_relativ_reduced, rede_common,lag, social_media_usage,rede_komplex,posts_komplex)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung im Bundestag\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_bundestag_complex.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse nach Parteien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AfD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 34, 35, 36, 37, 40, 43, 44, 46, 51, 52, 53, 54, 56, 58, 59, 61, 63, 64, 65, 68, 69, 70, 72, 74, 75, 77, 78, 84, 88, 90, 91, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 6, 7, 8, 10, 14, 15, 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\3059987655.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_afd[\"date\"] = pd.to_datetime(subset_reden_afd[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\3059987655.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_afd[\"date\"] = pd.to_datetime(subset_posts_afd[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_afd = subset_posts[subset_posts[\"partei\"] == \"AfD\"]\n",
    "subset_reden_afd = subset_reden[subset_reden[\"partei\"] == \"AfD\"]\n",
    "social_media_usage_afd = subset_posts_afd.groupby('date').size()\n",
    "subset_reden_afd[\"date\"] = pd.to_datetime(subset_reden_afd[\"date\"])\n",
    "subset_posts_afd[\"date\"] = pd.to_datetime(subset_posts_afd[\"date\"])\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_afd = subset_reden_afd.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_afd = subset_posts_afd.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "reden_komplexit√§t_t√§glich_afd = subset_reden_afd.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_afd = subset_posts_afd.groupby('date')['komplexit√§t'].sum()\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_afd = redethemen_t√§glich_afd.index.intersection(postthemen_t√§glich_afd.index)\n",
    "redethemen_t√§glich_aligned_afd = redethemen_t√§glich_afd.loc[common_dates_afd]\n",
    "postthemen_t√§glich_aligned_afd = postthemen_t√§glich_afd.loc[common_dates_afd]\n",
    "rede_komplex_afd = reden_komplexit√§t_t√§glich_afd.loc[common_dates_afd]\n",
    "posts_komplex_afd = posts_komplexit√§t_t√§glich_afd.loc[common_dates_afd]\n",
    "rede_common_afd, post_common_afd = filter_common_topics(redethemen_t√§glich_aligned_afd, postthemen_t√§glich_aligned_afd)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_afd =  rede_common_afd.div(rede_common_afd.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_afd = post_common_afd.div(post_common_afd.sum(axis=1), axis=0)\n",
    "reden_relativ_afd_red = remove_near_constant(reden_relativ_afd)\n",
    "post_relativ_afd_red = remove_near_constant(post_relativ_afd)\n",
    "rede_reduced_afd, post_reduced_afd = filter_common_topics(reden_relativ_afd_red, post_relativ_afd_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581177\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      764\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06912\n",
      "Time:                        11:17:12   Log-Likelihood:                -453.32\n",
      "converged:                       True   LL-Null:                       -486.98\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.334e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1055      0.463     -0.228      0.820      -1.013       0.802\n",
      "issue attention Facebook      4.0004      1.270      3.150      0.002       1.511       6.490\n",
      "issue attention Bundestag    -0.9976      0.723     -1.380      0.168      -2.415       0.420\n",
      "Social Media Nutzung         -0.0207      0.016     -1.261      0.207      -0.053       0.011\n",
      "Landtagswahlen                0.0320      0.148      0.217      0.829      -0.258       0.322\n",
      "topic_1                      -0.0548      0.363     -0.151      0.880      -0.766       0.656\n",
      "topic_2                       0.3643      0.365      0.998      0.318      -0.351       1.080\n",
      "topic_3                      -0.4699      0.372     -1.262      0.207      -1.200       0.260\n",
      "topic_4                      -0.4742      0.369     -1.284      0.199      -1.198       0.249\n",
      "topic_6                      -0.9948      0.423     -2.352      0.019      -1.824      -0.166\n",
      "topic_7                       0.3488      0.368      0.948      0.343      -0.372       1.070\n",
      "topic_8                      -0.6135      0.398     -1.540      0.124      -1.394       0.167\n",
      "topic_10                     -0.3328      0.393     -0.847      0.397      -1.103       0.438\n",
      "topic_14                     -0.6440      0.409     -1.574      0.115      -1.446       0.158\n",
      "topic_15                     -1.3035      0.457     -2.853      0.004      -2.199      -0.408\n",
      "topic_29                     -1.2907      0.457     -2.822      0.005      -2.187      -0.394\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6795922552810082\n",
      "Pr√§zision: 0.5333333333333333\n",
      "Recall: 0.16194331983805668\n",
      "F1-Score: 0.2484472049689441\n",
      "Brier-Score: 0.19855394249315453\n",
      "Confusion-Matrix:\n",
      "[[498  35]\n",
      " [207  40]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x22408927710>,\n",
       " 0.6795922552810082,\n",
       " 0.2484472049689441)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_FE_control(rede_reduced_afd,post_reduced_afd, rede_common_afd,1,social_media_usage_afd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581177\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      764\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06912\n",
      "Time:                        11:17:13   Log-Likelihood:                -453.32\n",
      "converged:                       True   LL-Null:                       -486.98\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.334e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1055      0.463     -0.228      0.820      -1.013       0.802\n",
      "issue attention Facebook      4.0004      1.270      3.150      0.002       1.511       6.490\n",
      "issue attention Bundestag    -0.9976      0.723     -1.380      0.168      -2.415       0.420\n",
      "Social Media Nutzung         -0.0207      0.016     -1.261      0.207      -0.053       0.011\n",
      "Landtagswahlen                0.0320      0.148      0.217      0.829      -0.258       0.322\n",
      "topic_1                      -0.0548      0.363     -0.151      0.880      -0.766       0.656\n",
      "topic_2                       0.3643      0.365      0.998      0.318      -0.351       1.080\n",
      "topic_3                      -0.4699      0.372     -1.262      0.207      -1.200       0.260\n",
      "topic_4                      -0.4742      0.369     -1.284      0.199      -1.198       0.249\n",
      "topic_6                      -0.9948      0.423     -2.352      0.019      -1.824      -0.166\n",
      "topic_7                       0.3488      0.368      0.948      0.343      -0.372       1.070\n",
      "topic_8                      -0.6135      0.398     -1.540      0.124      -1.394       0.167\n",
      "topic_10                     -0.3328      0.393     -0.847      0.397      -1.103       0.438\n",
      "topic_14                     -0.6440      0.409     -1.574      0.115      -1.446       0.158\n",
      "topic_15                     -1.3035      0.457     -2.853      0.004      -2.199      -0.408\n",
      "topic_29                     -1.2907      0.457     -2.822      0.005      -2.187      -0.394\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6795922552810082\n",
      "Pr√§zision: 0.5333333333333333\n",
      "Recall: 0.16194331983805668\n",
      "F1-Score: 0.2484472049689441\n",
      "Brier-Score: 0.19855394249315453\n",
      "Confusion-Matrix:\n",
      "[[498  35]\n",
      " [207  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.586429\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  768\n",
      "Model:                          Logit   Df Residuals:                      752\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06041\n",
      "Time:                        11:17:13   Log-Likelihood:                -450.38\n",
      "converged:                       True   LL-Null:                       -479.33\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.746e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2242      0.464     -0.483      0.629      -1.133       0.685\n",
      "issue attention Facebook      2.1433      1.258      1.704      0.088      -0.322       4.609\n",
      "issue attention Bundestag     0.3852      0.710      0.542      0.588      -1.007       1.777\n",
      "Social Media Nutzung         -0.0118      0.016     -0.713      0.476      -0.044       0.021\n",
      "Landtagswahlen               -0.1360      0.165     -0.823      0.411      -0.460       0.188\n",
      "topic_1                      -0.0871      0.365     -0.238      0.811      -0.802       0.628\n",
      "topic_2                       0.2827      0.364      0.776      0.438      -0.431       0.996\n",
      "topic_3                      -0.3236      0.373     -0.868      0.385      -1.055       0.407\n",
      "topic_4                      -0.3334      0.370     -0.902      0.367      -1.058       0.391\n",
      "topic_6                      -0.9942      0.425     -2.341      0.019      -1.827      -0.162\n",
      "topic_7                       0.2907      0.369      0.788      0.431      -0.432       1.013\n",
      "topic_8                      -0.6434      0.399     -1.611      0.107      -1.426       0.139\n",
      "topic_10                     -0.3707      0.394     -0.941      0.347      -1.143       0.402\n",
      "topic_14                     -0.6890      0.410     -1.681      0.093      -1.492       0.114\n",
      "topic_15                     -1.3194      0.458     -2.882      0.004      -2.217      -0.422\n",
      "topic_29                     -1.3162      0.458     -2.872      0.004      -2.214      -0.418\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6684891240446795\n",
      "Pr√§zision: 0.48936170212765956\n",
      "Recall: 0.09465020576131687\n",
      "F1-Score: 0.15862068965517243\n",
      "Brier-Score: 0.2009885708483469\n",
      "Confusion-Matrix:\n",
      "[[501  24]\n",
      " [220  23]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.585913\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  756\n",
      "Model:                          Logit   Df Residuals:                      740\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06092\n",
      "Time:                        11:17:13   Log-Likelihood:                -442.95\n",
      "converged:                       True   LL-Null:                       -471.69\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.825e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.0945      0.482     -2.269      0.023      -2.040      -0.149\n",
      "issue attention Facebook      1.4896      1.269      1.174      0.240      -0.998       3.977\n",
      "issue attention Bundestag     1.0221      0.715      1.429      0.153      -0.380       2.424\n",
      "Social Media Nutzung          0.0252      0.017      1.450      0.147      -0.009       0.059\n",
      "Landtagswahlen               -0.0992      0.184     -0.539      0.590      -0.460       0.262\n",
      "topic_1                      -0.0978      0.369     -0.265      0.791      -0.822       0.626\n",
      "topic_2                       0.2942      0.369      0.798      0.425      -0.428       1.017\n",
      "topic_3                      -0.2013      0.375     -0.537      0.591      -0.936       0.533\n",
      "topic_4                      -0.2871      0.374     -0.768      0.442      -1.020       0.445\n",
      "topic_6                      -0.9584      0.427     -2.242      0.025      -1.796      -0.121\n",
      "topic_7                       0.3120      0.373      0.838      0.402      -0.418       1.042\n",
      "topic_8                      -0.6186      0.403     -1.535      0.125      -1.408       0.171\n",
      "topic_10                     -0.4150      0.401     -1.036      0.300      -1.200       0.370\n",
      "topic_14                     -0.6608      0.413     -1.601      0.109      -1.470       0.148\n",
      "topic_15                     -1.2828      0.460     -2.788      0.005      -2.185      -0.381\n",
      "topic_29                     -1.2813      0.461     -2.781      0.005      -2.184      -0.378\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6719527690328011\n",
      "Pr√§zision: 0.5306122448979592\n",
      "Recall: 0.1087866108786611\n",
      "F1-Score: 0.18055555555555555\n",
      "Brier-Score: 0.20014294850927575\n",
      "Confusion-Matrix:\n",
      "[[494  23]\n",
      " [213  26]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589441\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  744\n",
      "Model:                          Logit   Df Residuals:                      728\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.05806\n",
      "Time:                        11:17:13   Log-Likelihood:                -438.54\n",
      "converged:                       True   LL-Null:                       -465.57\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.569e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.3414      0.479      0.713      0.476      -0.597       1.280\n",
      "issue attention Facebook      0.4461      1.262      0.353      0.724      -2.028       2.920\n",
      "issue attention Bundestag     0.3133      0.729      0.430      0.667      -1.116       1.742\n",
      "Social Media Nutzung         -0.0301      0.017     -1.725      0.084      -0.064       0.004\n",
      "Landtagswahlen               -0.0307      0.208     -0.147      0.883      -0.439       0.378\n",
      "topic_1                      -0.2400      0.372     -0.645      0.519      -0.969       0.489\n",
      "topic_2                       0.2733      0.368      0.743      0.458      -0.448       0.995\n",
      "topic_3                      -0.2222      0.377     -0.589      0.556      -0.961       0.517\n",
      "topic_4                      -0.2759      0.375     -0.736      0.462      -1.010       0.459\n",
      "topic_6                      -1.1110      0.428     -2.597      0.009      -1.950      -0.272\n",
      "topic_7                       0.2310      0.373      0.619      0.536      -0.501       0.963\n",
      "topic_8                      -0.7470      0.403     -1.854      0.064      -1.537       0.043\n",
      "topic_10                     -0.5722      0.401     -1.427      0.154      -1.358       0.214\n",
      "topic_14                     -0.8210      0.413     -1.987      0.047      -1.631      -0.011\n",
      "topic_15                     -1.4516      0.460     -3.153      0.002      -2.354      -0.549\n",
      "topic_29                     -1.4517      0.461     -3.149      0.002      -2.355      -0.548\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6635374795063208\n",
      "Pr√§zision: 0.5370370370370371\n",
      "Recall: 0.12236286919831224\n",
      "F1-Score: 0.19931271477663232\n",
      "Brier-Score: 0.20173118873032223\n",
      "Confusion-Matrix:\n",
      "[[482  25]\n",
      " [208  29]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.585306\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  732\n",
      "Model:                          Logit   Df Residuals:                      716\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06282\n",
      "Time:                        11:17:13   Log-Likelihood:                -428.44\n",
      "converged:                       True   LL-Null:                       -457.16\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.907e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.4491      0.484      0.928      0.354      -0.500       1.398\n",
      "issue attention Facebook      1.2649      1.276      0.992      0.321      -1.235       3.765\n",
      "issue attention Bundestag    -0.2876      0.744     -0.387      0.699      -1.745       1.170\n",
      "Social Media Nutzung         -0.0385      0.018     -2.171      0.030      -0.073      -0.004\n",
      "Landtagswahlen                0.0161      0.210      0.077      0.939      -0.396       0.428\n",
      "topic_1                      -0.2382      0.377     -0.632      0.527      -0.977       0.500\n",
      "topic_2                       0.3972      0.372      1.069      0.285      -0.331       1.126\n",
      "topic_3                      -0.2993      0.383     -0.780      0.435      -1.051       0.452\n",
      "topic_4                      -0.2787      0.379     -0.735      0.463      -1.022       0.465\n",
      "topic_6                      -1.0237      0.430     -2.378      0.017      -1.867      -0.180\n",
      "topic_7                       0.3543      0.377      0.940      0.347      -0.384       1.093\n",
      "topic_8                      -0.6478      0.406     -1.596      0.110      -1.443       0.148\n",
      "topic_10                     -0.4673      0.405     -1.155      0.248      -1.261       0.326\n",
      "topic_14                     -0.8108      0.421     -1.925      0.054      -1.637       0.015\n",
      "topic_15                     -1.5039      0.477     -3.151      0.002      -2.439      -0.568\n",
      "topic_29                     -1.3632      0.463     -2.943      0.003      -2.271      -0.455\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6702068965517242\n",
      "Pr√§zision: 0.5666666666666667\n",
      "Recall: 0.14655172413793102\n",
      "F1-Score: 0.2328767123287671\n",
      "Brier-Score: 0.20000535191170898\n",
      "Confusion-Matrix:\n",
      "[[474  26]\n",
      " [198  34]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.583675\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  720\n",
      "Model:                          Logit   Df Residuals:                      704\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06984\n",
      "Time:                        11:17:13   Log-Likelihood:                -420.25\n",
      "converged:                       True   LL-Null:                       -451.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.329e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.4185      0.492     -2.884      0.004      -2.382      -0.455\n",
      "issue attention Facebook      3.0846      1.329      2.321      0.020       0.480       5.689\n",
      "issue attention Bundestag     0.0968      0.745      0.130      0.897      -1.364       1.558\n",
      "Social Media Nutzung          0.0383      0.018      2.170      0.030       0.004       0.073\n",
      "Landtagswahlen               -0.2098      0.210     -0.998      0.318      -0.622       0.202\n",
      "topic_1                      -0.1648      0.381     -0.433      0.665      -0.911       0.581\n",
      "topic_2                       0.4775      0.378      1.262      0.207      -0.264       1.219\n",
      "topic_3                      -0.5112      0.394     -1.296      0.195      -1.284       0.262\n",
      "topic_4                      -0.3593      0.386     -0.932      0.351      -1.115       0.396\n",
      "topic_6                      -0.8483      0.434     -1.956      0.051      -1.698       0.002\n",
      "topic_7                       0.4928      0.382      1.290      0.197      -0.256       1.242\n",
      "topic_8                      -0.4870      0.409     -1.190      0.234      -1.289       0.315\n",
      "topic_10                     -0.2662      0.409     -0.651      0.515      -1.068       0.535\n",
      "topic_14                     -0.6138      0.425     -1.444      0.149      -1.447       0.220\n",
      "topic_15                     -1.3128      0.480     -2.732      0.006      -2.254      -0.371\n",
      "topic_29                     -1.1708      0.467     -2.509      0.012      -2.085      -0.256\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6837126745102206\n",
      "Pr√§zision: 0.5333333333333333\n",
      "Recall: 0.17316017316017315\n",
      "F1-Score: 0.26143790849673204\n",
      "Brier-Score: 0.19934230925833532\n",
      "Confusion-Matrix:\n",
      "[[454  35]\n",
      " [191  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.590149\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  708\n",
      "Model:                          Logit   Df Residuals:                      692\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06086\n",
      "Time:                        11:17:13   Log-Likelihood:                -417.83\n",
      "converged:                       True   LL-Null:                       -444.90\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.476e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1905      0.489     -0.389      0.697      -1.150       0.769\n",
      "issue attention Facebook      0.0298      1.319      0.023      0.982      -2.555       2.614\n",
      "issue attention Bundestag     0.7423      0.739      1.004      0.315      -0.707       2.191\n",
      "Social Media Nutzung         -0.0082      0.018     -0.463      0.643      -0.043       0.027\n",
      "Landtagswahlen               -0.0364      0.209     -0.175      0.861      -0.445       0.372\n",
      "topic_1                      -0.1815      0.381     -0.477      0.633      -0.927       0.564\n",
      "topic_2                       0.3981      0.377      1.056      0.291      -0.341       1.137\n",
      "topic_3                      -0.1976      0.392     -0.504      0.614      -0.966       0.571\n",
      "topic_4                      -0.1098      0.384     -0.286      0.775      -0.863       0.643\n",
      "topic_6                      -1.1134      0.441     -2.525      0.012      -1.978      -0.249\n",
      "topic_7                       0.3527      0.382      0.923      0.356      -0.396       1.101\n",
      "topic_8                      -0.6460      0.409     -1.581      0.114      -1.447       0.155\n",
      "topic_10                     -0.5443      0.412     -1.323      0.186      -1.351       0.262\n",
      "topic_14                     -0.8085      0.424     -1.907      0.056      -1.639       0.022\n",
      "topic_15                     -1.4835      0.479     -3.094      0.002      -2.423      -0.544\n",
      "topic_29                     -1.3480      0.465     -2.896      0.004      -2.260      -0.436\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6676169590643275\n",
      "Pr√§zision: 0.55\n",
      "Recall: 0.19298245614035087\n",
      "F1-Score: 0.2857142857142857\n",
      "Brier-Score: 0.20192232717395278\n",
      "Confusion-Matrix:\n",
      "[[444  36]\n",
      " [184  44]]\n"
     ]
    }
   ],
   "source": [
    "models_afd = []\n",
    "metrics_afd = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model_afd, auc_roc_afd, f1_afd = log_reg_FE_control(rede_reduced_afd,post_reduced_afd, rede_common_afd,lag,social_media_usage_afd)\n",
    "    models_afd.append(model_afd)\n",
    "    metrics_afd.append((auc_roc_afd, f1_afd))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models_afd)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - AfD\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes_afd = [f\"Lag {i}: AUC-ROC = {metrics_afd[i-1][0]:.3f}, F1-Score = {metrics_afd[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes_afd)\n",
    "\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_afd_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579777\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      762\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07136\n",
      "Time:                        11:17:13   Log-Likelihood:                -452.23\n",
      "converged:                       True   LL-Null:                       -486.98\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.624e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.3005      0.683      0.440      0.660      -1.039       1.640\n",
      "issue attention Facebook      4.0312      1.278      3.154      0.002       1.526       6.536\n",
      "issue attention Bundestag    -0.9692      0.721     -1.344      0.179      -2.383       0.444\n",
      "Social Media Nutzung         -0.0385      0.028     -1.393      0.164      -0.093       0.016\n",
      "Landtagswahlen               -0.0162      0.152     -0.106      0.915      -0.315       0.282\n",
      "Komplexit√§t Reden            -0.0980      0.084     -1.166      0.244      -0.263       0.067\n",
      "Komplexit√§t Posts             0.1244      0.138      0.899      0.369      -0.147       0.396\n",
      "topic_1                      -0.0522      0.364     -0.144      0.886      -0.765       0.661\n",
      "topic_2                       0.3660      0.366      1.001      0.317      -0.351       1.083\n",
      "topic_3                      -0.4708      0.373     -1.262      0.207      -1.202       0.261\n",
      "topic_4                      -0.4744      0.370     -1.282      0.200      -1.200       0.251\n",
      "topic_6                      -0.9922      0.424     -2.342      0.019      -1.823      -0.162\n",
      "topic_7                       0.3522      0.369      0.955      0.339      -0.370       1.075\n",
      "topic_8                      -0.6109      0.399     -1.530      0.126      -1.393       0.172\n",
      "topic_10                     -0.3296      0.394     -0.837      0.403      -1.102       0.443\n",
      "topic_14                     -0.6427      0.410     -1.568      0.117      -1.446       0.161\n",
      "topic_15                     -1.3032      0.458     -2.848      0.004      -2.200      -0.406\n",
      "topic_29                     -1.2883      0.458     -2.812      0.005      -2.186      -0.390\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6837623717252432\n",
      "Pr√§zision: 0.5131578947368421\n",
      "Recall: 0.15789473684210525\n",
      "F1-Score: 0.24148606811145512\n",
      "Brier-Score: 0.1976688857987978\n",
      "Confusion-Matrix:\n",
      "[[496  37]\n",
      " [208  39]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.584174\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  768\n",
      "Model:                          Logit   Df Residuals:                      750\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06402\n",
      "Time:                        11:17:13   Log-Likelihood:                -448.65\n",
      "converged:                       True   LL-Null:                       -479.33\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.225e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9785      0.672     -1.457      0.145      -2.295       0.338\n",
      "issue attention Facebook      2.2106      1.261      1.753      0.080      -0.262       4.683\n",
      "issue attention Bundestag     0.3780      0.711      0.532      0.595      -1.015       1.771\n",
      "Social Media Nutzung          0.0213      0.027      0.794      0.427      -0.031       0.074\n",
      "Landtagswahlen               -0.1172      0.170     -0.689      0.491      -0.451       0.216\n",
      "Komplexit√§t Reden            -0.0931      0.083     -1.125      0.261      -0.255       0.069\n",
      "Komplexit√§t Posts            -0.2038      0.139     -1.470      0.142      -0.476       0.068\n",
      "topic_1                      -0.0852      0.366     -0.233      0.816      -0.802       0.632\n",
      "topic_2                       0.2872      0.365      0.786      0.432      -0.429       1.003\n",
      "topic_3                      -0.3295      0.374     -0.881      0.378      -1.062       0.404\n",
      "topic_4                      -0.3378      0.370     -0.912      0.362      -1.064       0.388\n",
      "topic_6                      -0.9935      0.426     -2.334      0.020      -1.828      -0.159\n",
      "topic_7                       0.2962      0.370      0.801      0.423      -0.428       1.021\n",
      "topic_8                      -0.6444      0.400     -1.610      0.107      -1.429       0.140\n",
      "topic_10                     -0.3678      0.395     -0.931      0.352      -1.142       0.406\n",
      "topic_14                     -0.6875      0.411     -1.674      0.094      -1.492       0.117\n",
      "topic_15                     -1.3205      0.458     -2.880      0.004      -2.219      -0.422\n",
      "topic_29                     -1.3172      0.459     -2.870      0.004      -2.217      -0.418\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6682814030962179\n",
      "Pr√§zision: 0.5576923076923077\n",
      "Recall: 0.11934156378600823\n",
      "F1-Score: 0.19661016949152543\n",
      "Brier-Score: 0.20012353711888753\n",
      "Confusion-Matrix:\n",
      "[[502  23]\n",
      " [214  29]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582448\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  756\n",
      "Model:                          Logit   Df Residuals:                      738\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06647\n",
      "Time:                        11:17:13   Log-Likelihood:                -440.33\n",
      "converged:                       True   LL-Null:                       -471.69\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.726e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1446      0.694     -0.208      0.835      -1.505       1.216\n",
      "issue attention Facebook      1.4296      1.274      1.122      0.262      -1.067       3.927\n",
      "issue attention Bundestag     1.0340      0.719      1.438      0.150      -0.375       2.443\n",
      "Social Media Nutzung         -0.0167      0.028     -0.599      0.549      -0.072       0.038\n",
      "Landtagswahlen               -0.0958      0.195     -0.492      0.623      -0.477       0.286\n",
      "Komplexit√§t Reden             0.1216      0.085      1.431      0.153      -0.045       0.288\n",
      "Komplexit√§t Posts             0.2388      0.137      1.738      0.082      -0.030       0.508\n",
      "topic_1                      -0.1023      0.371     -0.276      0.783      -0.830       0.625\n",
      "topic_2                       0.2910      0.370      0.787      0.431      -0.434       1.016\n",
      "topic_3                      -0.1989      0.377     -0.528      0.597      -0.937       0.539\n",
      "topic_4                      -0.2875      0.376     -0.765      0.444      -1.024       0.449\n",
      "topic_6                      -0.9726      0.429     -2.268      0.023      -1.813      -0.132\n",
      "topic_7                       0.3086      0.374      0.824      0.410      -0.425       1.042\n",
      "topic_8                      -0.6272      0.404     -1.552      0.121      -1.419       0.165\n",
      "topic_10                     -0.4258      0.402     -1.058      0.290      -1.214       0.363\n",
      "topic_14                     -0.6736      0.414     -1.625      0.104      -1.486       0.139\n",
      "topic_15                     -1.2991      0.462     -2.814      0.005      -2.204      -0.394\n",
      "topic_29                     -1.2972      0.462     -2.806      0.005      -2.203      -0.391\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.681619902397967\n",
      "Pr√§zision: 0.5\n",
      "Recall: 0.14644351464435146\n",
      "F1-Score: 0.22653721682847897\n",
      "Brier-Score: 0.19855027837541966\n",
      "Confusion-Matrix:\n",
      "[[482  35]\n",
      " [204  35]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.585282\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  744\n",
      "Model:                          Logit   Df Residuals:                      726\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06470\n",
      "Time:                        11:17:13   Log-Likelihood:                -435.45\n",
      "converged:                       True   LL-Null:                       -465.57\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.568e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2634      0.688     -0.383      0.702      -1.613       1.086\n",
      "issue attention Facebook      0.4318      1.272      0.340      0.734      -2.061       2.924\n",
      "issue attention Bundestag     0.2596      0.734      0.353      0.724      -1.180       1.699\n",
      "Social Media Nutzung         -0.0041      0.028     -0.149      0.882      -0.059       0.050\n",
      "Landtagswahlen                0.1048      0.217      0.484      0.628      -0.320       0.529\n",
      "Komplexit√§t Reden             0.1681      0.085      1.985      0.047       0.002       0.334\n",
      "Komplexit√§t Posts            -0.2072      0.137     -1.514      0.130      -0.475       0.061\n",
      "topic_1                      -0.2457      0.374     -0.657      0.511      -0.979       0.487\n",
      "topic_2                       0.2762      0.370      0.746      0.455      -0.449       1.001\n",
      "topic_3                      -0.2249      0.379     -0.593      0.553      -0.968       0.518\n",
      "topic_4                      -0.2802      0.377     -0.744      0.457      -1.018       0.458\n",
      "topic_6                      -1.1269      0.430     -2.623      0.009      -1.969      -0.285\n",
      "topic_7                       0.2311      0.375      0.616      0.538      -0.504       0.967\n",
      "topic_8                      -0.7588      0.405     -1.875      0.061      -1.552       0.034\n",
      "topic_10                     -0.5834      0.403     -1.448      0.148      -1.373       0.206\n",
      "topic_14                     -0.8347      0.415     -2.011      0.044      -1.648      -0.021\n",
      "topic_15                     -1.4704      0.462     -3.181      0.001      -2.377      -0.564\n",
      "topic_29                     -1.4701      0.463     -3.177      0.001      -2.377      -0.563\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6698707545835101\n",
      "Pr√§zision: 0.5757575757575758\n",
      "Recall: 0.16033755274261605\n",
      "F1-Score: 0.2508250825082508\n",
      "Brier-Score: 0.20007622884099102\n",
      "Confusion-Matrix:\n",
      "[[479  28]\n",
      " [199  38]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.575631\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  732\n",
      "Model:                          Logit   Df Residuals:                      714\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07831\n",
      "Time:                        11:17:13   Log-Likelihood:                -421.36\n",
      "converged:                       True   LL-Null:                       -457.16\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.140e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.8969      0.688      1.303      0.193      -0.452       2.246\n",
      "issue attention Facebook      1.3349      1.291      1.034      0.301      -1.195       3.865\n",
      "issue attention Bundestag    -0.1888      0.746     -0.253      0.800      -1.652       1.274\n",
      "Social Media Nutzung         -0.0576      0.028     -2.057      0.040      -0.112      -0.003\n",
      "Landtagswahlen               -0.2099      0.220     -0.953      0.341      -0.642       0.222\n",
      "Komplexit√§t Reden            -0.3219      0.095     -3.404      0.001      -0.507      -0.137\n",
      "Komplexit√§t Posts             0.2032      0.137      1.483      0.138      -0.065       0.472\n",
      "topic_1                      -0.2374      0.381     -0.623      0.533      -0.984       0.509\n",
      "topic_2                       0.4058      0.376      1.079      0.281      -0.332       1.143\n",
      "topic_3                      -0.3076      0.388     -0.792      0.428      -1.069       0.453\n",
      "topic_4                      -0.2832      0.384     -0.738      0.461      -1.036       0.469\n",
      "topic_6                      -1.0307      0.434     -2.373      0.018      -1.882      -0.179\n",
      "topic_7                       0.3661      0.381      0.960      0.337      -0.381       1.113\n",
      "topic_8                      -0.6523      0.410     -1.592      0.111      -1.455       0.151\n",
      "topic_10                     -0.4666      0.409     -1.142      0.254      -1.268       0.334\n",
      "topic_14                     -0.8166      0.425     -1.921      0.055      -1.650       0.017\n",
      "topic_15                     -1.5173      0.481     -3.157      0.002      -2.459      -0.575\n",
      "topic_29                     -1.3743      0.467     -2.945      0.003      -2.289      -0.460\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6908362068965517\n",
      "Pr√§zision: 0.5483870967741935\n",
      "Recall: 0.21982758620689655\n",
      "F1-Score: 0.31384615384615383\n",
      "Brier-Score: 0.19589555408078352\n",
      "Confusion-Matrix:\n",
      "[[458  42]\n",
      " [181  51]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579910\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  720\n",
      "Model:                          Logit   Df Residuals:                      702\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07583\n",
      "Time:                        11:17:13   Log-Likelihood:                -417.54\n",
      "converged:                       True   LL-Null:                       -451.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.866e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.5084      0.703     -2.146      0.032      -2.886      -0.131\n",
      "issue attention Facebook      3.0495      1.328      2.297      0.022       0.447       5.652\n",
      "issue attention Bundestag     0.0511      0.752      0.068      0.946      -1.423       1.525\n",
      "Social Media Nutzung          0.0413      0.028      1.466      0.143      -0.014       0.097\n",
      "Landtagswahlen               -0.0805      0.219     -0.367      0.714      -0.511       0.350\n",
      "Komplexit√§t Reden             0.1975      0.086      2.294      0.022       0.029       0.366\n",
      "Komplexit√§t Posts            -0.0691      0.138     -0.500      0.617      -0.340       0.202\n",
      "topic_1                      -0.1722      0.383     -0.450      0.653      -0.922       0.578\n",
      "topic_2                       0.4773      0.380      1.257      0.209      -0.267       1.222\n",
      "topic_3                      -0.5105      0.396     -1.290      0.197      -1.286       0.265\n",
      "topic_4                      -0.3620      0.387     -0.935      0.350      -1.121       0.397\n",
      "topic_6                      -0.8662      0.436     -1.989      0.047      -1.720      -0.013\n",
      "topic_7                       0.4921      0.384      1.282      0.200      -0.261       1.245\n",
      "topic_8                      -0.4990      0.411     -1.214      0.225      -1.304       0.306\n",
      "topic_10                     -0.2778      0.411     -0.676      0.499      -1.083       0.527\n",
      "topic_14                     -0.6281      0.427     -1.471      0.141      -1.465       0.209\n",
      "topic_15                     -1.3311      0.482     -2.761      0.006      -2.276      -0.386\n",
      "topic_29                     -1.1894      0.468     -2.540      0.011      -2.107      -0.271\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6871696810347117\n",
      "Pr√§zision: 0.5340909090909091\n",
      "Recall: 0.20346320346320346\n",
      "F1-Score: 0.2946708463949843\n",
      "Brier-Score: 0.19797687441260794\n",
      "Confusion-Matrix:\n",
      "[[448  41]\n",
      " [184  47]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.590023\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  708\n",
      "Model:                          Logit   Df Residuals:                      690\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.06106\n",
      "Time:                        11:17:14   Log-Likelihood:                -417.74\n",
      "converged:                       True   LL-Null:                       -444.90\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.767e-06\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3200      0.697     -0.459      0.646      -1.686       1.046\n",
      "issue attention Facebook      0.0347      1.321      0.026      0.979      -2.553       2.623\n",
      "issue attention Bundestag     0.7310      0.740      0.988      0.323      -0.719       2.181\n",
      "Social Media Nutzung         -0.0027      0.028     -0.096      0.924      -0.058       0.052\n",
      "Landtagswahlen               -0.0118      0.217     -0.054      0.957      -0.437       0.414\n",
      "Komplexit√§t Reden             0.0261      0.087      0.299      0.765      -0.145       0.198\n",
      "Komplexit√§t Posts            -0.0421      0.138     -0.305      0.760      -0.312       0.228\n",
      "topic_1                      -0.1819      0.381     -0.478      0.633      -0.928       0.564\n",
      "topic_2                       0.3987      0.377      1.058      0.290      -0.340       1.138\n",
      "topic_3                      -0.1982      0.392     -0.505      0.613      -0.967       0.570\n",
      "topic_4                      -0.1105      0.384     -0.288      0.774      -0.864       0.643\n",
      "topic_6                      -1.1139      0.441     -2.526      0.012      -1.978      -0.250\n",
      "topic_7                       0.3530      0.382      0.924      0.356      -0.396       1.102\n",
      "topic_8                      -0.6462      0.409     -1.581      0.114      -1.447       0.155\n",
      "topic_10                     -0.5447      0.412     -1.323      0.186      -1.351       0.262\n",
      "topic_14                     -0.8090      0.424     -1.908      0.056      -1.640       0.022\n",
      "topic_15                     -1.4843      0.480     -3.095      0.002      -2.424      -0.544\n",
      "topic_29                     -1.3485      0.466     -2.896      0.004      -2.261      -0.436\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6687408625730994\n",
      "Pr√§zision: 0.5641025641025641\n",
      "Recall: 0.19298245614035087\n",
      "F1-Score: 0.2875816993464052\n",
      "Brier-Score: 0.20181352574823772\n",
      "Confusion-Matrix:\n",
      "[[446  34]\n",
      " [184  44]]\n"
     ]
    }
   ],
   "source": [
    "models_afd_complex = []\n",
    "metrics_afd_complex = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model_afd, auc_roc_afd, f1_afd = log_reg_FE_control_test(rede_reduced_afd,post_reduced_afd, rede_common_afd,lag,social_media_usage_afd, rede_komplex_afd, posts_komplex_afd)\n",
    "    models_afd_complex.append(model_afd)\n",
    "    metrics_afd_complex.append((auc_roc_afd, f1_afd))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models_afd_complex)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - AfD\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes_afd = [f\"Lag {i}: AUC-ROC = {metrics_afd_complex[i-1][0]:.3f}, F1-Score = {metrics_afd_complex[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes_afd)\n",
    "\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_afd_complex_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 68, 69, 70, 75, 77, 78, 79, 80, 83, 84, 90, 91, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 4, 6, 7, 8, 15, 19, 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\3605860070.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_spd[\"date\"] = pd.to_datetime(subset_reden_spd[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\3605860070.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_afd[\"date\"] = pd.to_datetime(subset_posts_spd[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_spd = subset_posts[subset_posts[\"partei\"] == \"SPD\"]\n",
    "subset_reden_spd = subset_reden[subset_reden[\"partei\"] == \"SPD\"]\n",
    "social_media_usage_spd = subset_posts_spd.groupby('date').size()\n",
    "subset_reden_spd[\"date\"] = pd.to_datetime(subset_reden_spd[\"date\"])\n",
    "subset_posts_afd[\"date\"] = pd.to_datetime(subset_posts_spd[\"date\"])\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_spd = subset_reden_spd.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_spd = subset_posts_spd.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "reden_komplexit√§t_t√§glich_spd = subset_reden_spd.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_spd = subset_posts_spd.groupby('date')['komplexit√§t'].sum()\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_spd = redethemen_t√§glich_spd.index.intersection(postthemen_t√§glich_spd.index)\n",
    "redethemen_t√§glich_aligned_spd = redethemen_t√§glich_spd.loc[common_dates_spd]\n",
    "postthemen_t√§glich_aligned_spd = postthemen_t√§glich_spd.loc[common_dates_spd]\n",
    "rede_common_spd, post_common_spd = filter_common_topics(redethemen_t√§glich_aligned_spd, postthemen_t√§glich_aligned_spd)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_spd =  rede_common_spd.div(rede_common_spd.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_spd = post_common_spd.div(post_common_spd.sum(axis=1), axis=0)\n",
    "reden_relativ_spd_red = remove_near_constant(reden_relativ_spd)\n",
    "post_relativ_spd_red = remove_near_constant(post_relativ_spd)\n",
    "rede_reduced_spd, post_reduced_spd = filter_common_topics(reden_relativ_spd_red, post_relativ_spd_red)\n",
    "rede_komplex_spd = reden_komplexit√§t_t√§glich_spd.loc[common_dates_spd]\n",
    "posts_komplex_spd = posts_komplexit√§t_t√§glich_spd.loc[common_dates_spd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.583381\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  640\n",
      "Model:                          Logit   Df Residuals:                      626\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1003\n",
      "Time:                        11:17:14   Log-Likelihood:                -373.36\n",
      "converged:                       True   LL-Null:                       -414.98\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.706e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2440      0.325     -0.750      0.453      -0.881       0.393\n",
      "issue attention Facebook      0.2888      0.956      0.302      0.763      -1.585       2.162\n",
      "issue attention Bundestag     1.1729      0.964      1.216      0.224      -0.717       3.063\n",
      "Social Media Nutzung         -0.0035      0.022     -0.159      0.874      -0.047       0.040\n",
      "Landtagswahlen                0.1418      0.161      0.878      0.380      -0.175       0.458\n",
      "topic_1                       0.2498      0.358      0.698      0.485      -0.452       0.951\n",
      "topic_2                       0.6640      0.365      1.819      0.069      -0.051       1.379\n",
      "topic_4                      -1.0851      0.397     -2.734      0.006      -1.863      -0.307\n",
      "topic_6                      -0.4787      0.368     -1.302      0.193      -1.199       0.242\n",
      "topic_7                       0.1804      0.359      0.503      0.615      -0.523       0.883\n",
      "topic_8                      -0.6296      0.371     -1.698      0.090      -1.357       0.097\n",
      "topic_15                     -1.7427      0.458     -3.803      0.000      -2.641      -0.845\n",
      "topic_19                     -1.0634      0.399     -2.665      0.008      -1.845      -0.281\n",
      "topic_24                     -1.4786      0.432     -3.424      0.001      -2.325      -0.632\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.712578313253012\n",
      "Pr√§zision: 0.6137931034482759\n",
      "Recall: 0.39555555555555555\n",
      "F1-Score: 0.4810810810810811\n",
      "Brier-Score: 0.19915395577605016\n",
      "Confusion-Matrix:\n",
      "[[359  56]\n",
      " [136  89]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x22404cf0950>,\n",
       " 0.712578313253012,\n",
       " 0.4810810810810811)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_FE_control(rede_reduced_spd,post_reduced_spd, rede_common_spd,1, social_media_usage_spd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.583381\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  640\n",
      "Model:                          Logit   Df Residuals:                      626\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1003\n",
      "Time:                        11:17:14   Log-Likelihood:                -373.36\n",
      "converged:                       True   LL-Null:                       -414.98\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.706e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2440      0.325     -0.750      0.453      -0.881       0.393\n",
      "issue attention Facebook      0.2888      0.956      0.302      0.763      -1.585       2.162\n",
      "issue attention Bundestag     1.1729      0.964      1.216      0.224      -0.717       3.063\n",
      "Social Media Nutzung         -0.0035      0.022     -0.159      0.874      -0.047       0.040\n",
      "Landtagswahlen                0.1418      0.161      0.878      0.380      -0.175       0.458\n",
      "topic_1                       0.2498      0.358      0.698      0.485      -0.452       0.951\n",
      "topic_2                       0.6640      0.365      1.819      0.069      -0.051       1.379\n",
      "topic_4                      -1.0851      0.397     -2.734      0.006      -1.863      -0.307\n",
      "topic_6                      -0.4787      0.368     -1.302      0.193      -1.199       0.242\n",
      "topic_7                       0.1804      0.359      0.503      0.615      -0.523       0.883\n",
      "topic_8                      -0.6296      0.371     -1.698      0.090      -1.357       0.097\n",
      "topic_15                     -1.7427      0.458     -3.803      0.000      -2.641      -0.845\n",
      "topic_19                     -1.0634      0.399     -2.665      0.008      -1.845      -0.281\n",
      "topic_24                     -1.4786      0.432     -3.424      0.001      -2.325      -0.632\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.712578313253012\n",
      "Pr√§zision: 0.6137931034482759\n",
      "Recall: 0.39555555555555555\n",
      "F1-Score: 0.4810810810810811\n",
      "Brier-Score: 0.19915395577605016\n",
      "Confusion-Matrix:\n",
      "[[359  56]\n",
      " [136  89]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580826\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  630\n",
      "Model:                          Logit   Df Residuals:                      616\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1049\n",
      "Time:                        11:17:14   Log-Likelihood:                -365.92\n",
      "converged:                       True   LL-Null:                       -408.81\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.895e-13\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0642      0.334     -0.192      0.848      -0.719       0.591\n",
      "issue attention Facebook      0.1141      0.967      0.118      0.906      -1.781       2.009\n",
      "issue attention Bundestag     2.5066      1.032      2.429      0.015       0.484       4.529\n",
      "Social Media Nutzung         -0.0336      0.023     -1.468      0.142      -0.078       0.011\n",
      "Landtagswahlen               -0.1092      0.182     -0.599      0.549      -0.466       0.248\n",
      "topic_1                       0.2759      0.364      0.758      0.448      -0.437       0.989\n",
      "topic_2                       0.6509      0.370      1.758      0.079      -0.075       1.377\n",
      "topic_4                      -0.9617      0.401     -2.397      0.017      -1.748      -0.176\n",
      "topic_6                      -0.3615      0.372     -0.971      0.332      -1.091       0.368\n",
      "topic_7                       0.2871      0.365      0.788      0.431      -0.427       1.002\n",
      "topic_8                      -0.5590      0.377     -1.482      0.138      -1.298       0.180\n",
      "topic_15                     -1.6186      0.462     -3.504      0.000      -2.524      -0.713\n",
      "topic_19                     -0.9301      0.404     -2.305      0.021      -1.721      -0.139\n",
      "topic_24                     -1.3542      0.436     -3.106      0.002      -2.209      -0.500\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7144111022787494\n",
      "Pr√§zision: 0.5753424657534246\n",
      "Recall: 0.3783783783783784\n",
      "F1-Score: 0.45652173913043476\n",
      "Brier-Score: 0.19851119032190806\n",
      "Confusion-Matrix:\n",
      "[[346  62]\n",
      " [138  84]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588062\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  620\n",
      "Model:                          Logit   Df Residuals:                      606\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09716\n",
      "Time:                        11:17:14   Log-Likelihood:                -364.60\n",
      "converged:                       True   LL-Null:                       -403.84\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.132e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4434      0.329     -1.347      0.178      -1.088       0.202\n",
      "issue attention Facebook      0.3559      0.974      0.365      0.715      -1.553       2.264\n",
      "issue attention Bundestag     0.1911      0.972      0.197      0.844      -1.715       2.097\n",
      "Social Media Nutzung          0.0333      0.022      1.517      0.129      -0.010       0.076\n",
      "Landtagswahlen                0.0385      0.196      0.197      0.844      -0.345       0.422\n",
      "topic_1                       0.1816      0.363      0.500      0.617      -0.530       0.893\n",
      "topic_2                       0.7297      0.371      1.968      0.049       0.003       1.456\n",
      "topic_4                      -1.0941      0.401     -2.729      0.006      -1.880      -0.308\n",
      "topic_6                      -0.4696      0.372     -1.263      0.207      -1.198       0.259\n",
      "topic_7                       0.2178      0.365      0.597      0.550      -0.497       0.932\n",
      "topic_8                      -0.5975      0.375     -1.592      0.111      -1.333       0.138\n",
      "topic_15                     -1.7644      0.462     -3.822      0.000      -2.669      -0.860\n",
      "topic_19                     -1.0828      0.403     -2.686      0.007      -1.873      -0.293\n",
      "topic_24                     -1.4975      0.436     -3.438      0.001      -2.351      -0.644\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7084169700268772\n",
      "Pr√§zision: 0.5637583892617449\n",
      "Recall: 0.38009049773755654\n",
      "F1-Score: 0.4540540540540541\n",
      "Brier-Score: 0.20112965731993787\n",
      "Confusion-Matrix:\n",
      "[[334  65]\n",
      " [137  84]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591486\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  610\n",
      "Model:                          Logit   Df Residuals:                      596\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09399\n",
      "Time:                        11:17:14   Log-Likelihood:                -360.81\n",
      "converged:                       True   LL-Null:                       -398.24\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.009e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1086      0.339     -0.320      0.749      -0.773       0.556\n",
      "issue attention Facebook     -0.2832      0.980     -0.289      0.773      -2.204       1.638\n",
      "issue attention Bundestag     0.2471      0.993      0.249      0.803      -1.699       2.193\n",
      "Social Media Nutzung          0.0048      0.023      0.208      0.836      -0.041       0.050\n",
      "Landtagswahlen               -0.1568      0.232     -0.676      0.499      -0.611       0.298\n",
      "topic_1                       0.1467      0.365      0.402      0.688      -0.569       0.863\n",
      "topic_2                       0.7322      0.374      1.960      0.050   -4.35e-05       1.464\n",
      "topic_4                      -1.1010      0.402     -2.736      0.006      -1.890      -0.312\n",
      "topic_6                      -0.4579      0.373     -1.226      0.220      -1.190       0.274\n",
      "topic_7                       0.1273      0.367      0.347      0.729      -0.591       0.846\n",
      "topic_8                      -0.6257      0.377     -1.660      0.097      -1.364       0.113\n",
      "topic_15                     -1.7872      0.463     -3.861      0.000      -2.694      -0.880\n",
      "topic_19                     -1.1075      0.405     -2.736      0.006      -1.901      -0.314\n",
      "topic_24                     -1.5294      0.437     -3.500      0.000      -2.386      -0.673\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7007380677107056\n",
      "Pr√§zision: 0.5512820512820513\n",
      "Recall: 0.3926940639269406\n",
      "F1-Score: 0.45866666666666667\n",
      "Brier-Score: 0.2029421109280378\n",
      "Confusion-Matrix:\n",
      "[[321  70]\n",
      " [133  86]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.587641\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  600\n",
      "Model:                          Logit   Df Residuals:                      586\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09799\n",
      "Time:                        11:17:14   Log-Likelihood:                -352.58\n",
      "converged:                       True   LL-Null:                       -390.89\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.784e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3254      0.344     -0.947      0.344      -0.999       0.348\n",
      "issue attention Facebook      0.2887      0.978      0.295      0.768      -1.628       2.206\n",
      "issue attention Bundestag    -0.0990      1.046     -0.095      0.925      -2.149       1.951\n",
      "Social Media Nutzung          0.0268      0.023      1.157      0.247      -0.019       0.072\n",
      "Landtagswahlen               -0.1550      0.234     -0.664      0.507      -0.613       0.303\n",
      "topic_1                       0.1210      0.369      0.328      0.743      -0.602       0.844\n",
      "topic_2                       0.7634      0.376      2.028      0.043       0.026       1.501\n",
      "topic_4                      -1.1602      0.412     -2.817      0.005      -1.967      -0.353\n",
      "topic_6                      -0.4253      0.377     -1.128      0.259      -1.164       0.314\n",
      "topic_7                       0.2110      0.371      0.569      0.569      -0.516       0.938\n",
      "topic_8                      -0.5528      0.380     -1.454      0.146      -1.298       0.192\n",
      "topic_15                     -1.8942      0.484     -3.914      0.000      -2.843      -0.946\n",
      "topic_19                     -1.0564      0.408     -2.589      0.010      -1.856      -0.257\n",
      "topic_24                     -1.4741      0.440     -3.349      0.001      -2.337      -0.612\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.71054670476006\n",
      "Pr√§zision: 0.5797101449275363\n",
      "Recall: 0.37383177570093457\n",
      "F1-Score: 0.45454545454545453\n",
      "Brier-Score: 0.20132966146973955\n",
      "Confusion-Matrix:\n",
      "[[328  58]\n",
      " [134  80]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588513\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  590\n",
      "Model:                          Logit   Df Residuals:                      576\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09879\n",
      "Time:                        11:17:14   Log-Likelihood:                -347.22\n",
      "converged:                       True   LL-Null:                       -385.29\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.870e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1310      0.346     -0.379      0.705      -0.808       0.546\n",
      "issue attention Facebook      0.3885      0.973      0.399      0.690      -1.519       2.296\n",
      "issue attention Bundestag     0.0089      1.051      0.009      0.993      -2.052       2.069\n",
      "Social Media Nutzung          0.0046      0.023      0.196      0.845      -0.041       0.050\n",
      "Landtagswahlen               -0.1528      0.233     -0.656      0.512      -0.610       0.304\n",
      "topic_1                       0.1198      0.372      0.322      0.747      -0.609       0.848\n",
      "topic_2                       0.7787      0.380      2.048      0.041       0.034       1.524\n",
      "topic_4                      -1.1617      0.413     -2.810      0.005      -1.972      -0.352\n",
      "topic_6                      -0.5001      0.381     -1.313      0.189      -1.247       0.246\n",
      "topic_7                       0.2226      0.374      0.596      0.551      -0.510       0.955\n",
      "topic_8                      -0.6283      0.384     -1.635      0.102      -1.381       0.125\n",
      "topic_15                     -1.8930      0.485     -3.902      0.000      -2.844      -0.942\n",
      "topic_19                     -1.0529      0.410     -2.571      0.010      -1.856      -0.250\n",
      "topic_24                     -1.4705      0.441     -3.332      0.001      -2.336      -0.605\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.706848357791754\n",
      "Pr√§zision: 0.5443037974683544\n",
      "Recall: 0.4056603773584906\n",
      "F1-Score: 0.4648648648648649\n",
      "Brier-Score: 0.20185593235161384\n",
      "Confusion-Matrix:\n",
      "[[306  72]\n",
      " [126  86]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588905\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  580\n",
      "Model:                          Logit   Df Residuals:                      566\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1004\n",
      "Time:                        11:17:14   Log-Likelihood:                -341.56\n",
      "converged:                       True   LL-Null:                       -379.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.673e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2250      0.347     -0.648      0.517      -0.906       0.456\n",
      "issue attention Facebook      0.6404      0.974      0.658      0.511      -1.268       2.549\n",
      "issue attention Bundestag    -0.4559      1.063     -0.429      0.668      -2.539       1.627\n",
      "Social Media Nutzung          0.0107      0.023      0.455      0.649      -0.035       0.057\n",
      "Landtagswahlen                0.0020      0.231      0.009      0.993      -0.451       0.455\n",
      "topic_1                       0.1736      0.375      0.463      0.643      -0.562       0.909\n",
      "topic_2                       0.8783      0.386      2.278      0.023       0.122       1.634\n",
      "topic_4                      -1.1298      0.416     -2.719      0.007      -1.944      -0.315\n",
      "topic_6                      -0.5387      0.386     -1.397      0.163      -1.295       0.217\n",
      "topic_7                       0.2905      0.377      0.770      0.441      -0.449       1.030\n",
      "topic_8                      -0.5670      0.387     -1.465      0.143      -1.326       0.192\n",
      "topic_15                     -1.8587      0.487     -3.817      0.000      -2.813      -0.904\n",
      "topic_19                     -1.0166      0.412     -2.468      0.014      -1.824      -0.209\n",
      "topic_24                     -1.4309      0.443     -3.228      0.001      -2.300      -0.562\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7106177606177606\n",
      "Pr√§zision: 0.5732484076433121\n",
      "Recall: 0.42857142857142855\n",
      "F1-Score: 0.4904632152588556\n",
      "Brier-Score: 0.20176879273767212\n",
      "Confusion-Matrix:\n",
      "[[303  67]\n",
      " [120  90]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_spd, post_reduced_spd, rede_common_spd,lag, social_media_usage_spd)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - SPD\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_spd_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582413\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  640\n",
      "Model:                          Logit   Df Residuals:                      624\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1018\n",
      "Time:                        11:17:14   Log-Likelihood:                -372.74\n",
      "converged:                       True   LL-Null:                       -414.98\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.052e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0259      0.477     -0.054      0.957      -0.961       0.909\n",
      "issue attention Facebook      0.3114      0.961      0.324      0.746      -1.573       2.196\n",
      "issue attention Bundestag     1.2459      0.972      1.282      0.200      -0.659       3.151\n",
      "Social Media Nutzung         -0.0304      0.048     -0.637      0.524      -0.124       0.063\n",
      "Landtagswahlen                0.1182      0.163      0.724      0.469      -0.202       0.438\n",
      "Komplexit√§t Reden            -0.0858      0.091     -0.946      0.344      -0.264       0.092\n",
      "Komplexit√§t Posts             0.1137      0.194      0.585      0.558      -0.267       0.495\n",
      "topic_1                       0.2500      0.358      0.698      0.485      -0.452       0.952\n",
      "topic_2                       0.6639      0.365      1.818      0.069      -0.052       1.380\n",
      "topic_4                      -1.0838      0.397     -2.728      0.006      -1.862      -0.305\n",
      "topic_6                      -0.4775      0.368     -1.298      0.194      -1.199       0.244\n",
      "topic_7                       0.1841      0.359      0.513      0.608      -0.520       0.888\n",
      "topic_8                      -0.6290      0.371     -1.694      0.090      -1.357       0.099\n",
      "topic_15                     -1.7403      0.459     -3.795      0.000      -2.639      -0.841\n",
      "topic_19                     -1.0605      0.399     -2.655      0.008      -1.843      -0.278\n",
      "topic_24                     -1.4761      0.432     -3.415      0.001      -2.323      -0.629\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7129210174029451\n",
      "Pr√§zision: 0.6038961038961039\n",
      "Recall: 0.41333333333333333\n",
      "F1-Score: 0.49076517150395776\n",
      "Brier-Score: 0.19875392536466302\n",
      "Confusion-Matrix:\n",
      "[[354  61]\n",
      " [132  93]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579805\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  630\n",
      "Model:                          Logit   Df Residuals:                      614\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1065\n",
      "Time:                        11:17:14   Log-Likelihood:                -365.28\n",
      "converged:                       True   LL-Null:                       -408.81\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.481e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0557      0.506     -0.110      0.912      -1.048       0.936\n",
      "issue attention Facebook      0.1751      0.972      0.180      0.857      -1.730       2.080\n",
      "issue attention Bundestag     2.5772      1.039      2.480      0.013       0.541       4.614\n",
      "Social Media Nutzung         -0.0352      0.053     -0.661      0.509      -0.139       0.069\n",
      "Landtagswahlen               -0.1264      0.185     -0.684      0.494      -0.489       0.236\n",
      "Komplexit√§t Reden            -0.1045      0.092     -1.132      0.258      -0.285       0.076\n",
      "Komplexit√§t Posts            -0.0026      0.216     -0.012      0.990      -0.426       0.421\n",
      "topic_1                       0.2738      0.364      0.752      0.452      -0.439       0.987\n",
      "topic_2                       0.6522      0.371      1.760      0.078      -0.074       1.379\n",
      "topic_4                      -0.9604      0.401     -2.393      0.017      -1.747      -0.174\n",
      "topic_6                      -0.3619      0.373     -0.971      0.332      -1.093       0.369\n",
      "topic_7                       0.2926      0.365      0.802      0.422      -0.422       1.008\n",
      "topic_8                      -0.5581      0.378     -1.478      0.139      -1.298       0.182\n",
      "topic_15                     -1.6146      0.462     -3.494      0.000      -2.520      -0.709\n",
      "topic_19                     -0.9262      0.404     -2.294      0.022      -1.718      -0.135\n",
      "topic_24                     -1.3500      0.436     -3.094      0.002      -2.205      -0.495\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7166247129482424\n",
      "Pr√§zision: 0.5862068965517241\n",
      "Recall: 0.38288288288288286\n",
      "F1-Score: 0.46321525885558584\n",
      "Brier-Score: 0.1980803314719624\n",
      "Confusion-Matrix:\n",
      "[[348  60]\n",
      " [137  85]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.586611\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  620\n",
      "Model:                          Logit   Df Residuals:                      604\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09939\n",
      "Time:                        11:17:15   Log-Likelihood:                -363.70\n",
      "converged:                       True   LL-Null:                       -403.84\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.219e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2245      0.501     -0.448      0.654      -1.206       0.757\n",
      "issue attention Facebook      0.2737      0.977      0.280      0.779      -1.641       2.188\n",
      "issue attention Bundestag     0.1365      0.974      0.140      0.889      -1.773       2.046\n",
      "Social Media Nutzung          0.0055      0.052      0.106      0.916      -0.097       0.108\n",
      "Landtagswahlen                0.1005      0.202      0.498      0.618      -0.295       0.496\n",
      "Komplexit√§t Reden             0.1093      0.092      1.184      0.237      -0.072       0.290\n",
      "Komplexit√§t Posts             0.1364      0.214      0.639      0.523      -0.282       0.555\n",
      "topic_1                       0.1852      0.364      0.509      0.611      -0.528       0.898\n",
      "topic_2                       0.7327      0.371      1.972      0.049       0.005       1.461\n",
      "topic_4                      -1.1009      0.402     -2.741      0.006      -1.888      -0.314\n",
      "topic_6                      -0.4719      0.373     -1.267      0.205      -1.202       0.258\n",
      "topic_7                       0.2128      0.365      0.583      0.560      -0.503       0.929\n",
      "topic_8                      -0.6040      0.376     -1.606      0.108      -1.341       0.133\n",
      "topic_15                     -1.7754      0.462     -3.841      0.000      -2.681      -0.870\n",
      "topic_19                     -1.0928      0.404     -2.707      0.007      -1.884      -0.302\n",
      "topic_24                     -1.5093      0.436     -3.460      0.001      -2.364      -0.654\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7115866589550799\n",
      "Pr√§zision: 0.6013071895424836\n",
      "Recall: 0.416289592760181\n",
      "F1-Score: 0.4919786096256685\n",
      "Brier-Score: 0.2003850673009821\n",
      "Confusion-Matrix:\n",
      "[[338  61]\n",
      " [129  92]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.590745\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  610\n",
      "Model:                          Logit   Df Residuals:                      594\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09513\n",
      "Time:                        11:17:15   Log-Likelihood:                -360.35\n",
      "converged:                       True   LL-Null:                       -398.24\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.113e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4359      0.499     -0.874      0.382      -1.414       0.542\n",
      "issue attention Facebook     -0.2691      0.982     -0.274      0.784      -2.194       1.656\n",
      "issue attention Bundestag     0.1991      0.997      0.200      0.842      -1.755       2.153\n",
      "Social Media Nutzung          0.0470      0.052      0.897      0.370      -0.056       0.150\n",
      "Landtagswahlen               -0.1816      0.236     -0.770      0.441      -0.644       0.281\n",
      "Komplexit√§t Reden             0.0308      0.092      0.336      0.737      -0.149       0.211\n",
      "Komplexit√§t Posts            -0.1862      0.209     -0.891      0.373      -0.596       0.223\n",
      "topic_1                       0.1457      0.366      0.398      0.690      -0.571       0.863\n",
      "topic_2                       0.7350      0.374      1.966      0.049       0.002       1.468\n",
      "topic_4                      -1.1054      0.403     -2.744      0.006      -1.895      -0.316\n",
      "topic_6                      -0.4611      0.374     -1.234      0.217      -1.194       0.271\n",
      "topic_7                       0.1264      0.367      0.344      0.731      -0.593       0.846\n",
      "topic_8                      -0.6274      0.377     -1.663      0.096      -1.367       0.112\n",
      "topic_15                     -1.7923      0.463     -3.869      0.000      -2.700      -0.884\n",
      "topic_19                     -1.1120      0.405     -2.744      0.006      -1.906      -0.318\n",
      "topic_24                     -1.5341      0.437     -3.507      0.000      -2.391      -0.677\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7048313071506148\n",
      "Pr√§zision: 0.5666666666666667\n",
      "Recall: 0.3881278538812785\n",
      "F1-Score: 0.46070460704607047\n",
      "Brier-Score: 0.20263230342092783\n",
      "Confusion-Matrix:\n",
      "[[326  65]\n",
      " [134  85]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.577848\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  600\n",
      "Model:                          Logit   Df Residuals:                      584\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1130\n",
      "Time:                        11:17:15   Log-Likelihood:                -346.71\n",
      "converged:                       True   LL-Null:                       -390.89\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.010e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.1376      0.511     -2.228      0.026      -2.139      -0.137\n",
      "issue attention Facebook      0.5247      0.992      0.529      0.597      -1.420       2.469\n",
      "issue attention Bundestag     0.0141      1.067      0.013      0.989      -2.076       2.104\n",
      "Social Media Nutzung          0.1295      0.053      2.424      0.015       0.025       0.234\n",
      "Landtagswahlen               -0.2946      0.239     -1.230      0.219      -0.764       0.175\n",
      "Komplexit√§t Reden            -0.2438      0.095     -2.575      0.010      -0.429      -0.058\n",
      "Komplexit√§t Posts            -0.4736      0.215     -2.199      0.028      -0.896      -0.051\n",
      "topic_1                       0.1163      0.373      0.311      0.756      -0.616       0.848\n",
      "topic_2                       0.7847      0.381      2.060      0.039       0.038       1.531\n",
      "topic_4                      -1.1797      0.416     -2.833      0.005      -1.996      -0.364\n",
      "topic_6                      -0.4354      0.381     -1.142      0.253      -1.182       0.312\n",
      "topic_7                       0.2306      0.375      0.615      0.539      -0.505       0.966\n",
      "topic_8                      -0.5542      0.384     -1.442      0.149      -1.307       0.199\n",
      "topic_15                     -1.9141      0.488     -3.921      0.000      -2.871      -0.957\n",
      "topic_19                     -1.0632      0.412     -2.577      0.010      -1.872      -0.255\n",
      "topic_24                     -1.4855      0.445     -3.342      0.001      -2.357      -0.614\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.724153794005133\n",
      "Pr√§zision: 0.5986394557823129\n",
      "Recall: 0.411214953271028\n",
      "F1-Score: 0.48753462603878117\n",
      "Brier-Score: 0.19718579177216736\n",
      "Confusion-Matrix:\n",
      "[[327  59]\n",
      " [126  88]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581410\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  590\n",
      "Model:                          Logit   Df Residuals:                      574\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1097\n",
      "Time:                        11:17:15   Log-Likelihood:                -343.03\n",
      "converged:                       True   LL-Null:                       -385.29\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.037e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.1251      0.515     -2.187      0.029      -2.134      -0.117\n",
      "issue attention Facebook      0.4270      0.980      0.436      0.663      -1.494       2.348\n",
      "issue attention Bundestag    -0.1543      1.065     -0.145      0.885      -2.242       1.934\n",
      "Social Media Nutzung          0.1337      0.054      2.463      0.014       0.027       0.240\n",
      "Landtagswahlen               -0.2284      0.238     -0.959      0.337      -0.695       0.238\n",
      "Komplexit√§t Reden             0.1085      0.094      1.150      0.250      -0.076       0.293\n",
      "Komplexit√§t Posts            -0.5742      0.220     -2.605      0.009      -1.006      -0.142\n",
      "topic_1                       0.1183      0.375      0.316      0.752      -0.616       0.853\n",
      "topic_2                       0.7960      0.384      2.074      0.038       0.044       1.548\n",
      "topic_4                      -1.1897      0.417     -2.854      0.004      -2.007      -0.373\n",
      "topic_6                      -0.5171      0.384     -1.346      0.178      -1.270       0.236\n",
      "topic_7                       0.2218      0.377      0.588      0.556      -0.517       0.961\n",
      "topic_8                      -0.6409      0.388     -1.654      0.098      -1.400       0.119\n",
      "topic_15                     -1.9273      0.488     -3.949      0.000      -2.884      -0.971\n",
      "topic_19                     -1.0795      0.413     -2.614      0.009      -1.889      -0.270\n",
      "topic_24                     -1.5009      0.445     -3.375      0.001      -2.373      -0.629\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7246306279325148\n",
      "Pr√§zision: 0.6089743589743589\n",
      "Recall: 0.4481132075471698\n",
      "F1-Score: 0.5163043478260869\n",
      "Brier-Score: 0.19834214225311944\n",
      "Confusion-Matrix:\n",
      "[[317  61]\n",
      " [117  95]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.587143\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  580\n",
      "Model:                          Logit   Df Residuals:                      564\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1030\n",
      "Time:                        11:17:15   Log-Likelihood:                -340.54\n",
      "converged:                       True   LL-Null:                       -379.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.458e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6603      0.508     -1.300      0.193      -1.655       0.335\n",
      "issue attention Facebook      0.6242      0.977      0.639      0.523      -1.290       2.538\n",
      "issue attention Bundestag    -0.5505      1.069     -0.515      0.606      -2.645       1.544\n",
      "Social Media Nutzung          0.0681      0.054      1.268      0.205      -0.037       0.173\n",
      "Landtagswahlen               -0.0267      0.235     -0.114      0.910      -0.487       0.434\n",
      "Komplexit√§t Reden             0.0763      0.094      0.810      0.418      -0.108       0.261\n",
      "Komplexit√§t Posts            -0.2530      0.218     -1.162      0.245      -0.680       0.174\n",
      "topic_1                       0.1738      0.376      0.462      0.644      -0.563       0.911\n",
      "topic_2                       0.8832      0.387      2.285      0.022       0.126       1.641\n",
      "topic_4                      -1.1399      0.417     -2.737      0.006      -1.956      -0.324\n",
      "topic_6                      -0.5448      0.387     -1.409      0.159      -1.302       0.213\n",
      "topic_7                       0.2872      0.378      0.760      0.447      -0.454       1.028\n",
      "topic_8                      -0.5719      0.388     -1.475      0.140      -1.332       0.188\n",
      "topic_15                     -1.8712      0.488     -3.837      0.000      -2.827      -0.915\n",
      "topic_19                     -1.0279      0.413     -2.489      0.013      -1.837      -0.218\n",
      "topic_24                     -1.4431      0.444     -3.249      0.001      -2.314      -0.573\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7163063063063063\n",
      "Pr√§zision: 0.6\n",
      "Recall: 0.44285714285714284\n",
      "F1-Score: 0.5095890410958904\n",
      "Brier-Score: 0.20101737431329308\n",
      "Confusion-Matrix:\n",
      "[[308  62]\n",
      " [117  93]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_spd, post_reduced_spd, rede_common_spd,lag, social_media_usage_spd,rede_komplex_spd,posts_komplex_spd)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - SPD\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_spd_complex_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 52, 54, 56, 58, 68, 69, 70, 74, 75, 77, 78, 80, 83, 84, 90, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 6, 8, 10, 12, 14, 15, 20, 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\688326972.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_cdu[\"date\"] = pd.to_datetime(subset_reden_cdu[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\688326972.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_cdu[\"date\"] = pd.to_datetime(subset_posts_cdu[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_cdu = subset_posts[subset_posts[\"partei\"] == \"CDU\"]\n",
    "subset_reden_cdu = subset_reden[subset_reden[\"partei\"] == \"CDU\"]\n",
    "social_media_usage_cdu = subset_posts_cdu.groupby('date').size()\n",
    "subset_reden_cdu[\"date\"] = pd.to_datetime(subset_reden_cdu[\"date\"])\n",
    "subset_posts_cdu[\"date\"] = pd.to_datetime(subset_posts_cdu[\"date\"])\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_cdu = subset_reden_cdu.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_cdu = subset_posts_cdu.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "reden_komplexit√§t_t√§glich_cdu = subset_reden_cdu.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_cdu = subset_posts_cdu.groupby('date')['komplexit√§t'].sum()\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_cdu = redethemen_t√§glich_cdu.index.intersection(postthemen_t√§glich_cdu.index)\n",
    "redethemen_t√§glich_aligned_cdu = redethemen_t√§glich_cdu.loc[common_dates_cdu]\n",
    "postthemen_t√§glich_aligned_cdu = postthemen_t√§glich_cdu.loc[common_dates_cdu]\n",
    "rede_common_cdu, post_common_cdu = filter_common_topics(redethemen_t√§glich_aligned_cdu, postthemen_t√§glich_aligned_cdu)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_cdu =  rede_common_cdu.div(rede_common_cdu.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_cdu = post_common_cdu.div(post_common_cdu.sum(axis=1), axis=0)\n",
    "reden_relativ_cdu_red = remove_near_constant(reden_relativ_cdu)\n",
    "post_relativ_cdu_red = remove_near_constant(post_relativ_cdu)\n",
    "rede_reduced_cdu, post_reduced_cdu = filter_common_topics(reden_relativ_cdu_red, post_relativ_cdu_red)\n",
    "rede_komplex_cdu = reden_komplexit√§t_t√§glich_cdu.loc[common_dates_cdu]\n",
    "posts_komplex_cdu = posts_komplexit√§t_t√§glich_cdu.loc[common_dates_cdu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544743\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  845\n",
      "Model:                          Logit   Df Residuals:                      828\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08371\n",
      "Time:                        11:17:15   Log-Likelihood:                -460.31\n",
      "converged:                       True   LL-Null:                       -502.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.999e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4247      0.331     -1.285      0.199      -1.073       0.223\n",
      "issue attention Facebook      2.5485      0.941      2.709      0.007       0.705       4.392\n",
      "issue attention Bundestag    -1.6819      0.873     -1.927      0.054      -3.392       0.029\n",
      "Social Media Nutzung      -6.586e-05      0.013     -0.005      0.996      -0.026       0.026\n",
      "Landtagswahlen               -0.0817      0.150     -0.546      0.585      -0.375       0.211\n",
      "topic_1                       0.1928      0.360      0.536      0.592      -0.512       0.898\n",
      "topic_2                       0.5658      0.362      1.561      0.119      -0.145       1.276\n",
      "topic_3                      -0.4998      0.376     -1.330      0.183      -1.236       0.237\n",
      "topic_4                      -1.1395      0.412     -2.765      0.006      -1.947      -0.332\n",
      "topic_6                      -0.1516      0.367     -0.413      0.680      -0.872       0.568\n",
      "topic_8                      -0.8578      0.399     -2.149      0.032      -1.640      -0.075\n",
      "topic_10                      0.1750      0.361      0.485      0.628      -0.532       0.882\n",
      "topic_12                     -1.5410      0.446     -3.453      0.001      -2.416      -0.666\n",
      "topic_14                     -0.5291      0.381     -1.388      0.165      -1.276       0.218\n",
      "topic_15                     -1.5883      0.460     -3.450      0.001      -2.491      -0.686\n",
      "topic_20                     -1.6023      0.461     -3.476      0.001      -2.506      -0.699\n",
      "topic_22                     -1.3074      0.432     -3.024      0.002      -2.155      -0.460\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6960703556546177\n",
      "Pr√§zision: 0.581081081081081\n",
      "Recall: 0.18067226890756302\n",
      "F1-Score: 0.27564102564102566\n",
      "Brier-Score: 0.18261120827763117\n",
      "Confusion-Matrix:\n",
      "[[576  31]\n",
      " [195  43]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x22404e126c0>,\n",
       " 0.6960703556546177,\n",
       " 0.27564102564102566)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_FE_control(rede_reduced_cdu,post_reduced_cdu, rede_common_cdu, 1,social_media_usage_cdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544743\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  845\n",
      "Model:                          Logit   Df Residuals:                      828\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08371\n",
      "Time:                        11:17:15   Log-Likelihood:                -460.31\n",
      "converged:                       True   LL-Null:                       -502.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.999e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4247      0.331     -1.285      0.199      -1.073       0.223\n",
      "issue attention Facebook      2.5485      0.941      2.709      0.007       0.705       4.392\n",
      "issue attention Bundestag    -1.6819      0.873     -1.927      0.054      -3.392       0.029\n",
      "Social Media Nutzung      -6.586e-05      0.013     -0.005      0.996      -0.026       0.026\n",
      "Landtagswahlen               -0.0817      0.150     -0.546      0.585      -0.375       0.211\n",
      "topic_1                       0.1928      0.360      0.536      0.592      -0.512       0.898\n",
      "topic_2                       0.5658      0.362      1.561      0.119      -0.145       1.276\n",
      "topic_3                      -0.4998      0.376     -1.330      0.183      -1.236       0.237\n",
      "topic_4                      -1.1395      0.412     -2.765      0.006      -1.947      -0.332\n",
      "topic_6                      -0.1516      0.367     -0.413      0.680      -0.872       0.568\n",
      "topic_8                      -0.8578      0.399     -2.149      0.032      -1.640      -0.075\n",
      "topic_10                      0.1750      0.361      0.485      0.628      -0.532       0.882\n",
      "topic_12                     -1.5410      0.446     -3.453      0.001      -2.416      -0.666\n",
      "topic_14                     -0.5291      0.381     -1.388      0.165      -1.276       0.218\n",
      "topic_15                     -1.5883      0.460     -3.450      0.001      -2.491      -0.686\n",
      "topic_20                     -1.6023      0.461     -3.476      0.001      -2.506      -0.699\n",
      "topic_22                     -1.3074      0.432     -3.024      0.002      -2.155      -0.460\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6960703556546177\n",
      "Pr√§zision: 0.581081081081081\n",
      "Recall: 0.18067226890756302\n",
      "F1-Score: 0.27564102564102566\n",
      "Brier-Score: 0.18261120827763117\n",
      "Confusion-Matrix:\n",
      "[[576  31]\n",
      " [195  43]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541360\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  832\n",
      "Model:                          Logit   Df Residuals:                      815\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08533\n",
      "Time:                        11:17:15   Log-Likelihood:                -450.41\n",
      "converged:                       True   LL-Null:                       -492.43\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.096e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6496      0.342     -1.900      0.057      -1.320       0.020\n",
      "issue attention Facebook      3.0318      0.947      3.200      0.001       1.175       4.889\n",
      "issue attention Bundestag    -0.2642      0.858     -0.308      0.758      -1.945       1.417\n",
      "Social Media Nutzung          0.0077      0.014      0.545      0.586      -0.020       0.035\n",
      "Landtagswahlen               -0.2970      0.174     -1.707      0.088      -0.638       0.044\n",
      "topic_1                       0.1889      0.365      0.517      0.605      -0.527       0.904\n",
      "topic_2                       0.5277      0.365      1.447      0.148      -0.187       1.242\n",
      "topic_3                      -0.5009      0.384     -1.305      0.192      -1.253       0.252\n",
      "topic_4                      -1.1282      0.425     -2.657      0.008      -1.960      -0.296\n",
      "topic_6                      -0.1026      0.373     -0.275      0.783      -0.834       0.629\n",
      "topic_8                      -0.7218      0.402     -1.795      0.073      -1.510       0.066\n",
      "topic_10                      0.2865      0.365      0.786      0.432      -0.428       1.001\n",
      "topic_12                     -1.3941      0.449     -3.105      0.002      -2.274      -0.514\n",
      "topic_14                     -0.3748      0.385     -0.973      0.331      -1.130       0.381\n",
      "topic_15                     -1.4316      0.463     -3.089      0.002      -2.340      -0.523\n",
      "topic_20                     -1.4718      0.466     -3.160      0.002      -2.385      -0.559\n",
      "topic_22                     -1.1603      0.436     -2.662      0.008      -2.014      -0.306\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7030603448275862\n",
      "Pr√§zision: 0.48214285714285715\n",
      "Recall: 0.11637931034482758\n",
      "F1-Score: 0.1875\n",
      "Brier-Score: 0.18184380628159455\n",
      "Confusion-Matrix:\n",
      "[[571  29]\n",
      " [205  27]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541751\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  819\n",
      "Model:                          Logit   Df Residuals:                      802\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08218\n",
      "Time:                        11:17:16   Log-Likelihood:                -443.69\n",
      "converged:                       True   LL-Null:                       -483.42\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.086e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9931      0.341     -2.914      0.004      -1.661      -0.325\n",
      "issue attention Facebook      2.0579      0.971      2.119      0.034       0.154       3.961\n",
      "issue attention Bundestag    -0.3326      0.868     -0.383      0.702      -2.033       1.368\n",
      "Social Media Nutzung          0.0361      0.014      2.632      0.008       0.009       0.063\n",
      "Landtagswahlen               -0.1007      0.187     -0.539      0.590      -0.467       0.266\n",
      "topic_1                       0.1516      0.367      0.413      0.679      -0.567       0.871\n",
      "topic_2                       0.5243      0.368      1.427      0.154      -0.196       1.245\n",
      "topic_3                      -0.5853      0.388     -1.510      0.131      -1.345       0.174\n",
      "topic_4                      -1.1446      0.425     -2.692      0.007      -1.978      -0.311\n",
      "topic_6                      -0.2130      0.377     -0.565      0.572      -0.951       0.525\n",
      "topic_8                      -0.7694      0.404     -1.904      0.057      -1.561       0.022\n",
      "topic_10                      0.1913      0.367      0.521      0.602      -0.528       0.911\n",
      "topic_12                     -1.4073      0.449     -3.132      0.002      -2.288      -0.527\n",
      "topic_14                     -0.5039      0.391     -1.289      0.197      -1.270       0.262\n",
      "topic_15                     -1.4741      0.464     -3.174      0.002      -2.384      -0.564\n",
      "topic_20                     -1.5058      0.465     -3.236      0.001      -2.418      -0.594\n",
      "topic_22                     -1.2086      0.437     -2.765      0.006      -2.065      -0.352\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6986769258245029\n",
      "Pr√§zision: 0.5263157894736842\n",
      "Recall: 0.13215859030837004\n",
      "F1-Score: 0.2112676056338028\n",
      "Brier-Score: 0.18145897364960223\n",
      "Confusion-Matrix:\n",
      "[[565  27]\n",
      " [197  30]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543977\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  806\n",
      "Model:                          Logit   Df Residuals:                      789\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08136\n",
      "Time:                        11:17:16   Log-Likelihood:                -438.45\n",
      "converged:                       True   LL-Null:                       -477.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.377e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4199      0.346     -1.213      0.225      -1.098       0.259\n",
      "issue attention Facebook      2.2043      0.965      2.285      0.022       0.313       4.095\n",
      "issue attention Bundestag     1.0864      0.867      1.253      0.210      -0.612       2.785\n",
      "Social Media Nutzung         -0.0086      0.015     -0.590      0.555      -0.037       0.020\n",
      "Landtagswahlen               -0.4048      0.215     -1.886      0.059      -0.825       0.016\n",
      "topic_1                       0.0859      0.369      0.233      0.816      -0.637       0.809\n",
      "topic_2                       0.4867      0.368      1.321      0.186      -0.235       1.209\n",
      "topic_3                      -0.6612      0.394     -1.677      0.093      -1.434       0.111\n",
      "topic_4                      -1.0862      0.426     -2.548      0.011      -1.922      -0.251\n",
      "topic_6                      -0.1750      0.378     -0.463      0.643      -0.915       0.565\n",
      "topic_8                      -0.7120      0.404     -1.760      0.078      -1.505       0.081\n",
      "topic_10                      0.2254      0.368      0.612      0.541      -0.497       0.948\n",
      "topic_12                     -1.3057      0.450     -2.903      0.004      -2.187      -0.424\n",
      "topic_14                     -0.4310      0.392     -1.100      0.271      -1.199       0.337\n",
      "topic_15                     -1.3808      0.465     -2.970      0.003      -2.292      -0.470\n",
      "topic_20                     -1.4155      0.465     -3.043      0.002      -2.327      -0.504\n",
      "topic_22                     -1.1237      0.438     -2.568      0.010      -1.981      -0.266\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6980990629183401\n",
      "Pr√§zision: 0.49122807017543857\n",
      "Recall: 0.12444444444444444\n",
      "F1-Score: 0.19858156028368795\n",
      "Brier-Score: 0.18225553268620617\n",
      "Confusion-Matrix:\n",
      "[[552  29]\n",
      " [197  28]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540043\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  793\n",
      "Model:                          Logit   Df Residuals:                      776\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08168\n",
      "Time:                        11:17:16   Log-Likelihood:                -428.25\n",
      "converged:                       True   LL-Null:                       -466.35\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.050e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4869      0.348     -1.399      0.162      -1.169       0.195\n",
      "issue attention Facebook      1.6464      0.999      1.648      0.099      -0.311       3.604\n",
      "issue attention Bundestag    -1.6268      0.950     -1.712      0.087      -3.489       0.235\n",
      "Social Media Nutzung          0.0096      0.014      0.675      0.500      -0.018       0.037\n",
      "Landtagswahlen               -0.3142      0.215     -1.464      0.143      -0.735       0.106\n",
      "topic_1                       0.0909      0.373      0.244      0.808      -0.641       0.823\n",
      "topic_2                       0.5529      0.373      1.483      0.138      -0.178       1.283\n",
      "topic_3                      -0.6295      0.395     -1.593      0.111      -1.404       0.145\n",
      "topic_4                      -1.1501      0.428     -2.686      0.007      -1.989      -0.311\n",
      "topic_6                      -0.1954      0.381     -0.513      0.608      -0.942       0.551\n",
      "topic_8                      -0.7780      0.408     -1.908      0.056      -1.577       0.021\n",
      "topic_10                      0.2248      0.372      0.604      0.546      -0.504       0.954\n",
      "topic_12                     -1.4202      0.452     -3.144      0.002      -2.306      -0.535\n",
      "topic_14                     -0.6060      0.398     -1.521      0.128      -1.387       0.175\n",
      "topic_15                     -1.6571      0.486     -3.413      0.001      -2.609      -0.705\n",
      "topic_20                     -1.6763      0.485     -3.454      0.001      -2.627      -0.725\n",
      "topic_22                     -1.3632      0.452     -3.015      0.003      -2.249      -0.477\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6962145991224571\n",
      "Pr√§zision: 0.5535714285714286\n",
      "Recall: 0.14220183486238533\n",
      "F1-Score: 0.22627737226277372\n",
      "Brier-Score: 0.18019784757194127\n",
      "Confusion-Matrix:\n",
      "[[550  25]\n",
      " [187  31]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542322\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      763\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07892\n",
      "Time:                        11:17:16   Log-Likelihood:                -423.01\n",
      "converged:                       True   LL-Null:                       -459.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.644e-09\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3875      0.349     -1.109      0.267      -1.072       0.297\n",
      "issue attention Facebook      0.6649      1.027      0.647      0.517      -1.349       2.678\n",
      "issue attention Bundestag     0.0870      0.902      0.096      0.923      -1.681       1.855\n",
      "Social Media Nutzung          0.0002      0.014      0.017      0.986      -0.028       0.028\n",
      "Landtagswahlen               -0.3260      0.215     -1.519      0.129      -0.747       0.095\n",
      "topic_1                       0.1192      0.373      0.320      0.749      -0.612       0.850\n",
      "topic_2                       0.4875      0.371      1.312      0.189      -0.241       1.216\n",
      "topic_3                      -0.6973      0.399     -1.747      0.081      -1.480       0.085\n",
      "topic_4                      -1.0848      0.428     -2.534      0.011      -1.924      -0.246\n",
      "topic_6                      -0.1919      0.380     -0.504      0.614      -0.938       0.554\n",
      "topic_8                      -0.7582      0.407     -1.862      0.063      -1.556       0.040\n",
      "topic_10                      0.1584      0.373      0.425      0.671      -0.573       0.889\n",
      "topic_12                     -1.3234      0.452     -2.928      0.003      -2.209      -0.438\n",
      "topic_14                     -0.5761      0.399     -1.445      0.148      -1.358       0.205\n",
      "topic_15                     -1.5952      0.486     -3.284      0.001      -2.547      -0.643\n",
      "topic_20                     -1.7780      0.508     -3.497      0.000      -2.775      -0.781\n",
      "topic_22                     -1.3077      0.452     -2.892      0.004      -2.194      -0.422\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6918090142004527\n",
      "Pr√§zision: 0.5102040816326531\n",
      "Recall: 0.11627906976744186\n",
      "F1-Score: 0.1893939393939394\n",
      "Brier-Score: 0.18157871635351547\n",
      "Confusion-Matrix:\n",
      "[[541  24]\n",
      " [190  25]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.545010\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  767\n",
      "Model:                          Logit   Df Residuals:                      750\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07746\n",
      "Time:                        11:17:16   Log-Likelihood:                -418.02\n",
      "converged:                       True   LL-Null:                       -453.12\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.203e-09\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2636      0.353     -0.746      0.456      -0.956       0.429\n",
      "issue attention Facebook      0.6256      1.027      0.609      0.542      -1.386       2.638\n",
      "issue attention Bundestag     0.0303      0.904      0.034      0.973      -1.741       1.801\n",
      "Social Media Nutzung         -0.0070      0.015     -0.477      0.633      -0.036       0.022\n",
      "Landtagswahlen               -0.2693      0.213     -1.266      0.205      -0.686       0.148\n",
      "topic_1                       0.1198      0.375      0.319      0.749      -0.615       0.855\n",
      "topic_2                       0.4929      0.374      1.319      0.187      -0.240       1.225\n",
      "topic_3                      -0.7046      0.401     -1.759      0.079      -1.490       0.081\n",
      "topic_4                      -1.0943      0.429     -2.549      0.011      -1.936      -0.253\n",
      "topic_6                      -0.2726      0.384     -0.710      0.478      -1.026       0.480\n",
      "topic_8                      -0.7687      0.408     -1.882      0.060      -1.569       0.032\n",
      "topic_10                      0.0870      0.376      0.232      0.817      -0.649       0.823\n",
      "topic_12                     -1.3373      0.453     -2.952      0.003      -2.225      -0.449\n",
      "topic_14                     -0.5864      0.400     -1.466      0.143      -1.370       0.197\n",
      "topic_15                     -1.6098      0.487     -3.308      0.001      -2.564      -0.656\n",
      "topic_20                     -1.7909      0.509     -3.516      0.000      -2.789      -0.793\n",
      "topic_22                     -1.3207      0.453     -2.915      0.004      -2.209      -0.433\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6907933763834512\n",
      "Pr√§zision: 0.5106382978723404\n",
      "Recall: 0.11267605633802817\n",
      "F1-Score: 0.18461538461538463\n",
      "Brier-Score: 0.18276171601827174\n",
      "Confusion-Matrix:\n",
      "[[531  23]\n",
      " [189  24]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_cdu, post_reduced_cdu, rede_common_cdu,lag, social_media_usage_cdu)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - CDU\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_cdu_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544367\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  845\n",
      "Model:                          Logit   Df Residuals:                      826\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08434\n",
      "Time:                        11:17:16   Log-Likelihood:                -459.99\n",
      "converged:                       True   LL-Null:                       -502.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.252e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.7213      0.580     -1.244      0.213      -1.857       0.415\n",
      "issue attention Facebook      2.5601      0.940      2.723      0.006       0.717       4.403\n",
      "issue attention Bundestag    -1.6724      0.872     -1.917      0.055      -3.382       0.037\n",
      "Social Media Nutzung          0.0219      0.038      0.580      0.562      -0.052       0.096\n",
      "Landtagswahlen               -0.0927      0.151     -0.615      0.539      -0.388       0.203\n",
      "Komplexit√§t Reden            -0.0363      0.082     -0.443      0.658      -0.197       0.124\n",
      "Komplexit√§t Posts            -0.1442      0.230     -0.627      0.531      -0.595       0.307\n",
      "topic_1                       0.1925      0.360      0.535      0.593      -0.513       0.898\n",
      "topic_2                       0.5656      0.362      1.560      0.119      -0.145       1.276\n",
      "topic_3                      -0.5004      0.376     -1.332      0.183      -1.237       0.236\n",
      "topic_4                      -1.1398      0.412     -2.765      0.006      -1.948      -0.332\n",
      "topic_6                      -0.1513      0.367     -0.412      0.680      -0.872       0.569\n",
      "topic_8                      -0.8586      0.399     -2.150      0.032      -1.641      -0.076\n",
      "topic_10                      0.1755      0.361      0.486      0.627      -0.532       0.883\n",
      "topic_12                     -1.5414      0.446     -3.453      0.001      -2.416      -0.667\n",
      "topic_14                     -0.5295      0.381     -1.388      0.165      -1.277       0.218\n",
      "topic_15                     -1.5905      0.461     -3.453      0.001      -2.493      -0.688\n",
      "topic_20                     -1.6030      0.461     -3.476      0.001      -2.507      -0.699\n",
      "topic_22                     -1.3083      0.432     -3.025      0.002      -2.156      -0.461\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7003308737003863\n",
      "Pr√§zision: 0.5833333333333334\n",
      "Recall: 0.17647058823529413\n",
      "F1-Score: 0.2709677419354839\n",
      "Brier-Score: 0.1825313301142033\n",
      "Confusion-Matrix:\n",
      "[[577  30]\n",
      " [196  42]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534222\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  832\n",
      "Model:                          Logit   Df Residuals:                      813\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09739\n",
      "Time:                        11:17:16   Log-Likelihood:                -444.47\n",
      "converged:                       True   LL-Null:                       -492.43\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.235e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2347      0.588     -0.400      0.689      -1.386       0.917\n",
      "issue attention Facebook      3.0724      0.954      3.220      0.001       1.202       4.943\n",
      "issue attention Bundestag    -0.1827      0.859     -0.213      0.832      -1.867       1.502\n",
      "Social Media Nutzung         -0.0234      0.039     -0.605      0.545      -0.099       0.053\n",
      "Landtagswahlen               -0.3682      0.182     -2.021      0.043      -0.725      -0.011\n",
      "Komplexit√§t Reden            -0.2922      0.088     -3.338      0.001      -0.464      -0.121\n",
      "Komplexit√§t Posts             0.1687      0.229      0.737      0.461      -0.280       0.617\n",
      "topic_1                       0.1956      0.369      0.530      0.596      -0.527       0.918\n",
      "topic_2                       0.5399      0.369      1.464      0.143      -0.183       1.263\n",
      "topic_3                      -0.5085      0.388     -1.312      0.189      -1.268       0.251\n",
      "topic_4                      -1.1347      0.427     -2.655      0.008      -1.972      -0.297\n",
      "topic_6                      -0.0985      0.376     -0.262      0.793      -0.836       0.639\n",
      "topic_8                      -0.7303      0.406     -1.801      0.072      -1.525       0.065\n",
      "topic_10                      0.2940      0.368      0.798      0.425      -0.428       1.016\n",
      "topic_12                     -1.4033      0.452     -3.106      0.002      -2.289      -0.518\n",
      "topic_14                     -0.3778      0.389     -0.971      0.331      -1.140       0.385\n",
      "topic_15                     -1.4494      0.467     -3.105      0.002      -2.364      -0.535\n",
      "topic_20                     -1.4863      0.468     -3.176      0.001      -2.404      -0.569\n",
      "topic_22                     -1.1711      0.439     -2.669      0.008      -2.031      -0.311\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7134770114942528\n",
      "Pr√§zision: 0.5679012345679012\n",
      "Recall: 0.19827586206896552\n",
      "F1-Score: 0.2939297124600639\n",
      "Brier-Score: 0.1782783857791112\n",
      "Confusion-Matrix:\n",
      "[[565  35]\n",
      " [186  46]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.533240\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  819\n",
      "Model:                          Logit   Df Residuals:                      800\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09660\n",
      "Time:                        11:17:16   Log-Likelihood:                -436.72\n",
      "converged:                       True   LL-Null:                       -483.42\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.529e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.2996      0.572     -2.270      0.023      -2.422      -0.178\n",
      "issue attention Facebook      2.1147      0.978      2.162      0.031       0.198       4.032\n",
      "issue attention Bundestag    -0.4057      0.881     -0.460      0.645      -2.133       1.322\n",
      "Social Media Nutzung          0.0559      0.037      1.517      0.129      -0.016       0.128\n",
      "Landtagswahlen                0.0356      0.192      0.186      0.853      -0.340       0.412\n",
      "Komplexit√§t Reden             0.3163      0.085      3.718      0.000       0.150       0.483\n",
      "Komplexit√§t Posts            -0.0861      0.218     -0.395      0.693      -0.513       0.341\n",
      "topic_1                       0.1546      0.371      0.417      0.677      -0.572       0.881\n",
      "topic_2                       0.5380      0.371      1.449      0.147      -0.190       1.266\n",
      "topic_3                      -0.5977      0.391     -1.527      0.127      -1.365       0.169\n",
      "topic_4                      -1.1726      0.429     -2.732      0.006      -2.014      -0.331\n",
      "topic_6                      -0.2212      0.381     -0.580      0.562      -0.968       0.526\n",
      "topic_8                      -0.7843      0.408     -1.924      0.054      -1.583       0.015\n",
      "topic_10                      0.1953      0.371      0.526      0.599      -0.532       0.923\n",
      "topic_12                     -1.4435      0.454     -3.179      0.001      -2.333      -0.554\n",
      "topic_14                     -0.5149      0.395     -1.304      0.192      -1.288       0.259\n",
      "topic_15                     -1.4975      0.468     -3.202      0.001      -2.414      -0.581\n",
      "topic_20                     -1.5348      0.469     -3.271      0.001      -2.454      -0.615\n",
      "topic_22                     -1.2320      0.441     -2.796      0.005      -2.096      -0.368\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.707368436718657\n",
      "Pr√§zision: 0.6265060240963856\n",
      "Recall: 0.2290748898678414\n",
      "F1-Score: 0.33548387096774196\n",
      "Brier-Score: 0.17711111055414114\n",
      "Confusion-Matrix:\n",
      "[[561  31]\n",
      " [175  52]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542857\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  806\n",
      "Model:                          Logit   Df Residuals:                      787\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08325\n",
      "Time:                        11:17:16   Log-Likelihood:                -437.54\n",
      "converged:                       True   LL-Null:                       -477.28\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.061e-09\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.0323      0.589     -1.753      0.080      -2.187       0.122\n",
      "issue attention Facebook      2.2345      0.964      2.318      0.020       0.345       4.124\n",
      "issue attention Bundestag     1.0706      0.868      1.233      0.218      -0.631       2.772\n",
      "Social Media Nutzung          0.0373      0.038      0.974      0.330      -0.038       0.112\n",
      "Landtagswahlen               -0.4568      0.223     -2.047      0.041      -0.894      -0.019\n",
      "Komplexit√§t Reden            -0.0230      0.087     -0.264      0.792      -0.193       0.147\n",
      "Komplexit√§t Posts            -0.2973      0.228     -1.304      0.192      -0.744       0.150\n",
      "topic_1                       0.0862      0.369      0.233      0.815      -0.638       0.810\n",
      "topic_2                       0.4890      0.369      1.326      0.185      -0.234       1.212\n",
      "topic_3                      -0.6589      0.394     -1.672      0.094      -1.431       0.113\n",
      "topic_4                      -1.0896      0.427     -2.553      0.011      -1.926      -0.253\n",
      "topic_6                      -0.1760      0.378     -0.465      0.642      -0.917       0.565\n",
      "topic_8                      -0.7137      0.405     -1.763      0.078      -1.507       0.080\n",
      "topic_10                      0.2264      0.369      0.613      0.540      -0.497       0.950\n",
      "topic_12                     -1.3081      0.450     -2.906      0.004      -2.190      -0.426\n",
      "topic_14                     -0.4328      0.392     -1.103      0.270      -1.202       0.336\n",
      "topic_15                     -1.3862      0.465     -2.978      0.003      -2.298      -0.474\n",
      "topic_20                     -1.4158      0.466     -3.040      0.002      -2.329      -0.503\n",
      "topic_22                     -1.1293      0.438     -2.578      0.010      -1.988      -0.271\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6990323197552114\n",
      "Pr√§zision: 0.5074626865671642\n",
      "Recall: 0.1511111111111111\n",
      "F1-Score: 0.2328767123287671\n",
      "Brier-Score: 0.18148630347766706\n",
      "Confusion-Matrix:\n",
      "[[548  33]\n",
      " [191  34]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.530052\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  793\n",
      "Model:                          Logit   Df Residuals:                      774\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.09867\n",
      "Time:                        11:17:16   Log-Likelihood:                -420.33\n",
      "converged:                       True   LL-Null:                       -466.35\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.233e-12\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0480      0.604     -0.079      0.937      -1.232       1.136\n",
      "issue attention Facebook      1.6732      1.013      1.651      0.099      -0.313       3.659\n",
      "issue attention Bundestag    -1.5419      0.951     -1.621      0.105      -3.407       0.323\n",
      "Social Media Nutzung         -0.0215      0.039     -0.545      0.586      -0.099       0.056\n",
      "Landtagswahlen               -0.5026      0.228     -2.205      0.027      -0.949      -0.056\n",
      "Komplexit√§t Reden            -0.3570      0.093     -3.845      0.000      -0.539      -0.175\n",
      "Komplexit√§t Posts             0.1590      0.236      0.673      0.501      -0.304       0.622\n",
      "topic_1                       0.0938      0.379      0.248      0.805      -0.649       0.837\n",
      "topic_2                       0.5685      0.379      1.502      0.133      -0.173       1.310\n",
      "topic_3                      -0.6396      0.400     -1.599      0.110      -1.424       0.144\n",
      "topic_4                      -1.1619      0.432     -2.687      0.007      -2.009      -0.314\n",
      "topic_6                      -0.1908      0.386     -0.495      0.621      -0.947       0.565\n",
      "topic_8                      -0.7920      0.413     -1.919      0.055      -1.601       0.017\n",
      "topic_10                      0.2340      0.377      0.620      0.535      -0.506       0.974\n",
      "topic_12                     -1.4350      0.456     -3.147      0.002      -2.329      -0.541\n",
      "topic_14                     -0.6161      0.403     -1.527      0.127      -1.407       0.175\n",
      "topic_15                     -1.6859      0.490     -3.440      0.001      -2.646      -0.725\n",
      "topic_20                     -1.6988      0.489     -3.473      0.001      -2.657      -0.740\n",
      "topic_22                     -1.3845      0.457     -3.032      0.002      -2.279      -0.490\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7146868767451137\n",
      "Pr√§zision: 0.5783132530120482\n",
      "Recall: 0.22018348623853212\n",
      "F1-Score: 0.31893687707641194\n",
      "Brier-Score: 0.17622950191853265\n",
      "Confusion-Matrix:\n",
      "[[540  35]\n",
      " [170  48]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539082\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  780\n",
      "Model:                          Logit   Df Residuals:                      761\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.08442\n",
      "Time:                        11:17:16   Log-Likelihood:                -420.48\n",
      "converged:                       True   LL-Null:                       -459.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.297e-09\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4905      0.589     -0.832      0.405      -1.645       0.665\n",
      "issue attention Facebook      0.6831      1.028      0.664      0.506      -1.332       2.698\n",
      "issue attention Bundestag     0.0488      0.910      0.054      0.957      -1.735       1.833\n",
      "Social Media Nutzung          0.0061      0.038      0.161      0.872      -0.068       0.081\n",
      "Landtagswahlen               -0.2260      0.220     -1.026      0.305      -0.658       0.206\n",
      "Komplexit√§t Reden             0.1950      0.087      2.251      0.024       0.025       0.365\n",
      "Komplexit√§t Posts            -0.0155      0.227     -0.069      0.945      -0.460       0.429\n",
      "topic_1                       0.1196      0.374      0.319      0.750      -0.614       0.854\n",
      "topic_2                       0.4928      0.373      1.321      0.186      -0.238       1.224\n",
      "topic_3                      -0.7034      0.401     -1.755      0.079      -1.489       0.082\n",
      "topic_4                      -1.0949      0.430     -2.547      0.011      -1.937      -0.252\n",
      "topic_6                      -0.1943      0.382     -0.509      0.611      -0.943       0.555\n",
      "topic_8                      -0.7647      0.409     -1.871      0.061      -1.566       0.037\n",
      "topic_10                      0.1592      0.375      0.425      0.671      -0.575       0.893\n",
      "topic_12                     -1.3364      0.454     -2.946      0.003      -2.225      -0.447\n",
      "topic_14                     -0.5816      0.400     -1.453      0.146      -1.366       0.203\n",
      "topic_15                     -1.6068      0.487     -3.298      0.001      -2.562      -0.652\n",
      "topic_20                     -1.7912      0.510     -3.513      0.000      -2.791      -0.792\n",
      "topic_22                     -1.3183      0.454     -2.906      0.004      -2.207      -0.429\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6999711874871373\n",
      "Pr√§zision: 0.5\n",
      "Recall: 0.12558139534883722\n",
      "F1-Score: 0.20074349442379183\n",
      "Brier-Score: 0.18014492328827666\n",
      "Confusion-Matrix:\n",
      "[[538  27]\n",
      " [188  27]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544228\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  767\n",
      "Model:                          Logit   Df Residuals:                      748\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.07879\n",
      "Time:                        11:17:16   Log-Likelihood:                -417.42\n",
      "converged:                       True   LL-Null:                       -453.12\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.615e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2941      0.595     -0.494      0.621      -1.461       0.873\n",
      "issue attention Facebook      0.6348      1.026      0.619      0.536      -1.377       2.646\n",
      "issue attention Bundestag     0.0127      0.907      0.014      0.989      -1.765       1.790\n",
      "Social Media Nutzung         -0.0056      0.038     -0.146      0.884      -0.081       0.069\n",
      "Landtagswahlen               -0.2169      0.219     -0.991      0.322      -0.646       0.212\n",
      "Komplexit√§t Reden             0.0957      0.087      1.097      0.273      -0.075       0.267\n",
      "Komplexit√§t Posts             0.0017      0.229      0.007      0.994      -0.448       0.451\n",
      "topic_1                       0.1196      0.375      0.319      0.750      -0.616       0.856\n",
      "topic_2                       0.4944      0.374      1.322      0.186      -0.239       1.228\n",
      "topic_3                      -0.7063      0.401     -1.761      0.078      -1.492       0.080\n",
      "topic_4                      -1.0974      0.430     -2.553      0.011      -1.940      -0.255\n",
      "topic_6                      -0.2735      0.385     -0.711      0.477      -1.027       0.480\n",
      "topic_8                      -0.7704      0.409     -1.885      0.059      -1.572       0.031\n",
      "topic_10                      0.0870      0.376      0.231      0.817      -0.650       0.824\n",
      "topic_12                     -1.3413      0.454     -2.958      0.003      -2.230      -0.452\n",
      "topic_14                     -0.5879      0.400     -1.469      0.142      -1.372       0.197\n",
      "topic_15                     -1.6129      0.487     -3.312      0.001      -2.567      -0.658\n",
      "topic_20                     -1.7946      0.510     -3.521      0.000      -2.794      -0.796\n",
      "topic_22                     -1.3236      0.453     -2.919      0.004      -2.212      -0.435\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6913696378027492\n",
      "Pr√§zision: 0.5102040816326531\n",
      "Recall: 0.11737089201877934\n",
      "F1-Score: 0.19083969465648856\n",
      "Brier-Score: 0.18265931297577107\n",
      "Confusion-Matrix:\n",
      "[[530  24]\n",
      " [188  25]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_cdu, post_reduced_cdu, rede_common_cdu,lag, social_media_usage_cdu,rede_komplex_cdu,posts_komplex_cdu)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - CDU\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_cdu_complex_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B√úNDNIS 90/ DIE GR√úNEN\n",
    "*Achtung* Scheinbar ist bei den Gr√ºnen Thema 0 nicht relevant, weshalb die Referenzkategorie in diesem Fall **nicht** Thema 0, sondern Thema 1 ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 41, 44, 46, 53, 54, 56, 58, 59, 61, 63, 65, 69, 70, 75, 79, 80, 81, 84, 90, 91, 92}\n",
      "Gemeinsame Topics: {1, 2, 6, 15, 24, 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\13039428.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_gruen[\"date\"] = pd.to_datetime(subset_reden_gruen[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\13039428.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_gruen[\"date\"] = pd.to_datetime(subset_posts_gruen[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_gruen = subset_posts[subset_posts[\"partei\"] == \"B√úNDNIS 90/DIE GR√úNEN\"]\n",
    "subset_reden_gruen = subset_reden[subset_reden[\"partei\"] == \"B√úNDNIS 90/DIE GR√úNEN\"]\n",
    "social_media_usage_gruen = subset_posts_gruen.groupby('date').size()\n",
    "subset_reden_gruen[\"date\"] = pd.to_datetime(subset_reden_gruen[\"date\"])\n",
    "subset_posts_gruen[\"date\"] = pd.to_datetime(subset_posts_gruen[\"date\"])\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_gruen = subset_reden_gruen.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_gruen = subset_posts_gruen.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "reden_komplexit√§t_t√§glich_gruen = subset_reden_gruen.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_gruen = subset_posts_gruen.groupby('date')['komplexit√§t'].sum()\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_gruen = redethemen_t√§glich_gruen.index.intersection(postthemen_t√§glich_gruen.index)\n",
    "redethemen_t√§glich_aligned_gruen = redethemen_t√§glich_gruen.loc[common_dates_gruen]\n",
    "postthemen_t√§glich_aligned_gruen = postthemen_t√§glich_gruen.loc[common_dates_gruen]\n",
    "rede_common_gruen, post_common_gruen = filter_common_topics(redethemen_t√§glich_aligned_gruen, postthemen_t√§glich_aligned_gruen)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_gruen =  rede_common_gruen.div(rede_common_gruen.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_gruen = post_common_gruen.div(post_common_gruen.sum(axis=1), axis=0)\n",
    "reden_relativ_gruen_red = remove_near_constant(reden_relativ_gruen)\n",
    "post_relativ_gruen_red = remove_near_constant(post_relativ_gruen)\n",
    "rede_reduced_gruen, post_reduced_gruen = filter_common_topics(reden_relativ_gruen_red, post_relativ_gruen_red)\n",
    "rede_komplex_gruen = reden_komplexit√§t_t√§glich_gruen.loc[common_dates_gruen]\n",
    "posts_komplex_gruen = posts_komplexit√§t_t√§glich_gruen.loc[common_dates_gruen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.533775\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  384\n",
      "Model:                          Logit   Df Residuals:                      374\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1157\n",
      "Time:                        11:17:17   Log-Likelihood:                -204.97\n",
      "converged:                       True   LL-Null:                       -231.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.196e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2096      0.353     -0.594      0.553      -0.901       0.482\n",
      "issue attention Facebook     -0.5199      0.790     -0.658      0.510      -2.068       1.028\n",
      "issue attention Bundestag    -1.8087      1.081     -1.673      0.094      -3.928       0.310\n",
      "Social Media Nutzung          0.0034      0.048      0.071      0.944      -0.092       0.098\n",
      "Landtagswahlen               -0.2006      0.232     -0.864      0.388      -0.656       0.254\n",
      "topic_2                       0.7579      0.372      2.038      0.042       0.029       1.487\n",
      "topic_6                      -0.2549      0.368     -0.692      0.489      -0.977       0.467\n",
      "topic_15                     -1.8051      0.478     -3.777      0.000      -2.742      -0.868\n",
      "topic_24                     -1.5102      0.444     -3.401      0.001      -2.381      -0.640\n",
      "topic_25                     -1.1586      0.412     -2.812      0.005      -1.966      -0.351\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7322249212184875\n",
      "Pr√§zision: 0.5555555555555556\n",
      "Recall: 0.26785714285714285\n",
      "F1-Score: 0.3614457831325301\n",
      "Brier-Score: 0.17892232846644088\n",
      "Confusion-Matrix:\n",
      "[[248  24]\n",
      " [ 82  30]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x224050d7710>,\n",
       " 0.7322249212184875,\n",
       " 0.3614457831325301)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_FE_control(rede_reduced_gruen, post_reduced_gruen, rede_common_gruen,1, social_media_usage_gruen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.533775\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  384\n",
      "Model:                          Logit   Df Residuals:                      374\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1157\n",
      "Time:                        11:17:17   Log-Likelihood:                -204.97\n",
      "converged:                       True   LL-Null:                       -231.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.196e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2096      0.353     -0.594      0.553      -0.901       0.482\n",
      "issue attention Facebook     -0.5199      0.790     -0.658      0.510      -2.068       1.028\n",
      "issue attention Bundestag    -1.8087      1.081     -1.673      0.094      -3.928       0.310\n",
      "Social Media Nutzung          0.0034      0.048      0.071      0.944      -0.092       0.098\n",
      "Landtagswahlen               -0.2006      0.232     -0.864      0.388      -0.656       0.254\n",
      "topic_2                       0.7579      0.372      2.038      0.042       0.029       1.487\n",
      "topic_6                      -0.2549      0.368     -0.692      0.489      -0.977       0.467\n",
      "topic_15                     -1.8051      0.478     -3.777      0.000      -2.742      -0.868\n",
      "topic_24                     -1.5102      0.444     -3.401      0.001      -2.381      -0.640\n",
      "topic_25                     -1.1586      0.412     -2.812      0.005      -1.966      -0.351\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7322249212184875\n",
      "Pr√§zision: 0.5555555555555556\n",
      "Recall: 0.26785714285714285\n",
      "F1-Score: 0.3614457831325301\n",
      "Brier-Score: 0.17892232846644088\n",
      "Confusion-Matrix:\n",
      "[[248  24]\n",
      " [ 82  30]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.533687\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  378\n",
      "Model:                          Logit   Df Residuals:                      368\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1115\n",
      "Time:                        11:17:17   Log-Likelihood:                -201.73\n",
      "converged:                       True   LL-Null:                       -227.06\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.147e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4572      0.358     -1.276      0.202      -1.160       0.245\n",
      "issue attention Facebook     -0.9689      0.868     -1.116      0.264      -2.670       0.733\n",
      "issue attention Bundestag     1.2378      1.065      1.162      0.245      -0.849       3.325\n",
      "Social Media Nutzung          0.0251      0.049      0.516      0.606      -0.070       0.120\n",
      "Landtagswahlen               -0.3454      0.261     -1.322      0.186      -0.858       0.167\n",
      "topic_2                       0.5432      0.371      1.464      0.143      -0.184       1.270\n",
      "topic_6                      -0.2818      0.374     -0.753      0.452      -1.015       0.452\n",
      "topic_15                     -1.6277      0.481     -3.385      0.001      -2.570      -0.685\n",
      "topic_24                     -1.3609      0.447     -3.047      0.002      -2.236      -0.486\n",
      "topic_25                     -0.9997      0.415     -2.407      0.016      -1.814      -0.186\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7262712731489377\n",
      "Pr√§zision: 0.5882352941176471\n",
      "Recall: 0.27522935779816515\n",
      "F1-Score: 0.375\n",
      "Brier-Score: 0.17742720832756748\n",
      "Confusion-Matrix:\n",
      "[[248  21]\n",
      " [ 79  30]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537010\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  372\n",
      "Model:                          Logit   Df Residuals:                      362\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1050\n",
      "Time:                        11:17:17   Log-Likelihood:                -199.77\n",
      "converged:                       True   LL-Null:                       -223.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.132e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3752      0.361     -1.040      0.298      -1.082       0.332\n",
      "issue attention Facebook     -0.0935      0.762     -0.123      0.902      -1.587       1.400\n",
      "issue attention Bundestag     0.3360      1.046      0.321      0.748      -1.715       2.387\n",
      "Social Media Nutzung         -0.0025      0.049     -0.050      0.960      -0.099       0.094\n",
      "Landtagswahlen               -0.4019      0.289     -1.388      0.165      -0.969       0.165\n",
      "topic_2                       0.7000      0.374      1.872      0.061      -0.033       1.433\n",
      "topic_6                      -0.2860      0.378     -0.756      0.449      -1.027       0.455\n",
      "topic_15                     -1.5961      0.482     -3.313      0.001      -2.540      -0.652\n",
      "topic_24                     -1.3103      0.448     -2.927      0.003      -2.188      -0.433\n",
      "topic_25                     -0.9615      0.417     -2.307      0.021      -1.778      -0.145\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7184447187444895\n",
      "Pr√§zision: 0.6122448979591837\n",
      "Recall: 0.2803738317757009\n",
      "F1-Score: 0.38461538461538464\n",
      "Brier-Score: 0.1792358968376204\n",
      "Confusion-Matrix:\n",
      "[[246  19]\n",
      " [ 77  30]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.530217\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  366\n",
      "Model:                          Logit   Df Residuals:                      356\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1153\n",
      "Time:                        11:17:17   Log-Likelihood:                -194.06\n",
      "converged:                       True   LL-Null:                       -219.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.315e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0699      0.377     -0.186      0.853      -0.808       0.669\n",
      "issue attention Facebook      0.2228      0.748      0.298      0.766      -1.242       1.688\n",
      "issue attention Bundestag    -2.2982      1.235     -1.861      0.063      -4.719       0.122\n",
      "Social Media Nutzung         -0.0620      0.053     -1.175      0.240      -0.166       0.041\n",
      "Landtagswahlen               -0.2656      0.326     -0.814      0.415      -0.905       0.374\n",
      "topic_2                       0.9455      0.382      2.473      0.013       0.196       1.695\n",
      "topic_6                      -0.2073      0.383     -0.541      0.589      -0.958       0.544\n",
      "topic_15                     -1.6430      0.485     -3.387      0.001      -2.594      -0.692\n",
      "topic_24                     -1.3370      0.452     -2.959      0.003      -2.223      -0.451\n",
      "topic_25                     -1.0999      0.429     -2.562      0.010      -1.941      -0.258\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7288086115672322\n",
      "Pr√§zision: 0.6226415094339622\n",
      "Recall: 0.3142857142857143\n",
      "F1-Score: 0.4177215189873418\n",
      "Brier-Score: 0.17502623713297946\n",
      "Confusion-Matrix:\n",
      "[[241  20]\n",
      " [ 72  33]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.521145\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  360\n",
      "Model:                          Logit   Df Residuals:                      350\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1219\n",
      "Time:                        11:17:17   Log-Likelihood:                -187.61\n",
      "converged:                       True   LL-Null:                       -213.65\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.367e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5052      0.383     -1.320      0.187      -1.255       0.245\n",
      "issue attention Facebook     -1.0960      0.951     -1.152      0.249      -2.960       0.769\n",
      "issue attention Bundestag    -2.1406      1.294     -1.655      0.098      -4.676       0.395\n",
      "Social Media Nutzung          0.0344      0.052      0.665      0.506      -0.067       0.136\n",
      "Landtagswahlen               -0.0893      0.329     -0.272      0.786      -0.734       0.555\n",
      "topic_2                       0.9023      0.385      2.346      0.019       0.149       1.656\n",
      "topic_6                      -0.1380      0.387     -0.357      0.721      -0.897       0.621\n",
      "topic_15                     -1.7619      0.512     -3.442      0.001      -2.765      -0.758\n",
      "topic_24                     -1.4254      0.470     -3.034      0.002      -2.346      -0.504\n",
      "topic_25                     -1.0294      0.432     -2.382      0.017      -1.876      -0.182\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7359990825337359\n",
      "Pr√§zision: 0.6326530612244898\n",
      "Recall: 0.3069306930693069\n",
      "F1-Score: 0.41333333333333333\n",
      "Brier-Score: 0.17280424974555122\n",
      "Confusion-Matrix:\n",
      "[[241  18]\n",
      " [ 70  31]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.517338\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  354\n",
      "Model:                          Logit   Df Residuals:                      344\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1271\n",
      "Time:                        11:17:17   Log-Likelihood:                -183.14\n",
      "converged:                       True   LL-Null:                       -209.79\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.554e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1308      0.397      0.330      0.742      -0.647       0.909\n",
      "issue attention Facebook      0.5998      0.799      0.750      0.453      -0.967       2.167\n",
      "issue attention Bundestag    -1.2781      1.231     -1.038      0.299      -3.691       1.135\n",
      "Social Media Nutzung         -0.1413      0.060     -2.337      0.019      -0.260      -0.023\n",
      "Landtagswahlen               -0.0758      0.322     -0.236      0.814      -0.706       0.555\n",
      "topic_2                       0.8596      0.389      2.212      0.027       0.098       1.621\n",
      "topic_6                      -0.1357      0.390     -0.348      0.728      -0.901       0.629\n",
      "topic_15                     -1.7327      0.514     -3.371      0.001      -2.740      -0.725\n",
      "topic_24                     -1.3939      0.472     -2.952      0.003      -2.319      -0.469\n",
      "topic_25                     -1.1315      0.445     -2.540      0.011      -2.004      -0.259\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7396712220241632\n",
      "Pr√§zision: 0.6041666666666666\n",
      "Recall: 0.29292929292929293\n",
      "F1-Score: 0.3945578231292517\n",
      "Brier-Score: 0.17141225918932446\n",
      "Confusion-Matrix:\n",
      "[[236  19]\n",
      " [ 70  29]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.510714\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  348\n",
      "Model:                          Logit   Df Residuals:                      338\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1409\n",
      "Time:                        11:17:17   Log-Likelihood:                -177.73\n",
      "converged:                       True   LL-Null:                       -206.87\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.856e-09\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.2439      0.396     -3.141      0.002      -2.020      -0.468\n",
      "issue attention Facebook      1.6661      0.792      2.104      0.035       0.114       3.218\n",
      "issue attention Bundestag    -0.4651      1.224     -0.380      0.704      -2.864       1.934\n",
      "Social Media Nutzung          0.1570      0.055      2.854      0.004       0.049       0.265\n",
      "Landtagswahlen               -0.0837      0.337     -0.248      0.804      -0.744       0.577\n",
      "topic_2                       0.8707      0.395      2.206      0.027       0.097       1.644\n",
      "topic_6                      -0.2387      0.399     -0.598      0.550      -1.021       0.544\n",
      "topic_15                     -1.7285      0.520     -3.324      0.001      -2.748      -0.709\n",
      "topic_24                     -1.3937      0.478     -2.914      0.004      -2.331      -0.456\n",
      "topic_25                     -1.1461      0.453     -2.527      0.011      -2.035      -0.257\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7533061224489797\n",
      "Pr√§zision: 0.5964912280701754\n",
      "Recall: 0.3469387755102041\n",
      "F1-Score: 0.43870967741935485\n",
      "Brier-Score: 0.16916131080769797\n",
      "Confusion-Matrix:\n",
      "[[227  23]\n",
      " [ 64  34]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_gruen, post_reduced_gruen, rede_common_gruen,lag, social_media_usage_gruen)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - B√úNDNIS 90/ DIE GR√úNEN\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_gruen_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532749\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  384\n",
      "Model:                          Logit   Df Residuals:                      372\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1174\n",
      "Time:                        11:17:17   Log-Likelihood:                -204.58\n",
      "converged:                       True   LL-Null:                       -231.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.803e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5359      0.615     -0.872      0.383      -1.741       0.669\n",
      "issue attention Facebook     -0.5034      0.793     -0.635      0.525      -2.057       1.051\n",
      "issue attention Bundestag    -1.8150      1.084     -1.674      0.094      -3.941       0.311\n",
      "Social Media Nutzung          0.0771      0.123      0.627      0.530      -0.164       0.318\n",
      "Landtagswahlen               -0.2211      0.233     -0.951      0.342      -0.677       0.235\n",
      "Komplexit√§t Reden             0.1008      0.129      0.783      0.434      -0.152       0.353\n",
      "Komplexit√§t Posts            -0.2055      0.314     -0.655      0.513      -0.820       0.410\n",
      "topic_2                       0.7610      0.372      2.043      0.041       0.031       1.491\n",
      "topic_6                      -0.2564      0.369     -0.695      0.487      -0.980       0.467\n",
      "topic_15                     -1.8044      0.478     -3.775      0.000      -2.741      -0.867\n",
      "topic_24                     -1.5105      0.444     -3.400      0.001      -2.381      -0.640\n",
      "topic_25                     -1.1622      0.413     -2.816      0.005      -1.971      -0.353\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7327008928571429\n",
      "Pr√§zision: 0.5490196078431373\n",
      "Recall: 0.25\n",
      "F1-Score: 0.34355828220858897\n",
      "Brier-Score: 0.17846388242664665\n",
      "Confusion-Matrix:\n",
      "[[249  23]\n",
      " [ 84  28]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.512570\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  378\n",
      "Model:                          Logit   Df Residuals:                      366\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1467\n",
      "Time:                        11:17:17   Log-Likelihood:                -193.75\n",
      "converged:                       True   LL-Null:                       -227.06\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.364e-10\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2893      0.647     -0.447      0.655      -1.558       0.979\n",
      "issue attention Facebook     -0.9187      0.848     -1.083      0.279      -2.581       0.744\n",
      "issue attention Bundestag     1.2508      1.107      1.130      0.259      -0.919       3.421\n",
      "Social Media Nutzung         -0.0189      0.130     -0.146      0.884      -0.273       0.235\n",
      "Landtagswahlen               -0.3753      0.269     -1.394      0.163      -0.903       0.152\n",
      "Komplexit√§t Reden            -0.5505      0.149     -3.689      0.000      -0.843      -0.258\n",
      "Komplexit√§t Posts             0.1257      0.332      0.379      0.705      -0.524       0.775\n",
      "topic_2                       0.5799      0.383      1.514      0.130      -0.171       1.330\n",
      "topic_6                      -0.3065      0.384     -0.797      0.425      -1.060       0.447\n",
      "topic_15                     -1.6966      0.490     -3.463      0.001      -2.657      -0.736\n",
      "topic_24                     -1.4199      0.455     -3.117      0.002      -2.313      -0.527\n",
      "topic_25                     -1.0449      0.424     -2.466      0.014      -1.875      -0.215\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.75447631390471\n",
      "Pr√§zision: 0.6229508196721312\n",
      "Recall: 0.3486238532110092\n",
      "F1-Score: 0.4470588235294118\n",
      "Brier-Score: 0.17011828369297313\n",
      "Confusion-Matrix:\n",
      "[[246  23]\n",
      " [ 71  38]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.530515\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  372\n",
      "Model:                          Logit   Df Residuals:                      360\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1158\n",
      "Time:                        11:17:17   Log-Likelihood:                -197.35\n",
      "converged:                       True   LL-Null:                       -223.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.075e-07\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.6222      0.664     -0.937      0.349      -1.923       0.679\n",
      "issue attention Facebook     -0.0880      0.774     -0.114      0.910      -1.606       1.430\n",
      "issue attention Bundestag     0.3502      1.045      0.335      0.737      -1.698       2.398\n",
      "Social Media Nutzung          0.0508      0.133      0.383      0.702      -0.209       0.311\n",
      "Landtagswahlen               -0.3962      0.292     -1.355      0.176      -0.969       0.177\n",
      "Komplexit√§t Reden             0.2841      0.131      2.165      0.030       0.027       0.541\n",
      "Komplexit√§t Posts            -0.1479      0.334     -0.443      0.658      -0.802       0.506\n",
      "topic_2                       0.7116      0.377      1.886      0.059      -0.028       1.451\n",
      "topic_6                      -0.2900      0.381     -0.761      0.447      -1.037       0.457\n",
      "topic_15                     -1.6169      0.485     -3.337      0.001      -2.567      -0.667\n",
      "topic_24                     -1.3286      0.451     -2.948      0.003      -2.212      -0.445\n",
      "topic_25                     -0.9754      0.420     -2.322      0.020      -1.799      -0.152\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7280902839005466\n",
      "Pr√§zision: 0.6415094339622641\n",
      "Recall: 0.3177570093457944\n",
      "F1-Score: 0.425\n",
      "Brier-Score: 0.17654465057003685\n",
      "Confusion-Matrix:\n",
      "[[246  19]\n",
      " [ 73  34]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.522641\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  366\n",
      "Model:                          Logit   Df Residuals:                      354\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1280\n",
      "Time:                        11:17:17   Log-Likelihood:                -191.29\n",
      "converged:                       True   LL-Null:                       -219.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.783e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.3669      0.683     -2.000      0.046      -2.707      -0.027\n",
      "issue attention Facebook      0.3125      0.748      0.418      0.676      -1.153       1.778\n",
      "issue attention Bundestag    -2.2441      1.253     -1.791      0.073      -4.700       0.212\n",
      "Social Media Nutzung          0.2248      0.136      1.656      0.098      -0.041       0.491\n",
      "Landtagswahlen               -0.2048      0.329     -0.622      0.534      -0.850       0.441\n",
      "Komplexit√§t Reden             0.1781      0.137      1.300      0.194      -0.090       0.447\n",
      "Komplexit√§t Posts            -0.7946      0.351     -2.262      0.024      -1.483      -0.106\n",
      "topic_2                       0.9624      0.387      2.487      0.013       0.204       1.721\n",
      "topic_6                      -0.2131      0.387     -0.551      0.582      -0.971       0.545\n",
      "topic_15                     -1.6560      0.487     -3.399      0.001      -2.611      -0.701\n",
      "topic_24                     -1.3462      0.454     -2.964      0.003      -2.236      -0.456\n",
      "topic_25                     -1.1172      0.433     -2.580      0.010      -1.966      -0.269\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7358511220580186\n",
      "Pr√§zision: 0.6153846153846154\n",
      "Recall: 0.3047619047619048\n",
      "F1-Score: 0.40764331210191085\n",
      "Brier-Score: 0.17267986021489062\n",
      "Confusion-Matrix:\n",
      "[[241  20]\n",
      " [ 73  32]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.504751\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  360\n",
      "Model:                          Logit   Df Residuals:                      348\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1495\n",
      "Time:                        11:17:17   Log-Likelihood:                -181.71\n",
      "converged:                       True   LL-Null:                       -213.65\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.747e-09\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3050      0.685     -0.445      0.656      -1.648       1.038\n",
      "issue attention Facebook     -1.0348      0.930     -1.113      0.266      -2.857       0.787\n",
      "issue attention Bundestag    -2.1953      1.281     -1.714      0.087      -4.705       0.315\n",
      "Social Media Nutzung         -0.0166      0.135     -0.123      0.902      -0.281       0.248\n",
      "Landtagswahlen               -0.1246      0.338     -0.369      0.712      -0.787       0.537\n",
      "Komplexit√§t Reden            -0.4888      0.152     -3.212      0.001      -0.787      -0.191\n",
      "Komplexit√§t Posts             0.1399      0.342      0.410      0.682      -0.530       0.809\n",
      "topic_2                       0.9565      0.397      2.412      0.016       0.179       1.734\n",
      "topic_6                      -0.1372      0.395     -0.347      0.728      -0.912       0.638\n",
      "topic_15                     -1.8246      0.520     -3.511      0.000      -2.843      -0.806\n",
      "topic_24                     -1.4758      0.478     -3.088      0.002      -2.412      -0.539\n",
      "topic_25                     -1.0540      0.439     -2.400      0.016      -1.915      -0.193\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7505256317137506\n",
      "Pr√§zision: 0.6530612244897959\n",
      "Recall: 0.31683168316831684\n",
      "F1-Score: 0.4266666666666667\n",
      "Brier-Score: 0.16655821962552253\n",
      "Confusion-Matrix:\n",
      "[[242  17]\n",
      " [ 69  32]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.515029\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  354\n",
      "Model:                          Logit   Df Residuals:                      342\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1309\n",
      "Time:                        11:17:17   Log-Likelihood:                -182.32\n",
      "converged:                       True   LL-Null:                       -209.79\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.937e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.2030      0.725      0.280      0.779      -1.217       1.623\n",
      "issue attention Facebook      0.5909      0.797      0.741      0.459      -0.972       2.154\n",
      "issue attention Bundestag    -1.2738      1.240     -1.027      0.304      -3.705       1.157\n",
      "Social Media Nutzung         -0.1578      0.149     -1.059      0.290      -0.450       0.134\n",
      "Landtagswahlen               -0.0854      0.325     -0.263      0.792      -0.722       0.551\n",
      "Komplexit√§t Reden             0.1575      0.135      1.168      0.243      -0.107       0.422\n",
      "Komplexit√§t Posts             0.0538      0.354      0.152      0.879      -0.640       0.748\n",
      "topic_2                       0.8641      0.390      2.217      0.027       0.100       1.628\n",
      "topic_6                      -0.1388      0.392     -0.354      0.723      -0.906       0.629\n",
      "topic_15                     -1.7388      0.515     -3.378      0.001      -2.748      -0.730\n",
      "topic_24                     -1.3998      0.473     -2.959      0.003      -2.327      -0.473\n",
      "topic_25                     -1.1363      0.447     -2.545      0.011      -2.011      -0.261\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7444246385422856\n",
      "Pr√§zision: 0.6078431372549019\n",
      "Recall: 0.31313131313131315\n",
      "F1-Score: 0.41333333333333333\n",
      "Brier-Score: 0.1706795450117769\n",
      "Confusion-Matrix:\n",
      "[[235  20]\n",
      " [ 68  31]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509104\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  348\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                  0.1436\n",
      "Time:                        11:17:17   Log-Likelihood:                -177.17\n",
      "converged:                       True   LL-Null:                       -206.87\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.192e-08\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.6306      0.686     -2.376      0.017      -2.975      -0.286\n",
      "issue attention Facebook      1.6759      0.788      2.126      0.033       0.131       3.221\n",
      "issue attention Bundestag    -0.4555      1.228     -0.371      0.711      -2.862       1.951\n",
      "Social Media Nutzung          0.2457      0.139      1.768      0.077      -0.027       0.518\n",
      "Landtagswahlen               -0.0687      0.340     -0.202      0.840      -0.735       0.597\n",
      "Komplexit√§t Reden             0.1373      0.139      0.990      0.322      -0.135       0.409\n",
      "Komplexit√§t Posts            -0.2212      0.327     -0.676      0.499      -0.863       0.420\n",
      "topic_2                       0.8729      0.395      2.208      0.027       0.098       1.648\n",
      "topic_6                      -0.2425      0.400     -0.606      0.544      -1.026       0.541\n",
      "topic_15                     -1.7409      0.521     -3.341      0.001      -2.762      -0.720\n",
      "topic_24                     -1.4019      0.479     -2.926      0.003      -2.341      -0.463\n",
      "topic_25                     -1.1491      0.454     -2.532      0.011      -2.039      -0.260\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7545714285714286\n",
      "Pr√§zision: 0.6226415094339622\n",
      "Recall: 0.336734693877551\n",
      "F1-Score: 0.4370860927152318\n",
      "Brier-Score: 0.16813488149750702\n",
      "Confusion-Matrix:\n",
      "[[230  20]\n",
      " [ 65  33]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_gruen, post_reduced_gruen, rede_common_gruen,lag, social_media_usage_gruen, rede_komplex_gruen, posts_komplex_gruen)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - B√úNDNIS 90/ DIE GR√úNEN\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_gruen_complex_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 34, 35, 36, 40, 43, 52, 53, 54, 55, 56, 58, 64, 68, 74, 75, 79, 85, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 6, 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\3798737155.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_linke[\"date\"] = pd.to_datetime(subset_reden_linke[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_14340\\3798737155.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_linke[\"date\"] = pd.to_datetime(subset_posts_linke[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_linke = subset_posts[subset_posts[\"partei\"] == \"DIE LINKE.\"]\n",
    "subset_reden_linke = subset_reden[subset_reden[\"partei\"] == \"DIE LINKE.\"]\n",
    "social_media_usage_linke = subset_posts_linke.groupby('date').size()\n",
    "subset_reden_linke[\"date\"] = pd.to_datetime(subset_reden_linke[\"date\"])\n",
    "subset_posts_linke[\"date\"] = pd.to_datetime(subset_posts_linke[\"date\"])\n",
    "reden_komplexit√§t_t√§glich_linke = subset_reden_linke.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_linke = subset_posts_linke.groupby('date')['komplexit√§t'].sum()\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_linke = subset_reden_linke.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_linke = subset_posts_linke.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_linke = redethemen_t√§glich_linke.index.intersection(postthemen_t√§glich_linke.index)\n",
    "redethemen_t√§glich_aligned_linke = redethemen_t√§glich_linke.loc[common_dates_linke]\n",
    "postthemen_t√§glich_aligned_linke = postthemen_t√§glich_linke.loc[common_dates_linke]\n",
    "rede_common_linke, post_common_linke = filter_common_topics(redethemen_t√§glich_aligned_linke, postthemen_t√§glich_aligned_linke)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_linke =  rede_common_linke.div(rede_common_linke.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_linke = post_common_linke.div(post_common_linke.sum(axis=1), axis=0)\n",
    "reden_relativ_linke_red = remove_near_constant(reden_relativ_linke)\n",
    "post_relativ_linke_red = remove_near_constant(post_relativ_linke)\n",
    "rede_reduced_linke, post_reduced_linke = filter_common_topics(reden_relativ_linke_red, post_relativ_linke_red)\n",
    "rede_komplex_linke = reden_komplexit√§t_t√§glich_linke.loc[common_dates_linke]\n",
    "posts_komplex_linke = posts_komplexit√§t_t√§glich_linke.loc[common_dates_linke]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608104\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  295\n",
      "Model:                          Logit   Df Residuals:                      286\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.03229\n",
      "Time:                        11:17:18   Log-Likelihood:                -179.39\n",
      "converged:                       True   LL-Null:                       -185.38\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1525\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4501      0.392     -1.148      0.251      -1.219       0.319\n",
      "issue attention Facebook      0.0563      0.585      0.096      0.923      -1.090       1.203\n",
      "issue attention Bundestag    -2.1475      1.053     -2.039      0.041      -4.212      -0.083\n",
      "Social Media Nutzung          0.1148      0.113      1.016      0.310      -0.107       0.336\n",
      "Landtagswahlen                0.1167      0.236      0.494      0.621      -0.346       0.580\n",
      "topic_1                      -0.3385      0.384     -0.882      0.378      -1.091       0.414\n",
      "topic_2                      -0.6198      0.396     -1.564      0.118      -1.397       0.157\n",
      "topic_6                      -0.5805      0.393     -1.479      0.139      -1.350       0.189\n",
      "topic_8                      -0.9244      0.410     -2.253      0.024      -1.729      -0.120\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6239473684210526\n",
      "Pr√§zision: 0.5555555555555556\n",
      "Recall: 0.05263157894736842\n",
      "F1-Score: 0.09615384615384616\n",
      "Brier-Score: 0.20933688466662081\n",
      "Confusion-Matrix:\n",
      "[[196   4]\n",
      " [ 90   5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x22408925880>,\n",
       " 0.6239473684210526,\n",
       " 0.09615384615384616)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_FE_control(rede_reduced_linke,post_reduced_linke,rede_common_linke,1,social_media_usage_linke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608104\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  295\n",
      "Model:                          Logit   Df Residuals:                      286\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.03229\n",
      "Time:                        11:17:18   Log-Likelihood:                -179.39\n",
      "converged:                       True   LL-Null:                       -185.38\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1525\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4501      0.392     -1.148      0.251      -1.219       0.319\n",
      "issue attention Facebook      0.0563      0.585      0.096      0.923      -1.090       1.203\n",
      "issue attention Bundestag    -2.1475      1.053     -2.039      0.041      -4.212      -0.083\n",
      "Social Media Nutzung          0.1148      0.113      1.016      0.310      -0.107       0.336\n",
      "Landtagswahlen                0.1167      0.236      0.494      0.621      -0.346       0.580\n",
      "topic_1                      -0.3385      0.384     -0.882      0.378      -1.091       0.414\n",
      "topic_2                      -0.6198      0.396     -1.564      0.118      -1.397       0.157\n",
      "topic_6                      -0.5805      0.393     -1.479      0.139      -1.350       0.189\n",
      "topic_8                      -0.9244      0.410     -2.253      0.024      -1.729      -0.120\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6239473684210526\n",
      "Pr√§zision: 0.5555555555555556\n",
      "Recall: 0.05263157894736842\n",
      "F1-Score: 0.09615384615384616\n",
      "Brier-Score: 0.20933688466662081\n",
      "Confusion-Matrix:\n",
      "[[196   4]\n",
      " [ 90   5]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.609307\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  290\n",
      "Model:                          Logit   Df Residuals:                      281\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.02475\n",
      "Time:                        11:17:18   Log-Likelihood:                -176.70\n",
      "converged:                       True   LL-Null:                       -181.18\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3448\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4120      0.393     -1.049      0.294      -1.182       0.358\n",
      "issue attention Facebook      0.2795      0.545      0.513      0.608      -0.789       1.348\n",
      "issue attention Bundestag     1.3536      0.774      1.750      0.080      -0.162       2.870\n",
      "Social Media Nutzung         -0.0400      0.113     -0.354      0.724      -0.262       0.182\n",
      "Landtagswahlen                0.0563      0.261      0.216      0.829      -0.455       0.568\n",
      "topic_1                      -0.2587      0.386     -0.670      0.503      -1.015       0.498\n",
      "topic_2                      -0.4710      0.395     -1.193      0.233      -1.245       0.303\n",
      "topic_6                      -0.5063      0.396     -1.280      0.201      -1.282       0.269\n",
      "topic_8                      -0.8764      0.416     -2.107      0.035      -1.692      -0.061\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6057037768994291\n",
      "Pr√§zision: 0.5\n",
      "Recall: 0.043478260869565216\n",
      "F1-Score: 0.08\n",
      "Brier-Score: 0.20994536534377195\n",
      "Confusion-Matrix:\n",
      "[[194   4]\n",
      " [ 88   4]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.616955\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  285\n",
      "Model:                          Logit   Df Residuals:                      276\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.02309\n",
      "Time:                        11:17:18   Log-Likelihood:                -175.83\n",
      "converged:                       True   LL-Null:                       -179.99\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.4035\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1745      0.394     -0.442      0.658      -0.947       0.598\n",
      "issue attention Facebook      0.1293      0.555      0.233      0.816      -0.959       1.218\n",
      "issue attention Bundestag     1.2997      0.777      1.672      0.095      -0.224       2.823\n",
      "Social Media Nutzung         -0.1085      0.114     -0.952      0.341      -0.332       0.115\n",
      "Landtagswahlen               -0.0163      0.295     -0.055      0.956      -0.594       0.561\n",
      "topic_1                      -0.2712      0.389     -0.698      0.485      -1.033       0.490\n",
      "topic_2                      -0.5508      0.399     -1.379      0.168      -1.333       0.232\n",
      "topic_6                      -0.4389      0.394     -1.113      0.266      -1.212       0.334\n",
      "topic_8                      -0.7983      0.412     -1.938      0.053      -1.606       0.009\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5910338261648745\n",
      "Pr√§zision: 0.7777777777777778\n",
      "Recall: 0.07526881720430108\n",
      "F1-Score: 0.13725490196078433\n",
      "Brier-Score: 0.2129343839271174\n",
      "Confusion-Matrix:\n",
      "[[190   2]\n",
      " [ 86   7]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.613708\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  280\n",
      "Model:                          Logit   Df Residuals:                      271\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        11:17:18   Log-Likelihood:                -171.84\n",
      "converged:                       True   LL-Null:                       -176.56\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3059\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1153      0.411      0.280      0.779      -0.691       0.922\n",
      "issue attention Facebook     -0.1309      0.599     -0.219      0.827      -1.304       1.042\n",
      "issue attention Bundestag    -1.7406      1.017     -1.712      0.087      -3.734       0.252\n",
      "Social Media Nutzung         -0.1293      0.120     -1.080      0.280      -0.364       0.105\n",
      "Landtagswahlen                0.0001      0.342      0.000      1.000      -0.670       0.670\n",
      "topic_1                      -0.2652      0.393     -0.675      0.500      -1.036       0.505\n",
      "topic_2                      -0.4967      0.404     -1.230      0.219      -1.288       0.294\n",
      "topic_6                      -0.4268      0.399     -1.070      0.285      -1.209       0.355\n",
      "topic_8                      -0.8858      0.423     -2.095      0.036      -1.714      -0.057\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5920983778126635\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.21307131289439435\n",
      "Confusion-Matrix:\n",
      "[[189   0]\n",
      " [ 91   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.627850\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  275\n",
      "Model:                          Logit   Df Residuals:                      266\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.01491\n",
      "Time:                        11:17:18   Log-Likelihood:                -172.66\n",
      "converged:                       True   LL-Null:                       -175.27\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7332\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3287      0.407     -0.808      0.419      -1.126       0.469\n",
      "issue attention Facebook      0.1943      0.574      0.339      0.735      -0.930       1.319\n",
      "issue attention Bundestag    -1.2299      0.973     -1.264      0.206      -3.137       0.677\n",
      "Social Media Nutzung          0.0336      0.115      0.293      0.770      -0.192       0.259\n",
      "Landtagswahlen                0.0567      0.336      0.169      0.866      -0.601       0.714\n",
      "topic_1                      -0.3292      0.396     -0.832      0.406      -1.105       0.447\n",
      "topic_2                      -0.4333      0.400     -1.083      0.279      -1.218       0.351\n",
      "topic_6                      -0.4125      0.399     -1.034      0.301      -1.194       0.369\n",
      "topic_8                      -0.7596      0.416     -1.827      0.068      -1.575       0.055\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6003504395343312\n",
      "Pr√§zision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Brier-Score: 0.21801311025363104\n",
      "Confusion-Matrix:\n",
      "[[183   0]\n",
      " [ 92   0]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623877\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  270\n",
      "Model:                          Logit   Df Residuals:                      261\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.01584\n",
      "Time:                        11:17:18   Log-Likelihood:                -168.45\n",
      "converged:                       True   LL-Null:                       -171.16\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7118\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3449      0.412     -0.837      0.403      -1.153       0.463\n",
      "issue attention Facebook     -0.0663      0.595     -0.112      0.911      -1.232       1.099\n",
      "issue attention Bundestag     0.8065      0.824      0.978      0.328      -0.809       2.422\n",
      "Social Media Nutzung         -0.0135      0.117     -0.115      0.908      -0.242       0.216\n",
      "Landtagswahlen                0.0396      0.337      0.117      0.906      -0.620       0.700\n",
      "topic_1                      -0.2940      0.397     -0.740      0.459      -1.072       0.484\n",
      "topic_2                      -0.4540      0.406     -1.119      0.263      -1.249       0.341\n",
      "topic_6                      -0.4678      0.403     -1.161      0.246      -1.258       0.322\n",
      "topic_8                      -0.8465      0.422     -2.006      0.045      -1.673      -0.020\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.5857595133155379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√§zision: 0.5\n",
      "Recall: 0.02247191011235955\n",
      "F1-Score: 0.043010752688172046\n",
      "Brier-Score: 0.21658773651392627\n",
      "Confusion-Matrix:\n",
      "[[179   2]\n",
      " [ 87   2]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605682\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  265\n",
      "Model:                          Logit   Df Residuals:                      256\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Feb 2025   Pseudo R-squ.:                 0.04311\n",
      "Time:                        11:17:18   Log-Likelihood:                -160.51\n",
      "converged:                       True   LL-Null:                       -167.74\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.07048\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.5463      0.425     -1.284      0.199      -1.380       0.288\n",
      "issue attention Facebook      1.1355      0.614      1.850      0.064      -0.067       2.338\n",
      "issue attention Bundestag    -3.3451      1.296     -2.581      0.010      -5.885      -0.805\n",
      "Social Media Nutzung          0.1384      0.120      1.155      0.248      -0.097       0.373\n",
      "Landtagswahlen                0.2600      0.340      0.764      0.445      -0.407       0.927\n",
      "topic_1                      -0.3632      0.412     -0.882      0.378      -1.170       0.444\n",
      "topic_2                      -0.5683      0.419     -1.355      0.176      -1.391       0.254\n",
      "topic_6                      -0.5696      0.420     -1.357      0.175      -1.393       0.253\n",
      "topic_8                      -0.7343      0.429     -1.712      0.087      -1.575       0.106\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.6299883765982177\n",
      "Pr√§zision: 0.6666666666666666\n",
      "Recall: 0.11494252873563218\n",
      "F1-Score: 0.19607843137254902\n",
      "Brier-Score: 0.20944085446641977\n",
      "Confusion-Matrix:\n",
      "[[173   5]\n",
      " [ 77  10]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_linke, post_reduced_linke, rede_common_linke,lag, social_media_usage_linke)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - DIE LINKE\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_linke_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 300 elements, new values have 295 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m):  \u001b[38;5;66;03m# F√ºr Lags 1 bis 7 \u001b[39;00m\n\u001b[0;32m      6\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m----> 7\u001b[0m     model, auc_roc, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mlog_reg_FE_control_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrede_reduced_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_reduced_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrede_common_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocial_media_usage_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrede_komplex_linke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposts_komplex_linke\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[0;32m      9\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mappend((auc_roc, f1))\n",
      "Cell \u001b[1;32mIn[24], line 64\u001b[0m, in \u001b[0;36mlog_reg_FE_control_test\u001b[1;34m(relativ_rede, relativ_posts, post_to_shift, shifts, social_media_usage, complexity_rede, complexity_post)\u001b[0m\n\u001b[0;32m     62\u001b[0m complexity_post_stacked \u001b[38;5;241m=\u001b[39m complexity_post_z\u001b[38;5;241m.\u001b[39mreindex(relativ_posts\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     63\u001b[0m complexity_post_stacked \u001b[38;5;241m=\u001b[39m complexity_post_stacked\u001b[38;5;241m.\u001b[39mrepeat(relativ_posts\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 64\u001b[0m \u001b[43mcomplexity_post_stacked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m \u001b[38;5;241m=\u001b[39m relative_posts\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Zielvariable und unabh√§ngige Variablen zusammenf√ºhren\u001b[39;00m\n\u001b[0;32m     67\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue attention Facebook\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_posts,\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue attention Bundestag\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_reden,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKomplexit√§t Posts\u001b[39m\u001b[38;5;124m'\u001b[39m: complexity_post_stacked\n\u001b[0;32m     74\u001b[0m })\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 300 elements, new values have 295 elements"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7 \n",
    "    models.append(model)\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_linke, post_reduced_linke, rede_common_linke,lag, social_media_usage_linke, rede_komplex_linke, posts_komplex_linke)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - DIE LINKE\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_linke_complex_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 36, 37, 39, 40, 41, 43, 44, 45, 46, 52, 53, 54, 56, 58, 59, 60, 61, 63, 64, 65, 69, 70, 72, 74, 75, 77, 78, 79, 80, 83, 90, 92}\n",
      "Gemeinsame Topics: {0, 1, 2, 3, 4, 34, 6, 7, 8, 10, 43, 14, 15, 22, 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_25552\\1677610708.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_reden_fdp[\"date\"] = pd.to_datetime(subset_reden_fdp[\"date\"])\n",
      "C:\\Users\\pturl\\AppData\\Local\\Temp\\ipykernel_25552\\1677610708.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_posts_fdp[\"date\"] = pd.to_datetime(subset_posts_fdp[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "subset_posts_fdp = subset_posts[subset_posts[\"partei\"] == \"FDP\"]\n",
    "subset_reden_fdp = subset_reden[subset_reden[\"partei\"] == \"FDP\"]\n",
    "social_media_usage_fdp = subset_posts_fdp.groupby('date').size()\n",
    "subset_reden_fdp[\"date\"] = pd.to_datetime(subset_reden_fdp[\"date\"])\n",
    "subset_posts_fdp[\"date\"] = pd.to_datetime(subset_posts_fdp[\"date\"])\n",
    "reden_komplexit√§t_t√§glich_fdp = subset_reden_fdp.groupby('date')['komplexit√§t'].sum()\n",
    "posts_komplexit√§t_t√§glich_fdp = subset_posts_fdp.groupby('date')['komplexit√§t'].sum()\n",
    "# üîπ 2Ô∏è‚É£ Gruppiere die Themen t√§glich und z√§hle die H√§ufigkeit der Themen pro Tag\n",
    "redethemen_t√§glich_fdp = subset_reden_fdp.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "postthemen_t√§glich_fdp = subset_posts_fdp.groupby(['date', 'Topic']).size().unstack(fill_value=0)\n",
    "# F√ºhre einen inner join durch, damit nur gemeinsame Tage beibehalten werden\n",
    "common_dates_fdp = redethemen_t√§glich_fdp.index.intersection(postthemen_t√§glich_fdp.index)\n",
    "redethemen_t√§glich_aligned_fdp = redethemen_t√§glich_fdp.loc[common_dates_fdp]\n",
    "postthemen_t√§glich_aligned_fdp = postthemen_t√§glich_fdp.loc[common_dates_fdp]\n",
    "rede_common_fdp, post_common_fdp = filter_common_topics(redethemen_t√§glich_aligned_fdp, postthemen_t√§glich_aligned_fdp)\n",
    "# Berechnung der relativen Anteile jedes Themas an allen Themen des jeweiligen Tages\n",
    "reden_relativ_fdp =  rede_common_fdp.div(rede_common_fdp.sum(axis=1), axis=0)  # Zeilenweise Division durch Gesamtsumme\n",
    "post_relativ_fdp = post_common_fdp.div(post_common_fdp.sum(axis=1), axis=0)\n",
    "reden_relativ_fdp_red = remove_near_constant(reden_relativ_fdp)\n",
    "post_relativ_fdp_red = remove_near_constant(post_relativ_fdp)\n",
    "rede_reduced_fdp, post_reduced_fdp = filter_common_topics(reden_relativ_fdp_red, post_relativ_fdp_red)\n",
    "rede_komplex_fdp = reden_komplexit√§t_t√§glich_fdp.loc[common_dates_fdp]\n",
    "posts_komplex_fdp = posts_komplexit√§t_t√§glich_fdp.loc[common_dates_fdp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539776\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      956\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09409\n",
      "Time:                        18:16:25   Log-Likelihood:                -526.28\n",
      "converged:                       True   LL-Null:                       -580.94\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.217e-15\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1807      0.319     -0.566      0.572      -0.807       0.445\n",
      "issue attention Facebook      1.4806      0.883      1.677      0.094      -0.250       3.211\n",
      "issue attention Bundestag    -1.0101      0.876     -1.153      0.249      -2.727       0.707\n",
      "Social Media Nutzung         -0.0095      0.020     -0.469      0.639      -0.049       0.030\n",
      "Landtagswahlen                0.0950      0.147      0.645      0.519      -0.194       0.384\n",
      "topic_1                       0.0537      0.358      0.150      0.881      -0.648       0.756\n",
      "topic_2                       0.3547      0.354      1.001      0.317      -0.340       1.049\n",
      "topic_3                      -0.4767      0.367     -1.299      0.194      -1.196       0.242\n",
      "topic_4                      -1.5906      0.441     -3.611      0.000      -2.454      -0.727\n",
      "topic_6                      -0.6746      0.371     -1.817      0.069      -1.402       0.053\n",
      "topic_7                       0.0393      0.355      0.111      0.912      -0.657       0.735\n",
      "topic_8                      -0.9493      0.389     -2.441      0.015      -1.712      -0.187\n",
      "topic_10                      0.1460      0.354      0.413      0.680      -0.547       0.839\n",
      "topic_14                     -1.1461      0.401     -2.857      0.004      -1.932      -0.360\n",
      "topic_15                     -1.6369      0.440     -3.721      0.000      -2.499      -0.775\n",
      "topic_22                     -1.4670      0.428     -3.425      0.001      -2.306      -0.628\n",
      "topic_23                     -1.7666      0.455     -3.879      0.000      -2.659      -0.874\n",
      "topic_34                     -1.3817      0.417     -3.313      0.001      -2.199      -0.564\n",
      "topic_43                     -1.9108      0.474     -4.029      0.000      -2.840      -0.981\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7076517177748751\n",
      "Pr√§zision: 0.5869565217391305\n",
      "Recall: 0.1956521739130435\n",
      "F1-Score: 0.29347826086956524\n",
      "Brier-Score: 0.18025823869401933\n",
      "Confusion-Matrix:\n",
      "[[661  38]\n",
      " [222  54]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2232370e270>,\n",
       " 0.7076517177748751,\n",
       " 0.29347826086956524)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_FE_control(rede_reduced_fdp,post_reduced_fdp,rede_common_fdp,1,social_media_usage_fdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541180\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      957\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09173\n",
      "Time:                        18:33:51   Log-Likelihood:                -527.65\n",
      "converged:                       True   LL-Null:                       -580.94\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.294e-15\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0923      0.194     -0.476      0.634      -0.472       0.287\n",
      "issue attention Facebook     -0.3931        nan        nan        nan         nan         nan\n",
      "issue attention Bundestag    -0.3931        nan        nan        nan         nan         nan\n",
      "Social Media Nutzung         -0.0109      0.020     -0.541      0.588      -0.050       0.029\n",
      "Landtagswahlen                0.0964      0.147      0.657      0.511      -0.191       0.384\n",
      "topic_1                       0.1432      0.163      0.876      0.381      -0.177       0.463\n",
      "topic_2                       0.3277      0.287      1.143      0.253      -0.234       0.890\n",
      "topic_3                      -0.5356      0.301     -1.779      0.075      -1.126       0.054\n",
      "topic_4                      -1.6446      0.407     -4.045      0.000      -2.442      -0.848\n",
      "topic_6                      -0.6876      0.308     -2.231      0.026      -1.292      -0.084\n",
      "topic_7                      -0.0096      0.287     -0.033      0.973      -0.572       0.553\n",
      "topic_8                      -1.0082      0.328     -3.078      0.002      -1.650      -0.366\n",
      "topic_10                      0.1253      0.286      0.438      0.661      -0.435       0.686\n",
      "topic_14                     -1.1995      0.342     -3.502      0.000      -1.871      -0.528\n",
      "topic_15                     -1.6497      0.464     -3.558      0.000      -2.558      -0.741\n",
      "topic_22                     -1.5234      0.374     -4.075      0.000      -2.256      -0.791\n",
      "topic_23                     -1.7852      0.401     -4.447      0.000      -2.572      -0.998\n",
      "topic_34                     -1.4087      0.093    -15.113      0.000      -1.591      -1.226\n",
      "topic_43                     -1.9360      0.378     -5.117      0.000      -2.678      -1.195\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7059463830316601\n",
      "Pr√§zision: 0.5714285714285714\n",
      "Recall: 0.14492753623188406\n",
      "F1-Score: 0.23121387283236994\n",
      "Brier-Score: 0.18086354923072848\n",
      "Confusion-Matrix:\n",
      "[[669  30]\n",
      " [236  40]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538952\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  960\n",
      "Model:                          Logit   Df Residuals:                      942\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09287\n",
      "Time:                        18:33:52   Log-Likelihood:                -517.39\n",
      "converged:                       True   LL-Null:                       -570.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.963e-15\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.1099      0.397     -0.277      0.782      -0.888       0.668\n",
      "issue attention Facebook      0.4406   1.68e+17   2.62e-18      1.000    -3.3e+17     3.3e+17\n",
      "issue attention Bundestag     0.4406   1.68e+17   2.62e-18      1.000    -3.3e+17     3.3e+17\n",
      "Social Media Nutzung         -0.0212      0.021     -1.001      0.317      -0.063       0.020\n",
      "Landtagswahlen                0.0206      0.156      0.132      0.895      -0.285       0.326\n",
      "topic_1                       0.1044      0.329      0.317      0.751      -0.541       0.749\n",
      "topic_2                       0.3039      0.328      0.927      0.354      -0.338       0.946\n",
      "topic_3                      -0.5262      0.342     -1.538      0.124      -1.197       0.144\n",
      "topic_4                      -1.6620      0.433     -3.838      0.000      -2.511      -0.813\n",
      "topic_6                      -0.5908      0.345     -1.712      0.087      -1.267       0.086\n",
      "topic_7                       0.0747      0.328      0.228      0.820      -0.567       0.717\n",
      "topic_8                      -0.9132      0.362     -2.519      0.012      -1.624      -0.203\n",
      "topic_10                      0.1880      0.327      0.575      0.565      -0.453       0.829\n",
      "topic_14                     -1.0847      0.376     -2.888      0.004      -1.821      -0.348\n",
      "topic_15                     -1.5187      0.418     -3.637      0.000      -2.337      -0.700\n",
      "topic_22                     -1.3987      0.404     -3.461      0.001      -2.191      -0.607\n",
      "topic_23                     -1.6557         -0        inf      0.000      -1.656      -1.656\n",
      "topic_34                     -1.4003      0.404     -3.465      0.001      -2.192      -0.608\n",
      "topic_43                     -1.8065      0.453     -3.986      0.000      -2.695      -0.918\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7033011272141707\n",
      "Pr√§zision: 0.4625\n",
      "Recall: 0.13703703703703704\n",
      "F1-Score: 0.21142857142857144\n",
      "Brier-Score: 0.1801647835946852\n",
      "Confusion-Matrix:\n",
      "[[647  43]\n",
      " [233  37]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.533852\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  945\n",
      "Model:                          Logit   Df Residuals:                      927\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09723\n",
      "Time:                        18:33:52   Log-Likelihood:                -504.49\n",
      "converged:                       True   LL-Null:                       -558.82\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.150e-15\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0226      0.284     -0.080      0.937      -0.580       0.535\n",
      "issue attention Facebook     -0.1449        nan        nan        nan         nan         nan\n",
      "issue attention Bundestag    -0.1449        nan        nan        nan         nan         nan\n",
      "Social Media Nutzung         -0.0244      0.021     -1.137      0.255      -0.067       0.018\n",
      "Landtagswahlen                0.2036      0.171      1.190      0.234      -0.132       0.539\n",
      "topic_1                       0.1347      0.333      0.405      0.685      -0.517       0.786\n",
      "topic_2                       0.2594      0.332      0.782      0.434      -0.391       0.909\n",
      "topic_3                      -0.5479      0.345     -1.587      0.112      -1.224       0.129\n",
      "topic_4                      -1.8721      0.455     -4.113      0.000      -2.764      -0.980\n",
      "topic_6                      -0.6253      0.348     -1.795      0.073      -1.308       0.057\n",
      "topic_7                      -0.0034      0.332     -0.010      0.992      -0.654       0.647\n",
      "topic_8                      -0.9497      0.365     -2.599      0.009      -1.666      -0.234\n",
      "topic_10                      0.1280      0.331      0.387      0.699      -0.521       0.777\n",
      "topic_14                     -1.1388      0.379     -3.007      0.003      -1.881      -0.397\n",
      "topic_15                     -1.7224      0.314     -5.494      0.000      -2.337      -1.108\n",
      "topic_22                     -1.5849      0.420     -3.776      0.000      -2.408      -0.762\n",
      "topic_23                     -1.7224      0.232     -7.439      0.000      -2.176      -1.269\n",
      "topic_34                     -1.5846      0.425     -3.732      0.000      -2.417      -0.752\n",
      "topic_43                     -1.8741      0.500     -3.752      0.000      -2.853      -0.895\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7104384331478653\n",
      "Pr√§zision: 0.4925373134328358\n",
      "Recall: 0.12547528517110265\n",
      "F1-Score: 0.2\n",
      "Brier-Score: 0.17809275252582765\n",
      "Confusion-Matrix:\n",
      "[[648  34]\n",
      " [230  33]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536551\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  930\n",
      "Model:                          Logit   Df Residuals:                      912\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09605\n",
      "Time:                        18:33:52   Log-Likelihood:                -498.99\n",
      "converged:                       True   LL-Null:                       -552.01\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.678e-15\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.0086      0.350     -0.025      0.980      -0.695       0.678\n",
      "issue attention Facebook     -0.0755        nan        nan        nan         nan         nan\n",
      "issue attention Bundestag    -0.0755        nan        nan        nan         nan         nan\n",
      "Social Media Nutzung         -0.0193      0.021     -0.897      0.370      -0.061       0.023\n",
      "Landtagswahlen                0.0308      0.201      0.153      0.878      -0.363       0.425\n",
      "topic_1                       0.0685      0.368      0.186      0.852      -0.653       0.790\n",
      "topic_2                       0.2600      0.367      0.708      0.479      -0.460       0.980\n",
      "topic_3                      -0.6254      0.383     -1.635      0.102      -1.375       0.124\n",
      "topic_4                      -1.8750      0.483     -3.886      0.000      -2.821      -0.929\n",
      "topic_6                      -0.6270      0.383     -1.637      0.102      -1.378       0.124\n",
      "topic_7                      -0.0018      0.368     -0.005      0.996      -0.723       0.720\n",
      "topic_8                      -0.9526      0.398     -2.391      0.017      -1.734      -0.172\n",
      "topic_10                      0.1297      0.367      0.353      0.724      -0.590       0.849\n",
      "topic_14                     -1.1402      0.411     -2.772      0.006      -1.946      -0.334\n",
      "topic_15                     -1.7242         -0        inf      0.000      -1.724      -1.724\n",
      "topic_22                     -1.5871      0.449     -3.531      0.000      -2.468      -0.706\n",
      "topic_23                     -1.7241      0.465     -3.711      0.000      -2.635      -0.814\n",
      "topic_34                     -1.5868      0.520     -3.053      0.002      -2.606      -0.568\n",
      "topic_43                     -1.8762      0.492     -3.812      0.000      -2.841      -0.912\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.707211541214943\n",
      "Pr√§zision: 0.5522388059701493\n",
      "Recall: 0.1417624521072797\n",
      "F1-Score: 0.22560975609756098\n",
      "Brier-Score: 0.17940048462655014\n",
      "Confusion-Matrix:\n",
      "[[639  30]\n",
      " [224  37]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532775\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  915\n",
      "Model:                          Logit   Df Residuals:                      897\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                  0.1012\n",
      "Time:                        18:33:52   Log-Likelihood:                -487.49\n",
      "converged:                       True   LL-Null:                       -542.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.345e-15\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3563          0       -inf      0.000      -0.356      -0.356\n",
      "issue attention Facebook     -0.5028   1.07e+17  -4.68e-18      1.000   -2.11e+17    2.11e+17\n",
      "issue attention Bundestag    -0.5028   1.07e+17  -4.68e-18      1.000   -2.11e+17    2.11e+17\n",
      "Social Media Nutzung          0.0207      0.021      0.983      0.326      -0.021       0.062\n",
      "Landtagswahlen               -0.0381      0.200     -0.190      0.849      -0.430       0.354\n",
      "topic_1                       0.0887      0.311      0.285      0.775      -0.521       0.698\n",
      "topic_2                       0.3351      0.309      1.086      0.278      -0.270       0.940\n",
      "topic_3                      -0.5796      0.324     -1.788      0.074      -1.215       0.056\n",
      "topic_4                      -1.8575      0.436     -4.259      0.000      -2.712      -1.003\n",
      "topic_6                      -0.5883      0.324     -1.816      0.069      -1.223       0.047\n",
      "topic_7                       0.0545      0.308      0.177      0.859      -0.549       0.658\n",
      "topic_8                      -0.9176      0.342     -2.683      0.007      -1.588      -0.247\n",
      "topic_10                      0.1980      0.308      0.644      0.520      -0.405       0.801\n",
      "topic_14                     -1.2204        nan        nan        nan         nan         nan\n",
      "topic_15                     -1.8640      0.436     -4.272      0.000      -2.719      -1.009\n",
      "topic_22                     -1.7078      0.465     -3.671      0.000      -2.620      -0.796\n",
      "topic_23                     -1.7136      0.386     -4.443      0.000      -2.470      -0.958\n",
      "topic_34                     -1.5697      0.407     -3.858      0.000      -2.367      -0.772\n",
      "topic_43                     -1.8634      0.444     -4.201      0.000      -2.733      -0.994\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7166279400606981\n",
      "Pr√§zision: 0.5176470588235295\n",
      "Recall: 0.171875\n",
      "F1-Score: 0.25806451612903225\n",
      "Brier-Score: 0.17782987467979025\n",
      "Confusion-Matrix:\n",
      "[[618  41]\n",
      " [212  44]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531344\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      882\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09908\n",
      "Time:                        18:33:52   Log-Likelihood:                -478.21\n",
      "converged:                       True   LL-Null:                       -530.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.669e-15\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.2470      0.206     -1.196      0.232      -0.652       0.158\n",
      "issue attention Facebook     -0.0076        nan        nan        nan         nan         nan\n",
      "issue attention Bundestag    -0.0076        nan        nan        nan         nan         nan\n",
      "Social Media Nutzung         -0.0024      0.022     -0.109      0.913      -0.045       0.040\n",
      "Landtagswahlen                0.0090      0.203      0.044      0.965      -0.389       0.407\n",
      "topic_1                       0.1350      0.298      0.453      0.651      -0.450       0.720\n",
      "topic_2                       0.3350      0.296      1.131      0.258      -0.246       0.916\n",
      "topic_3                      -0.5793      0.315     -1.836      0.066      -1.198       0.039\n",
      "topic_4                      -1.9296      0.434     -4.442      0.000      -2.781      -1.078\n",
      "topic_6                      -0.5794      0.315     -1.839      0.066      -1.197       0.038\n",
      "topic_7                       0.1345      0.295      0.456      0.649      -0.444       0.713\n",
      "topic_8                      -0.9217      0.336     -2.741      0.006      -1.581      -0.263\n",
      "topic_10                      0.2016      0.296      0.682      0.496      -0.378       0.781\n",
      "topic_14                     -1.1187      0.207     -5.409      0.000      -1.524      -0.713\n",
      "topic_15                     -1.7569      0.349     -5.033      0.000      -2.441      -1.073\n",
      "topic_22                     -1.6043      0.405     -3.959      0.000      -2.399      -0.810\n",
      "topic_23                     -1.6043      0.350     -4.589      0.000      -2.290      -0.919\n",
      "topic_34                     -1.4670      0.383     -3.826      0.000      -2.219      -0.716\n",
      "topic_43                     -1.7569      0.397     -4.429      0.000      -2.534      -0.979\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.709951942948445\n",
      "Pr√§zision: 0.5166666666666667\n",
      "Recall: 0.12449799196787148\n",
      "F1-Score: 0.20064724919093851\n",
      "Brier-Score: 0.177099499473851\n",
      "Confusion-Matrix:\n",
      "[[622  29]\n",
      " [218  31]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.531192\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  885\n",
      "Model:                          Logit   Df Residuals:                      867\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                  0.1012\n",
      "Time:                        18:33:52   Log-Likelihood:                -470.11\n",
      "converged:                       True   LL-Null:                       -523.05\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.095e-15\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.4383      0.333     -1.318      0.188      -1.090       0.213\n",
      "issue attention Facebook     -0.6609        nan        nan        nan         nan         nan\n",
      "issue attention Bundestag    -0.6609        nan        nan        nan         nan         nan\n",
      "Social Media Nutzung          0.0234      0.021      1.093      0.274      -0.019       0.065\n",
      "Landtagswahlen               -0.0342      0.202     -0.169      0.866      -0.431       0.362\n",
      "topic_1                       0.2314      0.373      0.621      0.535      -0.499       0.961\n",
      "topic_2                       0.4178      0.372      1.123      0.261      -0.311       1.147\n",
      "topic_3                      -0.5359      0.388     -1.382      0.167      -1.296       0.224\n",
      "topic_4                      -1.9293      0.507     -3.803      0.000      -2.923      -0.935\n",
      "topic_6                      -0.6289      0.391     -1.607      0.108      -1.396       0.138\n",
      "topic_7                       0.1898      0.372      0.511      0.610      -0.539       0.918\n",
      "topic_8                      -0.8975      0.406     -2.213      0.027      -1.693      -0.103\n",
      "topic_10                      0.2080      0.372      0.560      0.576      -0.520       0.936\n",
      "topic_14                     -1.1154      0.420     -2.657      0.008      -1.938      -0.293\n",
      "topic_15                     -1.7643      0.484     -3.645      0.000      -2.713      -0.816\n",
      "topic_22                     -1.6060      0.465     -3.452      0.001      -2.518      -0.694\n",
      "topic_23                     -1.6139      0.466     -3.465      0.001      -2.527      -0.701\n",
      "topic_34                     -1.4668      0.450     -3.256      0.001      -2.350      -0.584\n",
      "topic_43                     -1.7634      0.484     -3.644      0.000      -2.712      -0.815\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.718258966627225\n",
      "Pr√§zision: 0.5161290322580645\n",
      "Recall: 0.1951219512195122\n",
      "F1-Score: 0.2831858407079646\n",
      "Brier-Score: 0.17716590954862735\n",
      "Confusion-Matrix:\n",
      "[[594  45]\n",
      " [198  48]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control(rede_reduced_fdp, rede_reduced_fdp, rede_common_fdp,lag, social_media_usage_fdp)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - FDP\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_fdp_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534749\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  975\n",
      "Model:                          Logit   Df Residuals:                      954\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                  0.1025\n",
      "Time:                        18:33:58   Log-Likelihood:                -521.38\n",
      "converged:                       True   LL-Null:                       -580.94\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.149e-16\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.9291      0.473     -1.963      0.050      -1.857      -0.001\n",
      "issue attention Facebook      1.6040      0.887      1.808      0.071      -0.134       3.342\n",
      "issue attention Bundestag    -0.9213      0.880     -1.047      0.295      -2.646       0.803\n",
      "Social Media Nutzung          0.0644      0.040      1.615      0.106      -0.014       0.143\n",
      "Landtagswahlen                0.1502      0.151      0.995      0.320      -0.146       0.446\n",
      "Komplexit√§t Reden            -0.1766      0.081     -2.194      0.028      -0.334      -0.019\n",
      "Komplexit√§t Posts            -0.3950      0.171     -2.307      0.021      -0.731      -0.059\n",
      "topic_1                       0.0445      0.361      0.123      0.902      -0.663       0.752\n",
      "topic_2                       0.3596      0.357      1.007      0.314      -0.340       1.060\n",
      "topic_3                      -0.4770      0.370     -1.291      0.197      -1.201       0.247\n",
      "topic_4                      -1.5958      0.443     -3.605      0.000      -2.464      -0.728\n",
      "topic_6                      -0.6795      0.374     -1.817      0.069      -1.413       0.054\n",
      "topic_7                       0.0452      0.358      0.126      0.900      -0.656       0.746\n",
      "topic_8                      -0.9546      0.392     -2.438      0.015      -1.722      -0.187\n",
      "topic_10                      0.1495      0.356      0.420      0.674      -0.548       0.847\n",
      "topic_14                     -1.1525      0.404     -2.855      0.004      -1.944      -0.361\n",
      "topic_15                     -1.6493      0.442     -3.728      0.000      -2.517      -0.782\n",
      "topic_22                     -1.4716      0.431     -3.417      0.001      -2.316      -0.628\n",
      "topic_23                     -1.7790      0.458     -3.886      0.000      -2.676      -0.882\n",
      "topic_34                     -1.3941      0.420     -3.321      0.001      -2.217      -0.571\n",
      "topic_43                     -1.9203      0.476     -4.031      0.000      -2.854      -0.987\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7168314984138832\n",
      "Pr√§zision: 0.576271186440678\n",
      "Recall: 0.2463768115942029\n",
      "F1-Score: 0.34517766497461927\n",
      "Brier-Score: 0.17838251691503612\n",
      "Confusion-Matrix:\n",
      "[[649  50]\n",
      " [208  68]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536560\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  960\n",
      "Model:                          Logit   Df Residuals:                      939\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09690\n",
      "Time:                        18:33:58   Log-Likelihood:                -515.10\n",
      "converged:                       True   LL-Null:                       -570.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.569e-14\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1289      0.479      0.269      0.788      -0.810       1.068\n",
      "issue attention Facebook      0.2001      0.922      0.217      0.828      -1.608       2.008\n",
      "issue attention Bundestag     0.9544      0.885      1.078      0.281      -0.781       2.690\n",
      "Social Media Nutzung         -0.0469      0.041     -1.131      0.258      -0.128       0.034\n",
      "Landtagswahlen               -0.0274      0.160     -0.171      0.864      -0.342       0.287\n",
      "Komplexit√§t Reden            -0.1619      0.080     -2.014      0.044      -0.319      -0.004\n",
      "Komplexit√§t Posts             0.0862      0.160      0.539      0.590      -0.227       0.400\n",
      "topic_1                       0.0914      0.362      0.253      0.800      -0.617       0.800\n",
      "topic_2                       0.3083      0.358      0.862      0.389      -0.393       1.009\n",
      "topic_3                      -0.5198      0.373     -1.393      0.163      -1.251       0.211\n",
      "topic_4                      -1.6593      0.458     -3.621      0.000      -2.557      -0.761\n",
      "topic_6                      -0.5893      0.374     -1.574      0.115      -1.323       0.144\n",
      "topic_7                       0.0836      0.359      0.233      0.816      -0.620       0.787\n",
      "topic_8                      -0.9079      0.392     -2.315      0.021      -1.676      -0.139\n",
      "topic_10                      0.1921      0.357      0.538      0.590      -0.507       0.892\n",
      "topic_14                     -1.0787      0.404     -2.669      0.008      -1.871      -0.286\n",
      "topic_15                     -1.5178      0.442     -3.430      0.001      -2.385      -0.651\n",
      "topic_22                     -1.3950      0.431     -3.235      0.001      -2.240      -0.550\n",
      "topic_23                     -1.6562      0.458     -3.620      0.000      -2.553      -0.759\n",
      "topic_34                     -1.4001      0.430     -3.257      0.001      -2.243      -0.558\n",
      "topic_43                     -1.8062      0.477     -3.790      0.000      -2.740      -0.872\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.71\n",
      "Pr√§zision: 0.52\n",
      "Recall: 0.1925925925925926\n",
      "F1-Score: 0.2810810810810811\n",
      "Brier-Score: 0.17894072233185288\n",
      "Confusion-Matrix:\n",
      "[[642  48]\n",
      " [218  52]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.524735\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  945\n",
      "Model:                          Logit   Df Residuals:                      924\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                  0.1126\n",
      "Time:                        18:33:58   Log-Likelihood:                -495.88\n",
      "converged:                       True   LL-Null:                       -558.82\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.285e-17\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.5394      0.510      1.058      0.290      -0.460       1.538\n",
      "issue attention Facebook      0.1756      0.935      0.188      0.851      -1.656       2.008\n",
      "issue attention Bundestag    -0.5178      0.925     -0.560      0.575      -2.330       1.295\n",
      "Social Media Nutzung         -0.0841      0.045     -1.853      0.064      -0.173       0.005\n",
      "Landtagswahlen                0.2081      0.183      1.137      0.256      -0.151       0.567\n",
      "Komplexit√§t Reden             0.3012      0.080      3.781      0.000       0.145       0.457\n",
      "Komplexit√§t Posts             0.3013      0.171      1.762      0.078      -0.034       0.636\n",
      "topic_1                       0.1325      0.367      0.361      0.718      -0.587       0.852\n",
      "topic_2                       0.2713      0.363      0.747      0.455      -0.440       0.983\n",
      "topic_3                      -0.5569      0.378     -1.474      0.140      -1.297       0.184\n",
      "topic_4                      -1.9098      0.481     -3.967      0.000      -2.854      -0.966\n",
      "topic_6                      -0.6432      0.379     -1.695      0.090      -1.387       0.100\n",
      "topic_7                      -0.0003      0.365     -0.001      0.999      -0.716       0.715\n",
      "topic_8                      -0.9686      0.397     -2.440      0.015      -1.747      -0.190\n",
      "topic_10                      0.1320      0.363      0.363      0.716      -0.580       0.844\n",
      "topic_14                     -1.1649      0.409     -2.846      0.004      -1.967      -0.363\n",
      "topic_15                     -1.7626      0.462     -3.816      0.000      -2.668      -0.857\n",
      "topic_22                     -1.6192      0.448     -3.613      0.000      -2.498      -0.741\n",
      "topic_23                     -1.7623      0.462     -3.813      0.000      -2.668      -0.856\n",
      "topic_34                     -1.6203      0.447     -3.624      0.000      -2.497      -0.744\n",
      "topic_43                     -1.9154      0.481     -3.983      0.000      -2.858      -0.973\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.726235741444867\n",
      "Pr√§zision: 0.6\n",
      "Recall: 0.2623574144486692\n",
      "F1-Score: 0.36507936507936506\n",
      "Brier-Score: 0.17374928918115196\n",
      "Confusion-Matrix:\n",
      "[[636  46]\n",
      " [194  69]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535776\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  930\n",
      "Model:                          Logit   Df Residuals:                      909\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                 0.09735\n",
      "Time:                        18:33:58   Log-Likelihood:                -498.27\n",
      "converged:                       True   LL-Null:                       -552.01\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.641e-14\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -0.3274      0.483     -0.679      0.497      -1.273       0.618\n",
      "issue attention Facebook     -0.5422      0.964     -0.563      0.574      -2.431       1.347\n",
      "issue attention Bundestag    -0.0640      0.917     -0.070      0.944      -1.860       1.732\n",
      "Social Media Nutzung          0.0160      0.041      0.385      0.700      -0.065       0.097\n",
      "Landtagswahlen                0.0844      0.208      0.405      0.685      -0.324       0.493\n",
      "Komplexit√§t Reden            -0.0170      0.080     -0.211      0.832      -0.174       0.140\n",
      "Komplexit√§t Posts            -0.1697      0.166     -1.019      0.308      -0.496       0.157\n",
      "topic_1                       0.0986      0.366      0.270      0.788      -0.618       0.815\n",
      "topic_2                       0.2494      0.361      0.690      0.490      -0.459       0.958\n",
      "topic_3                      -0.6482      0.378     -1.714      0.087      -1.390       0.093\n",
      "topic_4                      -1.8983      0.479     -3.963      0.000      -2.837      -0.959\n",
      "topic_6                      -0.6341      0.377     -1.682      0.093      -1.373       0.105\n",
      "topic_7                      -0.0198      0.363     -0.055      0.957      -0.732       0.692\n",
      "topic_8                      -0.9771      0.395     -2.476      0.013      -1.750      -0.204\n",
      "topic_10                      0.1215      0.361      0.336      0.737      -0.586       0.829\n",
      "topic_14                     -1.1615      0.407     -2.854      0.004      -1.959      -0.364\n",
      "topic_15                     -1.7328      0.460     -3.770      0.000      -2.634      -0.832\n",
      "topic_22                     -1.6107      0.446     -3.613      0.000      -2.485      -0.737\n",
      "topic_23                     -1.7357      0.460     -3.775      0.000      -2.637      -0.835\n",
      "topic_34                     -1.6001      0.444     -3.600      0.000      -2.471      -0.729\n",
      "topic_43                     -1.8908      0.479     -3.949      0.000      -2.829      -0.952\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.711601349300437\n",
      "Pr√§zision: 0.5316455696202531\n",
      "Recall: 0.16091954022988506\n",
      "F1-Score: 0.24705882352941178\n",
      "Brier-Score: 0.1792145933363979\n",
      "Confusion-Matrix:\n",
      "[[632  37]\n",
      " [219  42]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.521964\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  915\n",
      "Model:                          Logit   Df Residuals:                      894\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                  0.1194\n",
      "Time:                        18:33:58   Log-Likelihood:                -477.60\n",
      "converged:                       True   LL-Null:                       -542.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.771e-18\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1614      0.482      0.335      0.738      -0.783       1.106\n",
      "issue attention Facebook      0.0002      0.984      0.000      1.000      -1.929       1.929\n",
      "issue attention Bundestag    -0.8145      0.949     -0.859      0.391      -2.674       1.045\n",
      "Social Media Nutzung         -0.0336      0.041     -0.825      0.409      -0.114       0.046\n",
      "Landtagswahlen               -0.1369      0.210     -0.651      0.515      -0.549       0.275\n",
      "Komplexit√§t Reden            -0.3535      0.085     -4.158      0.000      -0.520      -0.187\n",
      "Komplexit√§t Posts             0.1778      0.166      1.073      0.283      -0.147       0.503\n",
      "topic_1                       0.0848      0.375      0.226      0.821      -0.650       0.820\n",
      "topic_2                       0.3444      0.370      0.930      0.353      -0.382       1.070\n",
      "topic_3                      -0.5930      0.387     -1.534      0.125      -1.351       0.165\n",
      "topic_4                      -1.8891      0.485     -3.891      0.000      -2.841      -0.938\n",
      "topic_6                      -0.6002      0.385     -1.559      0.119      -1.355       0.154\n",
      "topic_7                       0.0576      0.372      0.155      0.877      -0.672       0.787\n",
      "topic_8                      -0.9367      0.402     -2.327      0.020      -1.726      -0.148\n",
      "topic_10                      0.2038      0.370      0.551      0.582      -0.521       0.929\n",
      "topic_14                     -1.2441      0.422     -2.947      0.003      -2.072      -0.417\n",
      "topic_15                     -1.8980      0.485     -3.912      0.000      -2.849      -0.947\n",
      "topic_22                     -1.7353      0.467     -3.715      0.000      -2.651      -0.820\n",
      "topic_23                     -1.7428      0.467     -3.734      0.000      -2.657      -0.828\n",
      "topic_34                     -1.5980      0.451     -3.541      0.000      -2.482      -0.714\n",
      "topic_43                     -1.8939      0.485     -3.904      0.000      -2.845      -0.943\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7365148425644917\n",
      "Pr√§zision: 0.5939849624060151\n",
      "Recall: 0.30859375\n",
      "F1-Score: 0.40616966580976865\n",
      "Brier-Score: 0.17352198104699243\n",
      "Confusion-Matrix:\n",
      "[[605  54]\n",
      " [177  79]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.521304\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      879\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                  0.1161\n",
      "Time:                        18:33:58   Log-Likelihood:                -469.17\n",
      "converged:                       True   LL-Null:                       -530.80\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.103e-17\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         0.1175      0.502      0.234      0.815      -0.866       1.100\n",
      "issue attention Facebook     -0.6763      1.000     -0.677      0.499      -2.636       1.283\n",
      "issue attention Bundestag    -0.0920      0.941     -0.098      0.922      -1.936       1.752\n",
      "Social Media Nutzung         -0.0352      0.044     -0.805      0.421      -0.121       0.050\n",
      "Landtagswahlen               -0.0563      0.215     -0.262      0.793      -0.477       0.364\n",
      "Komplexit√§t Reden             0.3286      0.082      4.020      0.000       0.168       0.489\n",
      "Komplexit√§t Posts             0.2219      0.172      1.293      0.196      -0.115       0.558\n",
      "topic_1                       0.1769      0.377      0.470      0.639      -0.561       0.915\n",
      "topic_2                       0.3321      0.373      0.891      0.373      -0.399       1.063\n",
      "topic_3                      -0.6242      0.391     -1.595      0.111      -1.391       0.143\n",
      "topic_4                      -2.0025      0.511     -3.919      0.000      -3.004      -1.001\n",
      "topic_6                      -0.6073      0.390     -1.558      0.119      -1.372       0.157\n",
      "topic_7                       0.1122      0.374      0.300      0.764      -0.621       0.846\n",
      "topic_8                      -0.9795      0.410     -2.390      0.017      -1.783      -0.176\n",
      "topic_10                      0.1972      0.372      0.530      0.596      -0.533       0.927\n",
      "topic_14                     -1.1796      0.424     -2.783      0.005      -2.010      -0.349\n",
      "topic_15                     -1.8105      0.486     -3.723      0.000      -2.764      -0.857\n",
      "topic_22                     -1.6746      0.469     -3.568      0.000      -2.594      -0.755\n",
      "topic_23                     -1.6624      0.469     -3.546      0.000      -2.581      -0.744\n",
      "topic_34                     -1.5256      0.454     -3.363      0.001      -2.415      -0.636\n",
      "topic_43                     -1.8174      0.487     -3.733      0.000      -2.772      -0.863\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7314974182444062\n",
      "Pr√§zision: 0.5980392156862745\n",
      "Recall: 0.24497991967871485\n",
      "F1-Score: 0.3475783475783476\n",
      "Brier-Score: 0.1729777528467521\n",
      "Confusion-Matrix:\n",
      "[[610  41]\n",
      " [188  61]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.528141\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  885\n",
      "Model:                          Logit   Df Residuals:                      864\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Tue, 28 Jan 2025   Pseudo R-squ.:                  0.1064\n",
      "Time:                        18:33:58   Log-Likelihood:                -467.40\n",
      "converged:                       True   LL-Null:                       -523.05\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.138e-14\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -1.0962      0.482     -2.272      0.023      -2.042      -0.151\n",
      "issue attention Facebook      1.2709      0.941      1.351      0.177      -0.573       3.115\n",
      "issue attention Bundestag    -1.4390      0.971     -1.482      0.138      -3.343       0.465\n",
      "Social Media Nutzung          0.0829      0.041      2.029      0.042       0.003       0.163\n",
      "Landtagswahlen                0.0715      0.211      0.339      0.734      -0.342       0.485\n",
      "Komplexit√§t Reden            -0.0706      0.083     -0.846      0.397      -0.234       0.093\n",
      "Komplexit√§t Posts            -0.3007      0.170     -1.771      0.077      -0.633       0.032\n",
      "topic_1                       0.1670      0.378      0.442      0.658      -0.573       0.907\n",
      "topic_2                       0.4500      0.374      1.202      0.229      -0.284       1.184\n",
      "topic_3                      -0.4841      0.392     -1.236      0.216      -1.251       0.283\n",
      "topic_4                      -1.8830      0.510     -3.693      0.000      -2.882      -0.884\n",
      "topic_6                      -0.6141      0.393     -1.561      0.118      -1.385       0.157\n",
      "topic_7                       0.2389      0.375      0.637      0.524      -0.496       0.974\n",
      "topic_8                      -0.8435      0.410     -2.059      0.039      -1.646      -0.041\n",
      "topic_10                      0.2309      0.373      0.618      0.536      -0.501       0.962\n",
      "topic_14                     -1.0662      0.423     -2.520      0.012      -1.896      -0.237\n",
      "topic_15                     -1.7578      0.486     -3.620      0.000      -2.710      -0.806\n",
      "topic_22                     -1.5535      0.469     -3.315      0.001      -2.472      -0.635\n",
      "topic_23                     -1.5930      0.468     -3.406      0.001      -2.510      -0.676\n",
      "topic_34                     -1.4465      0.452     -3.198      0.001      -2.333      -0.560\n",
      "topic_43                     -1.7387      0.486     -3.579      0.000      -2.691      -0.787\n",
      "=============================================================================================\n",
      "AUC-ROC: 0.7220377368092928\n",
      "Pr√§zision: 0.5268817204301075\n",
      "Recall: 0.1991869918699187\n",
      "F1-Score: 0.2890855457227139\n",
      "Brier-Score: 0.17572697959065012\n",
      "Confusion-Matrix:\n",
      "[[595  44]\n",
      " [197  49]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "metrics = []\n",
    "\n",
    "# Schleife √ºber Lags\n",
    "for lag in range(1, 8):  # F√ºr Lags 1 bis 7\n",
    "    model, auc_roc, f1 = log_reg_FE_control_test(rede_reduced_spd, post_reduced_fdp, rede_common_fdp,lag, social_media_usage_fdp, rede_komplex_fdp, posts_komplex_fdp)\n",
    "    models.append(model)\n",
    "    metrics.append((auc_roc, f1))\n",
    "\n",
    "# Stargazer-Tabelle erstellen\n",
    "stargazer = Stargazer(models)\n",
    "stargazer.title(\"Vergleich mit Lags 1-7\")\n",
    "stargazer.custom_columns([f\"Lag {i}\" for i in range(1, 8)], [1] * 7)\n",
    "stargazer.significant_digits(3)\n",
    "stargazer.dependent_variable_name(\"Themenerw√§hnung auf Social Media - FDP\")\n",
    "\n",
    "# Dynamisch AUC-ROC und F1-Score hinzuf√ºgen\n",
    "custom_notes = [f\"Lag {i}: AUC-ROC = {metrics[i-1][0]:.3f}, F1-Score = {metrics[i-1][1]:.3f}\" for i in range(1, 8)]\n",
    "stargazer.add_custom_notes(custom_notes)\n",
    "\n",
    "# Exportieren\n",
    "with open(\"regression_table_comparison_fdp_complex_bundestag.html\", \"w\") as f:\n",
    "    f.write(stargazer.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\seaborn\\matrix.py:309: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "  ax.set(xlim=(0, self.data.shape[1]), ylim=(0, self.data.shape[0]))\n",
      "c:\\Users\\pturl\\anaconda3_new\\envs\\myenv\\Lib\\site-packages\\seaborn\\matrix.py:309: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  ax.set(xlim=(0, self.data.shape[1]), ylim=(0, self.data.shape[0]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### HTML-Tabellen visualisieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# üîπ 1Ô∏è‚É£ HTML-Regressionstabelle einlesen und in DataFrame umwandeln\n",
    "def parse_regression_table(html_file):\n",
    "    with open(html_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    rows = soup.find_all(\"tr\")\n",
    "    data = []\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) >= 4:  # Sicherstellen, dass alle relevanten Spalten vorhanden sind\n",
    "            try:\n",
    "                variable = cols[0].text.strip()\n",
    "                coefficient = float(cols[1].text.strip())\n",
    "                p_value = float(cols[2].text.strip())\n",
    "                lag = float(cols[3].text.strip())\n",
    "\n",
    "                # Speichere alle Werte, um sp√§ter Signifikanz zu filtern\n",
    "                data.append([variable, coefficient, p_value, lag])\n",
    "            except ValueError:\n",
    "                pass  # Ignoriert Zeilen, die keine numerischen Werte enthalten\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"Variable\", \"Koeffizient\", \"p-Wert\", \"lag\"])\n",
    "\n",
    "# üîπ 2Ô∏è‚É£ Datei einlesen und DataFrame erstellen\n",
    "html_file = \"regression tables/AfD/regression_table_comparison_afd_all_lags.html\"  # üìÇ Datei-Pfad anpassen\n",
    "df = parse_regression_table(html_file)\n",
    "\n",
    "# üîπ 3Ô∏è‚É£ Bereinigung der Daten: Topics und Lags extrahieren\n",
    "df[\"Topic\"] = df[\"Variable\"].apply(lambda x: x.split(\"_\")[1] if \"topic\" in x else None)\n",
    "df[\"Lag\"] = df[\"Variable\"].apply(lambda x: x.split(\"_\")[-1] if \"lag\" in x else None)\n",
    "df = df.dropna()  # Entferne nicht-Topic-Werte\n",
    "\n",
    "# üîπ 4Ô∏è‚É£ Filterung: Nur statistisch signifikante Werte (p < 0.05)\n",
    "df_significant = df[df[\"p-Wert\"] < 0.1]\n",
    "\n",
    "# üîπ 5Ô∏è‚É£ Umwandlung in eine Pivot-Tabelle f√ºr Heatmap\n",
    "heatmap_data = df_significant.pivot(index=\"Topic\", columns=\"Lag\", values=\"Koeffizient\")\n",
    "\n",
    "# üîπ 6Ô∏è‚É£ Heatmap zeichnen: Signifikante Korrelationen mit farblicher Markierung\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(heatmap_data.astype(float), annot=True, cmap=\"coolwarm\", center=0,\n",
    "            fmt=\".2f\", linewidths=0.5, cbar_kws={'label': 'Koeffizient'}, vmin=-1, vmax=1)\n",
    "\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"Topic\")\n",
    "plt.title(\"Heatmap der statistisch signifikanten Korrelationen √ºber Lags\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                                   0   \\\n",
       " 0                                                 NaN   \n",
       " 1                                                 NaN   \n",
       " 2                                                 NaN   \n",
       " 3                                                 NaN   \n",
       " 4                                                 NaN   \n",
       " 5                                                 NaN   \n",
       " 6                                  Komplexit√É¬§t Posts   \n",
       " 7                                                 NaN   \n",
       " 8                                  Komplexit√É¬§t Reden   \n",
       " 9                                                 NaN   \n",
       " 10                                     Landtagswahlen   \n",
       " 11                                                NaN   \n",
       " 12                               Social Media Nutzung   \n",
       " 13                                                NaN   \n",
       " 14                                              const   \n",
       " 15                                                NaN   \n",
       " 16                          issue attention Bundestag   \n",
       " 17                                                NaN   \n",
       " 18                           issue attention Facebook   \n",
       " 19                                                NaN   \n",
       " 20                                            topic_1   \n",
       " 21                                                NaN   \n",
       " 22                                           topic_10   \n",
       " 23                                                NaN   \n",
       " 24                                           topic_14   \n",
       " 25                                                NaN   \n",
       " 26                                           topic_15   \n",
       " 27                                                NaN   \n",
       " 28                                            topic_2   \n",
       " 29                                                NaN   \n",
       " 30                                           topic_29   \n",
       " 31                                                NaN   \n",
       " 32                                            topic_3   \n",
       " 33                                                NaN   \n",
       " 34                                            topic_4   \n",
       " 35                                                NaN   \n",
       " 36                                            topic_6   \n",
       " 37                                                NaN   \n",
       " 38                                            topic_7   \n",
       " 39                                                NaN   \n",
       " 40                                            topic_8   \n",
       " 41                                                NaN   \n",
       " 42                                       Observations   \n",
       " 43                                          Pseudo R2   \n",
       " 44                                                NaN   \n",
       " 45                                              Note:   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    1   \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                   Lag 1 - Bundestag   \n",
       " 4                                                 (1)   \n",
       " 5                                                 NaN   \n",
       " 6                                               0.124   \n",
       " 7                                             (0.138)   \n",
       " 8                                              -0.098   \n",
       " 9                                             (0.084)   \n",
       " 10                                             -0.016   \n",
       " 11                                            (0.152)   \n",
       " 12                                             -0.039   \n",
       " 13                                            (0.028)   \n",
       " 14                                              0.301   \n",
       " 15                                            (0.683)   \n",
       " 16                                             -0.969   \n",
       " 17                                            (0.721)   \n",
       " 18                                           4.031***   \n",
       " 19                                            (1.278)   \n",
       " 20                                             -0.052   \n",
       " 21                                            (0.364)   \n",
       " 22                                             -0.330   \n",
       " 23                                            (0.394)   \n",
       " 24                                             -0.643   \n",
       " 25                                            (0.410)   \n",
       " 26                                          -1.303***   \n",
       " 27                                            (0.458)   \n",
       " 28                                              0.366   \n",
       " 29                                            (0.366)   \n",
       " 30                                          -1.288***   \n",
       " 31                                            (0.458)   \n",
       " 32                                             -0.471   \n",
       " 33                                            (0.373)   \n",
       " 34                                             -0.474   \n",
       " 35                                            (0.370)   \n",
       " 36                                           -0.992**   \n",
       " 37                                            (0.424)   \n",
       " 38                                              0.352   \n",
       " 39                                            (0.369)   \n",
       " 40                                             -0.611   \n",
       " 41                                            (0.399)   \n",
       " 42                                                780   \n",
       " 43                                              0.071   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    2   \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                    Lag 1 - Facebook   \n",
       " 4                                                 (2)   \n",
       " 5                                                 NaN   \n",
       " 6                                              -0.060   \n",
       " 7                                             (0.154)   \n",
       " 8                                              -0.089   \n",
       " 9                                             (0.093)   \n",
       " 10                                             -0.248   \n",
       " 11                                            (0.172)   \n",
       " 12                                              0.007   \n",
       " 13                                            (0.030)   \n",
       " 14                                             1.301*   \n",
       " 15                                            (0.781)   \n",
       " 16                                             -0.112   \n",
       " 17                                            (0.785)   \n",
       " 18                                           4.755***   \n",
       " 19                                            (1.738)   \n",
       " 20                                            -0.856*   \n",
       " 21                                            (0.455)   \n",
       " 22                                          -3.391***   \n",
       " 23                                            (0.542)   \n",
       " 24                                          -3.245***   \n",
       " 25                                            (0.531)   \n",
       " 26                                          -2.924***   \n",
       " 27                                            (0.503)   \n",
       " 28                                          -1.540***   \n",
       " 29                                            (0.449)   \n",
       " 30                                          -3.258***   \n",
       " 31                                            (0.530)   \n",
       " 32                                              0.055   \n",
       " 33                                            (0.549)   \n",
       " 34                                              0.500   \n",
       " 35                                            (0.596)   \n",
       " 36                                          -2.219***   \n",
       " 37                                            (0.466)   \n",
       " 38                                          -1.815***   \n",
       " 39                                            (0.452)   \n",
       " 40                                          -2.159***   \n",
       " 41                                            (0.462)   \n",
       " 42                                                780   \n",
       " 43                                              0.295   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    3   \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                   Lag 2 - Bundestag   \n",
       " 4                                                 (3)   \n",
       " 5                                                 NaN   \n",
       " 6                                              -0.204   \n",
       " 7                                             (0.139)   \n",
       " 8                                              -0.093   \n",
       " 9                                             (0.083)   \n",
       " 10                                             -0.117   \n",
       " 11                                            (0.170)   \n",
       " 12                                              0.021   \n",
       " 13                                            (0.027)   \n",
       " 14                                             -0.978   \n",
       " 15                                            (0.672)   \n",
       " 16                                              0.378   \n",
       " 17                                            (0.711)   \n",
       " 18                                             2.211*   \n",
       " 19                                            (1.261)   \n",
       " 20                                             -0.085   \n",
       " 21                                            (0.366)   \n",
       " 22                                             -0.368   \n",
       " 23                                            (0.395)   \n",
       " 24                                            -0.687*   \n",
       " 25                                            (0.411)   \n",
       " 26                                          -1.321***   \n",
       " 27                                            (0.458)   \n",
       " 28                                              0.287   \n",
       " 29                                            (0.365)   \n",
       " 30                                          -1.317***   \n",
       " 31                                            (0.459)   \n",
       " 32                                             -0.329   \n",
       " 33                                            (0.374)   \n",
       " 34                                             -0.338   \n",
       " 35                                            (0.370)   \n",
       " 36                                           -0.993**   \n",
       " 37                                            (0.426)   \n",
       " 38                                              0.296   \n",
       " 39                                            (0.370)   \n",
       " 40                                             -0.644   \n",
       " 41                                            (0.400)   \n",
       " 42                                                768   \n",
       " 43                                              0.064   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    4   \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                    Lag 2 - Facebook   \n",
       " 4                                                 (4)   \n",
       " 5                                                 NaN   \n",
       " 6                                              -0.229   \n",
       " 7                                             (0.158)   \n",
       " 8                                              -0.110   \n",
       " 9                                             (0.094)   \n",
       " 10                                             -0.054   \n",
       " 11                                            (0.188)   \n",
       " 12                                              0.016   \n",
       " 13                                            (0.031)   \n",
       " 14                                              0.872   \n",
       " 15                                            (0.798)   \n",
       " 16                                              0.562   \n",
       " 17                                            (0.843)   \n",
       " 18                                           7.377***   \n",
       " 19                                            (1.936)   \n",
       " 20                                            -0.915*   \n",
       " 21                                            (0.474)   \n",
       " 22                                          -3.273***   \n",
       " 23                                            (0.556)   \n",
       " 24                                          -3.116***   \n",
       " 25                                            (0.545)   \n",
       " 26                                          -2.797***   \n",
       " 27                                            (0.518)   \n",
       " 28                                          -1.563***   \n",
       " 29                                            (0.471)   \n",
       " 30                                          -3.267***   \n",
       " 31                                            (0.556)   \n",
       " 32                                             -0.177   \n",
       " 33                                            (0.568)   \n",
       " 34                                              0.331   \n",
       " 35                                            (0.612)   \n",
       " 36                                          -2.091***   \n",
       " 37                                            (0.484)   \n",
       " 38                                          -1.779***   \n",
       " 39                                            (0.471)   \n",
       " 40                                          -2.138***   \n",
       " 41                                            (0.483)   \n",
       " 42                                                768   \n",
       " 43                                              0.310   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    5   \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                   Lag 3 - Bundestag   \n",
       " 4                                                 (5)   \n",
       " 5                                                 NaN   \n",
       " 6                                              0.239*   \n",
       " 7                                             (0.137)   \n",
       " 8                                               0.122   \n",
       " 9                                             (0.085)   \n",
       " 10                                             -0.096   \n",
       " 11                                            (0.195)   \n",
       " 12                                             -0.017   \n",
       " 13                                            (0.028)   \n",
       " 14                                             -0.145   \n",
       " 15                                            (0.694)   \n",
       " 16                                              1.034   \n",
       " 17                                            (0.719)   \n",
       " 18                                              1.430   \n",
       " 19                                            (1.274)   \n",
       " 20                                             -0.102   \n",
       " 21                                            (0.371)   \n",
       " 22                                             -0.426   \n",
       " 23                                            (0.402)   \n",
       " 24                                             -0.674   \n",
       " 25                                            (0.414)   \n",
       " 26                                          -1.299***   \n",
       " 27                                            (0.462)   \n",
       " 28                                              0.291   \n",
       " 29                                            (0.370)   \n",
       " 30                                          -1.297***   \n",
       " 31                                            (0.462)   \n",
       " 32                                             -0.199   \n",
       " 33                                            (0.377)   \n",
       " 34                                             -0.287   \n",
       " 35                                            (0.376)   \n",
       " 36                                           -0.973**   \n",
       " 37                                            (0.429)   \n",
       " 38                                              0.309   \n",
       " 39                                            (0.374)   \n",
       " 40                                             -0.627   \n",
       " 41                                            (0.404)   \n",
       " 42                                                756   \n",
       " 43                                              0.066   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    6   \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                    Lag 3 - Facebook   \n",
       " 4                                                 (6)   \n",
       " 5                                                 NaN   \n",
       " 6                                              -0.035   \n",
       " 7                                             (0.154)   \n",
       " 8                                              -0.006   \n",
       " 9                                             (0.096)   \n",
       " 10                                             -0.199   \n",
       " 11                                            (0.219)   \n",
       " 12                                              0.014   \n",
       " 13                                            (0.031)   \n",
       " 14                                              1.103   \n",
       " 15                                            (0.797)   \n",
       " 16                                              1.187   \n",
       " 17                                            (0.844)   \n",
       " 18                                            4.587**   \n",
       " 19                                            (1.810)   \n",
       " 20                                           -0.974**   \n",
       " 21                                            (0.472)   \n",
       " 22                                          -3.393***   \n",
       " 23                                            (0.557)   \n",
       " 24                                          -3.248***   \n",
       " 25                                            (0.545)   \n",
       " 26                                          -2.905***   \n",
       " 27                                            (0.518)   \n",
       " 28                                          -1.700***   \n",
       " 29                                            (0.469)   \n",
       " 30                                          -3.382***   \n",
       " 31                                            (0.556)   \n",
       " 32                                             -0.047   \n",
       " 33                                            (0.563)   \n",
       " 34                                              0.408   \n",
       " 35                                            (0.608)   \n",
       " 36                                          -2.193***   \n",
       " 37                                            (0.484)   \n",
       " 38                                          -1.872***   \n",
       " 39                                            (0.471)   \n",
       " 40                                          -2.239***   \n",
       " 41                                            (0.482)   \n",
       " 42                                                756   \n",
       " 43                                              0.295   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    7   \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                   Lag 4 - Bundestag   \n",
       " 4                                                 (7)   \n",
       " 5                                                 NaN   \n",
       " 6                                              -0.207   \n",
       " 7                                             (0.137)   \n",
       " 8                                             0.168**   \n",
       " 9                                             (0.085)   \n",
       " 10                                              0.105   \n",
       " 11                                            (0.217)   \n",
       " 12                                             -0.004   \n",
       " 13                                            (0.028)   \n",
       " 14                                             -0.263   \n",
       " 15                                            (0.688)   \n",
       " 16                                              0.260   \n",
       " 17                                            (0.734)   \n",
       " 18                                              0.432   \n",
       " 19                                            (1.272)   \n",
       " 20                                             -0.246   \n",
       " 21                                            (0.374)   \n",
       " 22                                             -0.583   \n",
       " 23                                            (0.403)   \n",
       " 24                                           -0.835**   \n",
       " 25                                            (0.415)   \n",
       " 26                                          -1.470***   \n",
       " 27                                            (0.462)   \n",
       " 28                                              0.276   \n",
       " 29                                            (0.370)   \n",
       " 30                                          -1.470***   \n",
       " 31                                            (0.463)   \n",
       " 32                                             -0.225   \n",
       " 33                                            (0.379)   \n",
       " 34                                             -0.280   \n",
       " 35                                            (0.377)   \n",
       " 36                                          -1.127***   \n",
       " 37                                            (0.430)   \n",
       " 38                                              0.231   \n",
       " 39                                            (0.375)   \n",
       " 40                                            -0.759*   \n",
       " 41                                            (0.405)   \n",
       " 42                                                744   \n",
       " 43                                              0.065   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    8   \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                    Lag 4 - Facebook   \n",
       " 4                                                 (8)   \n",
       " 5                                                 NaN   \n",
       " 6                                               0.021   \n",
       " 7                                             (0.149)   \n",
       " 8                                               0.023   \n",
       " 9                                             (0.095)   \n",
       " 10                                              0.038   \n",
       " 11                                            (0.238)   \n",
       " 12                                             -0.017   \n",
       " 13                                            (0.031)   \n",
       " 14                                           2.208***   \n",
       " 15                                            (0.797)   \n",
       " 16                                              0.636   \n",
       " 17                                            (0.830)   \n",
       " 18                                              0.203   \n",
       " 19                                            (1.635)   \n",
       " 20                                           -1.141**   \n",
       " 21                                            (0.471)   \n",
       " 22                                          -3.767***   \n",
       " 23                                            (0.559)   \n",
       " 24                                          -3.630***   \n",
       " 25                                            (0.547)   \n",
       " 26                                          -3.276***   \n",
       " 27                                            (0.520)   \n",
       " 28                                          -1.795***   \n",
       " 29                                            (0.465)   \n",
       " 30                                          -3.760***   \n",
       " 31                                            (0.559)   \n",
       " 32                                              0.153   \n",
       " 33                                            (0.562)   \n",
       " 34                                              0.540   \n",
       " 35                                            (0.606)   \n",
       " 36                                          -2.525***   \n",
       " 37                                            (0.486)   \n",
       " 38                                          -2.092***   \n",
       " 39                                            (0.472)   \n",
       " 40                                          -2.540***   \n",
       " 41                                            (0.484)   \n",
       " 42                                                744   \n",
       " 43                                              0.280   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    9   \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                   Lag 5 - Bundestag   \n",
       " 4                                                 (9)   \n",
       " 5                                                 NaN   \n",
       " 6                                               0.203   \n",
       " 7                                             (0.137)   \n",
       " 8                                           -0.322***   \n",
       " 9                                             (0.095)   \n",
       " 10                                             -0.210   \n",
       " 11                                            (0.220)   \n",
       " 12                                           -0.058**   \n",
       " 13                                            (0.028)   \n",
       " 14                                              0.897   \n",
       " 15                                            (0.688)   \n",
       " 16                                             -0.189   \n",
       " 17                                            (0.746)   \n",
       " 18                                              1.335   \n",
       " 19                                            (1.291)   \n",
       " 20                                             -0.237   \n",
       " 21                                            (0.381)   \n",
       " 22                                             -0.467   \n",
       " 23                                            (0.409)   \n",
       " 24                                            -0.817*   \n",
       " 25                                            (0.425)   \n",
       " 26                                          -1.517***   \n",
       " 27                                            (0.481)   \n",
       " 28                                              0.406   \n",
       " 29                                            (0.376)   \n",
       " 30                                          -1.374***   \n",
       " 31                                            (0.467)   \n",
       " 32                                             -0.308   \n",
       " 33                                            (0.388)   \n",
       " 34                                             -0.283   \n",
       " 35                                            (0.384)   \n",
       " 36                                           -1.031**   \n",
       " 37                                            (0.434)   \n",
       " 38                                              0.366   \n",
       " 39                                            (0.381)   \n",
       " 40                                             -0.652   \n",
       " 41                                            (0.410)   \n",
       " 42                                                732   \n",
       " 43                                              0.078   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    10  \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                    Lag 5 - Facebook   \n",
       " 4                                                (10)   \n",
       " 5                                                 NaN   \n",
       " 6                                               0.157   \n",
       " 7                                             (0.151)   \n",
       " 8                                           -0.278***   \n",
       " 9                                             (0.100)   \n",
       " 10                                             -0.104   \n",
       " 11                                            (0.241)   \n",
       " 12                                             -0.033   \n",
       " 13                                            (0.031)   \n",
       " 14                                           2.189***   \n",
       " 15                                            (0.798)   \n",
       " 16                                              1.157   \n",
       " 17                                            (0.875)   \n",
       " 18                                            3.817**   \n",
       " 19                                            (1.818)   \n",
       " 20                                           -1.029**   \n",
       " 21                                            (0.475)   \n",
       " 22                                          -3.424***   \n",
       " 23                                            (0.561)   \n",
       " 24                                          -3.285***   \n",
       " 25                                            (0.549)   \n",
       " 26                                          -2.934***   \n",
       " 27                                            (0.522)   \n",
       " 28                                          -1.627***   \n",
       " 29                                            (0.471)   \n",
       " 30                                          -3.422***   \n",
       " 31                                            (0.560)   \n",
       " 32                                             -0.021   \n",
       " 33                                            (0.568)   \n",
       " 34                                              0.439   \n",
       " 35                                            (0.612)   \n",
       " 36                                          -2.197***   \n",
       " 37                                            (0.488)   \n",
       " 38                                          -1.849***   \n",
       " 39                                            (0.475)   \n",
       " 40                                          -2.242***   \n",
       " 41                                            (0.486)   \n",
       " 42                                                732   \n",
       " 43                                              0.291   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    11  \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                   Lag 6 - Bundestag   \n",
       " 4                                                (11)   \n",
       " 5                                                 NaN   \n",
       " 6                                              -0.069   \n",
       " 7                                             (0.138)   \n",
       " 8                                             0.197**   \n",
       " 9                                             (0.086)   \n",
       " 10                                             -0.080   \n",
       " 11                                            (0.219)   \n",
       " 12                                              0.041   \n",
       " 13                                            (0.028)   \n",
       " 14                                           -1.508**   \n",
       " 15                                            (0.703)   \n",
       " 16                                              0.051   \n",
       " 17                                            (0.752)   \n",
       " 18                                            3.050**   \n",
       " 19                                            (1.328)   \n",
       " 20                                             -0.172   \n",
       " 21                                            (0.383)   \n",
       " 22                                             -0.278   \n",
       " 23                                            (0.411)   \n",
       " 24                                             -0.628   \n",
       " 25                                            (0.427)   \n",
       " 26                                          -1.331***   \n",
       " 27                                            (0.482)   \n",
       " 28                                              0.477   \n",
       " 29                                            (0.380)   \n",
       " 30                                           -1.189**   \n",
       " 31                                            (0.468)   \n",
       " 32                                             -0.511   \n",
       " 33                                            (0.396)   \n",
       " 34                                             -0.362   \n",
       " 35                                            (0.387)   \n",
       " 36                                           -0.866**   \n",
       " 37                                            (0.436)   \n",
       " 38                                              0.492   \n",
       " 39                                            (0.384)   \n",
       " 40                                             -0.499   \n",
       " 41                                            (0.411)   \n",
       " 42                                                720   \n",
       " 43                                              0.076   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    12  \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                    Lag 6 - Facebook   \n",
       " 4                                                (12)   \n",
       " 5                                                 NaN   \n",
       " 6                                              -0.016   \n",
       " 7                                             (0.154)   \n",
       " 8                                             0.196**   \n",
       " 9                                             (0.097)   \n",
       " 10                                             -0.011   \n",
       " 11                                            (0.241)   \n",
       " 12                                              0.015   \n",
       " 13                                            (0.031)   \n",
       " 14                                             1.530*   \n",
       " 15                                            (0.813)   \n",
       " 16                                              0.624   \n",
       " 17                                            (0.844)   \n",
       " 18                                              1.305   \n",
       " 19                                            (1.684)   \n",
       " 20                                          -1.275***   \n",
       " 21                                            (0.492)   \n",
       " 22                                          -3.771***   \n",
       " 23                                            (0.577)   \n",
       " 24                                          -3.634***   \n",
       " 25                                            (0.565)   \n",
       " 26                                          -3.389***   \n",
       " 27                                            (0.545)   \n",
       " 28                                          -1.873***   \n",
       " 29                                            (0.487)   \n",
       " 30                                          -3.768***   \n",
       " 31                                            (0.575)   \n",
       " 32                                             -0.078   \n",
       " 33                                            (0.582)   \n",
       " 34                                              0.336   \n",
       " 35                                            (0.624)   \n",
       " 36                                          -2.522***   \n",
       " 37                                            (0.505)   \n",
       " 38                                          -2.089***   \n",
       " 39                                            (0.493)   \n",
       " 40                                          -2.542***   \n",
       " 41                                            (0.503)   \n",
       " 42                                                720   \n",
       " 43                                              0.283   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    13  \\\n",
       " 0                                                 NaN   \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne   \n",
       " 2                                                 NaN   \n",
       " 3                                   Lag 7 - Bundestag   \n",
       " 4                                                (13)   \n",
       " 5                                                 NaN   \n",
       " 6                                              -0.042   \n",
       " 7                                             (0.138)   \n",
       " 8                                               0.026   \n",
       " 9                                             (0.087)   \n",
       " 10                                             -0.012   \n",
       " 11                                            (0.217)   \n",
       " 12                                             -0.003   \n",
       " 13                                            (0.028)   \n",
       " 14                                             -0.320   \n",
       " 15                                            (0.697)   \n",
       " 16                                              0.731   \n",
       " 17                                            (0.740)   \n",
       " 18                                              0.035   \n",
       " 19                                            (1.321)   \n",
       " 20                                             -0.182   \n",
       " 21                                            (0.381)   \n",
       " 22                                             -0.545   \n",
       " 23                                            (0.412)   \n",
       " 24                                            -0.809*   \n",
       " 25                                            (0.424)   \n",
       " 26                                          -1.484***   \n",
       " 27                                            (0.480)   \n",
       " 28                                              0.399   \n",
       " 29                                            (0.377)   \n",
       " 30                                          -1.348***   \n",
       " 31                                            (0.466)   \n",
       " 32                                             -0.198   \n",
       " 33                                            (0.392)   \n",
       " 34                                             -0.111   \n",
       " 35                                            (0.384)   \n",
       " 36                                           -1.114**   \n",
       " 37                                            (0.441)   \n",
       " 38                                              0.353   \n",
       " 39                                            (0.382)   \n",
       " 40                                             -0.646   \n",
       " 41                                            (0.409)   \n",
       " 42                                                708   \n",
       " 43                                              0.061   \n",
       " 44                                                NaN   \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01   \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...   \n",
       " \n",
       "                                                    14  \n",
       " 0                                                 NaN  \n",
       " 1         Dependent variable: Themenerw√É¬§hnung Gr√É¬ºne  \n",
       " 2                                                 NaN  \n",
       " 3                                    Lag 7 - Facebook  \n",
       " 4                                                (14)  \n",
       " 5                                                 NaN  \n",
       " 6                                              -0.141  \n",
       " 7                                             (0.153)  \n",
       " 8                                              -0.061  \n",
       " 9                                             (0.098)  \n",
       " 10                                              0.001  \n",
       " 11                                            (0.240)  \n",
       " 12                                              0.044  \n",
       " 13                                            (0.031)  \n",
       " 14                                              0.798  \n",
       " 15                                            (0.811)  \n",
       " 16                                            2.258**  \n",
       " 17                                            (0.911)  \n",
       " 18                                              0.536  \n",
       " 19                                            (1.737)  \n",
       " 20                                          -1.271***  \n",
       " 21                                            (0.493)  \n",
       " 22                                          -3.724***  \n",
       " 23                                            (0.579)  \n",
       " 24                                          -3.589***  \n",
       " 25                                            (0.566)  \n",
       " 26                                          -3.312***  \n",
       " 27                                            (0.546)  \n",
       " 28                                          -1.960***  \n",
       " 29                                            (0.493)  \n",
       " 30                                          -3.698***  \n",
       " 31                                            (0.576)  \n",
       " 32                                             -0.013  \n",
       " 33                                            (0.586)  \n",
       " 34                                              0.413  \n",
       " 35                                            (0.626)  \n",
       " 36                                          -2.534***  \n",
       " 37                                            (0.509)  \n",
       " 38                                          -2.097***  \n",
       " 39                                            (0.497)  \n",
       " 40                                          -2.512***  \n",
       " 41                                            (0.508)  \n",
       " 42                                                708  \n",
       " 43                                              0.282  \n",
       " 44                                                NaN  \n",
       " 45                        *p<0.1; **p<0.05; ***p<0.01  \n",
       " 46  Lag 1: Modell 1 (Bundestag) - AUC-ROC = 0.669,...  \n",
       " 47  Lag 2: Modell 1 (Bundestag) - AUC-ROC = 0.669,...  \n",
       " 48  Lag 3: Modell 1 (Bundestag) - AUC-ROC = 0.669,...  \n",
       " 49  Lag 4: Modell 1 (Bundestag) - AUC-ROC = 0.669,...  \n",
       " 50  Lag 5: Modell 1 (Bundestag) - AUC-ROC = 0.669,...  \n",
       " 51  Lag 6: Modell 1 (Bundestag) - AUC-ROC = 0.669,...  \n",
       " 52  Lag 7: Modell 1 (Bundestag) - AUC-ROC = 0.669,...  ]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_file = \"regression tables/AfD/regression_table_comparison_afd_all_lags.html\"  # üìÇ Datei-Pfad anpassen\n",
    "df = pd.read_html(html_file)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
